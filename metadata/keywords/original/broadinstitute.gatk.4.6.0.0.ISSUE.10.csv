id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/broadinstitute/gatk/pull/6641:105,Testability,test,tests,105,Fix https://github.com/broadinstitute/gatk/issues/5559. Adds companion cram/bam for most of the existing tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6641
https://github.com/broadinstitute/gatk/issues/6642:1003,Availability,error,error,1003,"Hello,; I'm trying to run SparkPileup from the most recent GATK 4.1.7 on a WES sample like this:. gatk PileupSpark --spark-runner SPARK --spark-master local[{threads}] --conf ""spark.driver.memory=22g"" -I $DATA/NA12878.proper.wes.md.bam -R $DATA/Homo_sapiens_assembly18.fasta -O /tmp/gatk4s_{threads}.pileup'. mwiewior@Mareks-MacBook-Pro ~ % spark-submit --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 2.4.5; /_/; ; Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_252; Branch HEAD. No matter how high I set the max file descriptors (even to 1M); mwiewior@Mareks-MacBook-Pro ~ % ulimit -a; -t: cpu time (seconds) unlimited; -f: file size (blocks) unlimited; -d: data seg size (kbytes) unlimited; -s: stack size (kbytes) 8192; -c: core file size (blocks) 0; -v: address space (kbytes) unlimited; -l: locked-in-memory size (kbytes) unlimited; -u: processes 2048; -n: file descriptors 1000000. I'm keep on getting the following error:. 20/06/06 14:56:35 ERROR Utils: Aborting task; org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file file:///private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta. Error was: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:159); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.engine.ReferenceF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6642:1029,Availability,ERROR,ERROR,1029,"up from the most recent GATK 4.1.7 on a WES sample like this:. gatk PileupSpark --spark-runner SPARK --spark-master local[{threads}] --conf ""spark.driver.memory=22g"" -I $DATA/NA12878.proper.wes.md.bam -R $DATA/Homo_sapiens_assembly18.fasta -O /tmp/gatk4s_{threads}.pileup'. mwiewior@Mareks-MacBook-Pro ~ % spark-submit --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 2.4.5; /_/; ; Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_252; Branch HEAD. No matter how high I set the max file descriptors (even to 1M); mwiewior@Mareks-MacBook-Pro ~ % ulimit -a; -t: cpu time (seconds) unlimited; -f: file size (blocks) unlimited; -d: data seg size (kbytes) unlimited; -s: stack size (kbytes) 8192; -c: core file size (blocks) 0; -v: address space (kbytes) unlimited; -l: locked-in-memory size (kbytes) unlimited; -u: processes 2048; -n: file descriptors 1000000. I'm keep on getting the following error:. 20/06/06 14:56:35 ERROR Utils: Aborting task; org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file file:///private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta. Error was: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:159); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.engine.ReferenceFileSource.<init>(ReferenceFileSourc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6642:1339,Availability,Error,Error,1339,"_/_/ /_/\_\ version 2.4.5; /_/; ; Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_252; Branch HEAD. No matter how high I set the max file descriptors (even to 1M); mwiewior@Mareks-MacBook-Pro ~ % ulimit -a; -t: cpu time (seconds) unlimited; -f: file size (blocks) unlimited; -d: data seg size (kbytes) unlimited; -s: stack size (kbytes) 8192; -c: core file size (blocks) 0; -v: address space (kbytes) unlimited; -l: locked-in-memory size (kbytes) unlimited; -u: processes 2048; -n: file descriptors 1000000. I'm keep on getting the following error:. 20/06/06 14:56:35 ERROR Utils: Aborting task; org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file file:///private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta. Error was: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:159); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.engine.ReferenceFileSource.<init>(ReferenceFileSource.java:35); at org.broadinstitute.hellbender.engine.spark.LocusWalkerSpark.lambda$getAlignmentsFunction$a99dbf6a$1(LocusWalkerSpark.java:113); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:125); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:125); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6642:3257,Energy Efficiency,schedul,scheduler,3257,5); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$1$1.apply(JavaRDDLike.scala:125); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:130); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.samtools.SAMException: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at htsjdk.samtools.reference.FastaSequenceIndex.<init>(FastaSequenceIndex.java:74); at htsjdk.samtools.reference.IndexedFastaSequenceFile.<init>(IndexedFastaSequenceFile.java:98); at htsjdk.samto,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6642:3328,Energy Efficiency,schedul,scheduler,3328,RDDLike.scala:125); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:130); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.samtools.SAMException: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at htsjdk.samtools.reference.FastaSequenceIndex.<init>(FastaSequenceIndex.java:74); at htsjdk.samtools.reference.IndexedFastaSequenceFile.<init>(IndexedFastaSequenceFile.java:98); at htsjdk.samtools.reference.ReferenceSequenceFileFactory.getReferenceSequenceFile(Ref,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6642:3609,Performance,concurren,concurrent,3609,:409); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:130); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.samtools.SAMException: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at htsjdk.samtools.reference.FastaSequenceIndex.<init>(FastaSequenceIndex.java:74); at htsjdk.samtools.reference.IndexedFastaSequenceFile.<init>(IndexedFastaSequenceFile.java:98); at htsjdk.samtools.reference.ReferenceSequenceFileFactory.getReferenceSequenceFile(ReferenceSequenceFileFactory.java:139); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:148); ... 24 more; Caused by: java.nio.file.FileSystemException: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6642:3693,Performance,concurren,concurrent,3693,pWriter.scala:130); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$4.apply(SparkHadoopWriter.scala:129); at org.apache.spark.util.Utils$.tryWithSafeFinallyAndFailureCallbacks(Utils.scala:1394); at org.apache.spark.internal.io.SparkHadoopWriter$.org$apache$spark$internal$io$SparkHadoopWriter$$executeTask(SparkHadoopWriter.scala:141); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:83); at org.apache.spark.internal.io.SparkHadoopWriter$$anonfun$3.apply(SparkHadoopWriter.scala:78); at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); at java.lang.Thread.run(Thread.java:748); Caused by: htsjdk.samtools.SAMException: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at htsjdk.samtools.reference.FastaSequenceIndex.<init>(FastaSequenceIndex.java:74); at htsjdk.samtools.reference.IndexedFastaSequenceFile.<init>(IndexedFastaSequenceFile.java:98); at htsjdk.samtools.reference.ReferenceSequenceFileFactory.getReferenceSequenceFile(ReferenceSequenceFileFactory.java:139); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:148); ... 24 more; Caused by: java.nio.file.FileSystemException: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6642:1042,Safety,Abort,Aborting,1042,"up from the most recent GATK 4.1.7 on a WES sample like this:. gatk PileupSpark --spark-runner SPARK --spark-master local[{threads}] --conf ""spark.driver.memory=22g"" -I $DATA/NA12878.proper.wes.md.bam -R $DATA/Homo_sapiens_assembly18.fasta -O /tmp/gatk4s_{threads}.pileup'. mwiewior@Mareks-MacBook-Pro ~ % spark-submit --version; Welcome to; ____ __; / __/__ ___ _____/ /__; _\ \/ _ \/ _ `/ __/ '_/; /___/ .__/\_,_/_/ /_/\_\ version 2.4.5; /_/; ; Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_252; Branch HEAD. No matter how high I set the max file descriptors (even to 1M); mwiewior@Mareks-MacBook-Pro ~ % ulimit -a; -t: cpu time (seconds) unlimited; -f: file size (blocks) unlimited; -d: data seg size (kbytes) unlimited; -s: stack size (kbytes) 8192; -c: core file size (blocks) 0; -v: address space (kbytes) unlimited; -l: locked-in-memory size (kbytes) unlimited; -u: processes 2048; -n: file descriptors 1000000. I'm keep on getting the following error:. 20/06/06 14:56:35 ERROR Utils: Aborting task; org.broadinstitute.hellbender.exceptions.UserException$CouldNotReadInputFile: Couldn't read file file:///private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta. Error was: Fasta index file could not be opened: /private/var/folders/5s/v5t08tmd42z_2m2c30vqf6kc0000gn/T/spark-556aa7a2-4d88-4bae-ad16-36d5af920fa9/userFiles-aeb68992-3215-4897-8f8a-040396296185/Homo_sapiens_assembly18.fasta.fai; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:159); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.engine.ReferenceFileSource.<init>(ReferenceFileSourc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6642
https://github.com/broadinstitute/gatk/issues/6644:558,Availability,error,error,558,"I run the GATK MarkDuplicates in Spark mode and it throws an; **NoClassDefFoundError: scala/Product$class**. The GATK version is **4.1.7** and; **4.0.0**,the environment is: **spark-3.0.0**, **scala-2.12.11**. **GATK commands:**. ```; gatk MarkDuplicatesSpark \; -I hdfs://master2:9000/Drosophila/output/Drosophila.sorted.bam \; -O hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup.bam \; -M; hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup_metrics.txt; \; -- \; --spark-runner SPARK --spark-master spark://master2:7077; ```; **error logs:**. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError:; scala/Product$class; at; org.bdgenomics.adam.serialization.InputStreamWithDecoder.<init>(ADAMKryoRegistrator.scala:35); at; org.bdgenomics.adam.serialization.AvroSerializer.<init>(ADAMKryoRegistrator.scala:45); at; org.bdgenomics.adam.models.VariantContextSerializer.<init>(VariantContext.scala:94); at; org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:179); at; org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:78); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8(KryoSerializer.scala:170); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8$adapted(KryoSerializer.scala:170); at scala.Option.foreach(Option.scala:407); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:170); at; scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at; org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:221); at; org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:161); at; org.apache.spark.serializer.KryoSerializer$$anon$1.create(KryoSerializer.scala:102); at; com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.borrow(KryoPoolQueueImpl.java:48); at; org.apache.spark.serializer.KryoSerializer$PoolWrapper.borrow(KryoSerializer.scala:109); at; org.apache.spark",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:4851,Deployability,deploy,deploy,4851,TKSparkTool.runPipeline(GATKSparkTool.java:387); at; org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.load,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:4933,Deployability,deploy,deploy,4933,.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassL,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:4969,Deployability,deploy,deploy,4969,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5042,Deployability,deploy,deploy,5042,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5117,Deployability,deploy,deploy,5117,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5187,Deployability,deploy,deploy,5187,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5259,Deployability,deploy,deploy,5259,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5340,Deployability,deploy,deploy,5340,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5410,Deployability,deploy,deploy,5410,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:1308,Energy Efficiency,adapt,adapted,1308,"hila.sorted.bam \; -O hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup.bam \; -M; hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup_metrics.txt; \; -- \; --spark-runner SPARK --spark-master spark://master2:7077; ```; **error logs:**. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError:; scala/Product$class; at; org.bdgenomics.adam.serialization.InputStreamWithDecoder.<init>(ADAMKryoRegistrator.scala:35); at; org.bdgenomics.adam.serialization.AvroSerializer.<init>(ADAMKryoRegistrator.scala:45); at; org.bdgenomics.adam.models.VariantContextSerializer.<init>(VariantContext.scala:94); at; org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:179); at; org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:78); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8(KryoSerializer.scala:170); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8$adapted(KryoSerializer.scala:170); at scala.Option.foreach(Option.scala:407); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:170); at; scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at; org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:221); at; org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:161); at; org.apache.spark.serializer.KryoSerializer$$anon$1.create(KryoSerializer.scala:102); at; com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.borrow(KryoPoolQueueImpl.java:48); at; org.apache.spark.serializer.KryoSerializer$PoolWrapper.borrow(KryoSerializer.scala:109); at; org.apache.spark.serializer.KryoSerializerInstance.borrowKryo(KryoSerializer.scala:336); at; org.apache.spark.serializer.KryoSerializationStream.<init>(KryoSerializer.scala:256); at; org.apache.spark.serializer.KryoSerializerInstance.serializeStream(KryoSerializer.scala:422); at; org.apache.spark.broadcast.TorrentBroadcast$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:1308,Modifiability,adapt,adapted,1308,"hila.sorted.bam \; -O hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup.bam \; -M; hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup_metrics.txt; \; -- \; --spark-runner SPARK --spark-master spark://master2:7077; ```; **error logs:**. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError:; scala/Product$class; at; org.bdgenomics.adam.serialization.InputStreamWithDecoder.<init>(ADAMKryoRegistrator.scala:35); at; org.bdgenomics.adam.serialization.AvroSerializer.<init>(ADAMKryoRegistrator.scala:45); at; org.bdgenomics.adam.models.VariantContextSerializer.<init>(VariantContext.scala:94); at; org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:179); at; org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:78); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8(KryoSerializer.scala:170); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8$adapted(KryoSerializer.scala:170); at scala.Option.foreach(Option.scala:407); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:170); at; scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at; org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:221); at; org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:161); at; org.apache.spark.serializer.KryoSerializer$$anon$1.create(KryoSerializer.scala:102); at; com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.borrow(KryoPoolQueueImpl.java:48); at; org.apache.spark.serializer.KryoSerializer$PoolWrapper.borrow(KryoSerializer.scala:109); at; org.apache.spark.serializer.KryoSerializerInstance.borrowKryo(KryoSerializer.scala:336); at; org.apache.spark.serializer.KryoSerializationStream.<init>(KryoSerializer.scala:256); at; org.apache.spark.serializer.KryoSerializerInstance.serializeStream(KryoSerializer.scala:422); at; org.apache.spark.broadcast.TorrentBroadcast$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5685,Performance,load,loadClass,5685,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5762,Performance,load,loadClass,5762,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5851,Performance,load,loadClass,5851,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:5921,Performance,load,loadClass,5921,ram.doWork(SparkCommandLineProgram.java:30; ); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:136); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.jav; a:179); at; org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:198); at; org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:152); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:195); at org.broadinstitute.hellbender.Main.main(Main.java:275); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at; sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at; sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at; org.apache.spark.deploy.JavaMainApplication.start(SparkApplication.scala:52); at; org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:928); at; org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180); at org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203); at org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90); at; org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1007); at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1016); at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala); Caused by: java.lang.ClassNotFoundException: scala.Product$class; at java.lang.ClassLoader.findClass(ClassLoader.java:523); at; org.apache.spark.util.ParentClassLoader.findClass(ParentClassLoader.java:35); at java.lang.ClassLoader.loadClass(ClassLoader.java:418); at; org.apache.spark.util.ParentClassLoader.loadClass(ParentClassLoader.java:40); at; org.apache.spark.util.ChildFirstURLClassLoader.loadClass(ChildFirstURLClassLoader.java:48); at java.lang.ClassLoader.loadClass(ClassLoader.java:351); ... 55 more; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6644:564,Testability,log,logs,564,"I run the GATK MarkDuplicates in Spark mode and it throws an; **NoClassDefFoundError: scala/Product$class**. The GATK version is **4.1.7** and; **4.0.0**,the environment is: **spark-3.0.0**, **scala-2.12.11**. **GATK commands:**. ```; gatk MarkDuplicatesSpark \; -I hdfs://master2:9000/Drosophila/output/Drosophila.sorted.bam \; -O hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup.bam \; -M; hdfs://master2:9000/Drosophila/output/Drosophila.sorted.markdup_metrics.txt; \; -- \; --spark-runner SPARK --spark-master spark://master2:7077; ```; **error logs:**. ```; Exception in thread ""main"" java.lang.NoClassDefFoundError:; scala/Product$class; at; org.bdgenomics.adam.serialization.InputStreamWithDecoder.<init>(ADAMKryoRegistrator.scala:35); at; org.bdgenomics.adam.serialization.AvroSerializer.<init>(ADAMKryoRegistrator.scala:45); at; org.bdgenomics.adam.models.VariantContextSerializer.<init>(VariantContext.scala:94); at; org.bdgenomics.adam.serialization.ADAMKryoRegistrator.registerClasses(ADAMKryoRegistrator.scala:179); at; org.broadinstitute.hellbender.engine.spark.GATKRegistrator.registerClasses(GATKRegistrator.java:78); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8(KryoSerializer.scala:170); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$8$adapted(KryoSerializer.scala:170); at scala.Option.foreach(Option.scala:407); at; org.apache.spark.serializer.KryoSerializer.$anonfun$newKryo$5(KryoSerializer.scala:170); at; scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23); at; org.apache.spark.util.Utils$.withContextClassLoader(Utils.scala:221); at; org.apache.spark.serializer.KryoSerializer.newKryo(KryoSerializer.scala:161); at; org.apache.spark.serializer.KryoSerializer$$anon$1.create(KryoSerializer.scala:102); at; com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.borrow(KryoPoolQueueImpl.java:48); at; org.apache.spark.serializer.KryoSerializer$PoolWrapper.borrow(KryoSerializer.scala:109); at; org.apache.spark",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6644
https://github.com/broadinstitute/gatk/issues/6645:141,Availability,reliab,reliable,141,A couple of places in the GATK doc rely on an external web service (http://latex.codecogs.com) to generate equation images. It would be more reliable to generate these statically and embed them in the doc bundle rather than dynamicaly generating them (see https://github.com/broadinstitute/gatk/issues/6599). Whatever process used would need to work for both javadoc and gatkdoc.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6645
https://github.com/broadinstitute/gatk/pull/6646:213,Deployability,release,release,213,"Currently, if a tool programmatically adds default read filters (i.e, Mutect2 for one), they don't show up in the gatkDoc as the default value for the `--readFilter` arg. This fixes that. Requires the new Barclay release.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6646
https://github.com/broadinstitute/gatk/pull/6647:19,Deployability,integrat,integration,19,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647
https://github.com/broadinstitute/gatk/pull/6647:19,Integrability,integrat,integration,19,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647
https://github.com/broadinstitute/gatk/pull/6647:31,Testability,test,test,31,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647
https://github.com/broadinstitute/gatk/pull/6647:374,Testability,test,test,374,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647
https://github.com/broadinstitute/gatk/pull/6647:409,Testability,Assert,Assert,409,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647
https://github.com/broadinstitute/gatk/pull/6647:502,Testability,test,test,502,"The tab completion integration test wasn't actually emitting any output because the classpath contained a list of class names (basenames only, without the "".class"" extension), so no work units were ever created. This PR:. - changes the classpath to use package names that contain CLPs instead of class names; - runs the javadoc in the current JVM (which makes debugging the test so much easier...); - adds an Assert to ensure the javadoc process succeeds. I made the latter change to the doc gen smoke test as well, to make debugging easier.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6647
https://github.com/broadinstitute/gatk/issues/6648:251,Deployability,update,updated,251,"@jamesemery This is related to #6617. We've been using GATK4 DepthOfCoverage, and noticed that since it inherits from LocusWalkerByInterval, -L is now required. To this point:. 1) the usage examples still say -L is optional, at minimum this should be updated. 2) It would be nice if it was not required. Perhaps if omitted, all intervals (inferred from genome) would be used?. 3) Alternately, perhaps there could be a shortcut way to pass ""all intervals in the genome"" to GATK in the -L argument? While one can convert a .dict file to intervals manually, it would be convenient if this were more seamless. Thanks",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6648
https://github.com/broadinstitute/gatk/issues/6648:104,Modifiability,inherit,inherits,104,"@jamesemery This is related to #6617. We've been using GATK4 DepthOfCoverage, and noticed that since it inherits from LocusWalkerByInterval, -L is now required. To this point:. 1) the usage examples still say -L is optional, at minimum this should be updated. 2) It would be nice if it was not required. Perhaps if omitted, all intervals (inferred from genome) would be used?. 3) Alternately, perhaps there could be a shortcut way to pass ""all intervals in the genome"" to GATK in the -L argument? While one can convert a .dict file to intervals manually, it would be convenient if this were more seamless. Thanks",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6648
https://github.com/broadinstitute/gatk/issues/6649:450,Availability,error,error,450,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1036,Availability,error,error,1036,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1481,Availability,failure,failures,1481,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:465,Safety,detect,detected,465,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:130,Testability,test,test,130,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:292,Testability,test,tests,292,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:315,Testability,test,tests,315,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:338,Testability,test,tests,338,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:361,Testability,test,tests,361,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:384,Testability,test,tests,384,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:407,Testability,test,tests,407,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:430,Testability,test,tests,430,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1147,Testability,log,log,1147,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1288,Testability,test,test,1288,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1363,Testability,test,testLikelihoodsFromHaplotypesForAvailableImplementations,1363,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1454,Testability,test,tests,1454,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1511,Testability,test,test,1511,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6649:1536,Testability,log,log,1536,"I hit this same segmentation violation issue on 4 separate branches on travis today (I believe in each case only the Java 11 unit test job failed - the rest of the matrix succeeded). It seems to be intermittent since, so far rerunning the job seems to make it go away. . ```; Finished 210000 tests; Finished 220000 tests; Finished 230000 tests; Finished 240000 tests; Finished 250000 tests; Finished 260000 tests; Finished 270000 tests; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007f2bcaefd0f2, pid=10075, tid=10100; #; # JRE version: OpenJDK Runtime Environment (11.0.2+9) (build 11.0.2+9); # Java VM: OpenJDK 64-Bit Server VM (11.0.2+9, mixed mode, tiered, compressed oops, g1 gc, linux-amd64); # Problematic frame:; # V [libjvm.so+0x8fd0f2] jni_GetByteArrayElements+0x72; #; # Core dump will be written. Default location: Core dumps may be processed with ""/usr/share/apport/apport %p %s %c %d %P %E"" (or dumping to /home/travis/build/broadinstitute/gatk/core.10075); #; # An error report file with more information is saved as:; # /home/travis/build/broadinstitute/gatk/hs_err_pid10075.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; #. Gradle suite > Gradle test > org.broadinstitute.hellbender.utils.pairhmm.VectorPairHMMUnitTest > testLikelihoodsFromHaplotypesForAvailableImplementations SKIPPED; Results: SUCCESS (276386 tests, 276385 successes, 0 failures, 1 skipped). > Task :test FAILED; ```. Entire log is attached. ; [java11segv.txt](https://github.com/broadinstitute/gatk/files/4747769/java11segv.txt)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6649
https://github.com/broadinstitute/gatk/issues/6650:402,Availability,error,error,402,"This request was created from a contribution made by Lucas Kopecky Bobadilla on June 05, 2020 15:53 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067974992-AnalyzeCovariates. --. . Hello I am using the current 4.17 GATK version and I am trying to run AnalyzeCovariates. I ran the baserecalibrator to get the table file to run AnalyzeCovariates but I am getting this following error in the R command:. [June 5, 2020 10:45:08 AM CDT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes. Runtime.totalMemory()=1233649664. org.broadinstitute.hellbender.utils.R.RScriptExecutorException:. Rscript exited with 1. Command Line: Rscript -e tempLibDir = '/tmp/Rlib.323393943272793217';source('/tmp/BQSR.1306882797239975225.R'); /tmp/AnalyzeCovariates5750988274473323663.csv /media/brent/lucas\_SSD/dicamba\_rnaseq/GATK/qlty\_recalibration/trim\_DIC\_CHR\_F2\_R\_104\_1.table /media/brent/lucas\_SSD/dicamba\_rnaseq/GATK/qlty\_recalibration/AnalyzeCovariates.pdf. Stdout:. Stderr:. Attaching package: gplots. . The following object is masked from package:stats:. .   lowess. . Error in distributeGraphRows(list(a, b, c), c(1, 1, 1)) :.  object 'a' not found. Calls: source -> withVisible -> eval -> eval -> distributeGraphRows. Execution halted. . Any idea what is going on?. . Thanks!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/5868'>Zendesk ticket #5868</a>)<br>gz#5868</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6650
https://github.com/broadinstitute/gatk/issues/6650:1105,Availability,mask,masked,1105,"This request was created from a contribution made by Lucas Kopecky Bobadilla on June 05, 2020 15:53 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067974992-AnalyzeCovariates. --. . Hello I am using the current 4.17 GATK version and I am trying to run AnalyzeCovariates. I ran the baserecalibrator to get the table file to run AnalyzeCovariates but I am getting this following error in the R command:. [June 5, 2020 10:45:08 AM CDT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes. Runtime.totalMemory()=1233649664. org.broadinstitute.hellbender.utils.R.RScriptExecutorException:. Rscript exited with 1. Command Line: Rscript -e tempLibDir = '/tmp/Rlib.323393943272793217';source('/tmp/BQSR.1306882797239975225.R'); /tmp/AnalyzeCovariates5750988274473323663.csv /media/brent/lucas\_SSD/dicamba\_rnaseq/GATK/qlty\_recalibration/trim\_DIC\_CHR\_F2\_R\_104\_1.table /media/brent/lucas\_SSD/dicamba\_rnaseq/GATK/qlty\_recalibration/AnalyzeCovariates.pdf. Stdout:. Stderr:. Attaching package: gplots. . The following object is masked from package:stats:. .   lowess. . Error in distributeGraphRows(list(a, b, c), c(1, 1, 1)) :.  object 'a' not found. Calls: source -> withVisible -> eval -> eval -> distributeGraphRows. Execution halted. . Any idea what is going on?. . Thanks!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/5868'>Zendesk ticket #5868</a>)<br>gz#5868</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6650
https://github.com/broadinstitute/gatk/issues/6650:1153,Availability,Error,Error,1153,"This request was created from a contribution made by Lucas Kopecky Bobadilla on June 05, 2020 15:53 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067974992-AnalyzeCovariates. --. . Hello I am using the current 4.17 GATK version and I am trying to run AnalyzeCovariates. I ran the baserecalibrator to get the table file to run AnalyzeCovariates but I am getting this following error in the R command:. [June 5, 2020 10:45:08 AM CDT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes. Runtime.totalMemory()=1233649664. org.broadinstitute.hellbender.utils.R.RScriptExecutorException:. Rscript exited with 1. Command Line: Rscript -e tempLibDir = '/tmp/Rlib.323393943272793217';source('/tmp/BQSR.1306882797239975225.R'); /tmp/AnalyzeCovariates5750988274473323663.csv /media/brent/lucas\_SSD/dicamba\_rnaseq/GATK/qlty\_recalibration/trim\_DIC\_CHR\_F2\_R\_104\_1.table /media/brent/lucas\_SSD/dicamba\_rnaseq/GATK/qlty\_recalibration/AnalyzeCovariates.pdf. Stdout:. Stderr:. Attaching package: gplots. . The following object is masked from package:stats:. .   lowess. . Error in distributeGraphRows(list(a, b, c), c(1, 1, 1)) :.  object 'a' not found. Calls: source -> withVisible -> eval -> eval -> distributeGraphRows. Execution halted. . Any idea what is going on?. . Thanks!<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/5868'>Zendesk ticket #5868</a>)<br>gz#5868</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6650
https://github.com/broadinstitute/gatk/issues/6651:749,Availability,error,error,749,"This request was created from a contribution made by Mark Godek on May 28, 2020 12:43 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360067471451-Funcotator-cannot-complete-funcotaion-for-variant-due-to-alternate-allele. --. I'm attempting to annotate germline variants after VQSR with Funcotator using GATK 4.1.4.1. GATK command is:. gatk Funcotator \ ; -R ${REFERENCE\_GENOME} \ ; -V ${OUT}/germline.filtered.vcf.gz \ ; -O ${OUT}/annotated.germline.vcf \ ; --output-file-format VCF \ ; --data-sources-path /mnt/data/rbueno/analysis\_files/MedGenome\_FamilialMPMs/Annotation\_data\_sources/funcotator\_dataSources.v1.6.20190124s \ ; --ref-version hg19 ; ; I get many warnings and it terminates with aString index out of range error. Any help is appreciated. . The tail end of the output follows: ; ; ; 07:33:14.569 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756762-69756762 due to alternate allele: \* ; 07:33:14.575 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756763-69756763 due to alternate allele: \* ; 07:33:14.575 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756763-69756763 due to alternate allele: \* ; 07:33:14.580 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756764-69756764 due to alternate allele: \* ; 07:33:14.580 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756764-69756764 due to alternate allele: \* ; 07:33:16.681 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:70289137-70289137 due to alternate allele: \* ; 07:33:16.681 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:70289137-70289137 due to alternate allele: \* ; 07:33:17.957 INFO VcfFuncotationFactory - dbSNP 9606\_b150 cache hits/total: 521/453691 ; 07:33:18.138 INFO Funcotator - Shut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:2006,Availability,down,down,2006,"ctory - Cannot create complete funcotation for variant at chr12:69756763-69756763 due to alternate allele: \* ; 07:33:14.575 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756763-69756763 due to alternate allele: \* ; 07:33:14.580 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756764-69756764 due to alternate allele: \* ; 07:33:14.580 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756764-69756764 due to alternate allele: \* ; 07:33:16.681 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:70289137-70289137 due to alternate allele: \* ; 07:33:16.681 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:70289137-70289137 due to alternate allele: \* ; 07:33:17.957 INFO VcfFuncotationFactory - dbSNP 9606\_b150 cache hits/total: 521/453691 ; 07:33:18.138 INFO Funcotator - Shutting down engine ; [May 28, 2020 7:33:18 AM EDT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 34.35 minutes. ; Runtime.totalMemory()=3822059520 ; java.lang.StringIndexOutOfBoundsException: String index out of range: 545 ; at java.lang.String.substring(String.java:1963) ; at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.initializeForInsertion(ProteinChangeInfo.java:256) ; at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:93) ; at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:371) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2003) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotationForProteinCodingFeature(GencodeFuncotationFactory.java:1193) ; at org.broadinstitute.hellbende",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:4161,Energy Efficiency,Reduce,ReduceOps,4161,der.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:978) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:474) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:475) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:4171,Energy Efficiency,Reduce,ReduceOp,4171,der.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:978) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:474) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:475) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:4199,Energy Efficiency,Reduce,ReduceOps,4199,aSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:978) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:474) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:475) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:5685,Energy Efficiency,Reduce,ReduceOps,5685,ory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:5695,Energy Efficiency,Reduce,ReduceOp,5695,ory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:5723,Energy Efficiency,Reduce,ReduceOps,5723,roadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; at java.util.Spliterators$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:4096,Integrability,wrap,wrapAndCopyInto,4096,cotationFactory.java:1044) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:978) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:805) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:789) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:474) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:475) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:5620,Integrability,wrap,wrapAndCopyInto,5620,Factory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:530) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:233) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:201) ; at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:172) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499) ; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:6894,Integrability,wrap,wrapAndCopyInto,6894,stitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:903) ; at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:857) ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) ; at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102) ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191) ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210) ; at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163) ; at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206) ; at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/issues/6651:1935,Performance,cache,cache,1935,"756762-69756762 due to alternate allele: \* ; 07:33:14.575 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756763-69756763 due to alternate allele: \* ; 07:33:14.575 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756763-69756763 due to alternate allele: \* ; 07:33:14.580 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756764-69756764 due to alternate allele: \* ; 07:33:14.580 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:69756764-69756764 due to alternate allele: \* ; 07:33:16.681 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:70289137-70289137 due to alternate allele: \* ; 07:33:16.681 WARN GencodeFuncotationFactory - Cannot create complete funcotation for variant at chr12:70289137-70289137 due to alternate allele: \* ; 07:33:17.957 INFO VcfFuncotationFactory - dbSNP 9606\_b150 cache hits/total: 521/453691 ; 07:33:18.138 INFO Funcotator - Shutting down engine ; [May 28, 2020 7:33:18 AM EDT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 34.35 minutes. ; Runtime.totalMemory()=3822059520 ; java.lang.StringIndexOutOfBoundsException: String index out of range: 545 ; at java.lang.String.substring(String.java:1963) ; at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.initializeForInsertion(ProteinChangeInfo.java:256) ; at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:93) ; at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:371) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2003) ; at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createCodingRegionFuncotationForProtei",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6651
https://github.com/broadinstitute/gatk/pull/6653:15,Security,sanitiz,sanitize,15,Adds a tool to sanitize reads. This tool will convert any bases that do not match the reference into bases that do match the reference using the CIGAR as a key for which bases to change. The qualities for bases that match the reference are preserved.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6653
https://github.com/broadinstitute/gatk/pull/6654:1366,Availability,avail,avail,1366,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654
https://github.com/broadinstitute/gatk/pull/6654:1659,Integrability,message,messages,1659,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654
https://github.com/broadinstitute/gatk/pull/6654:42,Performance,optimiz,optimizations,42,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654
https://github.com/broadinstitute/gatk/pull/6654:213,Performance,perform,performance,213,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654
https://github.com/broadinstitute/gatk/pull/6654:795,Performance,perform,performance,795,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654
https://github.com/broadinstitute/gatk/pull/6654:1408,Testability,Log,Logging,1408,"1. Add new arg `genomicsdb-shared-posixfs-optimizations` to help with shared posix filesystems like NFS and Lustre. This turns on `disable file locking` and for GenomicsDB import it minimizes writes to disks. The performance on some of the gatk datasets for the import of about 10 samples went from 23.72m to 6.34m on NFS which was comparable to importing to a local filesystem. Hopefully this helps with Issue #6487 and #6627. Also, fixes Issue #6519.; 2. This version of GenomicsDB also uses pre-compression filters for offset and compression files for new workspaces and genomicsdb arrays. The total sizes for a GenomicsDB workspace using the same dataset as above and the 10 samples went from 313MB to 170MB with no change in import and query times. Smaller GenomicsDB arrays also help with performance on distributed and cloud file systems.; 3. This version has added support to handle MNVs similar to deletions as described in Issue #6500. See [GenomicsDB PR 88](https://github.com/GenomicsDB/GenomicsDB/pull/88). Thanks @kgururaj.; 4. There is added support in the GenomicsDBImporter to have multiple contigs in the same GenomicsDB partition/array. This will hopefully help import times in cases where users have many thousands of contigs. See [GenomicsDB PR 91](https://github.com/GenomicsDB/GenomicsDB/pull/91). Changes will be needed from the gatk side to avail this support. Thanks @mlathara.; 5. Logging has been improved somewhat with the native C/C++ code using [spdlog](https://github.com/gabime/spdlog) and [fmt](https://github.com/fmtlib/fmt) and the Java layer using apache log4j and log4j.properties provided by the application. Also, info messages like `No valid combination operation found for INFO field AA - the field will NOT be part of INFO fields in the generated VCF records` will only be output once for the operation. Also see open PR #6514 for code to actually suppress these warnings for known fields.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6654
https://github.com/broadinstitute/gatk/issues/6656:122,Deployability,release,release,122,"## Bug Report. ### Affected tool(s) or class(es); all tools, I would assume. ### Affected version(s); - [x] Latest public release version [version 4.1.7.0]. ### Description ; ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; #### Steps to reproduce; Install a fresh miniconda3 install on Linux. Then run:; ```; conda env create -f gatkcondaenv.yml; ```. #### Expected behavior; The conda environment should just work. #### Actual behavior; ```; conda env create -f gatkcondaenv.yml; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; I would like a fixing of the `gatkcondaenv.yaml` file.; ----. ## Documentation request. ### Tool(s) or class(es) involved; Conda install. ### Description ; Amendment to README.md for installation if not a bug fix; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656
https://github.com/broadinstitute/gatk/issues/6656:408,Deployability,Install,Install,408,"## Bug Report. ### Affected tool(s) or class(es); all tools, I would assume. ### Affected version(s); - [x] Latest public release version [version 4.1.7.0]. ### Description ; ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; #### Steps to reproduce; Install a fresh miniconda3 install on Linux. Then run:; ```; conda env create -f gatkcondaenv.yml; ```. #### Expected behavior; The conda environment should just work. #### Actual behavior; ```; conda env create -f gatkcondaenv.yml; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; I would like a fixing of the `gatkcondaenv.yaml` file.; ----. ## Documentation request. ### Tool(s) or class(es) involved; Conda install. ### Description ; Amendment to README.md for installation if not a bug fix; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656
https://github.com/broadinstitute/gatk/issues/6656:435,Deployability,install,install,435,"## Bug Report. ### Affected tool(s) or class(es); all tools, I would assume. ### Affected version(s); - [x] Latest public release version [version 4.1.7.0]. ### Description ; ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; #### Steps to reproduce; Install a fresh miniconda3 install on Linux. Then run:; ```; conda env create -f gatkcondaenv.yml; ```. #### Expected behavior; The conda environment should just work. #### Actual behavior; ```; conda env create -f gatkcondaenv.yml; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; I would like a fixing of the `gatkcondaenv.yaml` file.; ----. ## Documentation request. ### Tool(s) or class(es) involved; Conda install. ### Description ; Amendment to README.md for installation if not a bug fix; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656
https://github.com/broadinstitute/gatk/issues/6656:1094,Deployability,install,install,1094,"## Bug Report. ### Affected tool(s) or class(es); all tools, I would assume. ### Affected version(s); - [x] Latest public release version [version 4.1.7.0]. ### Description ; ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; #### Steps to reproduce; Install a fresh miniconda3 install on Linux. Then run:; ```; conda env create -f gatkcondaenv.yml; ```. #### Expected behavior; The conda environment should just work. #### Actual behavior; ```; conda env create -f gatkcondaenv.yml; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; I would like a fixing of the `gatkcondaenv.yaml` file.; ----. ## Documentation request. ### Tool(s) or class(es) involved; Conda install. ### Description ; Amendment to README.md for installation if not a bug fix; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656
https://github.com/broadinstitute/gatk/issues/6656:1148,Deployability,install,installation,1148,"## Bug Report. ### Affected tool(s) or class(es); all tools, I would assume. ### Affected version(s); - [x] Latest public release version [version 4.1.7.0]. ### Description ; ```; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; #### Steps to reproduce; Install a fresh miniconda3 install on Linux. Then run:; ```; conda env create -f gatkcondaenv.yml; ```. #### Expected behavior; The conda environment should just work. #### Actual behavior; ```; conda env create -f gatkcondaenv.yml; Collecting package metadata (repodata.json): done; Solving environment: failed. ResolvePackageNotFound:; - tk==8.5.18=0; - readline==6.2=2; - setuptools==36.4.0=py36_1; - certifi==2016.2.28=py36_0; ```; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; I would like a fixing of the `gatkcondaenv.yaml` file.; ----. ## Documentation request. ### Tool(s) or class(es) involved; Conda install. ### Description ; Amendment to README.md for installation if not a bug fix; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6656
https://github.com/broadinstitute/gatk/issues/6657:50,Testability,test,test,50,"Not sure if intermittent:; `Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.walkers.GnarlyGenotyperIntegrationTest > testUsingGenomicsDB[4]([Ljava.io.File;@4f23de76, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleAS.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleASDB.vcf, [20:1-2147483647], [], /home/travis/build/broadinstitute/gatk/src/test/resources/large/human_g1k_v37.20.21.fasta) SKIPPED`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6657
https://github.com/broadinstitute/gatk/issues/6657:134,Testability,test,testUsingGenomicsDB,134,"Not sure if intermittent:; `Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.walkers.GnarlyGenotyperIntegrationTest > testUsingGenomicsDB[4]([Ljava.io.File;@4f23de76, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleAS.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleASDB.vcf, [20:1-2147483647], [], /home/travis/build/broadinstitute/gatk/src/test/resources/large/human_g1k_v37.20.21.fasta) SKIPPED`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6657
https://github.com/broadinstitute/gatk/issues/6657:187,Testability,test,test,187,"Not sure if intermittent:; `Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.walkers.GnarlyGenotyperIntegrationTest > testUsingGenomicsDB[4]([Ljava.io.File;@4f23de76, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleAS.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleASDB.vcf, [20:1-2147483647], [], /home/travis/build/broadinstitute/gatk/src/test/resources/large/human_g1k_v37.20.21.fasta) SKIPPED`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6657
https://github.com/broadinstitute/gatk/issues/6657:283,Testability,test,test,283,"Not sure if intermittent:; `Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.walkers.GnarlyGenotyperIntegrationTest > testUsingGenomicsDB[4]([Ljava.io.File;@4f23de76, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleAS.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleASDB.vcf, [20:1-2147483647], [], /home/travis/build/broadinstitute/gatk/src/test/resources/large/human_g1k_v37.20.21.fasta) SKIPPED`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6657
https://github.com/broadinstitute/gatk/issues/6657:443,Testability,test,test,443,"Not sure if intermittent:; `Gradle suite > Gradle test > org.broadinstitute.hellbender.tools.walkers.GnarlyGenotyperIntegrationTest > testUsingGenomicsDB[4]([Ljava.io.File;@4f23de76, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleAS.vcf, src/test/resources/org/broadinstitute/hellbender/tools/walkers/GnarlyGenotyper/twoSampleASDB.vcf, [20:1-2147483647], [], /home/travis/build/broadinstitute/gatk/src/test/resources/large/human_g1k_v37.20.21.fasta) SKIPPED`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6657
https://github.com/broadinstitute/gatk/issues/6659:391,Modifiability,extend,extending,391,"PostProcessGermlineCNVCalls is currently single-sample, using input calls and model for the whole cohort. Specifying a sample index is not particularly user friendly. Given that we already output calls as a directory of files, including a sample map could enable the user to specify a sample name rather than an index. This would involve changes to GermlineCNVCaller as well. Alternatively, extending PostProcessGermlineCNVCalls to process all the samples at the same time would eliminate this problem and allow us to avoid some irritating transposes by parallelizing by shard instead of by sample.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659
https://github.com/broadinstitute/gatk/issues/6659:518,Safety,avoid,avoid,518,"PostProcessGermlineCNVCalls is currently single-sample, using input calls and model for the whole cohort. Specifying a sample index is not particularly user friendly. Given that we already output calls as a directory of files, including a sample map could enable the user to specify a sample name rather than an index. This would involve changes to GermlineCNVCaller as well. Alternatively, extending PostProcessGermlineCNVCalls to process all the samples at the same time would eliminate this problem and allow us to avoid some irritating transposes by parallelizing by shard instead of by sample.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6659
https://github.com/broadinstitute/gatk/pull/6660:247,Availability,down,downloader,247,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:629,Availability,error,error,629,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:905,Availability,down,downloader,905,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:157,Deployability,release,release,157,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:227,Deployability,Update,Update,227,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:266,Deployability,Update,Update,266,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:315,Deployability,update,updates,315,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:565,Deployability,Update,Updated,565,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:950,Deployability,update,updates,950,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:1008,Deployability,update,updates,1008,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:1020,Deployability,Update,Updated,1020,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:1104,Modifiability,config,config,1104,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:293,Security,validat,validation,293,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:1176,Security,hash,hash,1176,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:152,Testability,test,test,152,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/pull/6660:720,Testability,test,test,720,"Includes latest Gencode and an implicit fix for #6564. Had to make some code changes for latest liftover Gencode data(v34 -> hg19). . The associated DS test release correctly annotates data on hg19 and hg38. Left to do:. - [x] Update data sources downloader.; - [x] Update data source version validation code. Code updates:; - Now both hg19 and hg38 have the contig names translated to `chr__`; - Added 'lncRNA' to GeneTranscriptType.; - Added ""TAGENE"" gene tag.; - Added the MANE_SELECT tag to FeatureTag.; - Added the STOP_CODON_READTHROUGH tag to FeatureTag.; - Updated the GTF versions that are parseable.; - Fixed a parsing error with new versions of gencode and the remap; positions (for liftover files).; - Added test for indexing new lifted over gencode GTF.; - Added Gencode_34 entries to MAF output map.; - Minor changes to FuncotatorIntegrationTest.java for code syntax.; - Pointed data source downloader at new data sources URL.; - Minor updates to workflows to point at new data sources. Script updates:; - Updated retrieval scripts for dbSNP and Gencode.; - Added required field to gencode config file generation.; - Now gencode retrieval script enforces double hash comments at; top of gencode GTF files. Bug Fixes:; Removing erroneous trailing tab in MAF file output. - Fixes #6693",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6660
https://github.com/broadinstitute/gatk/issues/6663:1405,Performance,Load,Loading,1405,"tator-Processing-Speed-Drop. --. GATK 4.1.7.0 VariantAnnotator processing speed rapidly decreases over time. Running with single-sample VCF file obtained from GenotypeGVCFs. No other tools were executed during the VariantAnnotator running. No RAM or SSD space overuse was found. The INFO log is shown below. The exact command is at the top section of the log. . Using GATK jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar ; Running: ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -Xms1G -jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar VariantAnnotator --reference /home/wgs/Genomes/hg38/bwa/hg38.fa --dbsnp /home/wgs/Tools/Supplementary/dbsnp-153-hgvs.sorted.hg38.vcf.gz --variant ./barcode.raw21-22.vcf.gz --output ../annotated\_output/barcode.gatk\_annotated21-22.vcf.gz -L chr21 -L chr22 ; 18:34:24.702 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; May 07, 2020 6:34:24 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; INFO: Failed to detect whether we are running on Google Compute Engine. ; 18:34:24.814 INFO VariantAnnotator - ------------------------------------------------------------ ; 18:34:24.815 INFO VariantAnnotator - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; 18:34:24.815 INFO VariantAnnotator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; 18:34:24.815 INFO VariantAnnotator - Executing as wgs@wgs on Linux v4.15.0-99-generic amd64 ; 18:34:24.815 INFO VariantAnnotator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_201-b09 ; 18:34:24.815 INFO VariantAnnotator - Start Date/Time: May 7, 2020 6:34:24 PM MSK ; 18:34:24.815 INFO VariantAnnotato",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6663
https://github.com/broadinstitute/gatk/issues/6663:1688,Safety,detect,detect,1688,"The INFO log is shown below. The exact command is at the top section of the log. . Using GATK jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar ; Running: ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -Xms1G -jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar VariantAnnotator --reference /home/wgs/Genomes/hg38/bwa/hg38.fa --dbsnp /home/wgs/Tools/Supplementary/dbsnp-153-hgvs.sorted.hg38.vcf.gz --variant ./barcode.raw21-22.vcf.gz --output ../annotated\_output/barcode.gatk\_annotated21-22.vcf.gz -L chr21 -L chr22 ; 18:34:24.702 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; May 07, 2020 6:34:24 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; INFO: Failed to detect whether we are running on Google Compute Engine. ; 18:34:24.814 INFO VariantAnnotator - ------------------------------------------------------------ ; 18:34:24.815 INFO VariantAnnotator - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; 18:34:24.815 INFO VariantAnnotator - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; 18:34:24.815 INFO VariantAnnotator - Executing as wgs@wgs on Linux v4.15.0-99-generic amd64 ; 18:34:24.815 INFO VariantAnnotator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_201-b09 ; 18:34:24.815 INFO VariantAnnotator - Start Date/Time: May 7, 2020 6:34:24 PM MSK ; 18:34:24.815 INFO VariantAnnotator - ------------------------------------------------------------ ; 18:34:24.815 INFO VariantAnnotator - ------------------------------------------------------------ ; 18:34:24.815 INFO VariantAnnotator - HTSJDK Version: 2.21.2 ; 18:34:24.815 INFO VariantAnnotator - Picard Versio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6663
https://github.com/broadinstitute/gatk/issues/6663:691,Testability,log,log,691,"VariantAnnotator v4.1.7.0 is taking >300 mins to run and doesn't even run to completion while v3.8 takes only 10mins to run successfully. User has shared their vcf in this tar file: danilovk_11Jun2020_main.tar. This request was created from a contribution made by danilovkiri on May 07, 2020 15:54 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360062628652-GATK-4-1-7-0-VariantAnnotator-Processing-Speed-Drop. --. GATK 4.1.7.0 VariantAnnotator processing speed rapidly decreases over time. Running with single-sample VCF file obtained from GenotypeGVCFs. No other tools were executed during the VariantAnnotator running. No RAM or SSD space overuse was found. The INFO log is shown below. The exact command is at the top section of the log. . Using GATK jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar ; Running: ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -Xms1G -jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar VariantAnnotator --reference /home/wgs/Genomes/hg38/bwa/hg38.fa --dbsnp /home/wgs/Tools/Supplementary/dbsnp-153-hgvs.sorted.hg38.vcf.gz --variant ./barcode.raw21-22.vcf.gz --output ../annotated\_output/barcode.gatk\_annotated21-22.vcf.gz -L chr21 -L chr22 ; 18:34:24.702 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; May 07, 2020 6:34:24 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; INFO: Failed to detect whether we are running on Google Compute Engine. ; 18:34:24.814 INFO VariantAnnotator - ------------------------------------------------------------ ; 18:34:24.815 INFO VariantAnnotator - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; 18:34:24.815 INFO VariantAnnotator - For support and documentation go to",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6663
https://github.com/broadinstitute/gatk/issues/6663:758,Testability,log,log,758,"VariantAnnotator v4.1.7.0 is taking >300 mins to run and doesn't even run to completion while v3.8 takes only 10mins to run successfully. User has shared their vcf in this tar file: danilovk_11Jun2020_main.tar. This request was created from a contribution made by danilovkiri on May 07, 2020 15:54 UTC. Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360062628652-GATK-4-1-7-0-VariantAnnotator-Processing-Speed-Drop. --. GATK 4.1.7.0 VariantAnnotator processing speed rapidly decreases over time. Running with single-sample VCF file obtained from GenotypeGVCFs. No other tools were executed during the VariantAnnotator running. No RAM or SSD space overuse was found. The INFO log is shown below. The exact command is at the top section of the log. . Using GATK jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar ; Running: ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx30G -Xms1G -jar /home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar VariantAnnotator --reference /home/wgs/Genomes/hg38/bwa/hg38.fa --dbsnp /home/wgs/Tools/Supplementary/dbsnp-153-hgvs.sorted.hg38.vcf.gz --variant ./barcode.raw21-22.vcf.gz --output ../annotated\_output/barcode.gatk\_annotated21-22.vcf.gz -L chr21 -L chr22 ; 18:34:24.702 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/wgs/Tools/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; May 07, 2020 6:34:24 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; INFO: Failed to detect whether we are running on Google Compute Engine. ; 18:34:24.814 INFO VariantAnnotator - ------------------------------------------------------------ ; 18:34:24.815 INFO VariantAnnotator - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; 18:34:24.815 INFO VariantAnnotator - For support and documentation go to",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6663
https://github.com/broadinstitute/gatk/issues/6664:2350,Availability,avail,available,2350,"5.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=605028352; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:4888,Availability,error,error,4888,"Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It does not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:147,Deployability,release,release,147,"## Bug Report. ### Affected tool(s) or class(es); MergeVcfs (and potentially other Picard related tools). ### Affected version(s); - Latest public release version [4.1.7.0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:261,Deployability,release,release,261,"## Bug Report. ### Affected tool(s) or class(es); MergeVcfs (and potentially other Picard related tools). ### Affected version(s); - Latest public release version [4.1.7.0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:316,Deployability,release,release-,316,"## Bug Report. ### Affected tool(s) or class(es); MergeVcfs (and potentially other Picard related tools). ### Affected version(s); - Latest public release version [4.1.7.0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:2282,Deployability,release,release-,2282,"5.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=605028352; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:1364,Performance,Load,Loading,1364,"uild 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; P",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:2098,Safety,detect,detect,2098,"nc_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=605028352; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vc",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:919,Testability,test,test,919,"## Bug Report. ### Affected tool(s) or class(es); MergeVcfs (and potentially other Picard related tools). ### Affected version(s); - Latest public release version [4.1.7.0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:1193,Testability,test,test,1193,"0]. Here is my java version in case:; ```bash; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; When the upstream path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:1448,Testability,test,test,1448,"eam path of the current directory contains a whitespace **and** the VCFs are stored in a directory 2 level deeper, the VCF is not found. The bug does not happen if:; * VCFs are located in current directory or in a subdirectory (level 1) from the current working directory (see reproducible steps below).; * VCFs have themselves whitespace in their filenames (see reproducible steps below). Here is a GATK stacktrace example:; ```java; Using GATK jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar $HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz; 23:25:05.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:$HOME/local/pckg/python/miniconda3/envs/test/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Tue Jun 16 23:25:05 CDT 2020] MergeVcfs --INPUT data/calling/a.vcf.gz --INPUT data/calling/b.vcf.gz --OUTPUT c.vcf.gz --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] pica",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:2735,Testability,test,test,2735,"FO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX true --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jun 16, 2020 11:25:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Tue Jun 16 23:25:05 CDT 2020] Executing as xxxx on Linux 3.10.0-693.11.1.el7.x86_64 amd64; OpenJDK 64-Bit Server VM 1.8.0_152-release-1056-b12; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; [Tue Jun 16 23:25:05 CDT 2020] picard.vcf.MergeVcfs done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=605028352; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(N",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:3589,Testability,test,test,3589,"gHelp; htsjdk.tribble.TribbleException$MalformedFeatureFile: Unable to create BasicFeatureReader using feature file , for input source: file:///tmp/test%20a/data/calling/a.vcf.gz; at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:124); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:81); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:148); at htsjdk.variant.vcf.VCFFileReader.<init>(VCFFileReader.java:98); at picard.vcf.MergeVcfs.doWork(MergeVcfs.java:174); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:4409,Testability,test,test,4409,"ellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:4462,Testability,test,test-a,4462,"ellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:4487,Testability,test,test-a,4487,"ellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:4748,Testability,test,test-a,4748,"Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It does not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:4756,Testability,test,test,4756,"Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It does not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:4769,Testability,test,test,4769,"Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It does not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6664:5265,Testability,test,test,5265,"Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); Caused by: java.io.FileNotFoundException: /tmp/test%20a/data/calling/a.vcf.gz (No such file or directory); at java.io.RandomAccessFile.open0(Native Method); at java.io.RandomAccessFile.open(RandomAccessFile.java:316); at java.io.RandomAccessFile.<init>(RandomAccessFile.java:243); at htsjdk.samtools.seekablestream.SeekableFileStream.<init>(SeekableFileStream.java:47); at htsjdk.samtools.seekablestream.SeekableStreamFactory$DefaultSeekableStreamFactory.getStreamFor(SeekableStreamFactory.java:99); at htsjdk.tribble.readers.TabixReader.<init>(TabixReader.java:129); at htsjdk.tribble.TabixFeatureReader.<init>(TabixFeatureReader.java:80); at htsjdk.tribble.AbstractFeatureReader.getFeatureReader(AbstractFeatureReader.java:117); ... 9 more; ```. #### Steps to reproduce; Below few steps to reproduce the bug and the specificities mentioned above. ```bash; # Create test directory without whitespace; cd /tmp; mkdir -p test-a/data/calling/; cd test-a. # Upload appropriate VCFs in data/calling. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It runs as expected. # Introduce a whitespace in the directory name and move into the directory again; cd ..; mv test-a ""test a""; cd ""test a"". # Run MergeVcfs; gatk MergeVcfs -I data/calling/a.vcf.gz -I data/calling/b.vcf.gz -O c.vcf.gz ## It throws an error. # Introduce withespace in the VCFs; mv data/calling/a.vcf.gz -I data/calling/a\ 1.vcf.gz; mv data/calling/b.vcf.gz -I data/calling/b\ 1.vcf.gz. # Run MergeVcfs; gatk MergeVcfs -I data/calling/a\ 1.vcf.gz -I data/calling/b\ 1.vcf.gz -O c.vcf.gz ## It runs as expected. # If VCFs without whitespace in their names are moved into data or in the current working directory (""test a""), merging works as expected.; ```. #### Expected behavior; MergeVcfs should be able to handle whitespace when present anywhere in the file path. #### Actual behavior; It does not.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6664
https://github.com/broadinstitute/gatk/issues/6667:645,Availability,error,error,645,"We created a GenomicsDB workspace using GenomicsDBImport, followed by 2 rounds of adding new samples using GenomicsDBImport. We then ran GenotypeGVFs on it and received this NPE. Is there any information or debugging you can suggest that would help diagnose this?. The command run was approximately this (filepaths have been simplified):. java -Xmx48g -Xms48g -Xss2m GenomeAnalysisTK4.jar GenotypeGVCFs -R 128_Mmul_10.fasta --variant gendb://CombinedGenotypes_WES.gdb -O Test_WES_variantcalling.vcf.gz --annotate-with-num-discovered-alleles -stand-call-conf 30 --max-alternate-alleles 12 --allow-old-rms-mapping-quality-annotation-data. and the error:. 17 Jun 2020 15:49:59,410 DEBUG: java.lang.NullPointerException; 17 Jun 2020 15:49:59,412 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeInt(BCF2Decoder.java:226); 17 Jun 2020 15:49:59,413 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeSingleValue(BCF2Decoder.java:157); 17 Jun 2020 15:49:59,414 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:146); 17 Jun 2020 15:49:59,416 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:130); 17 Jun 2020 15:49:59,417 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:125); 17 Jun 2020 15:49:59,419 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeInfo(BCF2Codec.java:410); 17 Jun 2020 15:49:59,420 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeSitesExtendedInfo(BCF2Codec.java:298); 17 Jun 2020 15:49:59,422 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:132); 17 Jun 2020 15:49:59,423 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); 17 Jun 2020 15:49:59,425 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:183); 17 Jun 2020 15:49:59,426 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); 17 Jun 2020 15:49:59,428 DEBUG: at java.util.Iterator.forEachRemaining(Iterator.java:116); 17 Jun 2020 15:49:59,42",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6667
https://github.com/broadinstitute/gatk/issues/6667:2273,Integrability,wrap,wrapAndCopyInto,2273,"ariant.bcf2.BCF2Codec.decodeInfo(BCF2Codec.java:410); 17 Jun 2020 15:49:59,420 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeSitesExtendedInfo(BCF2Codec.java:298); 17 Jun 2020 15:49:59,422 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:132); 17 Jun 2020 15:49:59,423 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); 17 Jun 2020 15:49:59,425 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:183); 17 Jun 2020 15:49:59,426 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); 17 Jun 2020 15:49:59,428 DEBUG: at java.util.Iterator.forEachRemaining(Iterator.java:116); 17 Jun 2020 15:49:59,429 DEBUG: at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 17 Jun 2020 15:49:59,431 DEBUG: at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 17 Jun 2020 15:49:59,432 DEBUG: at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 17 Jun 2020 15:49:59,433 DEBUG: at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 17 Jun 2020 15:49:59,435 DEBUG: at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 17 Jun 2020 15:49:59,436 DEBUG: at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 17 Jun 2020 15:49:59,437 DEBUG: at java.util.stream.ReferencePipeline.forEachOrdered(ReferencePipeline.java:423); 17 Jun 2020 15:49:59,438 DEBUG: at org.broadinstitute.hellbender.engine.VariantLocusWalker.traverse(VariantLocusWalker.java:132); 17 Jun 2020 15:49:59,439 DEBUG: at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 17 Jun 2020 15:49:59,440 DEBUG: at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 17 Jun 2020 15:49:59,441 DEBUG: at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 17",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6667
https://github.com/broadinstitute/gatk/issues/6667:325,Usability,simpl,simplified,325,"We created a GenomicsDB workspace using GenomicsDBImport, followed by 2 rounds of adding new samples using GenomicsDBImport. We then ran GenotypeGVFs on it and received this NPE. Is there any information or debugging you can suggest that would help diagnose this?. The command run was approximately this (filepaths have been simplified):. java -Xmx48g -Xms48g -Xss2m GenomeAnalysisTK4.jar GenotypeGVCFs -R 128_Mmul_10.fasta --variant gendb://CombinedGenotypes_WES.gdb -O Test_WES_variantcalling.vcf.gz --annotate-with-num-discovered-alleles -stand-call-conf 30 --max-alternate-alleles 12 --allow-old-rms-mapping-quality-annotation-data. and the error:. 17 Jun 2020 15:49:59,410 DEBUG: java.lang.NullPointerException; 17 Jun 2020 15:49:59,412 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeInt(BCF2Decoder.java:226); 17 Jun 2020 15:49:59,413 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeSingleValue(BCF2Decoder.java:157); 17 Jun 2020 15:49:59,414 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:146); 17 Jun 2020 15:49:59,416 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:130); 17 Jun 2020 15:49:59,417 DEBUG: at htsjdk.variant.bcf2.BCF2Decoder.decodeTypedValue(BCF2Decoder.java:125); 17 Jun 2020 15:49:59,419 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeInfo(BCF2Codec.java:410); 17 Jun 2020 15:49:59,420 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decodeSitesExtendedInfo(BCF2Codec.java:298); 17 Jun 2020 15:49:59,422 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:132); 17 Jun 2020 15:49:59,423 DEBUG: at htsjdk.variant.bcf2.BCF2Codec.decode(BCF2Codec.java:58); 17 Jun 2020 15:49:59,425 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:183); 17 Jun 2020 15:49:59,426 DEBUG: at org.genomicsdb.reader.GenomicsDBFeatureIterator.next(GenomicsDBFeatureIterator.java:49); 17 Jun 2020 15:49:59,428 DEBUG: at java.util.Iterator.forEachRemaining(Iterator.java:116); 17 Jun 2020 15:49:59,42",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6667
https://github.com/broadinstitute/gatk/pull/6668:342,Deployability,upgrade,upgraded,342,"Re-enable tests for htsget now that the reference server is back to a stable version. * Some tests were disabled due to issues with the htsget reference server, now that it's back to running an older stable version; the tests which work on that version are re-enabled. * Partial fix for #6640 another commit will be needed when the server is upgraded to support fields/tags. The field test had to be disabled because it doesn't seem like the current server version supports the parameter correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6668
https://github.com/broadinstitute/gatk/pull/6668:10,Testability,test,tests,10,"Re-enable tests for htsget now that the reference server is back to a stable version. * Some tests were disabled due to issues with the htsget reference server, now that it's back to running an older stable version; the tests which work on that version are re-enabled. * Partial fix for #6640 another commit will be needed when the server is upgraded to support fields/tags. The field test had to be disabled because it doesn't seem like the current server version supports the parameter correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6668
https://github.com/broadinstitute/gatk/pull/6668:93,Testability,test,tests,93,"Re-enable tests for htsget now that the reference server is back to a stable version. * Some tests were disabled due to issues with the htsget reference server, now that it's back to running an older stable version; the tests which work on that version are re-enabled. * Partial fix for #6640 another commit will be needed when the server is upgraded to support fields/tags. The field test had to be disabled because it doesn't seem like the current server version supports the parameter correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6668
https://github.com/broadinstitute/gatk/pull/6668:220,Testability,test,tests,220,"Re-enable tests for htsget now that the reference server is back to a stable version. * Some tests were disabled due to issues with the htsget reference server, now that it's back to running an older stable version; the tests which work on that version are re-enabled. * Partial fix for #6640 another commit will be needed when the server is upgraded to support fields/tags. The field test had to be disabled because it doesn't seem like the current server version supports the parameter correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6668
https://github.com/broadinstitute/gatk/pull/6668:385,Testability,test,test,385,"Re-enable tests for htsget now that the reference server is back to a stable version. * Some tests were disabled due to issues with the htsget reference server, now that it's back to running an older stable version; the tests which work on that version are re-enabled. * Partial fix for #6640 another commit will be needed when the server is upgraded to support fields/tags. The field test had to be disabled because it doesn't seem like the current server version supports the parameter correctly.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6668
https://github.com/broadinstitute/gatk/issues/6669:101,Security,access,access,101,"If --gcs-project-for-requester-pays is not specified, gatk should use the current billing project to access requester pays buckets.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6669
https://github.com/broadinstitute/gatk/issues/6670:985,Availability,error,error,985,"I used HaplotypeCaller (-ERC GVCF) to generate a few hundred GVCF files (see a section below, Fig. 1; ![Fig1](https://user-images.githubusercontent.com/15146751/85318178-27d2d500-b485-11ea-8efb-a92bdad2cc1d.png); ). Then I was trying to use GenomicsDBImport to generate the datastore to be further processed by GenotypeGVCFs:; `gatk --java-options ""-Xmx10g -Xms10g"" GenomicsDBImport \; --genomicsdb-workspace-path /home/zhen.fu/fu_scratch/Helico/genotye/chr1 \; --batch-size 30 \; -L HaChr01 \; --sample-name-map sample_map_file \; --tmp-dir=/home/zhen.fu/fu_scratch/Helico/genotye/tmp \; --reader-threads 2; `. However, I realized that GenomicsDBImport seemed to only recognize ""GT:DP:GQ:MIN_DP:PL"", where ALT field is <NON_REF> for these sites. Conversely, GenomicsDBImport did not recognize the features in the true variant sites, where a true variant and <NON_REF> coexist, such as ""GT:AD:DP:GQ:PL:SB"". As GVCF records all sites, including the variant and non-variant sites. . The error I got was:; ![Fig2](https://user-images.githubusercontent.com/15146751/85318248-3f11c280-b485-11ea-9c5e-71f01b8db1d9.png). The GenomicsDBImport would only process the first batch (30 samples) and not going further. ; The version I am using is GATK 4.15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6670
https://github.com/broadinstitute/gatk/pull/6672:2,Performance,Cache,Cache,2,* Cache the result of getBestAvailableSequenceDictionary instead of calling it on every variant.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6672
https://github.com/broadinstitute/gatk/issues/6674:324,Availability,failure,failure,324,"After doing somatic variant calling, the AD shows that the alternate allele is supported by three to five reads out of typically about eighty reads for almost all of the variants and the patient has about 10 times less SNVs reported in their VCF than all of the other patients with the same disease. Could MuTect2 have a QC failure status output if almost all of the variants reported are close to the limit of detection, which appears to be about three reads for MuTect2, looking at the second AD values in the cancer sample?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674
https://github.com/broadinstitute/gatk/issues/6674:411,Safety,detect,detection,411,"After doing somatic variant calling, the AD shows that the alternate allele is supported by three to five reads out of typically about eighty reads for almost all of the variants and the patient has about 10 times less SNVs reported in their VCF than all of the other patients with the same disease. Could MuTect2 have a QC failure status output if almost all of the variants reported are close to the limit of detection, which appears to be about three reads for MuTect2, looking at the second AD values in the cancer sample?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6674
https://github.com/broadinstitute/gatk/pull/6675:234,Performance,perform,performance,234,"GenomicsDB sometimes returns a 64 bit type as a result of computations. This type is not supported by BCF2Codec while decoding resulting in NPEs - see #6548 and #6667. The initial reservation against using VCFCodec as the default was performance related, benchmarks show the BCF2Codec to be about 10-15% faster than VCF2Codec, but VCFCodec handles all the types correctly. This PR makes VCFCodec the default and the argument `--genomicsdb-use-vcf-codec` has been replaced by `--genomicsdb-use-bcf-codec`. Also, included in this PR are some argument documentation fixes and one bug fix where a com.google.cloud.storage.StorageException was being thrown if a -V argument pointing to a genomicsdb GCS workspace(e.g. gendb.gs://mybucket/myworkspace) did not end in a slash.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6675
https://github.com/broadinstitute/gatk/pull/6675:255,Testability,benchmark,benchmarks,255,"GenomicsDB sometimes returns a 64 bit type as a result of computations. This type is not supported by BCF2Codec while decoding resulting in NPEs - see #6548 and #6667. The initial reservation against using VCFCodec as the default was performance related, benchmarks show the BCF2Codec to be about 10-15% faster than VCF2Codec, but VCFCodec handles all the types correctly. This PR makes VCFCodec the default and the argument `--genomicsdb-use-vcf-codec` has been replaced by `--genomicsdb-use-bcf-codec`. Also, included in this PR are some argument documentation fixes and one bug fix where a com.google.cloud.storage.StorageException was being thrown if a -V argument pointing to a genomicsdb GCS workspace(e.g. gendb.gs://mybucket/myworkspace) did not end in a slash.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6675
https://github.com/broadinstitute/gatk/pull/6676:131,Availability,error,error,131,* A previouus change left a reference to an uninitialized property in build.gradle.; This caused a crash when trying to produce an error message warning that the JDK was not found. Ex: Caused by: groovy.lang.MissingPropertyException: Could not get unknown property 'requiredJavaVersion' for root project 'gatk' of type org.gradle.api.Project; * Fix the crash by removing the reference to the missing property.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6676
https://github.com/broadinstitute/gatk/pull/6676:137,Integrability,message,message,137,* A previouus change left a reference to an uninitialized property in build.gradle.; This caused a crash when trying to produce an error message warning that the JDK was not found. Ex: Caused by: groovy.lang.MissingPropertyException: Could not get unknown property 'requiredJavaVersion' for root project 'gatk' of type org.gradle.api.Project; * Fix the crash by removing the reference to the missing property.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6676
https://github.com/broadinstitute/gatk/issues/6680:1278,Availability,error,error,1278,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I dont see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680
https://github.com/broadinstitute/gatk/issues/6680:472,Modifiability,variab,variables,472,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I dont see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680
https://github.com/broadinstitute/gatk/issues/6680:669,Modifiability,variab,variables,669,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I dont see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680
https://github.com/broadinstitute/gatk/issues/6680:739,Modifiability,variab,variables,739,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I dont see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680
https://github.com/broadinstitute/gatk/issues/6680:992,Modifiability,variab,variables,992,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I dont see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680
https://github.com/broadinstitute/gatk/issues/6680:615,Usability,simpl,simply,615,"**Problem:**; Looking at the runtime block for the funcotator task in the Mutect2 WDL workflow, it doesn't look like `default_disk_space_gb` or `default_ram_mb` has any role in changing the VM resource settings. I dont see them being used at all in the rest of the task block. The correct parameters to change to adjust the memory and disk space for this task are `small_task_mem` and `small_task_disk`. **Suggestion**; Remove `default_disk_space_gb` or `default_ram_mb` variables since they are not being used in the task. This makes it less confusing when users need to adjust the resources being used, they can simply use the `small_task_mem` and `small_task_disk` variables; or ; Have the `default_disk_space_gb` and `default_ram_mb` variables be used in the runtime block with the `select_first` function that way users have the option to adjust the resources being used, and if not the task can use the default runtime_params dictionary values. This allows funcotator its own separate variables for adjusting resources. Workflow Link: ; https://github.com/broadinstitute/gatk/blob/79a4cda5e045a7f62cc7ed61d102fabc3637fafb/scripts/mutect2_wdl/mutect2.wdl#L1101. User Question Link:; https://gatk.broadinstitute.org/hc/en-us/community/posts/360068111052-Mutect2-Funcotator-error-?page=1#community_comment_360011181392",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6680
https://github.com/broadinstitute/gatk/pull/6681:457,Availability,down,down,457,"This introduces a feature for `GenomicsDBImport` that allows merging multiple contigs into fewer genomicsdb partitions. This should give a huge boost for cases where users have a very large number of contigs (see [here ](https://gatk.broadinstitute.org/hc/en-us/community/posts/360060623952-GenomicsDBImport-very-slow-on-genome-with-many-contigs), for instance). Currently, GenomicsDB would create a separate folder/partition for each contig and this slows down import to a crawl with a large number of contigs. . To use this feature, users should set the flag `--merge-contigs-into-num-partitions` to the number of partitions. Using the feature requires that entire contigs be passed as input intervals -- we don't support merging together an interval list that contains partial contigs. . There's no magic threshold where this would start to be useful - we currently warn users when they specify more than 100 intervals, and I think the same threshold makes sense for when they should consider using this flag. Choosing the right value for `--merge-contigs-into-num-partitions` would be dependent on amount of parallelism users want to use (for example, do they want to want to import using `max-num-intervals-to-import-in-parallel`). If no parallelism is envisioned either on import or query, setting `--merge-contigs-into-num-partitions` to `1` should work as well -- though the user may find it more reassuring to break up the work into more partitions just so you can see some progress being made....",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6681
https://github.com/broadinstitute/gatk/pull/6681:1089,Integrability,depend,dependent,1089,"This introduces a feature for `GenomicsDBImport` that allows merging multiple contigs into fewer genomicsdb partitions. This should give a huge boost for cases where users have a very large number of contigs (see [here ](https://gatk.broadinstitute.org/hc/en-us/community/posts/360060623952-GenomicsDBImport-very-slow-on-genome-with-many-contigs), for instance). Currently, GenomicsDB would create a separate folder/partition for each contig and this slows down import to a crawl with a large number of contigs. . To use this feature, users should set the flag `--merge-contigs-into-num-partitions` to the number of partitions. Using the feature requires that entire contigs be passed as input intervals -- we don't support merging together an interval list that contains partial contigs. . There's no magic threshold where this would start to be useful - we currently warn users when they specify more than 100 intervals, and I think the same threshold makes sense for when they should consider using this flag. Choosing the right value for `--merge-contigs-into-num-partitions` would be dependent on amount of parallelism users want to use (for example, do they want to want to import using `max-num-intervals-to-import-in-parallel`). If no parallelism is envisioned either on import or query, setting `--merge-contigs-into-num-partitions` to `1` should work as well -- though the user may find it more reassuring to break up the work into more partitions just so you can see some progress being made....",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6681
https://github.com/broadinstitute/gatk/issues/6685:38,Deployability,pipeline,pipeline,38,"According to #2858, the new [GATK CNV pipeline](https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/somatic) is intended to replace AllelicCNV (because it now segments jointly on total copy ratio and allelic fraction). We've found the segmentation to be great for WGS data, but the new workflow does not create the same outputs as AllelicCNV - in particular, AllelicCNV generated a *-sim-final.acs.seg that could be used for [ABSOLUTE](https://software.broadinstitute.org/cancer/cga/absolute) and [DeTiN](https://github.com/getzlab/deTiN). We'd like to run these tools - Is there any way to get the equivalent of this file from the workflow's outputs? None of the outputs look like *-sim-final.acs.seg. . If not, I had planned to simply run AllelicCNV (or AllelicCapseg) using files from the new workflow. The only issue is that the input files are unclear to me - I've provided a table below with what I believe the matchups relative to the old GATK CNV workflow to be, but it would be great to get clarification!. Name of file | Old GATK CNV (task) | New GATK CNV (task); -- | -- | --; tumorHets | *.tumor.hets.tsv (GetHetCoverage) | *.hets.tsv (ModelSegments); segments | *.seg (PerformSegmentation) | *.modelFinal.seg (ModelSegments); tangentNormalized | *.tn.tsv (NormalizeSomaticReadCounts) | ????? (maybe .denoisedCR.tsv from DenoiseReadCounts?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6685
https://github.com/broadinstitute/gatk/issues/6685:1197,Performance,Perform,PerformSegmentation,1197,"According to #2858, the new [GATK CNV pipeline](https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/somatic) is intended to replace AllelicCNV (because it now segments jointly on total copy ratio and allelic fraction). We've found the segmentation to be great for WGS data, but the new workflow does not create the same outputs as AllelicCNV - in particular, AllelicCNV generated a *-sim-final.acs.seg that could be used for [ABSOLUTE](https://software.broadinstitute.org/cancer/cga/absolute) and [DeTiN](https://github.com/getzlab/deTiN). We'd like to run these tools - Is there any way to get the equivalent of this file from the workflow's outputs? None of the outputs look like *-sim-final.acs.seg. . If not, I had planned to simply run AllelicCNV (or AllelicCapseg) using files from the new workflow. The only issue is that the input files are unclear to me - I've provided a table below with what I believe the matchups relative to the old GATK CNV workflow to be, but it would be great to get clarification!. Name of file | Old GATK CNV (task) | New GATK CNV (task); -- | -- | --; tumorHets | *.tumor.hets.tsv (GetHetCoverage) | *.hets.tsv (ModelSegments); segments | *.seg (PerformSegmentation) | *.modelFinal.seg (ModelSegments); tangentNormalized | *.tn.tsv (NormalizeSomaticReadCounts) | ????? (maybe .denoisedCR.tsv from DenoiseReadCounts?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6685
https://github.com/broadinstitute/gatk/issues/6685:745,Usability,simpl,simply,745,"According to #2858, the new [GATK CNV pipeline](https://github.com/broadinstitute/gatk/tree/master/scripts/cnv_wdl/somatic) is intended to replace AllelicCNV (because it now segments jointly on total copy ratio and allelic fraction). We've found the segmentation to be great for WGS data, but the new workflow does not create the same outputs as AllelicCNV - in particular, AllelicCNV generated a *-sim-final.acs.seg that could be used for [ABSOLUTE](https://software.broadinstitute.org/cancer/cga/absolute) and [DeTiN](https://github.com/getzlab/deTiN). We'd like to run these tools - Is there any way to get the equivalent of this file from the workflow's outputs? None of the outputs look like *-sim-final.acs.seg. . If not, I had planned to simply run AllelicCNV (or AllelicCapseg) using files from the new workflow. The only issue is that the input files are unclear to me - I've provided a table below with what I believe the matchups relative to the old GATK CNV workflow to be, but it would be great to get clarification!. Name of file | Old GATK CNV (task) | New GATK CNV (task); -- | -- | --; tumorHets | *.tumor.hets.tsv (GetHetCoverage) | *.hets.tsv (ModelSegments); segments | *.seg (PerformSegmentation) | *.modelFinal.seg (ModelSegments); tangentNormalized | *.tn.tsv (NormalizeSomaticReadCounts) | ????? (maybe .denoisedCR.tsv from DenoiseReadCounts?)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6685
https://github.com/broadinstitute/gatk/issues/6686:236,Availability,error,error,236,"Prior to assembly (in `AssemblyBasedCallerUtils.assembleReads`, we transform reads in several ways that are meant to be permanent (that is, we want to use them in both assembly and genotyping) within `finalizeRegion`. (Additionally, we error reads within `ReadThreadingAssembler.runLocalAssembly`, but this is done on temporary copies of reads that are used for kmers and discarded). These transformations include hard clipping low-quality ends, adaptor sequences, and, optionally, soft-clipped bases, as well as correcting the base qualities of overlapping mates. According to the git history, these transformations have been accidentally temporary for quite a while. Let's look at the relevant code. First, in `Mutect2Engine.callRegion` we have (comments added and code simplified for clarity). ```; final AssemblyRegion assemblyActiveRegion = AssemblyBasedCallerUtils.assemblyRegionWithWellMappedReads(originalAssemblyRegion . . .);. // assembleReads finalizes region, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686
https://github.com/broadinstitute/gatk/issues/6686:2719,Availability,error,error,2719,"egion, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(hcArgs.maxMnpDistance);. // same things as Mutect2  we trim on the unmodified region; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(region, allVariationEvents, referenceContext);. // same as Mutect2; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. In addition to the proposed simple fix, this brings up a few code smells:. * One would expect assembly not to modify its input reads, but it does through the side effect of `finalizeRegion`.; * Assembly has both the permanent changes of finalize region and the temporary changes of read error correction.; * `AssemblyResultSet` stores the reads but so does `AssemblyRegion`. Without doing any serious refactoring, perhaps `finalizeRegion` could at least be split off from assembly so that the latter does not stealthily modify reads.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686
https://github.com/broadinstitute/gatk/issues/6686:446,Energy Efficiency,adapt,adaptor,446,"Prior to assembly (in `AssemblyBasedCallerUtils.assembleReads`, we transform reads in several ways that are meant to be permanent (that is, we want to use them in both assembly and genotyping) within `finalizeRegion`. (Additionally, we error reads within `ReadThreadingAssembler.runLocalAssembly`, but this is done on temporary copies of reads that are used for kmers and discarded). These transformations include hard clipping low-quality ends, adaptor sequences, and, optionally, soft-clipped bases, as well as correcting the base qualities of overlapping mates. According to the git history, these transformations have been accidentally temporary for quite a while. Let's look at the relevant code. First, in `Mutect2Engine.callRegion` we have (comments added and code simplified for clarity). ```; final AssemblyRegion assemblyActiveRegion = AssemblyBasedCallerUtils.assemblyRegionWithWellMappedReads(originalAssemblyRegion . . .);. // assembleReads finalizes region, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686
https://github.com/broadinstitute/gatk/issues/6686:446,Modifiability,adapt,adaptor,446,"Prior to assembly (in `AssemblyBasedCallerUtils.assembleReads`, we transform reads in several ways that are meant to be permanent (that is, we want to use them in both assembly and genotyping) within `finalizeRegion`. (Additionally, we error reads within `ReadThreadingAssembler.runLocalAssembly`, but this is done on temporary copies of reads that are used for kmers and discarded). These transformations include hard clipping low-quality ends, adaptor sequences, and, optionally, soft-clipped bases, as well as correcting the base qualities of overlapping mates. According to the git history, these transformations have been accidentally temporary for quite a while. Let's look at the relevant code. First, in `Mutect2Engine.callRegion` we have (comments added and code simplified for clarity). ```; final AssemblyRegion assemblyActiveRegion = AssemblyBasedCallerUtils.assemblyRegionWithWellMappedReads(originalAssemblyRegion . . .);. // assembleReads finalizes region, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686
https://github.com/broadinstitute/gatk/issues/6686:2833,Modifiability,refactor,refactoring,2833,"egion, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(hcArgs.maxMnpDistance);. // same things as Mutect2  we trim on the unmodified region; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(region, allVariationEvents, referenceContext);. // same as Mutect2; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. In addition to the proposed simple fix, this brings up a few code smells:. * One would expect assembly not to modify its input reads, but it does through the side effect of `finalizeRegion`.; * Assembly has both the permanent changes of finalize region and the temporary changes of read error correction.; * `AssemblyResultSet` stores the reads but so does `AssemblyRegion`. Without doing any serious refactoring, perhaps `finalizeRegion` could at least be split off from assembly so that the latter does not stealthily modify reads.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686
https://github.com/broadinstitute/gatk/issues/6686:772,Usability,simpl,simplified,772,"Prior to assembly (in `AssemblyBasedCallerUtils.assembleReads`, we transform reads in several ways that are meant to be permanent (that is, we want to use them in both assembly and genotyping) within `finalizeRegion`. (Additionally, we error reads within `ReadThreadingAssembler.runLocalAssembly`, but this is done on temporary copies of reads that are used for kmers and discarded). These transformations include hard clipping low-quality ends, adaptor sequences, and, optionally, soft-clipped bases, as well as correcting the base qualities of overlapping mates. According to the git history, these transformations have been accidentally temporary for quite a while. Let's look at the relevant code. First, in `Mutect2Engine.callRegion` we have (comments added and code simplified for clarity). ```; final AssemblyRegion assemblyActiveRegion = AssemblyBasedCallerUtils.assemblyRegionWithWellMappedReads(originalAssemblyRegion . . .);. // assembleReads finalizes region, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686
https://github.com/broadinstitute/gatk/issues/6686:2460,Usability,simpl,simple,2460,"egion, modifying reads as a side effect; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(assemblyActiveRegion. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(MTAC.maxMnpDistance);. // when we trim on the originalAssemblyRegion, the trimmingResult takes its un-modified reads!; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(originalAssemblyRegion, allVariationEvents, referenceContext);. // now the assemblyResult gets the unmodified reads of the trimmingResult!; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. If we want things like `-dont-use-soft-clipped-bases` to work, we should call `trimmer.trim` on `untrimmedAssemblyResult`. I think that change alone may be all we need. Let's look at the corresponding code in `HaplotypeCallerEngine`:. ```; final AssemblyResultSet untrimmedAssemblyResult = AssemblyBasedCallerUtils.assembleReads(region. . .);. final SortedSet<VariantContext> allVariationEvents = untrimmedAssemblyResult.getVariationEvents(hcArgs.maxMnpDistance);. // same things as Mutect2  we trim on the unmodified region; final AssemblyRegionTrimmer.Result trimmingResult = trimmer.trim(region, allVariationEvents, referenceContext);. // same as Mutect2; final AssemblyResultSet assemblyResult = untrimmedAssemblyResult.trimTo(trimmingResult.getVariantRegion());; ```. In addition to the proposed simple fix, this brings up a few code smells:. * One would expect assembly not to modify its input reads, but it does through the side effect of `finalizeRegion`.; * Assembly has both the permanent changes of finalize region and the temporary changes of read error correction.; * `AssemblyResultSet` stores the reads but so does `AssemblyRegion`. Without doing any serious refactoring, perhaps `finalizeRegion` could at least be split off from assembly so that the latter does not stealthily modify reads.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6686
https://github.com/broadinstitute/gatk/issues/6687:575,Availability,avail,available,575,"## Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); version 4.1.6.0. ### Description ; I am pre-aligning a paired-end RNA-seq dataset to the human host genome using STAR. I get a `Uniquely mapped reads %` of 83.24%. Next, I run PathSeqPipelineSpark using `--is-host-aligned true` and the default options. When I look at the filter-metrics file, I see `PRIMARY_READS` = 1,057,098 and `READS_AFTER_PREALIGNED_HOST_FILTER` = 543,664. #### Steps to reproduce; This is on a dataset that I can't share but I'm happy to reproduce this on a publicly available dataset if you need that. . #### Expected behavior; I would expect >= 83.24% of reads to be filtered by the PREALIGNED_HOST_FILTER step. . #### Actual behavior; < 50% of the reads are filtered by the PREALIGNED_HOST_FILTER step. . Do you have any insight into what's going on? Should I be using an aligner other than STAR? Are there RNA-seq specific instructions for running PathSeq?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6687
https://github.com/broadinstitute/gatk/issues/6688:253,Usability,clear,clear,253,"We are running GenomicsDBImport on a single chromosome with about 96 WGS gVCF samples as input. It's being run on a slurm cluster, lustre filesystem. Most of the scatter jobs finished, but the 4 largest have been sitting for nearly 5 days, and it's not clear whether they're doing anything, or what the problem is. Can you suggest any debugging steps to try to troubleshoot what's going on with the jobs? The command is essentially this:. java -Djava.io.tmpdir=<a local SSD on the node> \; -Xmx128g -Xms128g -Xss2m \; -jar GenomeAnalysisTK4.jar \; GenomicsDBImport \; -V <repeated for 96 different gVCFs> \; -L intervals.list \; --genomicsdb-workspace-path <a lustre directory>. Thanks for any debugging suggestions. -Ben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6688
https://github.com/broadinstitute/gatk/issues/6689:3710,Availability,avail,available,3710,orEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitute.hellbender.Main.main(Main.java:292). I realize this is a open source project. But I've made copy of the failing VCF available at:; /dsde/working/fleharty/tmp/buggy.vcf; /dsde/working/fleharty/tmp/buggy.vcf.idx. #### Steps to reproduce; gatk VariantAnnotator -V buggy.vcf --resource:gnomad af-only-gnomad.raw.sites.vcf -E gnomad.AF --resource-allele-concordance -O gnomad_annotated.vcf; #### Expected behavior; Should work. #### Actual behavior; Throws exception,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:113,Deployability,release,release,113,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:2575,Integrability,wrap,wrapAndCopyInto,2575,AnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:392,Security,Validat,Validation,392,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:403,Security,validat,validateGenotypes,403,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:496,Security,Validat,Validation,496,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:507,Security,access,access,507,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:593,Security,Validat,Validation,593,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:606,Security,validat,validate,606,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:697,Security,validat,validate,697,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:834,Security,validat,validate,834,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6689:183,Testability,test,test,183,"## Bug Report. ### Affected tool(s) or class(es); VariantAnnotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description . Throws an exception on a legal variant. java.lang.IllegalStateException: Allele in genotype G not in the variant context [G*, G, GT]; 	at htsjdk.variant.variantcontext.VariantContext$Validation.validateGenotypes(VariantContext.java:382); 	at htsjdk.variant.variantcontext.VariantContext$Validation.access$200(VariantContext.java:323); 	at htsjdk.variant.variantcontext.VariantContext$Validation$2.validate(VariantContext.java:331); 	at htsjdk.variant.variantcontext.VariantContext.lambda$validate$0(VariantContext.java:1384); 	at java.lang.Iterable.forEach(Iterable.java:75); 	at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1384); 	at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); 	at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1329); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.trimAlleles(GATKVariantContextUtils.java:1285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.getMinRepresentationBiallelics(VariantAnnotatorEngine.java:499); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateExpressions(VariantAnnotatorEngine.java:440); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.annotateContext(VariantAnnotatorEngine.java:285); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:230); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6689
https://github.com/broadinstitute/gatk/issues/6690:54,Deployability,release,release,54,"Hello, thanks for great software.; After GATK 4.1.8.0 release we updated our internal Docker containers (from GATK v4.1.7.0) and noticed changes in Haplotype Caller results:. [check_against_37.woRandomLine.vcf.txt](https://github.com/broadinstitute/gatk/files/4864731/check_against_37.woRandomLine.vcf.txt); [test_v37.haplotypecaller.woRandomLine.vcf.txt](https://github.com/broadinstitute/gatk/files/4864733/test_v37.haplotypecaller.woRandomLine.vcf.txt). Here is the difference:; ```; 17	7571487	rs17880560	A	AGCCGTG	166.10	.	AC=2;AF=1.00;AN=2;DB;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.693	GT:AD:DP:GQ:PL	1/1:0,4:4:12:180,12,0; 17	7571487	rs17880560;rs79948390	A	AGCCGTG	166.10	.	AC=2;AF=1.00;AN=2;DB;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.693	GT:AD:DP:GQ:PL	1/1:0,4:4:12:180,12,0; ```; ```; 17	7578711	rs141204613	CTTT	C	232.93	.	AC=2;AF=1.00;AN=2;DB;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.83;QD=30.97;SOR=1.329	GT:AD:DP:GQ:PL	1/1:0,6:6:18:247,18,0; 17	7578711	rs141204613;rs5819162	CTTT	C	232.93	.	AC=2;AF=1.00;AN=2;DB;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.83;QD=30.97;SOR=1.329	GT:AD:DP:GQ:PL	1/1:0,6:6:18:247,18,0; ```; ```; 17	7579643	rs150200764	CCCCCAGCCCTCCAGGT	C	1834.03	.	AC=2;AF=1.00;AN=2;DB;DP=52;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=61.03;QD=27.24;SOR=0.843	GT:AD:DP:GQ:PL	1/1:0,41:41:99:1848,125,0; 17	7579643	rs150200764;rs146534833;rs59758982	CCCCCAGCCCTCCAGGT	C	1834.03	.	AC=2;AF=1.00;AN=2;DB;DP=52;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=61.03;QD=27.24;SOR=0.843	GT:AD:DP:GQ:PL	1/1:0,41:41:99:1848,125,0; ```; New file (test_v37) contains multiple `rsID` in `ID` field. Is that expected behavior or not? ; I can't find any info about in in changelog.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6690
https://github.com/broadinstitute/gatk/issues/6690:65,Deployability,update,updated,65,"Hello, thanks for great software.; After GATK 4.1.8.0 release we updated our internal Docker containers (from GATK v4.1.7.0) and noticed changes in Haplotype Caller results:. [check_against_37.woRandomLine.vcf.txt](https://github.com/broadinstitute/gatk/files/4864731/check_against_37.woRandomLine.vcf.txt); [test_v37.haplotypecaller.woRandomLine.vcf.txt](https://github.com/broadinstitute/gatk/files/4864733/test_v37.haplotypecaller.woRandomLine.vcf.txt). Here is the difference:; ```; 17	7571487	rs17880560	A	AGCCGTG	166.10	.	AC=2;AF=1.00;AN=2;DB;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.693	GT:AD:DP:GQ:PL	1/1:0,4:4:12:180,12,0; 17	7571487	rs17880560;rs79948390	A	AGCCGTG	166.10	.	AC=2;AF=1.00;AN=2;DB;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.00;QD=28.73;SOR=0.693	GT:AD:DP:GQ:PL	1/1:0,4:4:12:180,12,0; ```; ```; 17	7578711	rs141204613	CTTT	C	232.93	.	AC=2;AF=1.00;AN=2;DB;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.83;QD=30.97;SOR=1.329	GT:AD:DP:GQ:PL	1/1:0,6:6:18:247,18,0; 17	7578711	rs141204613;rs5819162	CTTT	C	232.93	.	AC=2;AF=1.00;AN=2;DB;DP=13;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=60.83;QD=30.97;SOR=1.329	GT:AD:DP:GQ:PL	1/1:0,6:6:18:247,18,0; ```; ```; 17	7579643	rs150200764	CCCCCAGCCCTCCAGGT	C	1834.03	.	AC=2;AF=1.00;AN=2;DB;DP=52;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=61.03;QD=27.24;SOR=0.843	GT:AD:DP:GQ:PL	1/1:0,41:41:99:1848,125,0; 17	7579643	rs150200764;rs146534833;rs59758982	CCCCCAGCCCTCCAGGT	C	1834.03	.	AC=2;AF=1.00;AN=2;DB;DP=52;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=61.03;QD=27.24;SOR=0.843	GT:AD:DP:GQ:PL	1/1:0,41:41:99:1848,125,0; ```; New file (test_v37) contains multiple `rsID` in `ID` field. Is that expected behavior or not? ; I can't find any info about in in changelog.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6690
https://github.com/broadinstitute/gatk/issues/6693:107,Deployability,release,release,107,## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; Funcotator appears to output an unnecessary extra tab at the end of each line. The change appears to have happened between gatk 4.1.4.0 and 4.1.6.0. #### Expected behavior; Output correct number of tabs corresponding to the number of column headers. #### Actual behavior; Outputs an extra tab.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6693
https://github.com/broadinstitute/gatk/issues/6693:177,Testability,test,test,177,## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); - [x] Latest public release version [version?]; - [x] Latest master branch as of [date of test?]. ### Description ; Funcotator appears to output an unnecessary extra tab at the end of each line. The change appears to have happened between gatk 4.1.4.0 and 4.1.6.0. #### Expected behavior; Output correct number of tabs corresponding to the number of column headers. #### Actual behavior; Outputs an extra tab.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6693
https://github.com/broadinstitute/gatk/issues/6695:277,Availability,Error,Error,277,"I have problems running gatk Mutect2. . ### gatk version; - 4.1.8.0. #### command-line. `gatk Mutect2 -R /home/proj/stage/cancer/reference/GRCh37/genome/human_g1k_v37_decoy.fasta -L /home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg1`. ### Error; ```; Using GATK jar /home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar Mutect2 -R /home/proj/stage/cancer/reference/GRCh37/genome/human_g1k_v37_decoy.fasta -L /home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed -I consensus/concatenated_ACC5611A1_XXXXXX_consensusalign_ss_r2.bam -O mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 09:39:55.358 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 03, 2020 9:39:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:39:55.559 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.559 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.0; 09:39:55.559 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:39:55.559 INFO Mutect2 - Executing as ashwini.jeggari@hasta.scilifelab.se on Linux v3.10.0-1062.4.1.el7.x86_64 amd64; 09:39:55.560 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 09:39:55.560 INFO Mutect2 - Start Date/Time: July 3, 2020 9:39:55 AM CEST; 09:39:55.560 INFO Mutect2 - ------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:3757,Availability,Avail,Available,3757,"ys: disabled; 09:39:55.561 INFO Mutect2 - Initializing engine; 09:39:56.014 INFO FeatureManager - Using codec BEDCodec to read file file:///home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed; 09:39:56.024 INFO IntervalArgumentCollection - Processing 74592 bp from intervals; 09:39:56.032 INFO Mutect2 - Done initializing engine; 09:39:56.044 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:39:56.077 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 09:39:56.139 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 09:39:56.139 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 09:39:56.139 INFO IntelPairHmm - Available threads: 36; 09:39:56.139 INFO IntelPairHmm - Requested threads: 4; 09:39:56.139 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 09:39:56.146 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 09:39:56.146 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 09:39:56.146 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 09:39:56.148 INFO Mutect2 - Shutting down engine; [July 3, 2020 9:39:56 AM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2233991168; htsjdk.samtools.util.RuntimeIOException: File not found: mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.java:451); 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:4244,Availability,down,down,4244,"hare/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:39:56.077 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 09:39:56.139 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 09:39:56.139 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 09:39:56.139 INFO IntelPairHmm - Available threads: 36; 09:39:56.139 INFO IntelPairHmm - Requested threads: 4; 09:39:56.139 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 09:39:56.146 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 09:39:56.146 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 09:39:56.146 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 09:39:56.148 INFO Mutect2 - Shutting down engine; [July 3, 2020 9:39:56 AM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2233991168; htsjdk.samtools.util.RuntimeIOException: File not found: mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.java:451); 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.java:415); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.createVCFWriter(GATKVariantContextUtils.java:121); 	at org.broadinstitute.hellbender.engine.GATKTool.createVCFWriter(GATKTool.java:887); 	at org.broadinstitute.hellbender.engine.GATKTool.createVCFWriter(GATKTool.java:841); 	at org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2.onTraversalStart(Mutect2.java:262); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:1862,Deployability,release,release-,1862,"_ACC5611A1_XXXXXX_consensusalign_ss_r2.bam -O mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 09:39:55.358 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 03, 2020 9:39:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:39:55.559 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.559 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.0; 09:39:55.559 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:39:55.559 INFO Mutect2 - Executing as ashwini.jeggari@hasta.scilifelab.se on Linux v3.10.0-1062.4.1.el7.x86_64 amd64; 09:39:55.560 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 09:39:55.560 INFO Mutect2 - Start Date/Time: July 3, 2020 9:39:55 AM CEST; 09:39:55.560 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.560 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.560 INFO Mutect2 - HTSJDK Version: 2.22.0; 09:39:55.561 INFO Mutect2 - Picard Version: 2.22.8; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:39:55.561 INFO Mutect2 - Deflater: IntelDeflater; 09:39:55.561 INFO Mutect2 - Inflater: IntelInflater; 09:39:55.561 INFO Mutect2 - GCS max retries/reopens: 20; 09:39:55.561 INFO Mutect2 - Requester pays: disabled; 09:39:55.561 INFO Mutect2 - Initializing engine; 09:39:56.014 INFO FeatureManager - Using codec BE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:1029,Performance,Load,Loading,1029,"k Mutect2. . ### gatk version; - 4.1.8.0. #### command-line. `gatk Mutect2 -R /home/proj/stage/cancer/reference/GRCh37/genome/human_g1k_v37_decoy.fasta -L /home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg1`. ### Error; ```; Using GATK jar /home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar Mutect2 -R /home/proj/stage/cancer/reference/GRCh37/genome/human_g1k_v37_decoy.fasta -L /home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed -I consensus/concatenated_ACC5611A1_XXXXXX_consensusalign_ss_r2.bam -O mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 09:39:55.358 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 03, 2020 9:39:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:39:55.559 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.559 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.0; 09:39:55.559 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:39:55.559 INFO Mutect2 - Executing as ashwini.jeggari@hasta.scilifelab.se on Linux v3.10.0-1062.4.1.el7.x86_64 amd64; 09:39:55.560 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 09:39:55.560 INFO Mutect2 - Start Date/Time: July 3, 2020 9:39:55 AM CEST; 09:39:55.560 INFO Mutect2 - --------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:3179,Performance,Load,Loading,3179,ion: 2.22.0; 09:39:55.561 INFO Mutect2 - Picard Version: 2.22.8; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:39:55.561 INFO Mutect2 - Deflater: IntelDeflater; 09:39:55.561 INFO Mutect2 - Inflater: IntelInflater; 09:39:55.561 INFO Mutect2 - GCS max retries/reopens: 20; 09:39:55.561 INFO Mutect2 - Requester pays: disabled; 09:39:55.561 INFO Mutect2 - Initializing engine; 09:39:56.014 INFO FeatureManager - Using codec BEDCodec to read file file:///home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed; 09:39:56.024 INFO IntervalArgumentCollection - Processing 74592 bp from intervals; 09:39:56.032 INFO Mutect2 - Done initializing engine; 09:39:56.044 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:39:56.077 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 09:39:56.139 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 09:39:56.139 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 09:39:56.139 INFO IntelPairHmm - Available threads: 36; 09:39:56.139 INFO IntelPairHmm - Requested threads: 4; 09:39:56.139 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 09:39:56.146 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 09:39:56.146 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 09:39:56.146 INFO SmithWatermanAligner - Total compute time in,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:3385,Performance,Load,Loading,3385,"false; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:39:55.561 INFO Mutect2 - Deflater: IntelDeflater; 09:39:55.561 INFO Mutect2 - Inflater: IntelInflater; 09:39:55.561 INFO Mutect2 - GCS max retries/reopens: 20; 09:39:55.561 INFO Mutect2 - Requester pays: disabled; 09:39:55.561 INFO Mutect2 - Initializing engine; 09:39:56.014 INFO FeatureManager - Using codec BEDCodec to read file file:///home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed; 09:39:56.024 INFO IntervalArgumentCollection - Processing 74592 bp from intervals; 09:39:56.032 INFO Mutect2 - Done initializing engine; 09:39:56.044 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:39:56.077 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 09:39:56.139 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 09:39:56.139 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 09:39:56.139 INFO IntelPairHmm - Available threads: 36; 09:39:56.139 INFO IntelPairHmm - Requested threads: 4; 09:39:56.139 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 09:39:56.146 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 09:39:56.146 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 09:39:56.146 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 09:39:56.148 INFO Mutect2 - Shutting down engine; [July 3, 2020 9:39:56 AM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; R",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:3880,Performance,multi-thread,multi-threaded,3880,":///home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed; 09:39:56.024 INFO IntervalArgumentCollection - Processing 74592 bp from intervals; 09:39:56.032 INFO Mutect2 - Done initializing engine; 09:39:56.044 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 09:39:56.077 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 09:39:56.139 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 09:39:56.139 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 09:39:56.139 INFO IntelPairHmm - Available threads: 36; 09:39:56.139 INFO IntelPairHmm - Requested threads: 4; 09:39:56.139 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 09:39:56.146 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 0.0; 09:39:56.146 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 0.0; 09:39:56.146 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 0.00 sec; 09:39:56.148 INFO Mutect2 - Shutting down engine; [July 3, 2020 9:39:56 AM CEST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=2233991168; htsjdk.samtools.util.RuntimeIOException: File not found: mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.java:451); 	at htsjdk.variant.variantcontext.writer.VariantContextWriterBuilder.build(VariantContextWriterBuilder.java:415); 	at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.createVCFWriter(GATKVariantContextUtils.java:121); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/issues/6695:1336,Safety,detect,detect,1336,"_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar Mutect2 -R /home/proj/stage/cancer/reference/GRCh37/genome/human_g1k_v37_decoy.fasta -L /home/proj/stage/cancer/reference/target_capture_bed/production/balsamic/gicfdna_3.1_hg19_design.bed -I consensus/concatenated_ACC5611A1_XXXXXX_consensusalign_ss_r2.bam -O mutect2/concatenated_ACC5611A1_XXXXXX_mutect2_unfiltered_ss_r2.vcf.gz; 09:39:55.358 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/proj/bin/conda/envs/D_UMI_APJ/share/gatk4-4.1.8.0-0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jul 03, 2020 9:39:55 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:39:55.559 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.559 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.0; 09:39:55.559 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:39:55.559 INFO Mutect2 - Executing as ashwini.jeggari@hasta.scilifelab.se on Linux v3.10.0-1062.4.1.el7.x86_64 amd64; 09:39:55.560 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 09:39:55.560 INFO Mutect2 - Start Date/Time: July 3, 2020 9:39:55 AM CEST; 09:39:55.560 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.560 INFO Mutect2 - ------------------------------------------------------------; 09:39:55.560 INFO Mutect2 - HTSJDK Version: 2.22.0; 09:39:55.561 INFO Mutect2 - Picard Version: 2.22.8; 09:39:55.561 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:39:55.561 INFO Mutect2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6695
https://github.com/broadinstitute/gatk/pull/6698:81,Deployability,patch,patch,81,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:239,Deployability,configurat,configuration,239,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:458,Deployability,configurat,configuration,458,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:676,Deployability,configurat,configuration,676,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:158,Energy Efficiency,reduce,reduce,158,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:356,Integrability,depend,dependencies,356,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:239,Modifiability,config,configuration,239,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:458,Modifiability,config,configuration,458,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:676,Modifiability,config,configuration,676,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:125,Security,access,access,125,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:211,Security,access,accesses,211,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6698:499,Security,access,access,499,"Currently, we need to copy files on S3 to local storage before using; them. This patch enables gatk local and spark modes to access s3a://; files directly to reduce copy overhead and local disk usages. s3a file accesses require additional configuration of core-site.xml; located in CLASSPATH as well as other hadoop applications. Spark; already has hadoop dependencies but local modes need to add hadoop; jars in the classpath. Example core-site.xml:. ```; <configuration>; <property>; <name>fs.s3a.access.key</name>; <value>{Your AWS_ACCESS_KEY_ID}</value>; </property>; <property>; <name>fs.s3a.secret.key</name>; <value>{Your AWS_SECRET_ACCESS_KEY}</value>; </property>; </configuration>; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6698
https://github.com/broadinstitute/gatk/pull/6700:40,Testability,test,tests,40,Discovered by running the autogenerated tests for autogenerated WDL.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6700
https://github.com/broadinstitute/gatk/issues/6701:64,Availability,error,error,64,"In GATK Office hours we found a change that contributed to this error message. The issue may be a bug or an issue with the data that is showing up with the more strict filters in the latest version. This request was created from a contribution made by Igor Islanov on July 06, 2020 12:11 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk](https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk). \--. Good day,. While updating gatk from 4.1.4.0 to 4.1.8.0 and after running pipeline it brakes on FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line is ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/refe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:679,Availability,error,error,679,"In GATK Office hours we found a change that contributed to this error message. The issue may be a bug or an issue with the data that is showing up with the more strict filters in the latest version. This request was created from a contribution made by Igor Islanov on July 06, 2020 12:11 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk](https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk). \--. Good day,. While updating gatk from 4.1.4.0 to 4.1.8.0 and after running pipeline it brakes on FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line is ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/refe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:1627,Availability,error,error,1627,"n FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line is ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O D1394-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp ; ; 14:50:12.699 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/nativ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:6596,Availability,down,down,6596,"0-All.vcf.gz.tbi is out of date (index older than input file). Use IndexFeatureFile to make a new index. ; ; 14:50:13.556 WARN IndexUtils - Feature file ""/mnt/d/GenLab/WES/db/00-common\_all.vcf.gz"" appears to contain no sequence dictionary. Attempting to retrieve a sequence dictionary from the associated index file ; ; 14:50:13.609 WARN IndexUtils - Index file /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz.tbi is out of date (index older than input file). Use IndexFeatureFile to make a new index. ; ; 14:50:13.615 INFO FilterVariantTranches - Done initializing engine ; ; 14:50:13.638 INFO ProgressMeter - Starting traversal ; ; 14:50:13.639 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute ; ; 14:50:13.642 INFO FilterVariantTranches - Starting pass 0 through the variants ; ; 14:50:13.857 INFO FilterVariantTranches - Filtered 0 SNPs out of 4 and filtered 0 indels out of 0 with INFO score: CNN\_2D. ; ; 14:50:13.871 INFO FilterVariantTranches - Shutting down engine ; ; \[July 6, 2020 2:50:13 PM MSK\] org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches done. Elapsed time: 0.02 minutes. ; ; Runtime.totalMemory()=721944576 ; ; htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\* ; ; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.determineReferenceAllele(GATKVariantContextUtils.java:209) ; ; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164) ; ; at org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches.firstPassApply(FilterVariantTranches.java:187) ; ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:625,Deployability,pipeline,pipeline,625,"In GATK Office hours we found a change that contributed to this error message. The issue may be a bug or an issue with the data that is showing up with the more strict filters in the latest version. This request was created from a contribution made by Igor Islanov on July 06, 2020 12:11 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk](https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk). \--. Good day,. While updating gatk from 4.1.4.0 to 4.1.8.0 and after running pipeline it brakes on FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line is ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/refe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:70,Integrability,message,message,70,"In GATK Office hours we found a change that contributed to this error message. The issue may be a bug or an issue with the data that is showing up with the more strict filters in the latest version. This request was created from a contribution made by Igor Islanov on July 06, 2020 12:11 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk](https://gatk.broadinstitute.org/hc/en-us/community/posts/360071204731-FilterVariantTranches-brakes-on-new-version-of-Gatk). \--. Good day,. While updating gatk from 4.1.4.0 to 4.1.8.0 and after running pipeline it brakes on FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line is ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/refe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:8087,Integrability,wrap,wrapAndCopyInto,8087,iantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164) ; ; at org.broadinstitute.hellbender.tools.walkers.vqsr.FilterVariantTranches.firstPassApply(FilterVariantTranches.java:187) ; ; at org.broadinstitute.hellbender.engine.TwoPassVariantWalker.nthPassApply(TwoPassVariantWalker.java:17) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverse$0(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.lambda$traverseVariants$1(MultiplePassVariantWalker.java:77) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472) ; ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverseVariants(MultiplePassVariantWalker.java:75) ; ; at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:40) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:2509,Performance,Load,Loading,2509,"ble-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O D1394-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp ; ; 14:50:12.699 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 06, 2020 2:50:12 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:50:12.890 INFO FilterVariantTranches - ------------------------------------------------------------ ; ; 14:50:12.891 INFO FilterVariantTranches - The Genome Analysis Toolkit (GATK) v4.1.8.0 ; ; 14:50:12.891 INFO FilterVariantTranches - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 14:50:12.891 INFO FilterVariantTranches - Executing as root@Genlab-srv on Linux v4.4.0-18362-Microsoft amd64 ; ; 14:50:12.891 INFO FilterVariantTranches - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_252-8u252-b09-1~18.04-b09 ; ; 14:50:12.891 INFO FilterVariantTranches - S",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:2807,Safety,detect,detect,2807,"samjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O D1394-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp ; ; 14:50:12.699 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 06, 2020 2:50:12 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 14:50:12.890 INFO FilterVariantTranches - ------------------------------------------------------------ ; ; 14:50:12.891 INFO FilterVariantTranches - The Genome Analysis Toolkit (GATK) v4.1.8.0 ; ; 14:50:12.891 INFO FilterVariantTranches - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 14:50:12.891 INFO FilterVariantTranches - Executing as root@Genlab-srv on Linux v4.4.0-18362-Microsoft amd64 ; ; 14:50:12.891 INFO FilterVariantTranches - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_252-8u252-b09-1~18.04-b09 ; ; 14:50:12.891 INFO FilterVariantTranches - Start Date/Time: July 6, 2020 2:50:12 PM MSK ; ; 14:50:12.891 INFO FilterVariantTranches - ------------------------------------------------------------ ; ; 14:50:12.891 INFO FilterVariantTranches - ------------------------------------------------------------ ; ; 14:50:12.892 INFO FilterVariant",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6701:1633,Testability,log,log,1633,"n FilterVariantTranches step with error:. htsjdk.tribble.TribbleException: The provided reference alleles do not appear to represent the same position, C\* vs. T\*. The command line is ; ; gatk FilterVariantTranches -I ${R1%%\_\*}-recal.bam -V ${R1%%\_\*}-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O ${R1%%\_\*}-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp --java-options ""-Xmx24G"". On 4.1.4.0 no problems whatsoever, on 4.1.8.0 not working at all. Double-confirmed by 2 seperate conda envs. The reference file is unchanged during whole running processes, obviously. Full error log: ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx24G -jar /mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar FilterVariantTranches -I D1394-recal.bam -V D1394-annotated.vcf -R /mnt/d/GenLab/WES/reference/hg19.fasta --create-output-variant-index true --resource /mnt/d/GenLab/WES/db/00-All.vcf.gz --resource /mnt/d/GenLab/WES/db/00-common\_all.vcf.gz --resource /mnt/d/GenLab/WES/reference/1000G\_phase1.indels.hg19.sites.vcf --resource /mnt/d/GenLab/WES/reference/Mills\_and\_1000G\_gold\_standard.indels.hg19.sites.vcf --snp-tranche 99.9 --snp-tranche 99.95 --indel-tranche 99.0 --indel-tranche 99.4 -O D1394-filtered.vcf --tmp-dir /mnt/d/GenLab/WES/output/tmp ; ; 14:50:12.699 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/mnt/d/GenLab/WES/software/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/nativ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6701
https://github.com/broadinstitute/gatk/issues/6703:51,Availability,Down,Downloads,51,I WAS running this commande : java -jar /Users/mac/Downloads/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar RealignerTargetCreator \ -R /Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta -I /Users/mac/Desktop/NGS/marked-duplicates42.bam -O SRR6369642_realtarget.list ; I get : ; A USER ERROR has occurred: RealignerTargetCreator is no longer included in GATK as of version 4.0.0.0. Please use GATK3 to run this tool. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6703
https://github.com/broadinstitute/gatk/issues/6703:287,Availability,ERROR,ERROR,287,I WAS running this commande : java -jar /Users/mac/Downloads/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar RealignerTargetCreator \ -R /Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta -I /Users/mac/Desktop/NGS/marked-duplicates42.bam -O SRR6369642_realtarget.list ; I get : ; A USER ERROR has occurred: RealignerTargetCreator is no longer included in GATK as of version 4.0.0.0. Please use GATK3 to run this tool. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6703
https://github.com/broadinstitute/gatk/issues/6705:606,Availability,error,error,606,"# Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:725,Availability,error,error,725,"# Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:810,Availability,error,error,810,"# Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:937,Availability,error,error,937,"g Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:1141,Availability,error,error,1141," subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/325/GCF_000007325.1_ASM732v1/GCF_000007325.1_ASM732v1_cds_from_genomic.fna.gz""; SL1344_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/855/GCF_000210855.2_ASM21085v2/GCF_000210855.2_ASM21085v2_cds_from_genomic.fna.gz""; LT2_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:1600,Availability,error,error,1600,"error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/325/GCF_000007325.1_ASM732v1/GCF_000007325.1_ASM732v1_cds_from_genomic.fna.gz""; SL1344_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/855/GCF_000210855.2_ASM21085v2/GCF_000210855.2_ASM21085v2_cds_from_genomic.fna.gz""; LT2_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/006/945/GCF_000006945.2_ASM694v2/GCF_000006945.2_ASM694v2_cds_from_genomic.fna.gz"". CDS_FA = join(""data"", ""{patient}_cds_from_genomic.fa""); SL1344_CDS_FA = CDS_FA.format(patient=""SL1344""); ATCC25586_CDS_FA = CDS_FA.format(patient=""ATCC25586""); LT2_CDS_FA = CDS_FA.format(patient=""LT2""); FQ1_PREFIX =",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:1840,Availability,error,error,1840,"umber of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/007/325/GCF_000007325.1_ASM732v1/GCF_000007325.1_ASM732v1_cds_from_genomic.fna.gz""; SL1344_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/210/855/GCF_000210855.2_ASM21085v2/GCF_000210855.2_ASM21085v2_cds_from_genomic.fna.gz""; LT2_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/006/945/GCF_000006945.2_ASM694v2/GCF_000006945.2_ASM694v2_cds_from_genomic.fna.gz"". CDS_FA = join(""data"", ""{patient}_cds_from_genomic.fa""); SL1344_CDS_FA = CDS_FA.format(patient=""SL1344""); ATCC25586_CDS_FA = CDS_FA.format(patient=""ATCC25586""); LT2_CDS_FA = CDS_FA.format(patient=""LT2""); FQ1_PREFIX = join(""output"", ""simulated_{patient}-{sample}""); FQ1 = join(""output"", ""simulated_{patient}-{sample}_R1.fastq.gz""); pathseq_bam = join(""output"", ""PathSeq"", ""{patient}-{sample}"", ""pathseq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:3754,Availability,down,download,3754,"seq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""ATCC25586"", ""SL1344"", ""LT2"", ""ATCC25586"", ""SL1344"", ""LT2""], ""sample"": [""1"", ""1"", ""1"", ""2"", ""2"", ""2""]}). localrules: simulate_RNAseq_reads, download_ATCC25586_cds_from_genomic, download_LT2_cds_from_genomic, download_SL1344_cds_from_genomic. rule all:; input:; expand(output/{patient}-{sample}/unaligned_simulated_bam.bam, zip, sample=samples[""sample""], patient=samples[""patient""]); # run this bam file through PathSeq. rule convert_FASTA_to_BAM:; input:; fq1=FQ1,; output:; output/{patient}-{sample}/unaligned_simulated_bam.bam; shell:; ""module load picard && ""; ""java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar ""; ""FastqToSam F1={input.fq1} O={output} ""; ""SM={wildcards.sample} RG={wildcards.sample} ""; ""TMP_DIR=/lscratch/$SLURM_JOBID"". rule simulate_RNAseq_reads:; conda:; ""../envs/rsubread-env.yaml""; params:; FQ1_PREFIX; input:; CDS_FA; output:; FQ1; script:; ""R/simulate_RNAseq.R"". # download the cds_from_genomic fasta file; rule download_SL1344_cds_from_genomic:; params:; url=SL1344_CDS_URL; output:; SL1344_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_LT2_cds_from_genomic:; params:; url=LT2_CDS_URL; output:; LT2_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_ATCC25586_cds_from_genomic:; params:; url=ATCC25586_CDS_URL; output:; ATCC25586_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}""; ```; rsubread-env.yaml; ```; name: rsubread; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - bioconductor-rsubread; - bioconductor-biostrings; ```; simulate_RNAseq.R; ```; library(Rsubread); library(Biostrings); set.seed(strtoi(snakemake@wildcards[[""sample""]])). fasta = readDNAStringSet(snakemake@input[[1]]). expr = matrix(1, ncol=1, nrow=length(fasta)). simReads(transcript.file=snakemake@input[[1]], expression.levels=expr,; output.prefix=snakemake@params[[1]], library.size=100000, simulate.sequencing.error=TRUE); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:4772,Availability,error,error,4772,"seq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""ATCC25586"", ""SL1344"", ""LT2"", ""ATCC25586"", ""SL1344"", ""LT2""], ""sample"": [""1"", ""1"", ""1"", ""2"", ""2"", ""2""]}). localrules: simulate_RNAseq_reads, download_ATCC25586_cds_from_genomic, download_LT2_cds_from_genomic, download_SL1344_cds_from_genomic. rule all:; input:; expand(output/{patient}-{sample}/unaligned_simulated_bam.bam, zip, sample=samples[""sample""], patient=samples[""patient""]); # run this bam file through PathSeq. rule convert_FASTA_to_BAM:; input:; fq1=FQ1,; output:; output/{patient}-{sample}/unaligned_simulated_bam.bam; shell:; ""module load picard && ""; ""java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar ""; ""FastqToSam F1={input.fq1} O={output} ""; ""SM={wildcards.sample} RG={wildcards.sample} ""; ""TMP_DIR=/lscratch/$SLURM_JOBID"". rule simulate_RNAseq_reads:; conda:; ""../envs/rsubread-env.yaml""; params:; FQ1_PREFIX; input:; CDS_FA; output:; FQ1; script:; ""R/simulate_RNAseq.R"". # download the cds_from_genomic fasta file; rule download_SL1344_cds_from_genomic:; params:; url=SL1344_CDS_URL; output:; SL1344_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_LT2_cds_from_genomic:; params:; url=LT2_CDS_URL; output:; LT2_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_ATCC25586_cds_from_genomic:; params:; url=ATCC25586_CDS_URL; output:; ATCC25586_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}""; ```; rsubread-env.yaml; ```; name: rsubread; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - bioconductor-rsubread; - bioconductor-biostrings; ```; simulate_RNAseq.R; ```; library(Rsubread); library(Biostrings); set.seed(strtoi(snakemake@wildcards[[""sample""]])). fasta = readDNAStringSet(snakemake@input[[1]]). expr = matrix(1, ncol=1, nrow=length(fasta)). simReads(transcript.file=snakemake@input[[1]], expression.levels=expr,; output.prefix=snakemake@params[[1]], library.size=100000, simulate.sequencing.error=TRUE); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:155,Deployability,pipeline,pipeline,155,"# Bug Report . ### Affected tool(s) or class(es); PathSeq. ### Affected version(s); - 4.1.6.0. ### Description . I wanted to better understand the PathSeq pipeline (and in particular, the Host Filter step) so I simulated RNA-seq reads from three microbial genomes of interest (Salmonella eneterica subsp. enterica serovar Typhimurium str. SL1344, Salmonella eneterica subsp. enterica serovar Typhimurium str. LT2, Fusobacterium nucleatum subsp. nucleatum ATCC 25586). I generate six datasets with 100,000 unpaired reads of length 75 bp (2 datasets from each genome) using Rsubread with simulate.sequencing.error=TRUE and ran them through PathSeq. I generated an identical six datasets using Rsubread with simulate.sequencing.error=FALSE. . #### Expected behavior; For the six datasets with simulate.sequencing.error=TRUE, I would expect a small number of reads to be filtered for each step. For the six datasets with simulate.sequencing.error=FALSE, I would expect similar results but with even fewer reads to be filtered for the low-quality or low complexity read filter. #### Actual behavior; For the six datasets with simulate.sequencing.error=TRUE, 8,496 - 18,103 reads were filtered by the low complexity or low quality filter (the Salmonella datasets were on the lower end and the Fusobacterium datasets were on the higher end), 115 - 311 reads were filtered by the host k-mer filter and 886 - 1822 reads were filtered by the duplicate read filter. . The number of reads filtered by the low complexity or low quality filter seemed high to me so I repeated the analysis with simulate.sequencing.error=FALSE. For these six datasets, all 100,000 reads are filtered by the low-quality or low complexity read filter. . #### Steps to reproduce; I wrote the workflow using snakemake and conda. In theory, you should be able to reproduce the error using `snakemake --use-conda`; Snakefile; ```; from os.path import join; import pandas as pd. ATCC25586_CDS_URL = ""ftp://ftp.ncbi.nlm.nih.gov/genomes/all/G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:4341,Integrability,depend,dependencies,4341,"seq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""ATCC25586"", ""SL1344"", ""LT2"", ""ATCC25586"", ""SL1344"", ""LT2""], ""sample"": [""1"", ""1"", ""1"", ""2"", ""2"", ""2""]}). localrules: simulate_RNAseq_reads, download_ATCC25586_cds_from_genomic, download_LT2_cds_from_genomic, download_SL1344_cds_from_genomic. rule all:; input:; expand(output/{patient}-{sample}/unaligned_simulated_bam.bam, zip, sample=samples[""sample""], patient=samples[""patient""]); # run this bam file through PathSeq. rule convert_FASTA_to_BAM:; input:; fq1=FQ1,; output:; output/{patient}-{sample}/unaligned_simulated_bam.bam; shell:; ""module load picard && ""; ""java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar ""; ""FastqToSam F1={input.fq1} O={output} ""; ""SM={wildcards.sample} RG={wildcards.sample} ""; ""TMP_DIR=/lscratch/$SLURM_JOBID"". rule simulate_RNAseq_reads:; conda:; ""../envs/rsubread-env.yaml""; params:; FQ1_PREFIX; input:; CDS_FA; output:; FQ1; script:; ""R/simulate_RNAseq.R"". # download the cds_from_genomic fasta file; rule download_SL1344_cds_from_genomic:; params:; url=SL1344_CDS_URL; output:; SL1344_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_LT2_cds_from_genomic:; params:; url=LT2_CDS_URL; output:; LT2_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_ATCC25586_cds_from_genomic:; params:; url=ATCC25586_CDS_URL; output:; ATCC25586_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}""; ```; rsubread-env.yaml; ```; name: rsubread; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - bioconductor-rsubread; - bioconductor-biostrings; ```; simulate_RNAseq.R; ```; library(Rsubread); library(Biostrings); set.seed(strtoi(snakemake@wildcards[[""sample""]])). fasta = readDNAStringSet(snakemake@input[[1]]). expr = matrix(1, ncol=1, nrow=length(fasta)). simReads(transcript.file=snakemake@input[[1]], expression.levels=expr,; output.prefix=snakemake@params[[1]], library.size=100000, simulate.sequencing.error=TRUE); ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6705:3391,Performance,load,load,3391,"t}_cds_from_genomic.fa""); SL1344_CDS_FA = CDS_FA.format(patient=""SL1344""); ATCC25586_CDS_FA = CDS_FA.format(patient=""ATCC25586""); LT2_CDS_FA = CDS_FA.format(patient=""LT2""); FQ1_PREFIX = join(""output"", ""simulated_{patient}-{sample}""); FQ1 = join(""output"", ""simulated_{patient}-{sample}_R1.fastq.gz""); pathseq_bam = join(""output"", ""PathSeq"", ""{patient}-{sample}"", ""pathseq.bam""). samples = pd.DataFrame.from_dict({""patient"": [""ATCC25586"", ""SL1344"", ""LT2"", ""ATCC25586"", ""SL1344"", ""LT2""], ""sample"": [""1"", ""1"", ""1"", ""2"", ""2"", ""2""]}). localrules: simulate_RNAseq_reads, download_ATCC25586_cds_from_genomic, download_LT2_cds_from_genomic, download_SL1344_cds_from_genomic. rule all:; input:; expand(output/{patient}-{sample}/unaligned_simulated_bam.bam, zip, sample=samples[""sample""], patient=samples[""patient""]); # run this bam file through PathSeq. rule convert_FASTA_to_BAM:; input:; fq1=FQ1,; output:; output/{patient}-{sample}/unaligned_simulated_bam.bam; shell:; ""module load picard && ""; ""java -Xmx8g -XX:ParallelGCThreads=5 -jar $PICARDJARPATH/picard.jar ""; ""FastqToSam F1={input.fq1} O={output} ""; ""SM={wildcards.sample} RG={wildcards.sample} ""; ""TMP_DIR=/lscratch/$SLURM_JOBID"". rule simulate_RNAseq_reads:; conda:; ""../envs/rsubread-env.yaml""; params:; FQ1_PREFIX; input:; CDS_FA; output:; FQ1; script:; ""R/simulate_RNAseq.R"". # download the cds_from_genomic fasta file; rule download_SL1344_cds_from_genomic:; params:; url=SL1344_CDS_URL; output:; SL1344_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_LT2_cds_from_genomic:; params:; url=LT2_CDS_URL; output:; LT2_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}"". rule download_ATCC25586_cds_from_genomic:; params:; url=ATCC25586_CDS_URL; output:; ATCC25586_CDS_FA; shell:; ""wget -O - {params.url} | gunzip -c > {output}""; ```; rsubread-env.yaml; ```; name: rsubread; channels:; - conda-forge; - bioconda; - defaults; dependencies:; - bioconductor-rsubread; - bioconductor-biostrings; ```; simulate_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6705
https://github.com/broadinstitute/gatk/issues/6706:323,Availability,down,down,323,"This issue has come up during my work on #6634 and has resulted in the decision to introduce a new argument to GATK `--use-original-alignments-for-genotyping-overlap` in order to better match DRAGEN for concordance. Reads in the GATK undergo a number of modifications before they are used for genotyping that I have listed down below. (Note: between each of these steps some reads get lost to various filtering code and this is not an exhaustive list). 1. Reads undergo modification in `AssemblyBasedCallerUtils.finalizeRegion()` where the reads have their soft-clipped bases reverted, low quality ends removed, mate overlapping base qualities modified, and overhangs outside of the active region removed. Then these reads are used for assembly to discover haplotypes. ; 2. Once we have discovered haplotypes the whole assembly region (reads, haplotypes and all) gets trimmed down to a smaller span that ~overlaps the variants discovered the haplotypes plus either 75+ or 20 bases of padding depending on what type of events are seen. ; 3. These clipped reads (with reads below 10 bases in length being removed) have their base qualities farther modified in `PairHMMLikelihoodCalculationEngine.createQualityModifiedRead()` in various ways. This modification does not stick however since the base qualities are all modified on a clean partial copy of the read.; 4. Following this the reads (the ones from step 2) are realigned to the reference according to their best haplotypes. Sometimes this means as few as 11 bases of ""read"" are being realigned at this stage. . It is these realigned reads that are used for genotyping, where the only reads that are actually used to contribute likelihoods for calls are reads that overlap the variant event within 2 bases of overlap on either side. In DRAGEN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and u",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6706:876,Availability,down,down,876,"This issue has come up during my work on #6634 and has resulted in the decision to introduce a new argument to GATK `--use-original-alignments-for-genotyping-overlap` in order to better match DRAGEN for concordance. Reads in the GATK undergo a number of modifications before they are used for genotyping that I have listed down below. (Note: between each of these steps some reads get lost to various filtering code and this is not an exhaustive list). 1. Reads undergo modification in `AssemblyBasedCallerUtils.finalizeRegion()` where the reads have their soft-clipped bases reverted, low quality ends removed, mate overlapping base qualities modified, and overhangs outside of the active region removed. Then these reads are used for assembly to discover haplotypes. ; 2. Once we have discovered haplotypes the whole assembly region (reads, haplotypes and all) gets trimmed down to a smaller span that ~overlaps the variants discovered the haplotypes plus either 75+ or 20 bases of padding depending on what type of events are seen. ; 3. These clipped reads (with reads below 10 bases in length being removed) have their base qualities farther modified in `PairHMMLikelihoodCalculationEngine.createQualityModifiedRead()` in various ways. This modification does not stick however since the base qualities are all modified on a clean partial copy of the read.; 4. Following this the reads (the ones from step 2) are realigned to the reference according to their best haplotypes. Sometimes this means as few as 11 bases of ""read"" are being realigned at this stage. . It is these realigned reads that are used for genotyping, where the only reads that are actually used to contribute likelihoods for calls are reads that overlap the variant event within 2 bases of overlap on either side. In DRAGEN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and u",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6706:992,Integrability,depend,depending,992,"This issue has come up during my work on #6634 and has resulted in the decision to introduce a new argument to GATK `--use-original-alignments-for-genotyping-overlap` in order to better match DRAGEN for concordance. Reads in the GATK undergo a number of modifications before they are used for genotyping that I have listed down below. (Note: between each of these steps some reads get lost to various filtering code and this is not an exhaustive list). 1. Reads undergo modification in `AssemblyBasedCallerUtils.finalizeRegion()` where the reads have their soft-clipped bases reverted, low quality ends removed, mate overlapping base qualities modified, and overhangs outside of the active region removed. Then these reads are used for assembly to discover haplotypes. ; 2. Once we have discovered haplotypes the whole assembly region (reads, haplotypes and all) gets trimmed down to a smaller span that ~overlaps the variants discovered the haplotypes plus either 75+ or 20 bases of padding depending on what type of events are seen. ; 3. These clipped reads (with reads below 10 bases in length being removed) have their base qualities farther modified in `PairHMMLikelihoodCalculationEngine.createQualityModifiedRead()` in various ways. This modification does not stick however since the base qualities are all modified on a clean partial copy of the read.; 4. Following this the reads (the ones from step 2) are realigned to the reference according to their best haplotypes. Sometimes this means as few as 11 bases of ""read"" are being realigned at this stage. . It is these realigned reads that are used for genotyping, where the only reads that are actually used to contribute likelihoods for calls are reads that overlap the variant event within 2 bases of overlap on either side. In DRAGEN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and u",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6706:1887,Performance,perform,performs,1887," reads (with reads below 10 bases in length being removed) have their base qualities farther modified in `PairHMMLikelihoodCalculationEngine.createQualityModifiedRead()` in various ways. This modification does not stick however since the base qualities are all modified on a clean partial copy of the read.; 4. Following this the reads (the ones from step 2) are realigned to the reference according to their best haplotypes. Sometimes this means as few as 11 bases of ""read"" are being realigned at this stage. . It is these realigned reads that are used for genotyping, where the only reads that are actually used to contribute likelihoods for calls are reads that overlap the variant event within 2 bases of overlap on either side. In DRAGEN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and using those reads for genotype assignment it instead for genotyping reaches back for each read (that has survived filtering) to its original BAM alignment (before being unclipped/hardclipped) and uses those reads for FRD/BQD calling. When running GATK with the new argument `--use-original-alignments-for-genotyping-overlap` this is what happens as well (step 4 is skipped entirely in addition). The results were somewhat surprising (listed below): . ![RealignmentPlotIndels](https://user-images.githubusercontent.com/16102845/87588690-13fc4680-c6b2-11ea-98e9-4c69259c2869.png); ![RealignmentPlotSNPs](https://user-images.githubusercontent.com/16102845/87588692-1494dd00-c6b2-11ea-96dc-ba06f45357c2.png). This says that running GATK in DRAGEN mode without realigning reads performs slightly better for low complexity region SNPs than it does with realignment. This could perhaps be a side effect of the BQD algorithm as it cares about the specific bases that are applied for SNPs. I have theorized that perhaps the explanation for this behavior has to d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6706:1978,Performance,perform,performing,1978," reads (with reads below 10 bases in length being removed) have their base qualities farther modified in `PairHMMLikelihoodCalculationEngine.createQualityModifiedRead()` in various ways. This modification does not stick however since the base qualities are all modified on a clean partial copy of the read.; 4. Following this the reads (the ones from step 2) are realigned to the reference according to their best haplotypes. Sometimes this means as few as 11 bases of ""read"" are being realigned at this stage. . It is these realigned reads that are used for genotyping, where the only reads that are actually used to contribute likelihoods for calls are reads that overlap the variant event within 2 bases of overlap on either side. In DRAGEN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and using those reads for genotype assignment it instead for genotyping reaches back for each read (that has survived filtering) to its original BAM alignment (before being unclipped/hardclipped) and uses those reads for FRD/BQD calling. When running GATK with the new argument `--use-original-alignments-for-genotyping-overlap` this is what happens as well (step 4 is skipped entirely in addition). The results were somewhat surprising (listed below): . ![RealignmentPlotIndels](https://user-images.githubusercontent.com/16102845/87588690-13fc4680-c6b2-11ea-98e9-4c69259c2869.png); ![RealignmentPlotSNPs](https://user-images.githubusercontent.com/16102845/87588692-1494dd00-c6b2-11ea-96dc-ba06f45357c2.png). This says that running GATK in DRAGEN mode without realigning reads performs slightly better for low complexity region SNPs than it does with realignment. This could perhaps be a side effect of the BQD algorithm as it cares about the specific bases that are applied for SNPs. I have theorized that perhaps the explanation for this behavior has to d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6706:2773,Performance,perform,performs,2773,side. In DRAGEN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and using those reads for genotype assignment it instead for genotyping reaches back for each read (that has survived filtering) to its original BAM alignment (before being unclipped/hardclipped) and uses those reads for FRD/BQD calling. When running GATK with the new argument `--use-original-alignments-for-genotyping-overlap` this is what happens as well (step 4 is skipped entirely in addition). The results were somewhat surprising (listed below): . ![RealignmentPlotIndels](https://user-images.githubusercontent.com/16102845/87588690-13fc4680-c6b2-11ea-98e9-4c69259c2869.png); ![RealignmentPlotSNPs](https://user-images.githubusercontent.com/16102845/87588692-1494dd00-c6b2-11ea-96dc-ba06f45357c2.png). This says that running GATK in DRAGEN mode without realigning reads performs slightly better for low complexity region SNPs than it does with realignment. This could perhaps be a side effect of the BQD algorithm as it cares about the specific bases that are applied for SNPs. I have theorized that perhaps the explanation for this behavior has to do with the fact that the reads at stage 4 have undergone 2 different rounds of clipping (at stages 1 and 2) and could in actuality be as short as 11 bases long by this stage. If this is indeed the problem then realigning the reads (without anchoring information from the rest of the read that might have resulted in more accurate placement) might well result in significant noise as to where reads actually get placed after realignment. A necessary step to completing this ticket would have to be evaluating what sites account for the lost sensitivity and understanding why the realignment is responsible and evaluating if there is not a better way to perform the realignment that can handle these short stubs if indeed they are ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6706:3705,Performance,perform,perform,3705,EN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and using those reads for genotype assignment it instead for genotyping reaches back for each read (that has survived filtering) to its original BAM alignment (before being unclipped/hardclipped) and uses those reads for FRD/BQD calling. When running GATK with the new argument `--use-original-alignments-for-genotyping-overlap` this is what happens as well (step 4 is skipped entirely in addition). The results were somewhat surprising (listed below): . ![RealignmentPlotIndels](https://user-images.githubusercontent.com/16102845/87588690-13fc4680-c6b2-11ea-98e9-4c69259c2869.png); ![RealignmentPlotSNPs](https://user-images.githubusercontent.com/16102845/87588692-1494dd00-c6b2-11ea-96dc-ba06f45357c2.png). This says that running GATK in DRAGEN mode without realigning reads performs slightly better for low complexity region SNPs than it does with realignment. This could perhaps be a side effect of the BQD algorithm as it cares about the specific bases that are applied for SNPs. I have theorized that perhaps the explanation for this behavior has to do with the fact that the reads at stage 4 have undergone 2 different rounds of clipping (at stages 1 and 2) and could in actuality be as short as 11 bases long by this stage. If this is indeed the problem then realigning the reads (without anchoring information from the rest of the read that might have resulted in more accurate placement) might well result in significant noise as to where reads actually get placed after realignment. A necessary step to completing this ticket would have to be evaluating what sites account for the lost sensitivity and understanding why the realignment is responsible and evaluating if there is not a better way to perform the realignment that can handle these short stubs if indeed they are the problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6706:3757,Testability,stub,stubs,3757,EN they do something different that we had to replicate to achieve concordance. Dragen still performs equivalent modifications for steps 1-3 as they apply to the reads but rather than performing step 4 and using those reads for genotype assignment it instead for genotyping reaches back for each read (that has survived filtering) to its original BAM alignment (before being unclipped/hardclipped) and uses those reads for FRD/BQD calling. When running GATK with the new argument `--use-original-alignments-for-genotyping-overlap` this is what happens as well (step 4 is skipped entirely in addition). The results were somewhat surprising (listed below): . ![RealignmentPlotIndels](https://user-images.githubusercontent.com/16102845/87588690-13fc4680-c6b2-11ea-98e9-4c69259c2869.png); ![RealignmentPlotSNPs](https://user-images.githubusercontent.com/16102845/87588692-1494dd00-c6b2-11ea-96dc-ba06f45357c2.png). This says that running GATK in DRAGEN mode without realigning reads performs slightly better for low complexity region SNPs than it does with realignment. This could perhaps be a side effect of the BQD algorithm as it cares about the specific bases that are applied for SNPs. I have theorized that perhaps the explanation for this behavior has to do with the fact that the reads at stage 4 have undergone 2 different rounds of clipping (at stages 1 and 2) and could in actuality be as short as 11 bases long by this stage. If this is indeed the problem then realigning the reads (without anchoring information from the rest of the read that might have resulted in more accurate placement) might well result in significant noise as to where reads actually get placed after realignment. A necessary step to completing this ticket would have to be evaluating what sites account for the lost sensitivity and understanding why the realignment is responsible and evaluating if there is not a better way to perform the realignment that can handle these short stubs if indeed they are the problem.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6706
https://github.com/broadinstitute/gatk/issues/6707:1993,Modifiability,extend,extends,1993,"the deletion more or less the same and call it (assigning B to the variant and A/C to reference) ; - At the second position:; -- DRAGEN (and GATK with the `--disable-spanning-event-genotyping` argument enabled) follow the GATK3 approach of assigning haplotype C to the variant and the A and B haplotypes to the reference. The B haplotype is assigned as such because the deletion does not START at position 224905964 thus its reference according to the old way of assigning likelihoods. This means that all of the likelihoods from the true deletion at this site are weighted towards the reference which will end up drowning out the SNP call resulting in no SNP being called at this site.; -- GATK assigns C to the variant, A to to the reference, and B to a third option spanning deletion which prevents the deletion from outweighing the likelihoods assigned to the SNP resulting in better performance at many sites. This pattern even extends to SNP sites where a deletion was not called, since we still assign the haplotype to ""spanning deletion"" if there was a deletion at that site. . For indels however this can cause some extra false positives at sites like this one (the left variant under the deletion in the gatk track):; <img width=""1616"" alt=""Screen Shot 2020-07-14 at 4 09 47 PM"" src=""https://user-images.githubusercontent.com/16102845/87471543-86a2ee80-c5ec-11ea-9cdd-8acf1beb8c14.png"">; <img width=""178"" alt=""Screen Shot 2020-07-14 at 4 10 45 PM"" src=""https://user-images.githubusercontent.com/16102845/87471596-9de1dc00-c5ec-11ea-9d4c-786e114d57d3.png"">; This is a messy site that is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as above we can see DRAGEN did not make the call because it assigned all of the likelihoods for the longer deletion to the reference when compared against the shorter insertion underlying it which outwe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6707:581,Performance,perform,performs,581,"This issue has come up during my work on #6634 and has resulted in the decision to add the `--disable-spanning-event-genotyping` argument in GATK. . The results from the GATK-DRAGEN ROC curves on synthetic diploid CHM samples looks like this: ; ![otherCH1_CHM13_WGS1_PAIR_indel](https://user-images.githubusercontent.com/16102845/87469757-c3211b00-c5e9-11ea-830f-f3db5f7b8aed.png); ![otherCH1_CHM13_WGS1_PAIR_snp](https://user-images.githubusercontent.com/16102845/87469766-c5837500-c5e9-11ea-8914-7bf5660c3ead.png); Clearly these show that for SNPs at low complexity regions GATK performs better but for indels it is less specific. To explain the SNPs here is an example site: ; <img width=""1614"" alt=""Screen Shot 2020-07-14 at 3 08 10 PM"" src=""https://user-images.githubusercontent.com/16102845/87470068-39be1880-c5ea-11ea-80b5-2dba4a23c1dc.png"">; We can explain what is going on here by imagining the 3 relevant haplotypes, A) reference haplotype, B) the one with the deletion, C) the one with the snp underlying the deltion. ; - GATK and dragen genotype the deletion more or less the same and call it (assigning B to the variant and A/C to reference) ; - At the second position:; -- DRAGEN (and GATK with the `--disable-spanning-event-genotyping` argument enabled) follow the GATK3 approach of assigning haplotype C to the variant and the A and B haplotypes to the reference. The B haplotype is assigned as such because the deletion does not START at position 224905964 thus its reference according to the old way of assigning likelihoods. This means that all of the likelihoods from the true deletion at this site are weighted towards the reference which will end up drowning out the SNP call resulting in no SNP being called at this site.; -- GATK assigns C to the variant, A to to the reference, and B to a third option spanning deletion which prevents the deletion from outweighing the likelihoods assigned to the SNP resulting in better performance at many sites. This pattern even extends ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6707:1948,Performance,perform,performance,1948,"plain what is going on here by imagining the 3 relevant haplotypes, A) reference haplotype, B) the one with the deletion, C) the one with the snp underlying the deltion. ; - GATK and dragen genotype the deletion more or less the same and call it (assigning B to the variant and A/C to reference) ; - At the second position:; -- DRAGEN (and GATK with the `--disable-spanning-event-genotyping` argument enabled) follow the GATK3 approach of assigning haplotype C to the variant and the A and B haplotypes to the reference. The B haplotype is assigned as such because the deletion does not START at position 224905964 thus its reference according to the old way of assigning likelihoods. This means that all of the likelihoods from the true deletion at this site are weighted towards the reference which will end up drowning out the SNP call resulting in no SNP being called at this site.; -- GATK assigns C to the variant, A to to the reference, and B to a third option spanning deletion which prevents the deletion from outweighing the likelihoods assigned to the SNP resulting in better performance at many sites. This pattern even extends to SNP sites where a deletion was not called, since we still assign the haplotype to ""spanning deletion"" if there was a deletion at that site. . For indels however this can cause some extra false positives at sites like this one (the left variant under the deletion in the gatk track):; <img width=""1616"" alt=""Screen Shot 2020-07-14 at 4 09 47 PM"" src=""https://user-images.githubusercontent.com/16102845/87471543-86a2ee80-c5ec-11ea-9cdd-8acf1beb8c14.png"">; <img width=""178"" alt=""Screen Shot 2020-07-14 at 4 10 45 PM"" src=""https://user-images.githubusercontent.com/16102845/87471596-9de1dc00-c5ec-11ea-9d4c-786e114d57d3.png"">; This is a messy site that is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6707:4188,Performance,perform,performance,4188,"at is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as above we can see DRAGEN did not make the call because it assigned all of the likelihoods for the longer deletion to the reference when compared against the shorter insertion underlying it which outweighed the event, whereas in GATK the likelihood from that longer event was assigned to the spanning deletion allele. Since there was little evidence for the reference at this site the insertion ended up being called. This particular pattern can also occur because there are differing lengths of deletions at a site that is anchored on the right, causing noise when calling the events independently from eachother (whereas we might not have called them independently if they were anchored from the left and thus started on the same base). Generally this pattern of differing haplotype allele assignments has a particularly pronounced effect in low complexity regions where it is highly likely there are apparent deletions relative to the reference in the data and can result in significant differences in calling. . Right now there is a tradeoff (when running DRAGEN-GATK mode) for running `--disable-spanning-event-genotyping` in GATK. Given that the DRAGEN-GATK variant calling mode is likely to be important going forwards we should investigate genotyping of spanning events and whether there is a way to keep the improved SNP performance without too drastically impacting indel performance. It is clear that assigning spanning event allele likelihoods to the reference is less ""correct"" but it appears to introduce a significant bias against calling multiple events at complex sites that turns out to save the emission of many false positives. One option might be to explore the possibility of calling spanning events all together based on haplotypes that might contain multiple variants.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6707:4240,Performance,perform,performance,4240,"at is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as above we can see DRAGEN did not make the call because it assigned all of the likelihoods for the longer deletion to the reference when compared against the shorter insertion underlying it which outweighed the event, whereas in GATK the likelihood from that longer event was assigned to the spanning deletion allele. Since there was little evidence for the reference at this site the insertion ended up being called. This particular pattern can also occur because there are differing lengths of deletions at a site that is anchored on the right, causing noise when calling the events independently from eachother (whereas we might not have called them independently if they were anchored from the left and thus started on the same base). Generally this pattern of differing haplotype allele assignments has a particularly pronounced effect in low complexity regions where it is highly likely there are apparent deletions relative to the reference in the data and can result in significant differences in calling. . Right now there is a tradeoff (when running DRAGEN-GATK mode) for running `--disable-spanning-event-genotyping` in GATK. Given that the DRAGEN-GATK variant calling mode is likely to be important going forwards we should investigate genotyping of spanning events and whether there is a way to keep the improved SNP performance without too drastically impacting indel performance. It is clear that assigning spanning event allele likelihoods to the reference is less ""correct"" but it appears to introduce a significant bias against calling multiple events at complex sites that turns out to save the emission of many false positives. One option might be to explore the possibility of calling spanning events all together based on haplotypes that might contain multiple variants.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6707:2851,Testability,log,logic,2851," SNP sites where a deletion was not called, since we still assign the haplotype to ""spanning deletion"" if there was a deletion at that site. . For indels however this can cause some extra false positives at sites like this one (the left variant under the deletion in the gatk track):; <img width=""1616"" alt=""Screen Shot 2020-07-14 at 4 09 47 PM"" src=""https://user-images.githubusercontent.com/16102845/87471543-86a2ee80-c5ec-11ea-9cdd-8acf1beb8c14.png"">; <img width=""178"" alt=""Screen Shot 2020-07-14 at 4 10 45 PM"" src=""https://user-images.githubusercontent.com/16102845/87471596-9de1dc00-c5ec-11ea-9d4c-786e114d57d3.png"">; This is a messy site that is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as above we can see DRAGEN did not make the call because it assigned all of the likelihoods for the longer deletion to the reference when compared against the shorter insertion underlying it which outweighed the event, whereas in GATK the likelihood from that longer event was assigned to the spanning deletion allele. Since there was little evidence for the reference at this site the insertion ended up being called. This particular pattern can also occur because there are differing lengths of deletions at a site that is anchored on the right, causing noise when calling the events independently from eachother (whereas we might not have called them independently if they were anchored from the left and thus started on the same base). Generally this pattern of differing haplotype allele assignments has a particularly pronounced effect in low complexity regions where it is highly likely there are apparent deletions relative to the reference in the data and can result in significant differences in calling. . Right now there is a tradeoff (when running DRAGEN-GATK mode) for running `--disable-spanning-event-genotyping` in GATK. Given th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6707:517,Usability,Clear,Clearly,517,"This issue has come up during my work on #6634 and has resulted in the decision to add the `--disable-spanning-event-genotyping` argument in GATK. . The results from the GATK-DRAGEN ROC curves on synthetic diploid CHM samples looks like this: ; ![otherCH1_CHM13_WGS1_PAIR_indel](https://user-images.githubusercontent.com/16102845/87469757-c3211b00-c5e9-11ea-830f-f3db5f7b8aed.png); ![otherCH1_CHM13_WGS1_PAIR_snp](https://user-images.githubusercontent.com/16102845/87469766-c5837500-c5e9-11ea-8914-7bf5660c3ead.png); Clearly these show that for SNPs at low complexity regions GATK performs better but for indels it is less specific. To explain the SNPs here is an example site: ; <img width=""1614"" alt=""Screen Shot 2020-07-14 at 3 08 10 PM"" src=""https://user-images.githubusercontent.com/16102845/87470068-39be1880-c5ea-11ea-80b5-2dba4a23c1dc.png"">; We can explain what is going on here by imagining the 3 relevant haplotypes, A) reference haplotype, B) the one with the deletion, C) the one with the snp underlying the deltion. ; - GATK and dragen genotype the deletion more or less the same and call it (assigning B to the variant and A/C to reference) ; - At the second position:; -- DRAGEN (and GATK with the `--disable-spanning-event-genotyping` argument enabled) follow the GATK3 approach of assigning haplotype C to the variant and the A and B haplotypes to the reference. The B haplotype is assigned as such because the deletion does not START at position 224905964 thus its reference according to the old way of assigning likelihoods. This means that all of the likelihoods from the true deletion at this site are weighted towards the reference which will end up drowning out the SNP call resulting in no SNP being called at this site.; -- GATK assigns C to the variant, A to to the reference, and B to a third option spanning deletion which prevents the deletion from outweighing the likelihoods assigned to the SNP resulting in better performance at many sites. This pattern even extends ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6707:4259,Usability,clear,clear,4259,"at is perhaps complicated by representation issues but we can see that GATK emitted an extra insertion underlying the longer event (which was marked as homozygous in the truth set). Following the same logic as above we can see DRAGEN did not make the call because it assigned all of the likelihoods for the longer deletion to the reference when compared against the shorter insertion underlying it which outweighed the event, whereas in GATK the likelihood from that longer event was assigned to the spanning deletion allele. Since there was little evidence for the reference at this site the insertion ended up being called. This particular pattern can also occur because there are differing lengths of deletions at a site that is anchored on the right, causing noise when calling the events independently from eachother (whereas we might not have called them independently if they were anchored from the left and thus started on the same base). Generally this pattern of differing haplotype allele assignments has a particularly pronounced effect in low complexity regions where it is highly likely there are apparent deletions relative to the reference in the data and can result in significant differences in calling. . Right now there is a tradeoff (when running DRAGEN-GATK mode) for running `--disable-spanning-event-genotyping` in GATK. Given that the DRAGEN-GATK variant calling mode is likely to be important going forwards we should investigate genotyping of spanning events and whether there is a way to keep the improved SNP performance without too drastically impacting indel performance. It is clear that assigning spanning event allele likelihoods to the reference is less ""correct"" but it appears to introduce a significant bias against calling multiple events at complex sites that turns out to save the emission of many false positives. One option might be to explore the possibility of calling spanning events all together based on haplotypes that might contain multiple variants.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6707
https://github.com/broadinstitute/gatk/issues/6708:305,Availability,error,error,305,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); gatk-4.1.8.0; funcotator_dataSources.v1.7.20200521s. ### Description . I am trying to use Funcotator to annotate the variants that I have already detected. Unfortunatelly, after a few seconds Funcotator stops with the error:. > java.lang.IllegalArgumentException: Unexpected value: lncRNA. I have no idea what is wrong and I did not find this error in the internet. Can it be a problem with JRE?. Full log below. #### Steps to reproduce. `~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF`. #### Expected behavior. Foncotator annotates my variants. #### Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/int",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:430,Availability,error,error,430,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); gatk-4.1.8.0; funcotator_dataSources.v1.7.20200521s. ### Description . I am trying to use Funcotator to annotate the variants that I have already detected. Unfortunatelly, after a few seconds Funcotator stops with the error:. > java.lang.IllegalArgumentException: Unexpected value: lncRNA. I have no idea what is wrong and I did not find this error in the internet. Can it be a problem with JRE?. Full log below. #### Steps to reproduce. `~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF`. #### Expected behavior. Foncotator annotates my variants. #### Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/int",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:13791,Availability,error,errors,13791,"NFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xrefseq_v90_38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/gencode_xrefseq_v90_38.tsv; > 15:16:43.878 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 15:16:43.926 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.annotation.REORDERED.gtf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:14064,Availability,error,errors,14064,"rceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 15:16:43.926 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.annotation.REORDERED.gtf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.pc_transcripts.fa -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.pc_transcripts.fa; > 15:16:54.854 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:14549,Availability,error,errors,14549,"tf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.pc_transcripts.fa -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.pc_transcripts.fa; > 15:16:54.854 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_fusion/hg38/cosmic_fusion.tsv; > 15:16:54.876 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/achilles_lineage_results.import.txt -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/achilles/hg38/achilles_lineage_results.import.txt; > 15:16:54.881 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:17161,Availability,down,down,17161,"r - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf15:16:55.375 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xhgnc_v90_38.hg38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xhgnc/hg38/gencode_xhgnc_v90_38.hg38.tsv; > 15:16:57.746 INFO Funcotator - Initializing Funcotator Engine...; > 15:16:57.777 INFO Funcotator - Creating a VCF file for output: file:/home/pkus/mutect_test/filtered_variants/P1.avcf.gz; > 15:16:57.894 INFO ProgressMeter - Starting traversal; > 15:16:57.894 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; > 15:16:57.979 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; > 15:16:57.981 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; > 15:16:57.991 INFO Funcotator - Shutting down engine; > [July 17, 2020 3:16:57 PM CEST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.31 minutes.; > Runtime.totalMemory()=883949568; > java.lang.IllegalArgumentException: Unexpected value: lncRNA; > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$GeneTranscriptType.getEnum(GencodeGtfFeature.java:1052); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:158); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.<init>(GencodeGtfGeneFeature.java:19); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.create(GencodeGtfGeneFeature.java:23); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$1.create(GencodeGtfFeature.java:753); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); > at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:22576,Availability,error,error,22576,"at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.java:116); > at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); > at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); > at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); > at org.broadinstitute.hellbender.Main.main(Main.java:292); > . I have also tried to use older version of funcotator data sources, funcotator_dataSources.v1.6.20190124s, then the resulting error is:. > org.broadinstitute.hellbender.exceptions.GATKException: Unable to query the database for geneName: NCRNA00115",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:20156,Energy Efficiency,Reduce,ReduceOps,20156,t org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:20166,Energy Efficiency,Reduce,ReduceOp,20166,t org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:20194,Energy Efficiency,Reduce,ReduceOps,20194,lbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.java:116); > at java.util.S,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:20090,Integrability,wrap,wrapAndCopyInto,20090,mFeatureContext(DataSourceFuncotationFactory.java:314); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); > at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); > at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:21379,Integrability,wrap,wrapAndCopyInto,21379,lbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); > at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); > at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); > at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); > at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); > at java.util.Iterator.forEachRemaining(Iterator.java:116); > at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); > at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); > at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); > at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); > at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); > at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); > at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); > at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); > at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); > at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); > at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); > at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); > at org.b,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:10284,Modifiability,config,config,10284,le path: file:///home/pkus/mutect_test/simple_uniprot_Dec012014.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg38/simple_uniprot_Dec012014.tsv; > 15:16:41.540 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/Familial_Cancer_Genes.no_dupes.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/familial/hg38/Familial_Cancer_Genes.no_dupes.tsv; > 15:16:41.545 INFO DataSourceUtils - Setting lookahead cache for data source: Oreganno : 100000; > 15:16:41.556 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.tsv; > 15:16:41.575 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.config; > 15:16:41.707 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.tsv; > 15:16:41.709 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.tsv; > WARNING 2020-07-17 15:16:41 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; > 15:16:41.717 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/dnaRepairGenes.20180524T145835.csv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/dna_repair_genes/hg38/dnaRepairGenes.20180524T145835.csv; > 15:16:41.723 INFO DataSourceUtils - Resolved data source file path: file://,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:1885,Performance,Load,Loading,1885,"# Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; > Jul 17, 2020 3:16:39 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; > INFO: Failed to detect whether we are running on Google Compute Engine.; > 15:16:39.785 INFO Funcotator - ------------------------------------------------------------; > 15:16:39.786 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.8.0; > 15:16:39.786 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; > 15:16:39.787 INFO Funcotator - Executing as xxx on Linux v3.10.0-957.5.1.el7.x86_64 amd64; > 15:16:39.787 INFO Funcotator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_251-b08; > 15:16:39.787 INFO Funcotator - Start Date/Time: July 17, 2020 3:16:39 PM CEST; > 15:16:39.787 INFO Funcotator - ------------------------------------------------------------; > 15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:9824,Performance,cache,cache,9824, INFO Funcotator - Finalizing data sources (this step can be long if data sources are cloud-based)...; > 15:16:41.066 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/CancerGeneCensus_Table_1_full_2012-03-15.txt -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cancer_gene_census/hg38/CancerGeneCensus_Table_1_full_2012-03-15.txt; > 15:16:41.083 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/simple_uniprot_Dec012014.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg38/simple_uniprot_Dec012014.tsv; > 15:16:41.540 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/Familial_Cancer_Genes.no_dupes.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/familial/hg38/Familial_Cancer_Genes.no_dupes.tsv; > 15:16:41.545 INFO DataSourceUtils - Setting lookahead cache for data source: Oreganno : 100000; > 15:16:41.556 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.tsv; > 15:16:41.575 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.config; > 15:16:41.707 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.tsv; > 15:16:41.709 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/oreganno.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/oreganno/hg38/oreganno.tsv; > WARNING 2020-07-17 15:16:41 AsciiLineReader Creating an indexable source for an ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:11993,Performance,cache,cache,11993,e file path: file:///home/pkus/mutect_test/dnaRepairGenes.20180524T145835.csv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/dna_repair_genes/hg38/dnaRepairGenes.20180524T145835.csv; > 15:16:41.723 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/Cosmic.db -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic/hg38/Cosmic.db; > 15:16:42.012 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/hgnc_download_Nov302017.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/hgnc/hg38/hgnc_download_Nov302017.tsv; > 15:16:42.274 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/hg38_All_20180418.vcf.gz -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/dbsnp/hg38/hg38_All_20180418.vcf.gz; > 15:16:42.274 INFO DataSourceUtils - Setting lookahead cache for data source: dbSNP : 100000; > 15:16:42.297 INFO FeatureManager - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/dbsnp/hg38/hg38_All_20180418.vcf.gz; > 15:16:43.390 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/hg38_All_20180418.vcf.gz -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/dbsnp/hg38/hg38_All_20180418.vcf.gz; > 15:16:43.481 INFO FeatureManager - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/dbsnp/hg38/hg38_All_20180418.vcf.gz; > 15:16:43.571 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xrefseq_v90_38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/gencode_xrefseq_v90_38.tsv; > 15:16:43.878 INFO DataSourceUtils - Resolved data source file path: fi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:13496,Performance,cache,cache,13496,"anager - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/dbsnp/hg38/hg38_All_20180418.vcf.gz; > 15:16:43.571 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xrefseq_v90_38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/gencode_xrefseq_v90_38.tsv; > 15:16:43.878 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 15:16:43.926 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.annotation.REORDERED.gtf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:15651,Performance,cache,cache,15651,mutect_test/gencode.v34.pc_transcripts.fa -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.pc_transcripts.fa; > 15:16:54.854 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_fusion/hg38/cosmic_fusion.tsv; > 15:16:54.876 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/achilles_lineage_results.import.txt -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/achilles/hg38/achilles_lineage_results.import.txt; > 15:16:54.881 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/clinvar_20180429_hg38.vcf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf; > 15:16:54.882 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar_VCF : 100000; > 15:16:54.890 INFO FeatureManager - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf15:16:55.098 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/clinvar_20180429_hg38.vcf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf; > 15:16:55.199 INFO FeatureManager - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf15:16:55.375 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xhgnc_v90_38.hg38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xhgnc/hg38/gencode_xhgnc_v90_38.hg38.tsv; > 15:16:57.746 INFO Funcotator - Initializing Funcotator Engine,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:17013,Performance,cache,cache,17013,"29_hg38.vcf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf; > 15:16:55.199 INFO FeatureManager - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf15:16:55.375 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xhgnc_v90_38.hg38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xhgnc/hg38/gencode_xhgnc_v90_38.hg38.tsv; > 15:16:57.746 INFO Funcotator - Initializing Funcotator Engine...; > 15:16:57.777 INFO Funcotator - Creating a VCF file for output: file:/home/pkus/mutect_test/filtered_variants/P1.avcf.gz; > 15:16:57.894 INFO ProgressMeter - Starting traversal; > 15:16:57.894 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; > 15:16:57.979 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; > 15:16:57.981 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; > 15:16:57.991 INFO Funcotator - Shutting down engine; > [July 17, 2020 3:16:57 PM CEST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.31 minutes.; > Runtime.totalMemory()=883949568; > java.lang.IllegalArgumentException: Unexpected value: lncRNA; > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$GeneTranscriptType.getEnum(GencodeGtfFeature.java:1052); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:158); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.<init>(GencodeGtfGeneFeature.java:19); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.create(GencodeGtfGeneFeature.java:23); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$1.create(GencodeGtfFeature.java:753); > at org.broadinstitut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:17096,Performance,cache,cache,17096,"20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf; > 15:16:55.199 INFO FeatureManager - Using codec VCFCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/clinvar/hg38/clinvar_20180429_hg38.vcf15:16:55.375 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xhgnc_v90_38.hg38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xhgnc/hg38/gencode_xhgnc_v90_38.hg38.tsv; > 15:16:57.746 INFO Funcotator - Initializing Funcotator Engine...; > 15:16:57.777 INFO Funcotator - Creating a VCF file for output: file:/home/pkus/mutect_test/filtered_variants/P1.avcf.gz; > 15:16:57.894 INFO ProgressMeter - Starting traversal; > 15:16:57.894 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; > 15:16:57.979 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; > 15:16:57.981 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; > 15:16:57.991 INFO Funcotator - Shutting down engine; > [July 17, 2020 3:16:57 PM CEST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.31 minutes.; > Runtime.totalMemory()=883949568; > java.lang.IllegalArgumentException: Unexpected value: lncRNA; > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$GeneTranscriptType.getEnum(GencodeGtfFeature.java:1052); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:158); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.<init>(GencodeGtfGeneFeature.java:19); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.create(GencodeGtfGeneFeature.java:23); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$1.create(GencodeGtfFeature.java:753); > at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); > at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:233,Safety,detect,detected,233,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); gatk-4.1.8.0; funcotator_dataSources.v1.7.20200521s. ### Description . I am trying to use Funcotator to annotate the variants that I have already detected. Unfortunatelly, after a few seconds Funcotator stops with the error:. > java.lang.IllegalArgumentException: Unexpected value: lncRNA. I have no idea what is wrong and I did not find this error in the internet. Can it be a problem with JRE?. Full log below. #### Steps to reproduce. `~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF`. #### Expected behavior. Foncotator annotates my variants. #### Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/int",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:2171,Safety,detect,detect,2171,"521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; > Jul 17, 2020 3:16:39 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; > INFO: Failed to detect whether we are running on Google Compute Engine.; > 15:16:39.785 INFO Funcotator - ------------------------------------------------------------; > 15:16:39.786 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.8.0; > 15:16:39.786 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; > 15:16:39.787 INFO Funcotator - Executing as xxx on Linux v3.10.0-957.5.1.el7.x86_64 amd64; > 15:16:39.787 INFO Funcotator - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_251-b08; > 15:16:39.787 INFO Funcotator - Start Date/Time: July 17, 2020 3:16:39 PM CEST; > 15:16:39.787 INFO Funcotator - ------------------------------------------------------------; > 15:16:39.787 INFO Funcotator - ------------------------------------------------------------; > 15:16:39.788 INFO Funcotator - HTSJDK Version: 2.22.0; > 15:16:39.788 INFO Funcotator - Picard Version: 2.22.8; > 15:16:39.788 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; > 15:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:3940,Security,Validat,Validating,3940,---------------------------; > 15:16:39.788 INFO Funcotator - HTSJDK Version: 2.22.0; > 15:16:39.788 INFO Funcotator - Picard Version: 2.22.8; > 15:16:39.788 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; > 15:16:39.788 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; > 15:16:39.788 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; > 15:16:39.788 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; > 15:16:39.789 INFO Funcotator - Deflater: IntelDeflater; > 15:16:39.789 INFO Funcotator - Inflater: IntelInflater; > 15:16:39.789 INFO Funcotator - GCS max retries/reopens: 20; > 15:16:39.789 INFO Funcotator - Requester pays: disabled; > 15:16:39.789 INFO Funcotator - Initializing engine; > 15:16:40.573 INFO FeatureManager - Using codec VCFCodec to read file file:///home/pkus/mutect_test/filtered_variants/P1.vcf.gz; > 15:16:40.902 INFO Funcotator - Done initializing engine; > 15:16:40.903 INFO Funcotator - Validating Sequence Dictionaries...; > 15:16:40.971 INFO Funcotator - Processing user transcripts/defaults/overrides...; > 15:16:40.972 INFO Funcotator - Initializing data sources...; > 15:16:40.975 INFO DataSourceUtils - Initializing data sources from directory: /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s; > 15:16:40.978 INFO DataSourceUtils - Data sources version: 1.7.2020429s; > 15:16:40.978 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; > 15:16:40.978 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; > 15:16:40.996 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/CancerGeneCensus_Table_1_full_2012-03-15.txt -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cancer_gene_census/hg38/CancerGeneC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:489,Testability,log,log,489,"## Bug Report. ### Affected tool(s) or class(es); Funcotator. ### Affected version(s); gatk-4.1.8.0; funcotator_dataSources.v1.7.20200521s. ### Description . I am trying to use Funcotator to annotate the variants that I have already detected. Unfortunatelly, after a few seconds Funcotator stops with the error:. > java.lang.IllegalArgumentException: Unexpected value: lncRNA. I have no idea what is wrong and I did not find this error in the internet. Can it be a problem with JRE?. Full log below. #### Steps to reproduce. `~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF`. #### Expected behavior. Foncotator annotates my variants. #### Actual behavior. > (base) [pkus@master1 mutect_test]$ ~/programs/gatk-4.1.8.0/gatk Funcotator --variant filtered_variants/P1.vcf.gz --reference ~/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path ~/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > Using GATK jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; > Running:; > java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar Funcotator --variant filtered_variants/P1.vcf.gz --reference /home/pkus/resources/hg38_for_bwa/hs38DH.fa --ref-version hg38 --data-sources-path /home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s --output filtered_variants/P1.avcf.gz --output-file-format VCF; > 15:16:39.460 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/pkus/programs/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/int",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:13644,Testability,test,tested,13644,"NFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode_xrefseq_v90_38.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg38/gencode_xrefseq_v90_38.tsv; > 15:16:43.878 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 15:16:43.926 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.annotation.REORDERED.gtf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:13917,Testability,test,tested,13917,"rceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_tissue.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg38/cosmic_tissue.tsv; > 15:16:43.926 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.annotation.REORDERED.gtf -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.pc_transcripts.fa -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.pc_transcripts.fa; > 15:16:54.854 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6708:14402,Testability,test,tested,14402,"tf; > 15:16:43.926 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; > 15:16:43.937 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.938 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:43.939 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; > 15:16:43.946 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100) Continuing, but errors may occur.; > 15:16:44.093 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/gencode.v34.pc_transcripts.fa -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/gencode/hg38/gencode.v34.pc_transcripts.fa; > 15:16:54.854 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/cosmic_fusion.tsv -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/cosmic_fusion/hg38/cosmic_fusion.tsv; > 15:16:54.876 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutect_test/achilles_lineage_results.import.txt -> file:///home/pkus/resources/gatk/funcotator2/funcotator_dataSources.v1.7.20200521s/achilles/hg38/achilles_lineage_results.import.txt; > 15:16:54.881 INFO DataSourceUtils - Resolved data source file path: file:///home/pkus/mutec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6708
https://github.com/broadinstitute/gatk/issues/6709:161,Availability,error,error,161,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:474,Availability,ERROR,ERROR,474,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:44,Deployability,pipeline,pipeline,44,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:1677,Energy Efficiency,schedul,scheduler,1677,"-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748); `. Looking at the aligned bams that go into the scoring task, they don't appear to be empty or different to the rest of the cohort. Any thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:1747,Energy Efficiency,schedul,scheduler,1747,"-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748); `. Looking at the aligned bams that go into the scoring task, they don't appear to be empty or different to the rest of the cohort. Any thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:167,Integrability,message,message,167,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:803,Integrability,Wrap,Wrappers,803,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:833,Integrability,Wrap,Wrappers,833,"Hi GATK team,. I tried running your PathSeq pipeline (broadinstitute/gatk:4.1.8.0) on my cohort and almost half of the samples failed the scoring step with this error message:; `20/07/17 09:38:35 INFO NewHadoopRDD: Input split: file:/cromwell_root/fc-6e61d4b2-bdc8-4abd-bb94-18d8fa11d9b6/7c1b0faa-e956-4289-9e2d-4fb8b9eff6ff/PathSeqPipeline/0ca5578f-70d3-498e-b7cc-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:2024,Performance,concurren,concurrent,2024,"-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748); `. Looking at the aligned bams that go into the scoring task, they don't appear to be empty or different to the rest of the cohort. Any thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6709:2107,Performance,concurren,concurrent,2107,"-23590f0ab31f/call-PathSeqAlign/MMRF_2072_2_BM.microbe_aligned.paired.bam:33554432+33554432 20/07/17 09:38:46 ERROR Executor: Exception in task 0.0 in stage 2.0 (TID 5) java.util.NoSuchElementException: next on empty iterator at scala.collection.Iterator$$anon$2.next(Iterator.scala:39) at scala.collection.Iterator$$anon$2.next(Iterator.scala:37) at scala.collection.Iterator$$anon$13.next(Iterator.scala:469) at scala.collection.convert.Wrappers$IteratorWrapper.next(Wrappers.scala:31) at org.broadinstitute.hellbender.relocated.com.google.common.collect.Iterators$PeekingImpl.next(Iterators.java:1155) at org.broadinstitute.hellbender.utils.spark.SparkUtils.lambda$putReadsWithTheSameNameInTheSamePartition$7bd206b0$1(SparkUtils.java:190) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$4$1.apply(JavaRDDLike.scala:153) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.RDD$$anonfun$mapPartitions$1$$anonfun$apply$23.apply(RDD.scala:823) at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52) at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:346) at org.apache.spark.rdd.RDD.iterator(RDD.scala:310) at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90) at org.apache.spark.scheduler.Task.run(Task.scala:123) at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408) at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360) at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414) at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) at java.lang.Thread.run(Thread.java:748); `. Looking at the aligned bams that go into the scoring task, they don't appear to be empty or different to the rest of the cohort. Any thoughts?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6709
https://github.com/broadinstitute/gatk/issues/6710:1848,Availability,heartbeat,heartbeat,1848,"ser-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1912,Availability,heartbeat,heartbeatInterval,1912,"ser-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1971,Availability,failure,failureShutdownDuration,1971,"ser-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8014,Availability,down,down,8014,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8102,Availability,down,down,8102,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8193,Availability,down,down,8193,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8545,Availability,down,down,8545,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8790,Availability,down,down,8790,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8837,Availability,down,down,8837,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8931,Availability,down,down,8931,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9135,Availability,down,down,9135,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9227,Availability,down,down,9227,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9340,Availability,down,down,9340,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9478,Availability,down,down,9478,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9566,Availability,down,down,9566,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9752,Availability,down,down,9752,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9901,Availability,down,down,9901,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10069,Availability,down,down,10069,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10146,Availability,down,down,10146,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10308,Availability,down,down,10308,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10385,Availability,down,down,10385,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10661,Availability,down,down,10661,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1858,Deployability,configurat,configuration,1858,"ser-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5347,Deployability,configurat,configuration,5347,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:7945,Deployability,release,released,7945,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9355,Integrability,message,messages,9355,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10084,Integrability,message,messages,10084,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10323,Integrability,message,messages,10323,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1858,Modifiability,config,configuration,1858,"ser-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:2371,Modifiability,config,configured,2371,"b.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:2485,Modifiability,config,configured,2485,"00000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bd",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:2605,Modifiability,config,configured,2605,"-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:3664,Modifiability,config,configured,3664,"se 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5347,Modifiability,config,configuration,5347,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:2279,Performance,throttle,throttle,2279,".url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4213,Performance,queue,queue,4213,",67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9348,Performance,queue,queued,9348,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10077,Performance,queue,queued,10077,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:10316,Performance,queue,queued,10316,"4 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] KvWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] ServiceRegistryActor stopped; [2020-07-14 05:09:55,58] [info] Database closed; [2020-07-14 05:09:55,58] [info] Stream materializer shut down; [2020-07-14 05:09:55,58] [info] WDL HTTP import resolver closed; Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 transitioned to state Failed",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8040,Safety,Timeout,Timeout,8040,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8131,Safety,Timeout,Timeout,8131,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8227,Safety,Timeout,Timeout,8227,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8348,Safety,Abort,Aborting,8348,"ential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8573,Safety,Timeout,Timeout,8573,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8866,Safety,Timeout,Timeout,8866,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:8952,Safety,Timeout,Timeout,8952,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9162,Safety,Timeout,Timeout,9162,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9255,Safety,Timeout,Timeout,9255,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9501,Safety,Timeout,Timeout,9501,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:9581,Safety,Timeout,Timeout,9581,"fo] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down WorkflowManagerActor - Timeout = 3600 seconds; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor All workflows finished; [2020-07-14 05:09:55,32] [info] WorkflowManagerActor stopped; [2020-07-14 05:09:55,53] [info] Connection pools shut down; [2020-07-14 05:09:55,53] [info] Shutting down SubWorkflowStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] Shutting down JobStoreActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,53] [info] SubWorkflowStoreActor stopped; [2020-07-14 05:09:55,54] [info] JobStoreActor stopped; [2020-07-14 05:09:55,53] [info] Shutting down CallCacheWriteActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down ServiceRegistryActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor Shutting down: 0 queued messages to process; [2020-07-14 05:09:55,54] [info] CallCacheWriteActor stopped; [2020-07-14 05:09:55,54] [info] Shutting down DockerHashActor - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] Shutting down IoProxy - Timeout = 1800 seconds; [2020-07-14 05:09:55,54] [info] IoProxy stopped; [2020-07-14 05:09:55,54] [info] DockerHashActor stopped; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=1 idleQueues.size=1 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] Shutting down connection pool: curAllocated=0 idleQueues.size=0 waitQueue.size=0 maxWaitQueueLimit=256 closed=false; [2020-07-14 05:09:55,55] [info] WriteMetadataActor Shutting down: 0 queued messag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:77,Security,validat,validation,77,"Hi ; I am using GATK 4.1.7.0, and have faced an issue running the seq-format-validation workflow. basically the process is ran but ends in failed state and the main output does not appear. I have attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:236,Security,validat,validate-bam-inputs,236,"Hi ; I am using GATK 4.1.7.0, and have faced an issue running the seq-format-validation workflow. basically the process is ran but ends in failed state and the main output does not appear. I have attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:265,Security,validat,validate-bam,265,"Hi ; I am using GATK 4.1.7.0, and have faced an issue running the seq-format-validation workflow. basically the process is ran but ends in failed state and the main output does not appear. I have attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1140,Security,validat,validation,1140," in failed state and the main output does not appear. I have attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1151,Security,validat,validate-bam,1151," in failed state and the main output does not appear. I have attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1202,Security,validat,validation,1202," attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-looku",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:1213,Security,validat,validate-bam,1213," attached here the exact command, stderr,validate-bam-inputs.json and validate-bam.wdl. The stdout just says 230. ; I would be grateful for any help on how to solve the issue. ; Best ; zara. <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 12 AM"" src=""https://user-images.githubusercontent.com/61913000/87845900-e6491480-c8e0-11ea-8dc0-ec5b3fbc15a8.png"">; <img width=""1280"" alt=""Screen Shot 2020-07-16 at 12 01 19 AM"" src=""https://user-images.githubusercontent.com/61913000/87845901-e77a4180-c8e0-11ea-8c6a-fb5783949ba3.png"">; <img width=""353"" alt=""Screen Shot 2020-07-16 at 12 00 30 AM"" src=""https://user-images.githubusercontent.com/61913000/87845902-ea753200-c8e0-11ea-96bc-caecee2ccb39.png"">; <img width=""1249"" alt=""stderr1"" src=""https://user-images.githubusercontent.com/61913000/87845904-eea14f80-c8e0-11ea-90bd-235c9205f72f.png"">. (gatk) root@bc3c6aca6231:/gatk/my_data/tools# java -jar cromwell-51.jar run /gatk/my_data/seq-format-validation/validate-bam.wdl --inputs /gatk/my_data/seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-looku",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:2185,Security,hash,hash-lookup,2185,"seq-format-validation/validate-bam.inputs.json; [2020-07-14 05:09:22,78] [info] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:2263,Security,hash,hash-lookup,2263,"] Running with database db.url = jdbc:hsqldb:mem:f10b64bd-d8ca-4428-917b-311fca24c372;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,36] [info] Running migration RenameWorkflowOptionsInMetadata with a read batch size of 100000 and a write batch size of 100000; [2020-07-14 05:09:29,37] [info] [RenameWorkflowOptionsInMetadata] 100%; [2020-07-14 05:09:29,47] [info] Running with database db.url = jdbc:hsqldb:mem:e337a356-2f0c-4389-92c5-255465180f24;shutdown=false;hsqldb.tx=mvcc; [2020-07-14 05:09:29,89] [info] Slf4jLogger started; [2020-07-14 05:09:30,10] [info] Workflow heartbeat configuration:; {; ""cromwellId"" : ""cromid-ca5c695"",; ""heartbeatInterval"" : ""2 minutes"",; ""ttl"" : ""10 minutes"",; ""failureShutdownDuration"" : ""5 minutes"",; ""writeBatchSize"" : 10000,; ""writeThreshold"" : 10000; }; [2020-07-14 05:09:30,23] [info] Metadata summary refreshing every 1 second.; [2020-07-14 05:09:30,23] [warn] 'docker.hash-lookup.gcr-api-queries-per-100-seconds' is being deprecated, use 'docker.hash-lookup.gcr.throttle' instead (see reference.conf); [2020-07-14 05:09:30,25] [info] CallCacheWriteActor configured to flush with batch size 100 and process rate 3 seconds.; [2020-07-14 05:09:30,26] [info] KvWriteActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,26] [info] WriteMetadataActor configured to flush with batch size 200 and process rate 5 seconds.; [2020-07-14 05:09:30,36] [info] JobExecutionTokenDispenser - Distribution rate: 50 per 1 seconds.; [2020-07-14 05:09:30,46] [info] SingleWorkflowRunnerActor: Version 51; [2020-07-14 05:09:30,48] [info] SingleWorkflowRunnerActor: Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:3951,Security,Validat,ValidateBamsWf,3951,"Submitting workflow; [2020-07-14 05:09:30,55] [info] Unspecified type (Unspecified version) workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-Val",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:3966,Security,Validat,ValidateBAM,3966,"d4e2ca70674 submitted; [2020-07-14 05:09:30,66] [info] SingleWorkflowRunnerActor: Workflow submitted 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [inf",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4371,Security,Validat,ValidateBamsWf,4371,"[info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4386,Security,Validat,ValidateBAM,4386,"4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4598,Security,Validat,ValidateBAM,4598,"ush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4763,Security,Validat,ValidateBAM,4763,"4 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4795,Security,Validat,ValidateSamFile,4795,"4 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4843,Security,Validat,ValidateBamsWf,4843,"4 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4900,Security,Validat,ValidateBAM,4900,"4 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5095,Security,Validat,ValidateBAM,5095,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5223,Security,Validat,ValidateBamsWf,5223,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5280,Security,Validat,ValidateBAM,5280,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5464,Security,Validat,ValidateBamsWf,5464,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5521,Security,Validat,ValidateBAM,5521,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5643,Security,Validat,ValidateBamsWf,5643,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5700,Security,Validat,ValidateBAM,5700,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5741,Security,Validat,ValidateBamsWf,5741,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5798,Security,Validat,ValidateBAM,5798,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:5944,Security,Validat,ValidateBamsWf,5944,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6001,Security,Validat,ValidateBAM,6001,"onActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be8",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6168,Security,Validat,ValidateBamsWf,6168,"xisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6225,Security,Validat,ValidateBAM,6225,"xisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6360,Security,Validat,ValidateBamsWf,6360,"ithout --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-execution",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6417,Security,Validat,ValidateBAM,6417,"ithout --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-execution",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6584,Security,Validat,ValidateBAM,6584,"dateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6710,Security,Validat,ValidateBAM,6710,"rd-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6901,Security,Validat,ValidateBamsWf,6901,"rd-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow fi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:6916,Security,Validat,ValidateBAM,6916,"e82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/script. # get the return code (working even if the container was detached); rc=$(docker wait cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:7181,Security,Validat,ValidateBamsWf,7181,"teBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:7238,Security,Validat,ValidateBAM,7238,"teBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid). # remove the container after waiting; docker rm cat /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid. # return exit code; exit $rc; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:7365,Security,Validat,ValidateBamsWf,7365,"r [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down Workflow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:7422,Security,Validat,ValidateBAM,7422,"r [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down Workflow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:7500,Security,Validat,ValidateBamsWf,7500,"r [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down Workflow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:7557,Security,Validat,ValidateBAM,7557,"r [968be82cValidateBamsWf.ValidateBAM:0:1]: job id: 243; [2020-07-14 05:09:45,29] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Status change from - to Done; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor Workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674 failed (during ExecutingWorkflowState): Job ValidateBamsWf.ValidateBAM:0:1 exited with return code -1 which has not been declared as a valid return code. See 'continueOnReturnCode' runtime attribute for more details.; Check the content of stderr for potential additional information: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr.; Could not retrieve content: Could not read from /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr: /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/stderr; [2020-07-14 05:09:46,38] [info] WorkflowManagerActor WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 is in a terminal state: WorkflowFailedState; [2020-07-14 05:09:51,97] [info] SingleWorkflowRunnerActor workflow finished with status 'Failed'.; [2020-07-14 05:09:55,28] [info] Workflow polling stopped; [2020-07-14 05:09:55,30] [info] 0 workflows released by cromid-ca5c695; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowStoreActor - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down WorkflowLogCopyRouter - Timeout = 5 seconds; [2020-07-14 05:09:55,30] [info] Shutting down JobExecutionTokenDispenser - Timeout = 5 seconds; [2020-07-14 05:09:55,31] [info] JobExecutionTokenDispenser stopped; [2020-07-14 05:09:55,31] [info] Aborting all running workflows.; [2020-07-14 05:09:55,31] [info] WorkflowStoreActor stopped; [2020-07-14 05:09:55,31] [info] WorkflowLogCopyRouter stopped; [2020-07-14 05:09:55,31] [info] Shutting down Workflow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4200,Testability,log,log,4200,",67] [info] 1 new workflows fetched by cromid-ca5c695: 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,68] [info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4237,Testability,log,log,4237,"[info] WorkflowManagerActor Starting workflow 968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] WorkflowManagerActor Successfully started WorkflowActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674; [2020-07-14 05:09:30,69] [info] Retrieved 1 workflows from the WorkflowStoreActor; [2020-07-14 05:09:30,72] [info] WorkflowStoreHeartbeatWriteActor configured to flush with batch size 10000 and process rate 2 minutes.; [2020-07-14 05:09:30,83] [info] MaterializeWorkflowDescriptorActor [968be82c]: Parsing workflow as WDL 1.0; [2020-07-14 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4939,Testability,test,test,4939,"4 05:09:31,60] [info] MaterializeWorkflowDescriptorActor [968be82c]: Call-to-Backend assignments: ValidateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6710:4960,Testability,test,test,4960,"idateBamsWf.ValidateBAM -> Local; [2020-07-14 05:09:31,82] [warn] Local [968be82c]: Key/s [memory, disks] is/are not supported by backend. Unsupported attributes will not be part of job executions.; [2020-07-14 05:09:35,38] [info] Not triggering log of token queue status. Effective log interval = None; [2020-07-14 05:09:37,15] [info] WorkflowExecutionActor-968be82c-eef3-4bdb-a1ab-3d4e2ca70674 [968be82c]: Starting ValidateBamsWf.ValidateBAM; [2020-07-14 05:09:37,39] [info] Assigned new job execution tokens to the following groups: 968be82c: 1; [2020-07-14 05:09:41,61] [warn] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: Unrecognized runtime attribute keys: disks, memory; [2020-07-14 05:09:41,71] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: /gatk/gatk \; ValidateSamFile \; --INPUT /cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/inputs/-1942028726/test.bam \; --OUTPUT test.validation_.txt \; --MODE SUMMARY; [2020-07-14 05:09:41,76] [info] BackgroundConfigAsyncJobExecutionActor [968be82cValidateBamsWf.ValidateBAM:0:1]: executing: # make sure there is no preexisting Docker CID file; rm -f /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid; # run as in the original configuration without --rm flag (will remove later); docker run \; --cidfile /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0/execution/docker_cid \; -i \; \; --entrypoint /bin/bash \; -v /gatk/my_data/tools/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:/cromwell-executions/ValidateBamsWf/968be82c-eef3-4bdb-a1ab-3d4e2ca70674/call-ValidateBAM/shard-0:delegated \; broadinstitute/gatk@sha256:18146e79d06787483310e5de666502090a480e10ac0fad06a36a5e7a5c9bb1dc /cromwell-executions/ValidateBam",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6710
https://github.com/broadinstitute/gatk/issues/6712:173,Deployability,release,released,173,Currently Funcotator will not check the version of the datasources on startup. This will cause breaking changes to raise stack traces in Funcotator when new datasources are released. Add a check for the version of the data sources so Funcotator will not open incompatible versions.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6712
https://github.com/broadinstitute/gatk/issues/6715:129,Availability,down,downloaded,129,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715
https://github.com/broadinstitute/gatk/issues/6715:353,Availability,avail,available,353,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715
https://github.com/broadinstitute/gatk/issues/6715:656,Availability,avail,available,656,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715
https://github.com/broadinstitute/gatk/issues/6715:1670,Availability,ERROR,ERROR,1670,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715
https://github.com/broadinstitute/gatk/issues/6715:815,Modifiability,polymorphi,polymorphic,815,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715
https://github.com/broadinstitute/gatk/issues/6715:1730,Safety,detect,detected,1730,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; Resource Bundle. ### Affected version(s); Resource Bundle downloaded 21. July 2020 (ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/ OR https://console.cloud.google.com/storage/browser/genomics-public-data/resources/broad/hg38/v0;tab=objects?prefix=). ### Description ; The available dataset lack information for FS, SOR etc. but this parameter are necessary for the best practice workflow of the VariantRecalibrator and cannot be added with the VariantAnnotator as the individual information is not included. #### Steps to reproduce; Run VariantRecalibrator with the publicly available reference files. And the recommended parameter settings. gatk --java-options ""-Xmx24g -Xms24g"" VariantRecalibrator \; -V ${inputfile} \; --trust-all-polymorphic \; -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 \; -an FS -an ReadPosRankSum -an MQRankSum -an QD -an SOR \; -mode INDEL \; --max-gaussians 4 \; -resource:mills,known=false,training=true,truth=true,prior=12 ${gatk_ref}Mills_and_1000G_gold_standard.indels.hg38.vcf.gz \; -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ${gatk_ref}Axiom_Exome_Plus.genotypes.all_populations.poly.hg38.vcf.gz \; -resource:dbsnp,known=true,training=false,truth=false,prior=2 ${gatk_ref}/Homo_sapiens_assembly38.dbsnp138.vcf \; -O ${fileprefix}_indels.recal \; --tranches-file ${fileprefix}_indels.tranches. #### Expected behavior; Calculation of VQSLOD tranches. #### Actual behavior; A USER ERROR has occurred: Bad input: Values for FS annotation not detected for ANY training variant in the input callset. VariantAnnotator may be used to add these annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6715
https://github.com/broadinstitute/gatk/issues/6719:2,Availability,down,download,2,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - 4.1.8.1.tar.gz saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719
https://github.com/broadinstitute/gatk/issues/6719:233,Availability,Error,Error,233,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - 4.1.8.1.tar.gz saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719
https://github.com/broadinstitute/gatk/issues/6719:379,Availability,Error,Error,379,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - 4.1.8.1.tar.gz saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719
https://github.com/broadinstitute/gatk/issues/6719:392,Availability,recover,recoverable,392,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - 4.1.8.1.tar.gz saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719
https://github.com/broadinstitute/gatk/issues/6719:19,Deployability,release,release,19,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - 4.1.8.1.tar.gz saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719
https://github.com/broadinstitute/gatk/issues/6719:392,Safety,recover,recoverable,392,I download 4.1.8.1 release tar.gz file but can't unzip.; ```; 63800K .......... .......... .......... .......... .......... 49.2K; 63850K 533G=21m48s. 2020-07-22 09:06:30 (48.8 KB/s) - 4.1.8.1.tar.gz saved [65382686]; ```; Here is Error:; ```; $tar -zxf 4.1.8.1.tar.gz . gzip: stdin: unexpected end of file; tar: Unexpected EOF in archive; tar: Unexpected EOF in archive; tar: Error is not recoverable: exiting now; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6719
https://github.com/broadinstitute/gatk/issues/6720:66,Deployability,release,release,66,"LearnReadOrientationModel json file does not exist within gatkdoc release subfolder in v.4.1.8.1. We are now utilizing these files to automatically create Galaxy tool wrappers, so it would be awesome to get this in for the next release. Thanks much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6720
https://github.com/broadinstitute/gatk/issues/6720:228,Deployability,release,release,228,"LearnReadOrientationModel json file does not exist within gatkdoc release subfolder in v.4.1.8.1. We are now utilizing these files to automatically create Galaxy tool wrappers, so it would be awesome to get this in for the next release. Thanks much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6720
https://github.com/broadinstitute/gatk/issues/6720:167,Integrability,wrap,wrappers,167,"LearnReadOrientationModel json file does not exist within gatkdoc release subfolder in v.4.1.8.1. We are now utilizing these files to automatically create Galaxy tool wrappers, so it would be awesome to get this in for the next release. Thanks much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6720
https://github.com/broadinstitute/gatk/issues/6720:0,Usability,Learn,LearnReadOrientationModel,0,"LearnReadOrientationModel json file does not exist within gatkdoc release subfolder in v.4.1.8.1. We are now utilizing these files to automatically create Galaxy tool wrappers, so it would be awesome to get this in for the next release. Thanks much!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6720
https://github.com/broadinstitute/gatk/issues/6724:492,Availability,ERROR,ERROR,492,"# Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - [x] 4.1.5.0 ~ 4.1.8.1. ### Description ; _Mutation with AF ~2.5% missed by Mutect2 paired-calling. It may be related to M2's active region selection module_. #### Steps to reproduce. * Default (both `--force_active` and `--alleles` are OFF)  **No call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O no_call.vcf.gz -L interval.bed --force-active false -verbosity ERROR; ```. * With force_active ON  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_active.vcf.gz -L interval.bed --force-active true -verbosity ERROR; ```. * With `--alleles` ON (make use of the above force_active results)  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_alleles.vcf.gz -L interval.bed --force-active false -verbosity ERROR --alleles force_active.vcf.gz; ```. #### Expected behavior. ```; bcftools query -s cancer -f '%CHROM\t%POS\t%REF\t%ALT\t[%AF{0}]\n' force_alleles.vcf.gz; 12	25378562	C	T	0.024; 12	25378660	A	G	0.014; ```. #### Actual behavior; _Empty output_. #### Other information. <details><summary> IGV screen shot of the mutation <code>12:g.25378562C>T</code></summary>; <img width=""1131"" alt=""igv"" src=""https://user-images.githubusercontent.com/4134899/88393449-3861cc80-cdf0-11ea-8e31-1a99b3b21ed9.png"">; </details>. We used the 1000genomes Phase2 Reference Genome Sequence (hs37d5).; ![ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz](ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz). The cancer and matched normal bams (aligned to hs37d5) to reproduce the above behaviors ([data.zip](https://github.com/broadinstitute/gatk/files/4971930/data.zip)). Thanks,; Richard",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6724
https://github.com/broadinstitute/gatk/issues/6724:700,Availability,ERROR,ERROR,700,"# Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - [x] 4.1.5.0 ~ 4.1.8.1. ### Description ; _Mutation with AF ~2.5% missed by Mutect2 paired-calling. It may be related to M2's active region selection module_. #### Steps to reproduce. * Default (both `--force_active` and `--alleles` are OFF)  **No call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O no_call.vcf.gz -L interval.bed --force-active false -verbosity ERROR; ```. * With force_active ON  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_active.vcf.gz -L interval.bed --force-active true -verbosity ERROR; ```. * With `--alleles` ON (make use of the above force_active results)  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_alleles.vcf.gz -L interval.bed --force-active false -verbosity ERROR --alleles force_active.vcf.gz; ```. #### Expected behavior. ```; bcftools query -s cancer -f '%CHROM\t%POS\t%REF\t%ALT\t[%AF{0}]\n' force_alleles.vcf.gz; 12	25378562	C	T	0.024; 12	25378660	A	G	0.014; ```. #### Actual behavior; _Empty output_. #### Other information. <details><summary> IGV screen shot of the mutation <code>12:g.25378562C>T</code></summary>; <img width=""1131"" alt=""igv"" src=""https://user-images.githubusercontent.com/4134899/88393449-3861cc80-cdf0-11ea-8e31-1a99b3b21ed9.png"">; </details>. We used the 1000genomes Phase2 Reference Genome Sequence (hs37d5).; ![ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz](ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz). The cancer and matched normal bams (aligned to hs37d5) to reproduce the above behaviors ([data.zip](https://github.com/broadinstitute/gatk/files/4971930/data.zip)). Thanks,; Richard",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6724
https://github.com/broadinstitute/gatk/issues/6724:954,Availability,ERROR,ERROR,954,"# Bug Report. ### Affected tool(s) or class(es); _Mutect2_. ### Affected version(s); - [x] 4.1.5.0 ~ 4.1.8.1. ### Description ; _Mutation with AF ~2.5% missed by Mutect2 paired-calling. It may be related to M2's active region selection module_. #### Steps to reproduce. * Default (both `--force_active` and `--alleles` are OFF)  **No call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O no_call.vcf.gz -L interval.bed --force-active false -verbosity ERROR; ```. * With force_active ON  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_active.vcf.gz -L interval.bed --force-active true -verbosity ERROR; ```. * With `--alleles` ON (make use of the above force_active results)  **Correct call**; ```; gatk Mutect2 -I cancer.bam -I normal.bam -R /opt/dat/hs37d5.fa -normal normal -O force_alleles.vcf.gz -L interval.bed --force-active false -verbosity ERROR --alleles force_active.vcf.gz; ```. #### Expected behavior. ```; bcftools query -s cancer -f '%CHROM\t%POS\t%REF\t%ALT\t[%AF{0}]\n' force_alleles.vcf.gz; 12	25378562	C	T	0.024; 12	25378660	A	G	0.014; ```. #### Actual behavior; _Empty output_. #### Other information. <details><summary> IGV screen shot of the mutation <code>12:g.25378562C>T</code></summary>; <img width=""1131"" alt=""igv"" src=""https://user-images.githubusercontent.com/4134899/88393449-3861cc80-cdf0-11ea-8e31-1a99b3b21ed9.png"">; </details>. We used the 1000genomes Phase2 Reference Genome Sequence (hs37d5).; ![ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz](ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/phase2_reference_assembly_sequence/hs37d5.fa.gz). The cancer and matched normal bams (aligned to hs37d5) to reproduce the above behaviors ([data.zip](https://github.com/broadinstitute/gatk/files/4971930/data.zip)). Thanks,; Richard",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6724
https://github.com/broadinstitute/gatk/issues/6725:171,Availability,error,error,171,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:182,Availability,error,error,182,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:323,Availability,error,error,323,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:2410,Availability,avail,available,2410,"analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jul 26, 2020 10:20:35 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Sun Jul 26 10:20:35 EDT 2020] Executing as farrell@scc-hadoop.bu.edu on Linux 3.10.0-1062.12.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; INFO 2020-07-26 10:20:35 LiftoverVcf Loading up the target reference genome.; INFO 2020-07-26 10:20:56 LiftoverVcf Lifting variants over and sorting (not yet writing the output file.); [Sun Jul 26 10:20:56 EDT 2020] picard.vcf.LiftoverVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=5861015552; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException: Badly formed variant context at location chr1:596697; getEnd() was 596797 but this VariantContext contains an END key with value 532177; at htsjdk.variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.Variant",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:4011,Availability,Down,Download,4011,variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:4910,Availability,error,error,4910,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:5009,Availability,error,error,5009,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:5180,Availability,error,error,5180,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:377,Deployability,install,install,377,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:622,Deployability,install,install,622,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:1028,Deployability,install,install,1028,") or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jul 26, 2020 10:20:35 AM shaded",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:5341,Deployability,update,updated-not,5341,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:4916,Integrability,message,message,4916,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:958,Performance,Load,Loading,958,----. ## Bug Report. ### Affected tool(s) or class(es); GATK LiftoverVcf. ### Affected version(s); gatk/4.1.7.0. ### Description . The LiftoverVcf generates the following error. The error occurs with SVs where the INFO/END is not also lifted over. This results in INFO/END before the site start position which triggers the error.; ```; Using GATK jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar LiftoverVcf -I b37/HG002_SVs_Tier1_v0.6.vcf.gz -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz -CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa; 10:20:35.165 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/share/pkg.7/gatk/4.1.7.0/install/bin/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; [Sun Jul 26 10:20:35 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:2491,Performance,Load,Loading,2491,"WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jul 26, 2020 10:20:35 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Sun Jul 26 10:20:35 EDT 2020] Executing as farrell@scc-hadoop.bu.edu on Linux 3.10.0-1062.12.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; INFO 2020-07-26 10:20:35 LiftoverVcf Loading up the target reference genome.; INFO 2020-07-26 10:20:56 LiftoverVcf Lifting variants over and sorting (not yet writing the output file.); [Sun Jul 26 10:20:56 EDT 2020] picard.vcf.LiftoverVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=5861015552; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException: Badly formed variant context at location chr1:596697; getEnd() was 596797 but this VariantContext contains an END key with value 532177; at htsjdk.variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:2140,Safety,detect,detect,2140,"5 EDT 2020] LiftoverVcf --INPUT b37/HG002_SVs_Tier1_v0.6.vcf.gz --OUTPUT b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz --CHAIN grch37_to_grch38.over.chain.gz --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz --REFERENCE_SEQUENCE /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa --WARN_ON_MISSING_CONTIG false --LOG_FAILED_INTERVALS true --WRITE_ORIGINAL_POSITION false --WRITE_ORIGINAL_ALLELES false --LIFTOVER_MIN_MATCH 1.0 --ALLOW_MISSING_FIELDS_IN_HEADER false --RECOVER_SWAPPED_REF_ALT false --TAGS_TO_REVERSE AF --TAGS_TO_DROP MAX_AF --DISABLE_SORT false --VERBOSITY INFO --QUIET false --VALIDATION_STRINGENCY STRICT --COMPRESSION_LEVEL 2 --MAX_RECORDS_IN_RAM 500000 --CREATE_INDEX false --CREATE_MD5_FILE false --GA4GH_CLIENT_SECRETS client_secrets.json --help false --version false --showHidden false --USE_JDK_DEFLATER false --USE_JDK_INFLATER false; Jul 26, 2020 10:20:35 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Sun Jul 26 10:20:35 EDT 2020] Executing as farrell@scc-hadoop.bu.edu on Linux 3.10.0-1062.12.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; INFO 2020-07-26 10:20:35 LiftoverVcf Loading up the target reference genome.; INFO 2020-07-26 10:20:56 LiftoverVcf Lifting variants over and sorting (not yet writing the output file.); [Sun Jul 26 10:20:56 EDT 2020] picard.vcf.LiftoverVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=5861015552; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException: Badly formed variant context at location chr1:596697; getEnd() was 596797 but this VariantContext contains an END key with value 532177; at htsjdk.variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.Va",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:5228,Safety,abort,aborts,5228,variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz. gatk LiftoverVcf \; -I b37/HG002_SVs_Tier1_v0.6.vcf.gz \; -O b38/HG002_SVs_Tier1_v0.6.hg38.vcf.gz \; -CHAIN grch37_to_grch38.over.chain.gz \; --REJECT b38/HG002_SVs_Tier1_v0.6.rejected.vcf.gz \; -R /restricted/projectnb/casa/ref/GRCh38_full_analysis_set_plus_decoy_hla.fa. #### Expected behavior; The original b37 vcf has a deletion here:. 1 532077 ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT A; SVLEN=-100;;SVTYPE=DEL;END=532177;sizecat=100to299;. The liftover to hg38 should look like this:; chr1 596697 REF=ACATTCATGCTCACTCATACACACCCAGATCATATATACACTCGTGCACACATTCACACTCATACACACCCAAATCATACTCACATTCATGCACACATGTT; ALT=A; INFO Fields; SVLEN=-100; SVTYPE=DEL;END=596797;sizecat=100to299;. The error message suggests LiftoverVcf is not updating the INFO/END field from 532177 to 596797 and an error is being triggered since the END is before the start. An incorrect INFO/END will cause problems with tabix and other programs. #### Actual behavior; It generates an error when the INFO/END is before the start and aborts.. ----. ## Feature request; Liftover INFO/END . ### Description; ; The INFO/END position also needs to be updated-not just the site position.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:3060,Security,validat,validateStop,3060,".ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; [Sun Jul 26 10:20:35 EDT 2020] Executing as farrell@scc-hadoop.bu.edu on Linux 3.10.0-1062.12.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; INFO 2020-07-26 10:20:35 LiftoverVcf Loading up the target reference genome.; INFO 2020-07-26 10:20:56 LiftoverVcf Lifting variants over and sorting (not yet writing the output file.); [Sun Jul 26 10:20:56 EDT 2020] picard.vcf.LiftoverVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=5861015552; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException: Badly formed variant context at location chr1:596697; getEnd() was 596797 but this VariantContext contains an END key with value 532177; at htsjdk.variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6725:3148,Security,validat,validate,3148,"e running on Google Compute Engine.; [Sun Jul 26 10:20:35 EDT 2020] Executing as farrell@scc-hadoop.bu.edu on Linux 3.10.0-1062.12.1.el7.x86_64 amd64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_121-b13; Deflater: Intel; Inflater: Intel; Provider GCS is available; Picard version: Version:4.1.7.0; INFO 2020-07-26 10:20:35 LiftoverVcf Loading up the target reference genome.; INFO 2020-07-26 10:20:56 LiftoverVcf Lifting variants over and sorting (not yet writing the output file.); [Sun Jul 26 10:20:56 EDT 2020] picard.vcf.LiftoverVcf done. Elapsed time: 0.36 minutes.; Runtime.totalMemory()=5861015552; To get help, see http://broadinstitute.github.io/picard/index.html#GettingHelp; htsjdk.tribble.TribbleException: Badly formed variant context at location chr1:596697; getEnd() was 596797 but this VariantContext contains an END key with value 532177; at htsjdk.variant.variantcontext.VariantContext.validateStop(VariantContext.java:1401); at htsjdk.variant.variantcontext.VariantContext.validate(VariantContext.java:1383); at htsjdk.variant.variantcontext.VariantContext.<init>(VariantContext.java:489); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:647); at htsjdk.variant.variantcontext.VariantContextBuilder.make(VariantContextBuilder.java:638); at picard.util.LiftoverUtils.liftVariant(LiftoverUtils.java:92); at picard.vcf.LiftoverVcf.doWork(LiftoverVcf.java:426); at picard.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:305); at org.broadinstitute.hellbender.cmdline.PicardCommandLineProgramExecutor.instanceMain(PicardCommandLineProgramExecutor.java:25); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292). ```. #### Steps to reproduce. Download vcf from here:. ftp://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/data/AshkenazimTrio/analysis/NIST_SVs_Integration_v0.6/HG002_SVs_Tier1_v0.6.vcf.gz",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6725
https://github.com/broadinstitute/gatk/issues/6727:185,Availability,error,error,185,"## Bug Report. ### Affected tool(s) or class(es); CalculateContamination. ### Affected version(s); - [x] Latest public release version 4.1.8.1. ### Description . There appears to be an error mode where if not a lot of sites are provided, the contamination estimation tool will estimate the error on contamination as 0.0. We should change this to either error out if enough sites are not provided, or modify the calculation to correctly reflect the uncertainty in contamination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727
https://github.com/broadinstitute/gatk/issues/6727:290,Availability,error,error,290,"## Bug Report. ### Affected tool(s) or class(es); CalculateContamination. ### Affected version(s); - [x] Latest public release version 4.1.8.1. ### Description . There appears to be an error mode where if not a lot of sites are provided, the contamination estimation tool will estimate the error on contamination as 0.0. We should change this to either error out if enough sites are not provided, or modify the calculation to correctly reflect the uncertainty in contamination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727
https://github.com/broadinstitute/gatk/issues/6727:353,Availability,error,error,353,"## Bug Report. ### Affected tool(s) or class(es); CalculateContamination. ### Affected version(s); - [x] Latest public release version 4.1.8.1. ### Description . There appears to be an error mode where if not a lot of sites are provided, the contamination estimation tool will estimate the error on contamination as 0.0. We should change this to either error out if enough sites are not provided, or modify the calculation to correctly reflect the uncertainty in contamination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727
https://github.com/broadinstitute/gatk/issues/6727:119,Deployability,release,release,119,"## Bug Report. ### Affected tool(s) or class(es); CalculateContamination. ### Affected version(s); - [x] Latest public release version 4.1.8.1. ### Description . There appears to be an error mode where if not a lot of sites are provided, the contamination estimation tool will estimate the error on contamination as 0.0. We should change this to either error out if enough sites are not provided, or modify the calculation to correctly reflect the uncertainty in contamination.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6727
https://github.com/broadinstitute/gatk/issues/6728:267,Deployability,release,release,267,"## Bug Report. No changes have been made to the BQSR code that calculates qualities, but there are differences in quality scores from version to version. This is to understand why. ### Affected tool(s) or class(es); BQSR. ### Affected version(s); - [x] Latest public release version. #### Steps to reproduce. Ran GATK 4.1.8 and 4.1.3 on the same bam, got different quality scores. #### Expected behavior. Expect same quality scores across these versions. #### Actual behavior. These are quality distributions that differ from the two different versions on the same bam.; [qual.pdf](https://github.com/broadinstitute/gatk/files/4984005/qual.pdf); [qual.pdf](https://github.com/broadinstitute/gatk/files/4984007/qual.pdf)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6728
https://github.com/broadinstitute/gatk/pull/6729:16,Performance,optimiz,optimization,16,"* There was an ""optimization"" put in place in SelectVariants which accidentally added a quadraticly scaling check on the genotypes.; * This keeps the optimization but makes it linear instead of quadratic on the number of samples.; * On one example with several thousand samples there was a speed up from ~5 minutes to .1 minutes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6729
https://github.com/broadinstitute/gatk/pull/6729:150,Performance,optimiz,optimization,150,"* There was an ""optimization"" put in place in SelectVariants which accidentally added a quadraticly scaling check on the genotypes.; * This keeps the optimization but makes it linear instead of quadratic on the number of samples.; * On one example with several thousand samples there was a speed up from ~5 minutes to .1 minutes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6729
https://github.com/broadinstitute/gatk/issues/6730:2321,Availability,error,error,2321,"; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath(CachingIndexedFastaSequenceFile.java:173); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:143); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSeque",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:2440,Availability,ERROR,ERROR,2440,"ter'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath(CachingIndexedFastaSequenceFile.java:173); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:143); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.processAssemblyRegions(HaplotypeCallerSpark.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:172,Deployability,release,release,172,"## Bug Report. ### Affected tool(s) or class(es); ReadsPipelineSpark (HaplotypeCallerSpark) when running over a spark cluster. ### Affected version(s); - [x] Latest public release version [GATK v4.1.8.1]. ### Description . #### Tools used:; latest docker image from broadinstitute/gatk; latest hadoop (3.3.0); spark 2.3.1 without hadoop which is able to use the custom hadoop setup. #### Steps to reproduce. **Script run:**; ```; #!/bin/bash. export HADOOP_CONF_DIR=/etc/hadoop; export HADOOP_HOME=/mnt/hadoop-latest; export JAVA_HOME=/mnt/jre1.8.0_192; export SPARK_HOME=/mnt/spark-2.3.1-bin-without-hadoop; export HADOOP_USER_NAME=hadoop. # export SPARK_DIST_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath). TEST_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/small""; COMMON_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common""; INPUT_DIR=""$TEST_DIR/input""; OUTPUT_DIR=""$TEST_DIR/output"". input_bam=""$INPUT_DIR/small_CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam""; output_vcf_basename=""$OUTPUT_DIR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21"". ref_fasta=""$COMMON_DIR/human_g1k_v37.20.21.fasta""; known_sites=""$COMMON_DIR/dbsnp_138.b37.20.21.vcf"". gatk ReadsPipelineSpark \; -R ${ref_fasta} \; -I ${input_bam} \; -O ${output_vcf_basename}.vcf \; --known-sites ${known_sites} \; -pairHMM AVX_LOGLESS_CACHING \; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:1414,Deployability,deploy,deployMode,1414,"``; #!/bin/bash. export HADOOP_CONF_DIR=/etc/hadoop; export HADOOP_HOME=/mnt/hadoop-latest; export JAVA_HOME=/mnt/jre1.8.0_192; export SPARK_HOME=/mnt/spark-2.3.1-bin-without-hadoop; export HADOOP_USER_NAME=hadoop. # export SPARK_DIST_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath). TEST_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/small""; COMMON_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common""; INPUT_DIR=""$TEST_DIR/input""; OUTPUT_DIR=""$TEST_DIR/output"". input_bam=""$INPUT_DIR/small_CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam""; output_vcf_basename=""$OUTPUT_DIR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21"". ref_fasta=""$COMMON_DIR/human_g1k_v37.20.21.fasta""; known_sites=""$COMMON_DIR/dbsnp_138.b37.20.21.vcf"". gatk ReadsPipelineSpark \; -R ${ref_fasta} \; -I ${input_bam} \; -O ${output_vcf_basename}.vcf \; --known-sites ${known_sites} \; -pairHMM AVX_LOGLESS_CACHING \; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; *******************************************************************",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:3624,Deployability,pipeline,pipelines,3624,****; org.broadinstitute.hellbender.exceptions.UserException$MissingReference: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.checkFastaPath(CachingIndexedFastaSequenceFile.java:173); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:143); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:125); at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.<init>(CachingIndexedFastaSequenceFile.java:110); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.processAssemblyRegions(HaplotypeCallerSpark.java:148); at org.broadinstitute.hellbender.tools.HaplotypeCallerSpark.callVariantsWithHaplotypeCallerAndWriteOutput(HaplotypeCallerSpark.java:277); at org.broadinstitute.hellbender.tools.spark.pipelines.ReadsPipelineSpark.runTool(ReadsPipelineSpark.java:224); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:4724,Deployability,deploy,deploy,4724,"ine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:546); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721) ; ```. When I specify input as: `hdfs:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, the tool tries to access `hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. **Stack trace for this:**; ```; java.lang.IllegalArgumentException: Wrong FS: hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta, expected: hdfs://cromwellhadooptest; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:776); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:247); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1725); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1722); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1737); at org.apa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:8033,Deployability,deploy,deploy,8033,"y.getReferenceSequenceFile(ReferenceSequenceFileFactory.java:111); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceHadoopSparkSource.getReferenceSequenceDictionary(ReferenceHadoopSparkSource.java:41); at org.broadinstitute.hellbender.engine.spark.datasources.ReferenceMultiSparkSource.getReferenceSequenceDictionary(ReferenceMultiSparkSource.java:93); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeReference(GATKSparkTool.java:604); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.initializeToolInputs(GATKSparkTool.java:553); at org.broadinstitute.hellbender.engine.spark.GATKSparkTool.runPipeline(GATKSparkTool.java:544); at org.broadinstitute.hellbender.engine.spark.SparkCommandLineProgram.doWork(SparkCommandLineProgram.java:31); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721) ; ```; The above makes sense, that's why I added the hostname and port for the namenode. It seems like after verifying that the file `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` exists, some code transforms this path into `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:1653,Security,access,access,1653,"_CLASSPATH=$($HADOOP_HOME/bin/hadoop classpath). TEST_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/small""; COMMON_DIR=""hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common""; INPUT_DIR=""$TEST_DIR/input""; OUTPUT_DIR=""$TEST_DIR/output"". input_bam=""$INPUT_DIR/small_CEUTrio.HiSeq.WGS.b37.NA12878.20.21.bam""; output_vcf_basename=""$OUTPUT_DIR/CEUTrio.HiSeq.WGS.b37.NA12878.20.21"". ref_fasta=""$COMMON_DIR/human_g1k_v37.20.21.fasta""; known_sites=""$COMMON_DIR/dbsnp_138.b37.20.21.vcf"". gatk ReadsPipelineSpark \; -R ${ref_fasta} \; -I ${input_bam} \; -O ${output_vcf_basename}.vcf \; --known-sites ${known_sites} \; -pairHMM AVX_LOGLESS_CACHING \; --spark-verbosity DEBUG \; -- --spark-runner SPARK --spark-master yarn-cluster \; # --conf 'spark.submit.deployMode=cluster'; ```. #### Expected behavior. ReadsPipelineSpark should be able to resolve the hdfs file path: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. #### Actual behavior; The tool tries to access: `file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta` even when the input is: `hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. Verified that the file is accesible through hdfs:; ```; (gatk) root@2e738717b9c1:/gatk/mnt# $HADOOP_HOME/bin/hdfs dfs -ls hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; -rw-r--r-- 3 hadoop supergroup 113008112 2020-07-29 15:54 hdfs://cromwellhadooptest:8020/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta; ```; When I specify input as: `hdfs://cromwellhadooptest/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, (i.e. without the port) I get the same error. **Stack trace for this**:; ```; ***********************************************************************; A USER ERROR has occurred: The specified fasta file (file:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta) does not exist.; ***********************************************************************; org.broadinstitute.hellbe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6730:4906,Security,access,access,4906,"r.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); at java.lang.reflect.Method.invoke(Method.java:498); at org.apache.spark.deploy.yarn.ApplicationMaster$$anon$4.run(ApplicationMaster.scala:721) ; ```. When I specify input as: `hdfs:///user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`, the tool tries to access `hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta`. **Stack trace for this:**; ```; java.lang.IllegalArgumentException: Wrong FS: hdfs://cromwellhadooptest:-1/user/hadoop/gatk/common/human_g1k_v37.20.21.fasta, expected: hdfs://cromwellhadooptest; at org.apache.hadoop.fs.FileSystem.checkPath(FileSystem.java:776); at org.apache.hadoop.hdfs.DistributedFileSystem.getPathName(DistributedFileSystem.java:247); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1725); at org.apache.hadoop.hdfs.DistributedFileSystem$29.doCall(DistributedFileSystem.java:1722); at org.apache.hadoop.fs.FileSystemLinkResolver.resolve(FileSystemLinkResolver.java:81); at org.apache.hadoop.hdfs.DistributedFileSystem.getFileStatus(DistributedFileSystem.java:1737); at org.apache.hadoop.fs.FileSystem.exists(FileSystem.java:1729); at hdfs.jsr203.HadoopFileSystem.checkAccess(HadoopFileSystem.java:937); at hdfs.jsr203.HadoopFileSystemProvider.checkAccess(HadoopFileSystemProvider",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6730
https://github.com/broadinstitute/gatk/issues/6731:619,Availability,echo,echo,619,"## Feature request. ### Tool(s) or class(es) involved; MuTect2 wdl (mutect2.wdl), task Funcotate. ### Description; May I know if it sounds like a good idea to add a option to skip the ""Extract our data sources"" part in mutect2.wdl. I am using mutect2.wdl in HPC system and all the data sources and gnomad for Funcotate were unzipped and ready to use. So there is no need to ""Extract data sources"" every time (and save time and resources). I can change it and make a pull request if it sounds like a good idea. The code in mutect2.wdl that I'm going to make an option to skip listed below:. # Extract our data sources:; echo ""Extracting data sources zip file...""; mkdir datasources_dir; tar zxvf ~{data_sources_tar_gz} -C datasources_dir --strip-components 1; DATA_SOURCES_FOLDER=""$PWD/datasources_dir"". # Handle gnomAD:; if ~{use_gnomad} ; then; echo ""Enabling gnomAD...""; for potential_gnomad_gz in gnomAD_exome.tar.gz gnomAD_genome.tar.gz ; do; if [[ -f ~{dollar}{DATA_SOURCES_FOLDER}/~{dollar}{potential_gnomad_gz} ]] ; then; cd ~{dollar}{DATA_SOURCES_FOLDER}; tar -zvxf ~{dollar}{potential_gnomad_gz}; cd -; else; echo ""ERROR: Cannot find gnomAD folder: ~{dollar}{potential_gnomad_gz}"" 1>&2; false; fi; done; fi. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6731
https://github.com/broadinstitute/gatk/issues/6731:846,Availability,echo,echo,846,"## Feature request. ### Tool(s) or class(es) involved; MuTect2 wdl (mutect2.wdl), task Funcotate. ### Description; May I know if it sounds like a good idea to add a option to skip the ""Extract our data sources"" part in mutect2.wdl. I am using mutect2.wdl in HPC system and all the data sources and gnomad for Funcotate were unzipped and ready to use. So there is no need to ""Extract data sources"" every time (and save time and resources). I can change it and make a pull request if it sounds like a good idea. The code in mutect2.wdl that I'm going to make an option to skip listed below:. # Extract our data sources:; echo ""Extracting data sources zip file...""; mkdir datasources_dir; tar zxvf ~{data_sources_tar_gz} -C datasources_dir --strip-components 1; DATA_SOURCES_FOLDER=""$PWD/datasources_dir"". # Handle gnomAD:; if ~{use_gnomad} ; then; echo ""Enabling gnomAD...""; for potential_gnomad_gz in gnomAD_exome.tar.gz gnomAD_genome.tar.gz ; do; if [[ -f ~{dollar}{DATA_SOURCES_FOLDER}/~{dollar}{potential_gnomad_gz} ]] ; then; cd ~{dollar}{DATA_SOURCES_FOLDER}; tar -zvxf ~{dollar}{potential_gnomad_gz}; cd -; else; echo ""ERROR: Cannot find gnomAD folder: ~{dollar}{potential_gnomad_gz}"" 1>&2; false; fi; done; fi. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6731
https://github.com/broadinstitute/gatk/issues/6731:1118,Availability,echo,echo,1118,"## Feature request. ### Tool(s) or class(es) involved; MuTect2 wdl (mutect2.wdl), task Funcotate. ### Description; May I know if it sounds like a good idea to add a option to skip the ""Extract our data sources"" part in mutect2.wdl. I am using mutect2.wdl in HPC system and all the data sources and gnomad for Funcotate were unzipped and ready to use. So there is no need to ""Extract data sources"" every time (and save time and resources). I can change it and make a pull request if it sounds like a good idea. The code in mutect2.wdl that I'm going to make an option to skip listed below:. # Extract our data sources:; echo ""Extracting data sources zip file...""; mkdir datasources_dir; tar zxvf ~{data_sources_tar_gz} -C datasources_dir --strip-components 1; DATA_SOURCES_FOLDER=""$PWD/datasources_dir"". # Handle gnomAD:; if ~{use_gnomad} ; then; echo ""Enabling gnomAD...""; for potential_gnomad_gz in gnomAD_exome.tar.gz gnomAD_genome.tar.gz ; do; if [[ -f ~{dollar}{DATA_SOURCES_FOLDER}/~{dollar}{potential_gnomad_gz} ]] ; then; cd ~{dollar}{DATA_SOURCES_FOLDER}; tar -zvxf ~{dollar}{potential_gnomad_gz}; cd -; else; echo ""ERROR: Cannot find gnomAD folder: ~{dollar}{potential_gnomad_gz}"" 1>&2; false; fi; done; fi. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6731
https://github.com/broadinstitute/gatk/issues/6731:1124,Availability,ERROR,ERROR,1124,"## Feature request. ### Tool(s) or class(es) involved; MuTect2 wdl (mutect2.wdl), task Funcotate. ### Description; May I know if it sounds like a good idea to add a option to skip the ""Extract our data sources"" part in mutect2.wdl. I am using mutect2.wdl in HPC system and all the data sources and gnomad for Funcotate were unzipped and ready to use. So there is no need to ""Extract data sources"" every time (and save time and resources). I can change it and make a pull request if it sounds like a good idea. The code in mutect2.wdl that I'm going to make an option to skip listed below:. # Extract our data sources:; echo ""Extracting data sources zip file...""; mkdir datasources_dir; tar zxvf ~{data_sources_tar_gz} -C datasources_dir --strip-components 1; DATA_SOURCES_FOLDER=""$PWD/datasources_dir"". # Handle gnomAD:; if ~{use_gnomad} ; then; echo ""Enabling gnomAD...""; for potential_gnomad_gz in gnomAD_exome.tar.gz gnomAD_genome.tar.gz ; do; if [[ -f ~{dollar}{DATA_SOURCES_FOLDER}/~{dollar}{potential_gnomad_gz} ]] ; then; cd ~{dollar}{DATA_SOURCES_FOLDER}; tar -zvxf ~{dollar}{potential_gnomad_gz}; cd -; else; echo ""ERROR: Cannot find gnomAD folder: ~{dollar}{potential_gnomad_gz}"" 1>&2; false; fi; done; fi. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6731
https://github.com/broadinstitute/gatk/issues/6733:71,Availability,error,errors,71,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:828,Availability,error,error,828,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:857,Availability,error,error,857,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:1422,Availability,error,error,1422,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:1639,Availability,error,error,1639,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:686,Deployability,release,release,686,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:741,Deployability,release,release-,741,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:1072,Deployability,release,release-,1072,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:872,Safety,detect,detected,872,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:1703,Security,checksum,checksum,1703,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:21,Testability,test,test,21,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/issues/6733:353,Testability,test,test,353,"Hey folks,. I have a test dataset that interestingly core-dumps or JVM errors with `--smith-waterman FASTEST_AVAILABLE` but not with `--smith-waterman JAVA`. The only thing I can think of is somehow Intel's HMM has a length limitation, as I am using `--assembly-region-padding 1000` to GATK to call 100-1000bp indels (and it works!). I cannot share the test BAM unfortunately. What can I do to help debug further?. I'm using `gatk4-4.1.8.1-0` from `conda create -n debug-gatk4 -c defaults -c conda-forge -c bioconda gatk4`. ```; $gatk ... -version; The Genome Analysis Toolkit (GATK) v4.1.8.1; HTSJDK Version: 2.23.0; Picard Version: 2.22.8; $ java -version; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. First error motif:; ```; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010efa9dc2, pid=23946, tid=0x000000000000a503; #; # JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); # Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # V [libjvm.dylib+0x3a9dc2] PhaseIdealLoop::set_ctrl(Node*, Node*)+0x10; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; #; # Compiler replay data is saved as:; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; ```. Second error motif:; ```; java(24057,0x7000035bd000) malloc: Incorrect checksum for freed object 0x7fd8a8193600: probably modified after being freed.; Corrupt value: 0x2e4630002e47e; java(24057,0x7000035bd000) malloc: *** set a breakpoint in malloc_error_break to debug; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6733
https://github.com/broadinstitute/gatk/pull/6735:177,Availability,error,error,177,"Hello, . I made two changes in output files of cnv_somatic_pair_workflow.wdl to fix bugs:; 1. Change ""File"" into ""String"" for all ""entity_id"" outputs. The ""File"" type will make error when Output Copying was used in cromwell, as there is no such file in output;; 2. Change ""File select_first([CNVOncotatorWorkflow.oncotated_called_file, ""null""])"" into ""File? oncotated_called_file_tumor"" for oncotate and funcotate outputs. If oncotate or funcotate was not performed, the original will output ""null"" and make error when Output Copying was used in cromwell, as there is ""null"" file in output;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6735
https://github.com/broadinstitute/gatk/pull/6735:508,Availability,error,error,508,"Hello, . I made two changes in output files of cnv_somatic_pair_workflow.wdl to fix bugs:; 1. Change ""File"" into ""String"" for all ""entity_id"" outputs. The ""File"" type will make error when Output Copying was used in cromwell, as there is no such file in output;; 2. Change ""File select_first([CNVOncotatorWorkflow.oncotated_called_file, ""null""])"" into ""File? oncotated_called_file_tumor"" for oncotate and funcotate outputs. If oncotate or funcotate was not performed, the original will output ""null"" and make error when Output Copying was used in cromwell, as there is ""null"" file in output;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6735
https://github.com/broadinstitute/gatk/pull/6735:456,Performance,perform,performed,456,"Hello, . I made two changes in output files of cnv_somatic_pair_workflow.wdl to fix bugs:; 1. Change ""File"" into ""String"" for all ""entity_id"" outputs. The ""File"" type will make error when Output Copying was used in cromwell, as there is no such file in output;; 2. Change ""File select_first([CNVOncotatorWorkflow.oncotated_called_file, ""null""])"" into ""File? oncotated_called_file_tumor"" for oncotate and funcotate outputs. If oncotate or funcotate was not performed, the original will output ""null"" and make error when Output Copying was used in cromwell, as there is ""null"" file in output;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6735
https://github.com/broadinstitute/gatk/pull/6736:70,Deployability,release,release,70,Moving us off of of the weird beta protobuf version to the newest 3.x release.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6736
https://github.com/broadinstitute/gatk/issues/6738:329,Availability,error,error,329,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:427,Availability,error,error,427,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:612,Availability,error,error,612,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:637,Availability,ERROR,ERROR,637,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:714,Performance,Concurren,ConcurrentModificationException,714,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:452,Testability,test,testing,452,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:624,Testability,log,log,624,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:759,Testability,log,log,759,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:1024,Testability,log,log,1024,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:1076,Testability,log,log,1076,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/issues/6738:1131,Testability,log,log,1131,"As discussed in GATK office hours, this issue was reported by a user with HaplotypeCaller Spark. The entire stack trace is included below. This request was created from a contribution made by stanedav on August 03, 2020 10:07 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072104512-HaplotypeCallerSpark-error). \--. Hello, I am testing HaplotypeCallerSpark algorithm on my local machine for speeding up the variant calling. I tried to apply algorithm on my BQSR bam but I am getting this error (full log below):. ERROR Executor: Exception in task 15.0 in stage 5.0 (TID 1324) ; ; java.util.ConcurrentModificationException ... (more in log). Version of GATK: 4.1.7.0. Command I used:. $gatk --java-options ""-Xmx48g -Xms32g"" HaplotypeCallerSpark \\ ; ; \-R hg19.fasta \\ ; ; \-I remdup\_recal.bam \\ ; ; \-O output.g.vcf \\ ; ; \-L wes.bed \\ ; ; \-ERC GVCF \\ ; ; \--dont-use-soft-clipped-bases. Full log:. [https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0](https://www.dropbox.com/s/iez0zixclsh86zp/hc.log?dl=0)<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6546'>Zendesk ticket #6546</a>)<br>gz#6546</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6738
https://github.com/broadinstitute/gatk/pull/6739:184,Security,expose,expose,184,"@ahaessly Could you please take a look at this? We had a request to change this argument which wasn't previously possible since it was hardcoded into the WDL task. Ideally I'd like to expose all of the arguments but even wiring this one through the imported WDL was annoying. I tried making it an input to the task with a value like this:. ```; task M2 {; input {; Int max_reads_arg = 75; }; ...; ```; which looks a lot cleaner (don't have to make sure you wire it through from the main inputs), but when I looked in Terra it didn't actually expose the argument (I'm assuming because the M2 task is in a sub-workflow). Any thoughts on how to make this better so I can expose everything? Or is this the best way to do that at the moment?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6739
https://github.com/broadinstitute/gatk/pull/6739:542,Security,expose,expose,542,"@ahaessly Could you please take a look at this? We had a request to change this argument which wasn't previously possible since it was hardcoded into the WDL task. Ideally I'd like to expose all of the arguments but even wiring this one through the imported WDL was annoying. I tried making it an input to the task with a value like this:. ```; task M2 {; input {; Int max_reads_arg = 75; }; ...; ```; which looks a lot cleaner (don't have to make sure you wire it through from the main inputs), but when I looked in Terra it didn't actually expose the argument (I'm assuming because the M2 task is in a sub-workflow). Any thoughts on how to make this better so I can expose everything? Or is this the best way to do that at the moment?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6739
https://github.com/broadinstitute/gatk/pull/6739:668,Security,expose,expose,668,"@ahaessly Could you please take a look at this? We had a request to change this argument which wasn't previously possible since it was hardcoded into the WDL task. Ideally I'd like to expose all of the arguments but even wiring this one through the imported WDL was annoying. I tried making it an input to the task with a value like this:. ```; task M2 {; input {; Int max_reads_arg = 75; }; ...; ```; which looks a lot cleaner (don't have to make sure you wire it through from the main inputs), but when I looked in Terra it didn't actually expose the argument (I'm assuming because the M2 task is in a sub-workflow). Any thoughts on how to make this better so I can expose everything? Or is this the best way to do that at the moment?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6739
https://github.com/broadinstitute/gatk/pull/6740:125,Deployability,patch,patch,125,Running with default arguments locally the runtime (for a WGS full chr15) drops from ~8.9 minutes to ~4.7 minutes after this patch. If I had to peg something else to optimize it would be replacing CSVWriter which seems to be somewhat slow but I can be contented that this tool is reasonably fast when nothing pathological is being triggered.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6740
https://github.com/broadinstitute/gatk/pull/6740:166,Performance,optimiz,optimize,166,Running with default arguments locally the runtime (for a WGS full chr15) drops from ~8.9 minutes to ~4.7 minutes after this patch. If I had to peg something else to optimize it would be replacing CSVWriter which seems to be somewhat slow but I can be contented that this tool is reasonably fast when nothing pathological is being triggered.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6740
https://github.com/broadinstitute/gatk/pull/6741:137,Availability,failure,failures,137,This seems to resolve the issue (which I had no problem reproducing) locally. Interestingly when I run the test suite locally I get test failures here but apparently we never caught this on travis. There must be something different about the tests on travis... I am happy for advice as to how to write a test for this fix though because the error seems to be occurring under a dizzying array of spark/hadoop internal serialization code and I'm not sure how to test that properly. . Fixes #6513 #6738,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6741
https://github.com/broadinstitute/gatk/pull/6741:341,Availability,error,error,341,This seems to resolve the issue (which I had no problem reproducing) locally. Interestingly when I run the test suite locally I get test failures here but apparently we never caught this on travis. There must be something different about the tests on travis... I am happy for advice as to how to write a test for this fix though because the error seems to be occurring under a dizzying array of spark/hadoop internal serialization code and I'm not sure how to test that properly. . Fixes #6513 #6738,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6741
https://github.com/broadinstitute/gatk/pull/6741:107,Testability,test,test,107,This seems to resolve the issue (which I had no problem reproducing) locally. Interestingly when I run the test suite locally I get test failures here but apparently we never caught this on travis. There must be something different about the tests on travis... I am happy for advice as to how to write a test for this fix though because the error seems to be occurring under a dizzying array of spark/hadoop internal serialization code and I'm not sure how to test that properly. . Fixes #6513 #6738,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6741
https://github.com/broadinstitute/gatk/pull/6741:132,Testability,test,test,132,This seems to resolve the issue (which I had no problem reproducing) locally. Interestingly when I run the test suite locally I get test failures here but apparently we never caught this on travis. There must be something different about the tests on travis... I am happy for advice as to how to write a test for this fix though because the error seems to be occurring under a dizzying array of spark/hadoop internal serialization code and I'm not sure how to test that properly. . Fixes #6513 #6738,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6741
https://github.com/broadinstitute/gatk/pull/6741:242,Testability,test,tests,242,This seems to resolve the issue (which I had no problem reproducing) locally. Interestingly when I run the test suite locally I get test failures here but apparently we never caught this on travis. There must be something different about the tests on travis... I am happy for advice as to how to write a test for this fix though because the error seems to be occurring under a dizzying array of spark/hadoop internal serialization code and I'm not sure how to test that properly. . Fixes #6513 #6738,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6741
https://github.com/broadinstitute/gatk/pull/6741:304,Testability,test,test,304,This seems to resolve the issue (which I had no problem reproducing) locally. Interestingly when I run the test suite locally I get test failures here but apparently we never caught this on travis. There must be something different about the tests on travis... I am happy for advice as to how to write a test for this fix though because the error seems to be occurring under a dizzying array of spark/hadoop internal serialization code and I'm not sure how to test that properly. . Fixes #6513 #6738,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6741
https://github.com/broadinstitute/gatk/pull/6741:460,Testability,test,test,460,This seems to resolve the issue (which I had no problem reproducing) locally. Interestingly when I run the test suite locally I get test failures here but apparently we never caught this on travis. There must be something different about the tests on travis... I am happy for advice as to how to write a test for this fix though because the error seems to be occurring under a dizzying array of spark/hadoop internal serialization code and I'm not sure how to test that properly. . Fixes #6513 #6738,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6741
https://github.com/broadinstitute/gatk/issues/6742:65,Availability,error,error,65,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:766,Availability,avail,available,766,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:869,Availability,error,error,869,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:2398,Availability,error,error,2398,"KTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz. **c) The entire error log if applicable.**. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17 ; ; 20:05:36.112 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 27, 2020 8:05:40 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 20:05:40.627 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:6618,Availability,down,down,6618," 20:05:41.342 INFO GenomicsDBImport - Importing to array - /tmp/tmp.ceRdvv/GDB/genomicsdb\_array ; ; 20:05:41.342 INFO ProgressMeter - Starting traversal ; ; 20:05:41.342 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute ; ; 20:05:41.890 INFO GenomicsDBImport - Starting batch input file preload ; ; 20:05:42.320 INFO GenomicsDBImport - Finished batch preload ; ; 20:05:42.320 INFO GenomicsDBImport - Importing batch 1 with 100 samples ; ; 20:06:03.127 INFO ProgressMeter - chr1:5149001 0.4 1 2.8. .... 03:37:31.740 INFO GenomicsDBImport - Importing batch 1502 with 19 samples ; ; 03:37:35.318 INFO GenomicsDBImport - Done importing batch 1502/1502 ; ; 03:37:35.318 INFO ProgressMeter - chr1:5149001 451.9 1502 3.3 ; ; 03:37:35.318 INFO ProgressMeter - Traversal complete. Processed 1502 total batches in 451.9 minutes. ; ; 03:37:35.318 INFO GenomicsDBImport - Import of all batches to GenomicsDB completed! ; ; 03:37:35.318 INFO GenomicsDBImport - Shutting down engine ; ; \[July 28, 2020 3:37:35 AM GMT\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 451.99 minutes. ; ; Runtime.totalMemory()=1351453507584. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz ; ; 03:37:53.320 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:686,Integrability,wrap,wrapped,686,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:907,Integrability,depend,dependencies,907,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:18942,Integrability,depend,dependencies,18942,"hromosome chr1 position 5160262 (TileDB column 5160261) has too many alleles in the combined VCF record : 209 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; 04:30:07.108 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location chr1:5160262 ; ; Chromosome chr1 position 5160266 (TileDB column 5160265) has too many alleles in the combined VCF record : 1601 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; 04:33:01.269 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location chr1:5160266 ; ; Chromosome chr1 position 5160272 (TileDB column 5160271) has too many alleles in the combined VCF record : 183 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; Chromosome chr1 position 5160273 (TileDB column 5160272) has too many alleles in the combined VCF record : 25795 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. ; ; parallel: This job failed: ; ; /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk --java-options ""-Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M"" GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6566'>Zendesk ticket #6566</a>)<br>gz#6566</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:3021,Performance,Load,Loading,3021,"age-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz. **c) The entire error log if applicable.**. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17 ; ; 20:05:36.112 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 27, 2020 8:05:40 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 20:05:40.627 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 20:05:40.628 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; ; 20:05:40.628 INFO GenomicsDBImport - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 20:05:40.628 INFO GenomicsDBImport - Executing as [brynjars@lhpc-1403.decode.is](mailto:brynjars@lhpc-1403.decode.is) on Linux v3.10.0-957.5.1.el7.x86\_64 amd64 ; ; 20:05:40.628 INFO GenomicsDBImport - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_151-b12 ; ; 20:05:40.628",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:7517,Performance,Load,Loading,7517,"ort - Import of all batches to GenomicsDB completed! ; ; 03:37:35.318 INFO GenomicsDBImport - Shutting down engine ; ; \[July 28, 2020 3:37:35 AM GMT\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 451.99 minutes. ; ; Runtime.totalMemory()=1351453507584. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz ; ; 03:37:53.320 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 28, 2020 3:37:57 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 03:37:57.487 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 03:37:57.488 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; ; 03:37:57.488 INFO GenotypeGVCFs - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 03:37:57.524 INFO GenotypeGVCFs - Executing as [brynjars@lhpc-1403.decode.is](mailto:brynjars@lhpc-1403.decode.is) on Linux v3.10.0-957.5.1.el7.x86\_64 amd64 ; ; 03:37:57.524 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_151-b12 ; ; 03:37:57.524 INFO GenotypeG",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:3327,Safety,detect,detect,3327,"113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz. **c) The entire error log if applicable.**. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17 ; ; 20:05:36.112 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 27, 2020 8:05:40 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 20:05:40.627 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 20:05:40.628 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; ; 20:05:40.628 INFO GenomicsDBImport - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 20:05:40.628 INFO GenomicsDBImport - Executing as [brynjars@lhpc-1403.decode.is](mailto:brynjars@lhpc-1403.decode.is) on Linux v3.10.0-957.5.1.el7.x86\_64 amd64 ; ; 20:05:40.628 INFO GenomicsDBImport - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_151-b12 ; ; 20:05:40.628 INFO GenomicsDBImport - Start Date/Time: July 27, 2020 8:05:36 PM GMT ; ; 20:05:40.628 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 20:05:40.628 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 20:05:40.629 INFO Geno",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:7823,Safety,detect,detect,7823," ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz ; ; 03:37:53.320 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 28, 2020 3:37:57 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 03:37:57.487 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 03:37:57.488 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.7.0 ; ; 03:37:57.488 INFO GenotypeGVCFs - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 03:37:57.524 INFO GenotypeGVCFs - Executing as [brynjars@lhpc-1403.decode.is](mailto:brynjars@lhpc-1403.decode.is) on Linux v3.10.0-957.5.1.el7.x86\_64 amd64 ; ; 03:37:57.524 INFO GenotypeGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0\_151-b12 ; ; 03:37:57.524 INFO GenotypeGVCFs - Start Date/Time: July 28, 2020 3:37:53 AM GMT ; ; 03:37:57.524 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 03:37:57.524 INFO GenotypeGVCFs - ------------------------------------------------------------ ; ; 03:37:57.524 INFO GenotypeGVCFs - HTSJDK Versi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:364,Testability,Assert,Assertion-nps-nps-line-n-sample-n-failed,364,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:476,Testability,Assert,Assertion-nps-nps-line-n-sample-n-failed,476,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:859,Testability,assert,assertion,859,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:960,Testability,Assert,Assertion,960,"Issue from the forum regarding GenotypeGVCFs. User is getting an error with the bcf codec. They are running 4.1.7.0, so I recommended updating to 4.1.8.1 for now to see if it is fixed. This request was created from a contribution made by Brynjar Sigursson on August 04, 2020 09:49 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072049511-Assertion-nps-nps-line-n-sample-n-failed). \--. Hello,. I am running a variant calling using GenotypeGVCFs. The process first creates a GenomicsDB on 50Kbase regions from 150K GVCFs and then runs GenotypeGVCFs wrapped in GNU parallel (after splitting the region into as many threads as are available). Most regions complete without a problem, but some fail on GenotypeGVCFs with the assertion error. java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. Some of the failing regions I have run with up to 1.5 TB memory (18 threads) but they still fail. **a) GATK version used**. **version 4.1.7.0**. **b) Exact GATK commands used**. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:2404,Testability,log,log,2404,"KTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17. java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz. **c) The entire error log if applicable.**. Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -Xmx1290240M -Xms1290240M -DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true -jar /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar GenomicsDBImport --genomicsdb-workspace-path /tmp/tmp.ceRdvv/GDB --intervals chr1:5149001-5201000 --tmp-dir /tmp/tmp.ceRdvv/GDB\_tmp --sample-name-map /tmp/tmp.ceRdvv/snmap --batch-size 100 --reader-threads 17 ; ; 20:05:36.112 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jul 27, 2020 8:05:40 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 20:05:40.627 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6742:18995,Testability,Assert,Assertion,18995,"hromosome chr1 position 5160262 (TileDB column 5160261) has too many alleles in the combined VCF record : 209 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; 04:30:07.108 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location chr1:5160262 ; ; Chromosome chr1 position 5160266 (TileDB column 5160265) has too many alleles in the combined VCF record : 1601 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; 04:33:01.269 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location chr1:5160266 ; ; Chromosome chr1 position 5160272 (TileDB column 5160271) has too many alleles in the combined VCF record : 183 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; Chromosome chr1 position 5160273 (TileDB column 5160272) has too many alleles in the combined VCF record : 25795 : current limit : 50. Fields, such as PL, with length equal to the number of genotypes will NOT be added for this location. ; ; java: /home/vagrant/GenomicsDB/dependencies/htslib/vcf.c:4225: bcf\_update\_format: Assertion \`nps && nps\*line->n\_sample==n' failed. ; ; parallel: This job failed: ; ; /nfs/fs1/bioinfo/apps-x86\_64/GATK/gatk-4.1.7.0/gatk --java-options ""-Djava.io.tmpdir=/tmp/tmp.ceRdvv -Xmx71680M -Xms71680M"" GenotypeGVCFs --genomicsdb-use-vcf-codec -R /odinn/data/extdata/1000genomes/2019-06-21\_GRCh38/GRCh38\_full\_analysis\_set\_plus\_decoy\_hla.fa -V gendb:///tmp/tmp.ceRdvv/GDB --tmp-dir=/tmp/tmp.ceRdvv --interval-padding 1000 --only-output-calls-starting-in-intervals -L chr1:5161113-5163890 -O /tmp/tmp.ceRdvv/splitdir/reg\_5.padded.vcf.gz<br><br><i>(created from <a href='https://broadinstitute.zendesk.com/agent/tickets/6566'>Zendesk ticket #6566</a>)<br>gz#6566</i>",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6742
https://github.com/broadinstitute/gatk/issues/6744:829,Availability,error,error,829,"## Bug Report. ### Affected tool; CreateSomaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744
https://github.com/broadinstitute/gatk/issues/6744:1645,Deployability,update,update,1645,"omaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of the loss (6.8% / 52% missing ALT alleles).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744
https://github.com/broadinstitute/gatk/issues/6744:85,Testability,Test,Tested,85,"## Bug Report. ### Affected tool; CreateSomaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744
https://github.com/broadinstitute/gatk/issues/6744:308,Testability,test,tested,308,"## Bug Report. ### Affected tool; CreateSomaticPanelOfNormals. ### Affected version; Tested on version 4.1.8.0 (likely commit 3e921c6, GenomicsDB 1.3.0 #6654). ### Description ; Panel of normals generated from version 4.1.8.0 has some ~28% less records (~52% less ALT alleles) than one created with 4.1.7.0 (tested at commit 9cc92e3) with all input data and arguments unchanged. The GenomicsDB version does not seem to matter as PoN created running CreateSomaticPanelOfNormals on 4.1.8.0 has the result is about the same regardless of whether GenomicsDBImport was run on 4.1.7.0 or 4.1.8.0. CreateSomaticPanelOfNormals on 4.1.7.0 fails to run on the new GenomicsDBs. |Mutect2|GenomicsDB|CreateSomaticPanelOfNormals|Output|; |---|---|---|---|; |4.1.7.0|4.1.7.0|4.1.7.0|100% alleles (reference)|; |4.1.8.0|4.1.8.0|4.1.7.0|expected error|; |4.1.7.0|4.1.7.0|4.1.8.0|48% alleles|; |4.1.8.0|4.1.8.0|4.1.8.0|48% alleles|. #### Steps to reproduce; The PoN was created with GRCh38, scattered over chromosomes. Mutect command:; ```; $gatk/gatk --java-options ""-Xmx4G"" Mutect2 \; 	-R $reference -L $chr \; 	-I $bam --max-mnp-distance 0 \; 	-O @out1@; ```. GenomicsDBImport command:; ```; $gatk/gatk --java-options ""-Xms8G -Xmx8G"" GenomicsDBImport \; 	-R $reference -L $chr \; 	--sample-name-map ${inputGenomicsDB.out1} \; 	--genomicsdb-workspace-path @folder1@; ```. CreateSomaticPanelOfNormals:; ```; $gatk/gatk --java-options ""-Xms8G"" CreateSomaticPanelOfNormals \; 	-R $reference -V gendb://@folder1@ -O @out1@ \; 	--germline-resource $gnomad \; 	--max-germline-probability 0.5; ```. #### Expected behavior; Based on description of the GenomicsDB 1.3.0 update, CreateSomaticPanelOfNormals is expected to behave similarly in 4.1.8.0 as before with the output PoN containing a similar number of variants. #### Actual behavior; 28% of PoN records (52% alleles) are missing in 4.1.8.0 compared to 4.1.7.0. Although all spanning deletions are dropped in the new version, they account for only a small portion of th",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6744
https://github.com/broadinstitute/gatk/issues/6745:11,Availability,error,error,11,I got this error running tests once. It's unclear what the problem was. It's nice that it bubbles up as a java exception but it's hard to know what the underlying issue was. ```; java.io.IOException: GenomicsDB JNI Error: std::exception; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:215,Availability,Error,Error,215,I got this error running tests once. It's unclear what the problem was. It's nice that it bubbles up as a java exception but it's hard to know what the underlying issue was. ```; java.io.IOException: GenomicsDB JNI Error: std::exception; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:4995,Integrability,Message,MessageHubBackedObjectConnection,4995,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5053,Integrability,Message,MessageHubBackedObjectConnection,5053,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5141,Integrability,Message,MessageHubBackedObjectConnection,5141,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5199,Integrability,Message,MessageHubBackedObjectConnection,5199,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5287,Integrability,Message,MessageHub,5287,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5310,Integrability,Message,MessageHub,5310,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5356,Performance,concurren,concurrent,5356,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5464,Performance,concurren,concurrent,5464,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5555,Performance,concurren,concurrent,5555,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5650,Performance,concurren,concurrent,5650,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:5745,Performance,concurren,concurrent,5745,internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128); 	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.base/java.lang.Thread.run(Thread.java:834); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:25,Testability,test,tests,25,I got this error running tests once. It's unclear what the problem was. It's nice that it bubbles up as a java exception but it's hard to know what the underlying issue was. ```; java.io.IOException: GenomicsDB JNI Error: std::exception; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1333,Testability,test,testWriteToAndQueryFromGCS,1333,tream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMet,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1772,Testability,test,testng,1772,va:85); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.getGenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.tes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1866,Testability,test,testng,1866,GenomicsDBFeatureReader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunn,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1882,Testability,Test,TestInvoker,1882,ader(GenomicsDBImportIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1907,Testability,Test,TestInvoker,1907,ortIntegrationTest.java:927); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.Sui,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1938,Testability,test,testng,1938,rg.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorke,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1954,Testability,Test,TestInvoker,1954,ellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:1983,Testability,Test,TestInvoker,1983,micsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2014,Testability,test,testng,2014,t.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:551); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2088,Testability,test,testng,2088,; 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.Te,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2104,Testability,Test,TestInvoker,2104,ender.tools.genomicsdb.GenomicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:10,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2145,Testability,Test,TestInvoker,2145,omicsDBImportIntegrationTest.checkGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2176,Testability,test,testng,2176,ckGenomicsDBAgainstExpected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2192,Testability,Test,TestInvoker,2192,Expected(GenomicsDBImportIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2222,Testability,Test,TestInvoker,2222,portIntegrationTest.java:521); 	at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2253,Testability,test,testng,2253,g.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(Tes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2269,Testability,Test,TestMethodWorker,2269,bender.tools.genomicsdb.GenomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2304,Testability,Test,TestMethodWorker,2304,nomicsDBImportIntegrationTest.testWriteToAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2340,Testability,test,testng,2340,oAndQueryFromGCS(GenomicsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestN,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2356,Testability,Test,TestMethodWorker,2356,micsDBImportIntegrationTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2377,Testability,Test,TestMethodWorker,2377,tionTest.java:1104); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2477,Testability,test,testng,2477,ethod); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2484,Testability,Test,TestRunner,2484,at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2506,Testability,Test,TestRunner,2506,internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2536,Testability,test,testng,2536,ssorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.refl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2543,Testability,Test,TestRunner,2543,invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.Nativ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2558,Testability,Test,TestRunner,2558,MethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccess,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2588,Testability,test,testng,2588,at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2646,Testability,test,testng,2646,Impl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorIm,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2712,Testability,test,testng,2712,ava.lang.reflect.Method.invoke(Method.java:566); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.int,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2773,Testability,test,testng,2773,ng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingM,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2827,Testability,test,testng,2827,InvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.re,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2897,Testability,test,testng,2897,Method(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2962,Testability,test,testng,2962,.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2969,Testability,Test,TestNG,2969,TestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:2998,Testability,Test,TestNG,2998,oker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3025,Testability,test,testng,3025,l.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(Reflectio,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3032,Testability,Test,TestNG,3032,dRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3056,Testability,Test,TestNG,3056,uence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	a,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3083,Testability,test,testng,3083,g.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.Conte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3090,Testability,Test,TestNG,3090,g.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3107,Testability,Test,TestNG,3107,estInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3134,Testability,test,testng,3134,.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3141,Testability,Test,TestNG,3141,(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3152,Testability,Test,TestNG,3152,ker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3205,Testability,test,testing,3205,eTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3213,Testability,test,testng,3213,thods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$Dispatch,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3220,Testability,Test,TestNGTestClassProcessor,3220,r.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHan,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3254,Testability,Test,TestNGTestClassProcessor,3254,ternal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3324,Testability,test,testing,3324,6); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3332,Testability,test,testng,3332, org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.grad,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3339,Testability,Test,TestNGTestClassProcessor,3339,rnal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3369,Testability,Test,TestNGTestClassProcessor,3369,stMethodWorker.java:128); 	at java.base/java.util.ArrayList.forEach(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:3438,Testability,test,testing,3438,Each(ArrayList.java:1540); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.refl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:4358,Testability,test,testing,4358,r.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concur,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:4373,Testability,Test,TestWorker,4373,tClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPoli,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/issues/6745:4389,Testability,Test,TestWorker,4389,r.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy5.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.base/java.lang.reflect.Method.invoke(Method.java:566); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRe,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6745
https://github.com/broadinstitute/gatk/pull/6746:114,Security,expose,exposed,114,"Since GenomicsDB can be used with `CreateSomaticPanelOfNormals`, allow for the GenomicsDBArgumentCollection to be exposed with this tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6746
https://github.com/broadinstitute/gatk/issues/6747:93,Testability,test,testing,93,This change is necessary for the automatic building of GATK docker images in our large-scale testing framework.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6747
https://github.com/broadinstitute/gatk/issues/6748:6359,Availability,failure,failures,6359,"tion.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pas",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5278,Integrability,Message,MessageHubBackedObjectConnection,5278,"a:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. F",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5336,Integrability,Message,MessageHubBackedObjectConnection,5336,"tionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that severa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5424,Integrability,Message,MessageHubBackedObjectConnection,5424,"erDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5482,Integrability,Message,MessageHubBackedObjectConnection,5482,".java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5570,Integrability,Message,MessageHub,5570,"nHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5593,Integrability,Message,MessageHub,5593,"roxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:7487,Integrability,depend,depending,7487,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:402,Modifiability,variab,variable,402,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5639,Performance,concurren,concurrent,5639,"$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5747,Performance,concurren,concurrent,5747,"va:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5828,Performance,concurren,concurrent,5828,".reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass indivi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:5913,Performance,concurren,concurrent,5913,"eflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/tes",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6008,Performance,concurren,concurrent,6008,".reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_resu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:336,Testability,test,test,336,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:369,Testability,test,test,369,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:440,Testability,test,tests,440,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:522,Testability,test,tests,522,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:1632,Testability,test,testutils,1632,broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invoke,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:1811,Testability,test,testExclusionListOverridesManualDefaultAnnotations,1811,FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.Arra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2199,Testability,test,testng,2199,urce.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteR,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2293,Testability,test,testng,2293,ource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2309,Testability,Test,TestInvoker,2309,t org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.t,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2334,Testability,Test,TestInvoker,2334,te.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2365,Testability,test,testng,2365,rce.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2381,Testability,Test,TestInvoker,2381,ataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.T,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2410,Testability,Test,TestInvoker,2410, 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequen,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2441,Testability,test,testng,2441,gine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.tes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2515,Testability,test,testng,2515,stitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2531,Testability,Test,TestInvoker,2531,ureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2572,Testability,Test,TestInvoker,2572,reDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2603,Testability,test,testng,2603,broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2619,Testability,Test,TestInvoker,2619,bender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.tes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2649,Testability,Test,TestInvoker,2649,antContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2680,Testability,test,testng,2680,Memory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestCla,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2696,Testability,Test,TestMethodWorker,2696,TestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2731,Testability,Test,TestMethodWorker,2731,g.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.inter,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2767,Testability,test,testng,2767,ator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClass,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2783,Testability,Test,TestMethodWorker,2783,putRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNG,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2804,Testability,Test,TestMethodWorker,2804,.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2894,Testability,test,testng,2894, 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteT,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2901,Testability,Test,TestRunner,2901,reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassP,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2923,Testability,Test,TestRunner,2923,hodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2953,Testability,test,testng,2953,thod); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAcc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2960,Testability,Test,TestRunner,2960,t sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:2975,Testability,Test,TestRunner,2975,.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Nati,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3005,Testability,test,testng,3005,ke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.Na,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3063,Testability,test,testng,3063,gatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3129,Testability,test,testng,3129,43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(Delegat,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3190,Testability,test,testng,3190,t org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3244,Testability,test,testng,3244,hod(MethodInvocationHelper.java:133); 	at org.testng.internal.TestInvoker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispa,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3314,Testability,test,testng,3314,ker.invokeMethod(TestInvoker.java:584); 	at org.testng.internal.TestInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3379,Testability,test,testng,3379,estInvoker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3386,Testability,Test,TestNG,3386,ker.invokeTestMethod(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3415,Testability,Test,TestNG,3415,od(TestInvoker.java:172); 	at org.testng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3442,Testability,test,testng,3442,ng.internal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3449,Testability,Test,TestNG,3449,rnal.MethodRunner.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3473,Testability,Test,TestNG,3473,r.runInSequence(MethodRunner.java:46); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3500,Testability,test,testng,3500,6); 	at org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3507,Testability,Test,TestNG,3507, org.testng.internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3524,Testability,Test,TestNG,3524,internal.TestInvoker$MethodInvocationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.int,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3551,Testability,test,testng,3551,ationAgent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdap,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3558,Testability,Test,TestNG,3558,ent.invoke(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$Dis,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3569,Testability,Test,TestNG,3569,e(TestInvoker.java:804); 	at org.testng.internal.TestInvoker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingI,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3622,Testability,test,testing,3622,oker.invokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3630,Testability,test,testng,3630,vokeTestMethods(TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3637,Testability,Test,TestNGTestClassProcessor,3637,TestInvoker.java:145); 	at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3671,Testability,Test,TestNGTestClassProcessor,3671,.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3741,Testability,test,testing,3741,er.java:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3749,Testability,test,testng,3749,:146); 	at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.jav,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3756,Testability,Test,TestNGTestClassProcessor,3756,estng.internal.TestMethodWorker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3786,Testability,Test,TestNGTestClassProcessor,3786,ker.run(TestMethodWorker.java:128); 	at java.util.ArrayList.forEach(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccesso,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:3855,Testability,test,testing,3855,Each(ArrayList.java:1257); 	at org.testng.TestRunner.privateRun(TestRunner.java:770); 	at org.testng.TestRunner.run(TestRunner.java:591); 	at org.testng.SuiteRunner.runTest(SuiteRunner.java:402); 	at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:396); 	at org.testng.SuiteRunner.privateRun(SuiteRunner.java:355); 	at org.testng.SuiteRunner.run(SuiteRunner.java:304); 	at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:53); 	at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:96); 	at org.testng.TestNG.runSuitesSequentially(TestNG.java:1180); 	at org.testng.TestNG.runSuitesLocally(TestNG.java:1102); 	at org.testng.TestNG.runSuites(TestNG.java:1032); 	at org.testng.TestNG.run(TestNG.java:1000); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.runTests(TestNGTestClassProcessor.java:141); 	at org.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAcces,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:4708,Testability,test,testing,4708,rg.gradle.api.internal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:4723,Testability,Test,TestWorker,4723,ternal.tasks.testing.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at or,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:4739,Testability,Test,TestWorker,4739,esting.testng.TestNGTestClassProcessor.stop(TestNGTestClassProcessor.java:90); 	at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.stop(SuiteTestClassProcessor.java:61); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:33); 	at org.gradle.internal.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:94); 	at com.sun.proxy.$Proxy2.stop(Unknown Source); 	at org.gradle.api.internal.tasks.testing.worker.TestWorker.stop(TestWorker.java:132); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62); 	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43); 	at java.lang.reflect.Method.invoke(Method.java:498); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:36); 	at org.gradle.internal.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.inte,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6176,Testability,test,tests,6176,"lectionDispatch.dispatch(ReflectionDispatch.java:24); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6231,Testability,test,test,6231,"ote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6238,Testability,test,tests,6238,"ote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6285,Testability,test,tests,6285,"ote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:182); 	at org.gradle.internal.remote.internal.hub.MessageHubBackedObjectConnection$DispatchWrapper.dispatch(MessageHubBackedObjectConnection.java:164); 	at org.gradle.internal.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6704,Testability,test,test,6704,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6795,Testability,test,tests,6795,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6846,Testability,test,test,6846,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6916,Testability,test,test,6916,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:6989,Testability,test,test,6989,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:7158,Testability,test,test,7158,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:7174,Testability,test,test,7174,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:7181,Testability,test,tests,7181,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:7353,Testability,test,tests,7353,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:7460,Testability,test,test,7460,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:7507,Testability,test,test,7507,"rnal.hub.MessageHub$Handler.run(MessageHub.java:412); 	at org.gradle.internal.concurrent.ExecutorPolicy$CatchAndRecordFailures.onExecute(ExecutorPolicy.java:64); 	at org.gradle.internal.concurrent.ManagedExecutorImpl$1.run(ManagedExecutorImpl.java:48); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at org.gradle.internal.concurrent.ThreadFactoryImpl$ManagedThreadRunnable.run(ThreadFactoryImpl.java:56); 	at java.lang.Thread.run(Thread.java:748); ```. However, when trying to run the unit tests that failed using commands like:; ```; ./gradlew test --tests VctOutputRendererUnitTest; ```; The same tests will pass. Following the stack trace, I found that several of these failures were because the FeatureManager class threw a GATKException. Per the source code in FeatureManager.java, the exception was thrown because of either an InstantiationException, IllegalAccessException, NoSuchMethodException, or an InvocationTargetException caught when trying to determine candidate codecs for reading a VCF file. The unit test files FeatureDataSourceUnitTest and FeatureManagerUnitTest pass when running the unit tests all at once, and also pass individually. The test files correctly generate under appropriate directories under src/test/resources, as far as I can tell. . Attached is a zip archive of the test results:; [test_results.zip](https://github.com/broadinstitute/gatk/files/5065501/test_results.zip). #### Steps to reproduce; ```; export TEST_TYPE=unit; ./gradlew test; ./gradlew test --tests VcfOutputRendererUnitTest; ```; The above also will give the same results for any of the other affected classes listed above. . #### Expected behavior; I expect unit tests to pass or fail whether or not they are run as a group or individually. . #### Actual behavior; Unit test results are different depending on if the test classes are run as a large group or individually.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:81,Usability,Simpl,SimpleKeyXsvFuncotationFactoryUnitTest,81,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6748:121,Usability,Simpl,SimpleTsvOutputRendererUnitTest,121,"## Bug Report. ### Affected tool(s) or class(es); VcfFuncotationFactoryUnitTest; SimpleKeyXsvFuncotationFactoryUnitTest; SimpleTsvOutputRendererUnitTest; VcfOutputRendererUnitTest; VariantOverlapAnnotaterUnitTest. ### Affected version(s). - [x] Latest master branch as of August 12, 2020. ### Description ; When running the entire unit test suite using; ```; ./gradlew test; ```; where the environment variable TEST_TYPE=unit. The same 371 tests will fail. The following stack trace gives an example of one of the failing tests:; ```; org.broadinstitute.hellbender.exceptions.GATKException: Unable to automatically instantiate codec org.broadinstitute.hellbender.utils.codecs.AnnotatedIntervalCodec; 	at org.broadinstitute.hellbender.engine.FeatureManager.getCandidateCodecsForFile(FeatureManager.java:508); 	at org.broadinstitute.hellbender.engine.FeatureManager.getCodecForFile(FeatureManager.java:455); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getCodecForFeatureInput(FeatureDataSource.java:354); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:334); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:238); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:206); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:193); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:156); 	at org.broadinstitute.hellbender.testutils.VariantContextTestUtils.readEntireVCFIntoMemory(VariantContextTestUtils.java:67); 	at org.broadinstitute.hellbender.tools.funcotator.vcfOutput.VcfOutputRendererUnitTest.testExclusionListOverridesManualDefaultAnnotations(VcfOutputRendererUnitTest.java:40); 	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method); 	at sun.reflect.NativeMethodAccessorIm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6748
https://github.com/broadinstitute/gatk/issues/6749:270,Availability,error,error,270,"## Feature request. ### Tool(s) or class(es) involved; CNNScoreVariants and perhaps other tools. ### Description; It would be nice to take stdout as the input. For example, when it is necessary to pass raw VCF from caller to CNNScoreVariants. In the current version, an error is produced. ```; zcat /home/platon/Dissertation/Exp/ngs_test/no_filtered.vcf.gz | gatk CNNScoreVariants \; -V /dev/stdin \; -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \; -O /home/platon/Dissertation/Exp/Output; ```. ```; Using GATK jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar CNNScoreVariants -V /dev/stdin -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz -O /home/platon/Dissertation/Exp/Output; 18:04:27.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 26, 2020 6:04:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:04:27.246 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.246 INFO CNNScoreVariants - The Genome Analysis Toolkit (GATK) v4.1.8.1; 18:04:27.246 INFO CNNScoreVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749
https://github.com/broadinstitute/gatk/issues/6749:3108,Availability,down,down,3108,- For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247 INFO CNNScoreVariants - Start Date/Time: 26  2020 . 18:04:27 MSK; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Version: 2.23.0; 18:04:27.247 INFO CNNScoreVariants - Picard Version: 2.22.8; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:04:27.247 INFO CNNScoreVariants - Deflater: IntelDeflater; 18:04:27.247 INFO CNNScoreVariants - Inflater: IntelInflater; 18:04:27.247 INFO CNNScoreVariants - GCS max retries/reopens: 20; 18:04:27.247 INFO CNNScoreVariants - Requester pays: disabled; 18:04:27.247 INFO CNNScoreVariants - Initializing engine; 18:04:27.481 INFO CNNScoreVariants - Shutting down engine; [26  2020 . 18:04:27 MSK] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=362807296; ***********************************************************************. A USER ERROR has occurred: Couldn't read file file:///dev/stdin. Error was: It isn't a regular file. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749
https://github.com/broadinstitute/gatk/issues/6749:3369,Availability,ERROR,ERROR,3369,- For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247 INFO CNNScoreVariants - Start Date/Time: 26  2020 . 18:04:27 MSK; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Version: 2.23.0; 18:04:27.247 INFO CNNScoreVariants - Picard Version: 2.22.8; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:04:27.247 INFO CNNScoreVariants - Deflater: IntelDeflater; 18:04:27.247 INFO CNNScoreVariants - Inflater: IntelInflater; 18:04:27.247 INFO CNNScoreVariants - GCS max retries/reopens: 20; 18:04:27.247 INFO CNNScoreVariants - Requester pays: disabled; 18:04:27.247 INFO CNNScoreVariants - Initializing engine; 18:04:27.481 INFO CNNScoreVariants - Shutting down engine; [26  2020 . 18:04:27 MSK] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=362807296; ***********************************************************************. A USER ERROR has occurred: Couldn't read file file:///dev/stdin. Error was: It isn't a regular file. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749
https://github.com/broadinstitute/gatk/issues/6749:3427,Availability,Error,Error,3427,- For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247 INFO CNNScoreVariants - Start Date/Time: 26  2020 . 18:04:27 MSK; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Version: 2.23.0; 18:04:27.247 INFO CNNScoreVariants - Picard Version: 2.22.8; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:04:27.247 INFO CNNScoreVariants - Deflater: IntelDeflater; 18:04:27.247 INFO CNNScoreVariants - Inflater: IntelInflater; 18:04:27.247 INFO CNNScoreVariants - GCS max retries/reopens: 20; 18:04:27.247 INFO CNNScoreVariants - Requester pays: disabled; 18:04:27.247 INFO CNNScoreVariants - Initializing engine; 18:04:27.481 INFO CNNScoreVariants - Shutting down engine; [26  2020 . 18:04:27 MSK] org.broadinstitute.hellbender.tools.walkers.vqsr.CNNScoreVariants done. Elapsed time: 0.01 minutes.; Runtime.totalMemory()=362807296; ***********************************************************************. A USER ERROR has occurred: Couldn't read file file:///dev/stdin. Error was: It isn't a regular file. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749
https://github.com/broadinstitute/gatk/issues/6749:1116,Performance,Load,Loading,1116,"It would be nice to take stdout as the input. For example, when it is necessary to pass raw VCF from caller to CNNScoreVariants. In the current version, an error is produced. ```; zcat /home/platon/Dissertation/Exp/ngs_test/no_filtered.vcf.gz | gatk CNNScoreVariants \; -V /dev/stdin \; -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \; -O /home/platon/Dissertation/Exp/Output; ```. ```; Using GATK jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar CNNScoreVariants -V /dev/stdin -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz -O /home/platon/Dissertation/Exp/Output; 18:04:27.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 26, 2020 6:04:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:04:27.246 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.246 INFO CNNScoreVariants - The Genome Analysis Toolkit (GATK) v4.1.8.1; 18:04:27.246 INFO CNNScoreVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247 INFO CNNScoreVariants - Start Date/Time: 26  2020 . 18:04:27 MSK; 18:04:27.247 INFO CNNScoreVariants - -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749
https://github.com/broadinstitute/gatk/issues/6749:1411,Safety,detect,detect,1411,"ome/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz \; -O /home/platon/Dissertation/Exp/Output; ```. ```; Using GATK jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar CNNScoreVariants -V /dev/stdin -R /home/platon/Dissertation/Exp/ngs_test/homo_sapiens/Homo_sapiens.GRCh38.dna.primary_assembly.fa.gz -O /home/platon/Dissertation/Exp/Output; 18:04:27.033 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/platon/miniconda3/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 26, 2020 6:04:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:04:27.246 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.246 INFO CNNScoreVariants - The Genome Analysis Toolkit (GATK) v4.1.8.1; 18:04:27.246 INFO CNNScoreVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:04:27.246 INFO CNNScoreVariants - Executing as platon@platon-VivoBook-ASUSLaptop-X712FA-X712FA on Linux v5.4.0-42-generic amd64; 18:04:27.246 INFO CNNScoreVariants - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 18:04:27.247 INFO CNNScoreVariants - Start Date/Time: 26  2020 . 18:04:27 MSK; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - ------------------------------------------------------------; 18:04:27.247 INFO CNNScoreVariants - HTSJDK Version: 2.23.0; 18:04:27.247 INFO CNNScoreVariants - Picard Version: 2.22.8; 18:04:27.2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6749
https://github.com/broadinstitute/gatk/issues/6750:312,Availability,error,error,312,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:613,Availability,error,error,613,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:1338,Availability,Redundant,Redundant,1338,"ublic release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:1482,Availability,Redundant,Redundant,1482,"-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3.10.0-1062.9.1.el7.x86_64 amd64; 09:38:05.912 INFO HaplotypeCallerSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 09:38:05.913 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:11574,Availability,down,down,11574," is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 09:38:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.8 MB, free 15.8 GB); 20/08/15 09:38:13 INFO SparkUI: Stopped Spark web UI at http://amarel2.amarel.rutgers.edu:4040; 20/08/15 09:38:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 09:38:13 INFO MemoryStore: MemoryStore cleared; 20/08/15 09:38:13 INFO BlockManager: BlockManager stopped; 20/08/15 09:38:13 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 09:38:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 09:38:13 INFO SparkContext: Successfully stopped SparkContext; 09:38:13.271 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 9:38:13 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=15164506112; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:80); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575). 20/08/15 09:38:13 INFO ShutdownHookManager: Shutdown h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:374,Deployability,release,release,374,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:446,Deployability,release,release,446,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:501,Deployability,release,release-,501,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:318,Integrability,message,message,318,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:619,Integrability,message,message,619,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:660,Performance,cache,cache,660,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:942,Performance,cache,cache,942,"### Affected tool(s) or class(es); HaplotypeCallerSpark. gatk HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I GatherBamFiles.bam -O g.vcf.gz. The HaplotypeCaller works, but not HaplotypeCallerSpark.; Tried to use the docker image, and different server; tried to build the newest gatk, same error message. ### Affected version(s); - [ x ] Latest public release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:1617,Performance,Load,Loading,1617,"ror message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3.10.0-1062.9.1.el7.x86_64 amd64; 09:38:05.912 INFO HaplotypeCallerSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 09:38:05.913 INFO HaplotypeCallerSpark - Start Date/Time: August 15, 2020 9:38:05 AM EDT; 09:38:05.913 INFO HaplotypeC",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:1662,Performance,cache,cache,1662,"me/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3.10.0-1062.9.1.el7.x86_64 amd64; 09:38:05.912 INFO HaplotypeCallerSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 09:38:05.913 INFO HaplotypeCallerSpark - Start Date/Time: August 15, 2020 9:38:05 AM EDT; 09:38:05.913 INFO HaplotypeCallerSpark - -----------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4141,Performance,load,load,4141,JDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:38:05.914 INFO HaplotypeCallerSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:38:05.914 INFO HaplotypeCallerSpark - Deflater: IntelDeflater; 09:38:05.915 INFO HaplotypeCallerSpark - Inflater: IntelInflater; 09:38:05.915 INFO HaplotypeCallerSpark - GCS max retries/reopens: 20; 09:38:05.915 INFO HaplotypeCallerSpark - Requester pays: disabled; 09:38:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apach,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:1338,Safety,Redund,Redundant,1338,"ublic release version 4.1.8.1; java version ; ```; openjdk version ""1.8.0_152-release""; OpenJDK Runtime Environment (build 1.8.0_152-release-1056-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:1482,Safety,Redund,Redundant,1482,"-b12); OpenJDK 64-Bit Server VM (build 25.152-b12, mixed mode); ```. ### Description ; keep get the error message like below. ```; Using GATK jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3.10.0-1062.9.1.el7.x86_64 amd64; 09:38:05.912 INFO HaplotypeCallerSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 09:38:05.913 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:1904,Safety,detect,detect,1904,"-Dsamjdk.compression_level=5 -Xms10G -jar /cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCallerSpark -R GRCh38_full_analysis_set_plus_decoy_hla.fa -I SRR1573206.GatherBamFiles.bam -O SRR1573206.g.vcf.gz -G StandardAnnotation -G StandardHCAnnotation -G AS_StandardAnnotation -GQB 10 -GQB 20 -GQB 30 -GQB 40 -GQB 50 -GQB 60 -GQB 70 -GQB 80 -GQB 90 -ERC GVCF; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 09:38:05.617 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardHCAnnotation) is enabled for this tool by default; 09:38:05.655 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/cache/home/xc278/p/GATK/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 15, 2020 9:38:05 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:38:05.911 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.912 INFO HaplotypeCallerSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 09:38:05.912 INFO HaplotypeCallerSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:38:05.912 INFO HaplotypeCallerSpark - Executing as xc278@amarel2.amarel.rutgers.edu on Linux v3.10.0-1062.9.1.el7.x86_64 amd64; 09:38:05.912 INFO HaplotypeCallerSpark - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_232-b09; 09:38:05.913 INFO HaplotypeCallerSpark - Start Date/Time: August 15, 2020 9:38:05 AM EDT; 09:38:05.913 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.913 INFO HaplotypeCallerSpark - ------------------------------------------------------------; 09:38:05.914 INFO HaplotypeCallerSpark - HTSJDK Version: 2.23.0; 09:38:05.914 INFO HaplotypeCallerSpark - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4339,Security,Secur,SecurityManager,4339,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4409,Security,Secur,SecurityManager,4409,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4481,Security,Secur,SecurityManager,4481,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4552,Security,Secur,SecurityManager,4552,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4625,Security,Secur,SecurityManager,4625,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4642,Security,Secur,SecurityManager,4642,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:4659,Security,authenticat,authentication,4659,:05.915 WARN HaplotypeCallerSpark -. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. Warning: HaplotypeCallerSpark is a BETA tool and is not yet ready for use in production. !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!. 09:38:05.915 INFO HaplotypeCallerSpark - Initializing engine; 09:38:05.915 INFO HaplotypeCallerSpark - Done initializing engine; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/08/15 09:38:06 INFO SparkContext: Running Spark version 2.4.5; 09:38:06.440 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/08/15 09:38:06 INFO SparkContext: Submitted application: HaplotypeCallerSpark; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls to: xc278; 20/08/15 09:38:06 INFO SecurityManager: Changing view acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: Changing modify acls groups to:; 20/08/15 09:38:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(xc278); groups with view permissions: Set(); users with modify permissions: Set(xc278); groups with modify permissions: Set(); 20/08/15 09:38:06 INFO Utils: Successfully started service 'sparkDriver' on port 33339.; 20/08/15 09:38:06 INFO SparkEnv: Registering MapOutputTracker; 20/08/15 09:38:06 INFO SparkEnv: Registering BlockManagerMaster; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/08/15 09:38:06 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/08/15 09:38:06 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-e8d90ed7-8009-437a-8d5e-571b3a582f62; 20/08/15 09:38:06 INFO MemoryStore: MemoryStore started with capacity 15.8 GB; 20/08/15 09:38:06 INFO SparkEnv: Registering OutputCommitCoordinator; 2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/issues/6750:11199,Usability,clear,cleared,11199," 09:38:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on amarel2.amarel.rutgers.edu:46683 (size: 25.5 KB, free: 15.8 GB); 20/08/15 09:38:12 INFO SparkContext: Created broadcast 2 from newAPIHadoopFile at PathSplitSource.java:96; 09:38:12.973 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 20/08/15 09:38:13 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 11.8 MB, free 15.8 GB); 20/08/15 09:38:13 INFO SparkUI: Stopped Spark web UI at http://amarel2.amarel.rutgers.edu:4040; 20/08/15 09:38:13 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/08/15 09:38:13 INFO MemoryStore: MemoryStore cleared; 20/08/15 09:38:13 INFO BlockManager: BlockManager stopped; 20/08/15 09:38:13 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/08/15 09:38:13 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/08/15 09:38:13 INFO SparkContext: Successfully stopped SparkContext; 09:38:13.271 INFO HaplotypeCallerSpark - Shutting down engine; [August 15, 2020 9:38:13 AM EDT] org.broadinstitute.hellbender.tools.HaplotypeCallerSpark done. Elapsed time: 0.13 minutes.; Runtime.totalMemory()=15164506112; Exception in thread ""main"" java.lang.StackOverflowError; at com.esotericsoftware.kryo.util.DefaultClassResolver.writeName(DefaultClassResolver.java:108); at com.esotericsoftware.kryo.util.DefaultClassResolver.writeClass(DefaultClassResolver.java:99); at com.esotericsoftware.kryo.Kryo.writeClass(Kryo.java:540); at com.esotericsoftware.kryo.serializers.ObjectField.write(ObjectField.java:76); at com.esotericsoftware.kryo.serializers.FieldSerializer.write(FieldSerializer.java:505); at com.esotericsoftware.kryo.Kryo.writeObject(Kryo.java:575",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6750
https://github.com/broadinstitute/gatk/pull/6754:319,Performance,perform,performed,319,"Currently, SelectVariants includes a call to `initalizeAlleleAnyploidIndicesCache` for every processed variant. `initalizeAlleleAnyploidIndicesCache` requires extracting genotype information, which forces the LazyGenotypeContext machinery in htsjdk to fully decode all genotypes, even if the subsetting operation being performed does not require genotype information. This can cause such subsetting operations to take unnecessarily long amounts of time when run on large mutlisample vcfs. As an example, it takes ~24 hours to extract all snps from a 1000Genomes vcf. This PR bumps the version of htsjdk to no longer need the call to `initalizeAlleleAnyploidIndicesCache`, thus saving the performance boost from lazy genotype parsing. On the example mentioned above, this results in a ~13x speedup, as the time to extract all snps from a 1000Genomes vcf drops to under 2 hours. requires samtools/htsjdk#1500",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6754
https://github.com/broadinstitute/gatk/pull/6754:688,Performance,perform,performance,688,"Currently, SelectVariants includes a call to `initalizeAlleleAnyploidIndicesCache` for every processed variant. `initalizeAlleleAnyploidIndicesCache` requires extracting genotype information, which forces the LazyGenotypeContext machinery in htsjdk to fully decode all genotypes, even if the subsetting operation being performed does not require genotype information. This can cause such subsetting operations to take unnecessarily long amounts of time when run on large mutlisample vcfs. As an example, it takes ~24 hours to extract all snps from a 1000Genomes vcf. This PR bumps the version of htsjdk to no longer need the call to `initalizeAlleleAnyploidIndicesCache`, thus saving the performance boost from lazy genotype parsing. On the example mentioned above, this results in a ~13x speedup, as the time to extract all snps from a 1000Genomes vcf drops to under 2 hours. requires samtools/htsjdk#1500",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6754
https://github.com/broadinstitute/gatk/issues/6755:451,Availability,error,error,451,"I am trying to run GATK (v4.1.8.0) BaseRecalibrator for my whole exome sequencing data. I generated the interval_list file using picard such that:. ```; dict=/data/anderslab/Annotation/GATK/Homo_sapiens_assembly38.dict; picard_jar=/nfs/software/helmod/apps/Core/picard-tools/2.4.1-gcb01/picard.jar; java -jar ${picard_jar} BedToIntervalList \; I=Padded.bed \; O=Padded.interval_list \; SD=${dict}; ```; But when I feed the file into the GATK I got an error:. ```; [August 18, 2020 10:31:17 AM EDT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2224553984; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ; ""/data/refs/GATK/S31285117_hs_hg38/interval_list/Padded.interval_list"" is not valid for this input. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Some suggestions?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6755
https://github.com/broadinstitute/gatk/issues/6755:713,Availability,ERROR,ERROR,713,"I am trying to run GATK (v4.1.8.0) BaseRecalibrator for my whole exome sequencing data. I generated the interval_list file using picard such that:. ```; dict=/data/anderslab/Annotation/GATK/Homo_sapiens_assembly38.dict; picard_jar=/nfs/software/helmod/apps/Core/picard-tools/2.4.1-gcb01/picard.jar; java -jar ${picard_jar} BedToIntervalList \; I=Padded.bed \; O=Padded.interval_list \; SD=${dict}; ```; But when I feed the file into the GATK I got an error:. ```; [August 18, 2020 10:31:17 AM EDT] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=2224553984; ***********************************************************************. A USER ERROR has occurred: Badly formed genome unclippedLoc: Query interval ; ""/data/refs/GATK/S31285117_hs_hg38/interval_list/Padded.interval_list"" is not valid for this input. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Some suggestions?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6755
https://github.com/broadinstitute/gatk/issues/6756:223,Deployability,release,release,223,"Apple is going to turn on Software Signing with OSX Catalina very soon (sometime this fall or so). While signing GATK will be fine, theoretically we have to sign all of the dynamic libraries that we leverage. OpenJDK did a release a while ago with these security features on and it was a major fiasco. We need to research what the signing requirements are and how they will affect the GATK release process.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6756
https://github.com/broadinstitute/gatk/issues/6756:390,Deployability,release,release,390,"Apple is going to turn on Software Signing with OSX Catalina very soon (sometime this fall or so). While signing GATK will be fine, theoretically we have to sign all of the dynamic libraries that we leverage. OpenJDK did a release a while ago with these security features on and it was a major fiasco. We need to research what the signing requirements are and how they will affect the GATK release process.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6756
https://github.com/broadinstitute/gatk/issues/6756:254,Security,secur,security,254,"Apple is going to turn on Software Signing with OSX Catalina very soon (sometime this fall or so). While signing GATK will be fine, theoretically we have to sign all of the dynamic libraries that we leverage. OpenJDK did a release a while ago with these security features on and it was a major fiasco. We need to research what the signing requirements are and how they will affect the GATK release process.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6756
https://github.com/broadinstitute/gatk/issues/6758:1653,Availability,error,error,1653,"Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Funcotator; gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; ### Affected version(s); gatk4.1.8.1 (installed using conda). ### Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-format MAF; 15:41:48.793 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shiyang/s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:1811,Availability,ERROR,ERROR,1811,"l behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Funcotator; gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; ### Affected version(s); gatk4.1.8.1 (installed using conda). ### Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-format MAF; 15:41:48.793 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 19, 2020 3:41:49 PM shaded.cloud_nio.com.google.auth.oau",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:18040,Availability,error,errors,18040,"Census_Table_1_full_2012-03-15.txt -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cancer_gene_census/hg19/CancerGeneCensus_Table_1_full_2012-03-15.txt; 15:41:51.073 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:18350,Availability,error,errors,18350,"1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO Dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:18885,Availability,error,errors,18885,"41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:20315,Availability,down,down,20315,"Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:532); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.<init>(TribbleIndexedFeatureReader.java:441); at htsjdk.tribble.TribbleIndexedFeatureReader.query(TribbleIndexedFeatureReader.java:297); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:567); at org.broadinstitute.hellbender.engine.FeatureDataSource.queryAndPrefetch(FeatureDataSource.java:536); at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:20542,Availability,Error,Error,20542,".tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:532); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.<init>(TribbleIndexedFeatureReader.java:441); at htsjdk.tribble.TribbleIndexedFeatureReader.query(TribbleIndexedFeatureReader.java:297); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:567); at org.broadinstitute.hellbender.engine.FeatureDataSource.queryAndPrefetch(FeatureDataSource.java:536); at org.broadinstitute.hellbender.engine.FeatureManager.getFeatures(FeatureManager.java:352); at org.broadinstitute.hellbender.engine.FeatureContext.getValues(FeatureContext.java:173); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.queryFeaturesFromFeatureContext(",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26177,Availability,down,downloaded,26177,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26219,Availability,down,downloaded,26219,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26324,Availability,error,error,26324,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26627,Availability,error,error,26627,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:1460,Deployability,install,installed,1460,"ss.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Funcotator; gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; ### Affected version(s); gatk4.1.8.1 (installed using conda). ### Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --outpu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:1592,Deployability,pipeline,pipeline,1592,"uest**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Funcotator; gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; ### Affected version(s); gatk4.1.8.1 (installed using conda). ### Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-for",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:22632,Energy Efficiency,Reduce,ReduceOps,22632,ctory.java:314); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.S,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:22642,Energy Efficiency,Reduce,ReduceOp,22642,ctory.java:314); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.S,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:22670,Energy Efficiency,Reduce,ReduceOps,22670,broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpli,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:22568,Integrability,wrap,wrapAndCopyInto,22568,y.queryFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:314); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.getFeaturesFromFeatureContext(DataSourceFuncotationFactory.java:229); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:207); at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:566); at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Ite,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:23827,Integrability,wrap,wrapAndCopyInto,23827,org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:482); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:472); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:485); at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:12207,Modifiability,config,config,12207,osmic_tissue.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg19/cosmic_tissue.tsv; 15:41:49.599 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/dnaRepairGenes.20180524T145835.csv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/dna_repair_genes/hg19/dnaRepairGenes.20180524T145835.csv; 15:41:49.600 INFO DataSourceUtils - Setting lookahead cache for data source: Oreganno : 100000; 15:41:49.604 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/oreganno.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.tsv; 15:41:49.604 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.config; 15:41:49.659 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/oreganno.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.tsv; 15:41:49.659 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/oreganno.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.tsv; WARNING 2020-08-19 15:41:49 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 15:41:49.663 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/hgnc_download_Nov302017.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/hgnc/hg19/hgnc_download_Nov302017.tsv; 15:41:49.851 INFO DataSourceUtils - Resol,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:14753,Modifiability,config,config,14753,Utils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_20180401.vcf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:50.021 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:50.092 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar : 100000; 15:41:50.093 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; 15:41:50.093 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.config; 15:41:50.158 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; 15:41:50.158 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; WARNING 2020-08-19 15:41:50 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 15:41:50.159 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/hg19_All_20180423.vcf.gz -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/dbsnp/hg19/hg19_All_20180423.vcf.gz; 15:41:50.159 INFO Data,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:2591,Performance,Load,Loading,2591,"00 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-format MAF; 15:41:48.793 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 19, 2020 3:41:49 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:41:49.028 INFO Funcotator - ------------------------------------------------------------; 15:41:49.028 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.8.1; 15:41:49.028 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:41:49.028 INFO Funcotator - Executing as shiyang@r740 on Linux v3.10.0-957.el7.x86_64 amd64; 15:41:49.028 INFO Funcotator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 15:41:49.028 INFO Funcotator - Start Date/Time: August 19, 2020 3:41:48 PM CST; 15:41:49.029 INFO Funcotator - ------------------------------------------------------------; 15:41:49.029 INFO Fun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:11719,Performance,cache,cache,11719,dataSources/funcotator_dataSources.v1.7.20200521s/cosmic_fusion/hg19/cosmic_fusion.tsv; 15:41:49.525 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/Familial_Cancer_Genes.no_dupes.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/familial/hg19/Familial_Cancer_Genes.no_dupes.tsv; 15:41:49.527 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/cosmic_tissue.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic_tissue/hg19/cosmic_tissue.tsv; 15:41:49.599 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/dnaRepairGenes.20180524T145835.csv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/dna_repair_genes/hg19/dnaRepairGenes.20180524T145835.csv; 15:41:49.600 INFO DataSourceUtils - Setting lookahead cache for data source: Oreganno : 100000; 15:41:49.604 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/oreganno.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.tsv; 15:41:49.604 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.config; 15:41:49.659 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/oreganno.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.tsv; 15:41:49.659 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/oreganno.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.tsv; WARNING 202,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:13492,Performance,cache,cache,13492, - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/oreganno.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/oreganno/hg19/oreganno.tsv; WARNING 2020-08-19 15:41:49 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 15:41:49.663 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/hgnc_download_Nov302017.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/hgnc/hg19/hgnc_download_Nov302017.tsv; 15:41:49.851 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_20180401.vcf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:49.851 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar_VCF : 100000; 15:41:49.852 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:49.938 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_20180401.vcf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:50.021 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:50.092 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar : 100000; 15:41:50.093 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:14246,Performance,cache,cache,14246,///home/shiyang/softwares/gatk-4.1.8.1/clinvar_20180401.vcf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:49.851 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar_VCF : 100000; 15:41:49.852 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:49.938 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_20180401.vcf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:50.021 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar/hg19/clinvar_20180401.vcf; 15:41:50.092 INFO DataSourceUtils - Setting lookahead cache for data source: ClinVar : 100000; 15:41:50.093 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; 15:41:50.093 INFO FeatureManager - Using codec XsvLocatableTableCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.config; 15:41:50.158 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; 15:41:50.158 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:15794,Performance,cache,cache,15794,- Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; 15:41:50.158 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/clinvar_hgmd.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/clinvar_hgmd/hg19/clinvar_hgmd.tsv; WARNING 2020-08-19 15:41:50 AsciiLineReader Creating an indexable source for an AsciiFeatureCodec using a stream that is neither a PositionalBufferedStream nor a BlockCompressedInputStream; 15:41:50.159 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/hg19_All_20180423.vcf.gz -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/dbsnp/hg19/hg19_All_20180423.vcf.gz; 15:41:50.159 INFO DataSourceUtils - Setting lookahead cache for data source: dbSNP : 100000; 15:41:50.163 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/dbsnp/hg19/hg19_All_20180423.vcf.gz; 15:41:50.277 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/hg19_All_20180423.vcf.gz -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/dbsnp/hg19/hg19_All_20180423.vcf.gz; 15:41:50.375 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/dbsnp/hg19/hg19_All_20180423.vcf.gz; 15:41:50.490 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xhgnc_v75_37.hg19.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xhgnc/hg19/gencode_xhgnc_v75_37.hg19.tsv; 15:41:51.07,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:17708,Performance,cache,cache,17708,"taSources.v1.7.20200521s/gencode_xhgnc/hg19/gencode_xhgnc_v75_37.hg19.tsv; 15:41:51.070 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/CancerGeneCensus_Table_1_full_2012-03-15.txt -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cancer_gene_census/hg19/CancerGeneCensus_Table_1_full_2012-03-15.txt; 15:41:51.073 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested versi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:20171,Performance,cache,cache,20171,"gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:532); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.<init>(TribbleIndexedFeatureReader.java:441); at htsjdk.tribble.TribbleIndexedFeatureReader.query(TribbleIndexedFeatureReader.java:297); at org.broadinstitute.hellbender.engine.Featu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:20252,Performance,cache,cache,20252,"ata source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:532); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.<init>(TribbleIndexedFeatureReader.java:441); at htsjdk.tribble.TribbleIndexedFeatureReader.query(TribbleIndexedFeatureReader.java:297); at org.broadinstitute.hellbender.engine.FeatureDataSource.refillQueryCache(FeatureDataSource.java:567); at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:2877,Safety,detect,detect,2877,".1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-format MAF; 15:41:48.793 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 19, 2020 3:41:49 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:41:49.028 INFO Funcotator - ------------------------------------------------------------; 15:41:49.028 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.8.1; 15:41:49.028 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:41:49.028 INFO Funcotator - Executing as shiyang@r740 on Linux v3.10.0-957.el7.x86_64 amd64; 15:41:49.028 INFO Funcotator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 15:41:49.028 INFO Funcotator - Start Date/Time: August 19, 2020 3:41:48 PM CST; 15:41:49.029 INFO Funcotator - ------------------------------------------------------------; 15:41:49.029 INFO Funcotator - ------------------------------------------------------------; 15:41:49.029 INFO Funcotator - HTSJDK Version: 2.23.0; 15:41:49.029 INFO Funcotator - Picard Version: 2.22.8; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:41:49.029 INFO Funcotator - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:4657,Security,Validat,Validating,4657,5:41:49.029 INFO Funcotator - HTSJDK Version: 2.23.0; 15:41:49.029 INFO Funcotator - Picard Version: 2.22.8; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:41:49.029 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:41:49.029 INFO Funcotator - Deflater: IntelDeflater; 15:41:49.029 INFO Funcotator - Inflater: IntelInflater; 15:41:49.029 INFO Funcotator - GCS max retries/reopens: 20; 15:41:49.029 INFO Funcotator - Requester pays: disabled; 15:41:49.029 INFO Funcotator - Initializing engine; 15:41:49.471 INFO FeatureManager - Using codec VCFCodec to read file file:///home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf; 15:41:49.489 INFO Funcotator - Done initializing engine; 15:41:49.489 INFO Funcotator - Validating Sequence Dictionaries...; 15:41:49.490 INFO Funcotator - Processing user transcripts/defaults/overrides...; 15:41:49.490 INFO Funcotator - Initializing data sources...; 15:41:49.492 INFO DataSourceUtils - Initializing data sources from directory: /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s; 15:41:49.492 INFO DataSourceUtils - Data sources version: 1.7.2020429s; 15:41:49.492 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 15:41:49.492 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200429s.tar.gz; 15:41:49.496 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/achilles_lineage_results.import.txt -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/achilles/hg19/achilles_lin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:1256,Testability,test,test,1256,"ial support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Funcotator; gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; ### Affected version(s); gatk4.1.8.1 (installed using conda). ### Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_som",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:1387,Testability,test,test,1387,"n reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Funcotator; gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; ### Affected version(s); gatk4.1.8.1 (installed using conda). ### Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:2516,Testability,test,test,2516," Description ; I want to use Funcotator to annotate the VCF file given by Illumina TruSight Oncology 500 pipeline. But when I run the command above, it throws out an error, seems something related with malformat. I check my VCF file and think it should be OK. So I wonder if you can kindly tell me how to fix this bug?; The ERROR is:; `Using GATK jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar Funcotator --variant /home/shiyang/Project/BGB900_101/TSO_result/TSO_somatic_vcf/112-0005-0031-B1_L1.UP12.tmb.tsv.tso.somatic.vcf --reference /storage01/ref_genome/hg19/bwa/ucsc.hg19.fasta --ref-version hg19 --data-sources-path /home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s --output /home/shiyang/Project/BGB900_101/TSO_result/test.maf --output-file-format MAF; 15:41:48.793 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/shiyang/softwares/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 19, 2020 3:41:49 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:41:49.028 INFO Funcotator - ------------------------------------------------------------; 15:41:49.028 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.8.1; 15:41:49.028 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:41:49.028 INFO Funcotator - Executing as shiyang@r740 on Linux v3.10.0-957.el7.x86_64 amd64; 15:41:49.028 INFO Funcotator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 15:41:49.028 INFO Funcotator - Start Date/Time: August 19, 2020 3:41:48 PM CST; 15:41:49.029",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:17854,Testability,test,tested,17854,"Census_Table_1_full_2012-03-15.txt -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cancer_gene_census/hg19/CancerGeneCensus_Table_1_full_2012-03-15.txt; 15:41:51.073 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:4",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:18164,Testability,test,tested,18164,"1/Cosmic.db -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/cosmic/hg19/Cosmic.db; 15:41:51.190 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.annotation.REORDERED.gtf -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.190 INFO DataSourceUtils - Setting lookahead cache for data source: Gencode : 100000; 15:41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO Dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:18699,Testability,test,tested,18699,"41:51.191 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.192 INFO FeatureManager - Using codec GencodeGtfCodec to read file file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; 15:41:51.193 WARN GencodeGtfCodec - GENCODE GTF Header line 1 has a version number that is above maximum tested version (v 28) (given: 34): ##description: evidence-based annotation of the human genome (GRCh38), version 34 (Ensembl 100), mapped to GRCh37 with gencode-backmap Continuing, but errors may occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:19944,Testability,test,test,19944," occur.; 15:41:51.201 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode.v34lift37.pc_transcripts.fa -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.pc_transcripts.fa; 15:41:54.713 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/simple_uniprot_Dec012014.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/simple_uniprot/hg19/simple_uniprot_Dec012014.tsv; 15:41:54.747 INFO DataSourceUtils - Resolved data source file path: file:///home/shiyang/softwares/gatk-4.1.8.1/gencode_xrefseq_v75_37.tsv -> file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode_xrefseq/hg19/gencode_xrefseq_v75_37.tsv; 15:41:54.798 INFO Funcotator - Initializing Funcotator Engine...; 15:41:54.811 INFO Funcotator - Creating a MAF file for output: file:/home/shiyang/Project/BGB900_101/TSO_result/test.maf; 15:41:54.826 INFO ProgressMeter - Starting traversal; 15:41:54.827 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 15:41:54.853 INFO VcfFuncotationFactory - ClinVar_VCF 20180401 cache hits/total: 0/0; 15:41:54.854 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 15:41:54.860 INFO Funcotator - Shutting down engine; [August 19, 2020 3:41:54 PM CST] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.10 minutes.; Runtime.totalMemory()=2588409856; htsjdk.tribble.TribbleException$MalformedFeatureFile: Error parsing LineIteratorImpl(SynchronousLineReader) at the first queried after chr1:2489658, for input source: file:///home/shiyang/softwares/funcotator_dataSources/funcotator_dataSources.v1.7.20200521s/gencode/hg19/gencode.v34lift37.annotation.REORDERED.gtf; at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26032,Testability,test,test,26032,":65); at java.lang.Long.parseLong(Long.java:589); at java.lang.Long.valueOf(Long.java:803); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26106,Testability,test,test,26106,"a.lang.Long.valueOf(Long.java:803); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26359,Testability,test,test,26359,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26490,Testability,test,test,26490,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/issues/6758:26282,Usability,simpl,simply,26282,"3); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:224); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.<init>(GencodeGtfExonFeature.java:19); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfExonFeature.create(GencodeGtfExonFeature.java:23); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$4.create(GencodeGtfFeature.java:777); at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:320); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:138); at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCodec.decode(AbstractGtfCodec.java:23); at htsjdk.tribble.TribbleIndexedFeatureReader$QueryIterator.readNextRecord(TribbleIndexedFeatureReader.java:501); ... 43 more; `; #### Steps to reproduce. [test.somatic.vcf.gz](https://github.com/broadinstitute/gatk/files/5094900/test.somatic.vcf.gz). I upload my VCF file here. The reference is hg19 downloaded from UCSC. The data sources is downloaded from funcotator official website (somatic). You can simply run this command to reproduce this error:; `gatk Funcotator --variant test.somatic.vcf --reference ucsc.hg19.fasta --ref-version hg19 --data-sources-path funcotator_dataSources.v1.7.20200521s --output test.maf --output-file-format MAF; `; #### Expected behavior; Successfully run and output a MAF file. #### Actual behavior; Throw out an error and an MAF file with only header; ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6758
https://github.com/broadinstitute/gatk/pull/6759:24,Deployability,update,update,24,Add bq util classes and update dependencies; add local sort classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6759
https://github.com/broadinstitute/gatk/pull/6759:31,Integrability,depend,dependencies,31,Add bq util classes and update dependencies; add local sort classes,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6759
https://github.com/broadinstitute/gatk/issues/6762:82,Availability,error,error,82,"The `PS` tag should be type `Integer`, not `String` according to the spec, but no error is reported (for me). ```bash; bcftools view https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz chr1:4001310-4001310 > test.vcf; ```. Related: https://github.com/genome-in-a-bottle/giab_latest_release/issues/15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762
https://github.com/broadinstitute/gatk/issues/6762:177,Deployability,release,release,177,"The `PS` tag should be type `Integer`, not `String` according to the spec, but no error is reported (for me). ```bash; bcftools view https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz chr1:4001310-4001310 > test.vcf; ```. Related: https://github.com/genome-in-a-bottle/giab_latest_release/issues/15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762
https://github.com/broadinstitute/gatk/issues/6762:351,Testability,test,test,351,"The `PS` tag should be type `Integer`, not `String` according to the spec, but no error is reported (for me). ```bash; bcftools view https://ftp-trace.ncbi.nlm.nih.gov/giab/ftp/release/NA12878_HG001/latest/GRCh38/HG001_GRCh38_GIAB_highconf_CG-IllFB-IllGATKHC-Ion-10X-SOLID_CHROM1-X_v.3.3.2_highconf_PGandRTGphasetransfer.vcf.gz chr1:4001310-4001310 > test.vcf; ```. Related: https://github.com/genome-in-a-bottle/giab_latest_release/issues/15",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6762
https://github.com/broadinstitute/gatk/pull/6763:22,Deployability,release,release,22,Requires a new htsjdk release - draft state until then.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6763
https://github.com/broadinstitute/gatk/issues/6765:5817,Availability,down,down,5817,".2 14260000 4500268.2. 10:46:40.543 INFO ProgressMeter - chr1:178147829 3.3 14969000 4487827.8. 10:46:50.551 INFO ProgressMeter - chr1:186125500 3.5 15636000 4464516.0. 10:47:00.555 INFO ProgressMeter - chr1:194986011 3.7 16297000 4441809.8. 10:47:10.565 INFO ProgressMeter - chr1:203560084 3.8 17001000 4432191.5. 10:47:20.577 INFO ProgressMeter - chr1:211951736 4.0 17700000 4421996.7. 10:47:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765
https://github.com/broadinstitute/gatk/issues/6765:7222,Integrability,wrap,wrapAndCopyInto,7222,e.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481). at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471). at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151). at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174). at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234). at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418). at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206). at org.broadinstitute.hellbender.Main.m,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765
https://github.com/broadinstitute/gatk/issues/6765:1335,Performance,Load,Loading,1335,"ATK version (4.1.4.1), however it still persists in the current GATK version. #### Steps to reproduce; Issue was reproduced by the support team using just chr2. #### Associated forum post; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072506131-leftalignindels-java-lang-IllegalArgumentException-the-range-cannot-contain-negative-indices. Command: ; gatk LeftAlignIndels \; -R /projects/beck-lab/walawi/GATK/hg38.fa \; -I /projects/beck-lab/walawi/GATK/sorted_bam/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2.withRG.sorted.bam \; -O /projects/beck-lab/walawi/GATK/sorted_bam/leftalignindels/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2_leftaligned.withRG.sorted.bam. ```; gatk LeftAlignIndels -R /projects/beck-lab/walawi/GATK/hg38.fa -I /projects/beck-lab/walawi/GATK/sorted_bam/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2.withRG.sorted.bam -O /projects/beck-lab/walawi/GATK/sorted_bam/leftalignindels/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2_leftaligned.withRG.sorted.bam. 10:43:19.190 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/walawi/miniconda3/envs/gatk4_venv/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Aug 18, 2020 10:43:19 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 10:43:19.667 INFO LeftAlignIndels - ------------------------------------------------------------. 10:43:19.668 INFO LeftAlignIndels - The Genome Analysis Toolkit (GATK) v4.1.7.0. 10:43:19.668 INFO LeftAlignIndels - For support and documentation go to https://software.broadinstitute.org/gatk/. 10:43:19.668 INFO LeftAlignIndels - Executing as walawi@sumner055 on Linux v3.10.0-1062.1.2.el7.x86_64 amd64. 10:43:19.668 INFO LeftAlignIndels - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01. 10:43:19.668 INFO LeftAlignIndels - Start Date/Time: August 18, 2020 10:43:19 AM EDT. 10:43:19.668 INFO LeftAlignIndels - -------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765
https://github.com/broadinstitute/gatk/issues/6765:1647,Safety,detect,detect,1647,"n-negative-indices. Command: ; gatk LeftAlignIndels \; -R /projects/beck-lab/walawi/GATK/hg38.fa \; -I /projects/beck-lab/walawi/GATK/sorted_bam/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2.withRG.sorted.bam \; -O /projects/beck-lab/walawi/GATK/sorted_bam/leftalignindels/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2_leftaligned.withRG.sorted.bam. ```; gatk LeftAlignIndels -R /projects/beck-lab/walawi/GATK/hg38.fa -I /projects/beck-lab/walawi/GATK/sorted_bam/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2.withRG.sorted.bam -O /projects/beck-lab/walawi/GATK/sorted_bam/leftalignindels/H1-L_GT19_35266_GACCTGAA-TTGGTGAG_S2_leftaligned.withRG.sorted.bam. 10:43:19.190 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/walawi/miniconda3/envs/gatk4_venv/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Aug 18, 2020 10:43:19 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 10:43:19.667 INFO LeftAlignIndels - ------------------------------------------------------------. 10:43:19.668 INFO LeftAlignIndels - The Genome Analysis Toolkit (GATK) v4.1.7.0. 10:43:19.668 INFO LeftAlignIndels - For support and documentation go to https://software.broadinstitute.org/gatk/. 10:43:19.668 INFO LeftAlignIndels - Executing as walawi@sumner055 on Linux v3.10.0-1062.1.2.el7.x86_64 amd64. 10:43:19.668 INFO LeftAlignIndels - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01. 10:43:19.668 INFO LeftAlignIndels - Start Date/Time: August 18, 2020 10:43:19 AM EDT. 10:43:19.668 INFO LeftAlignIndels - ------------------------------------------------------------. 10:43:19.668 INFO LeftAlignIndels - ------------------------------------------------------------. 10:43:19.668 INFO LeftAlignIndels - HTSJDK Version: 2.21.2. 10:43:19.669 INFO LeftAlignIndels - Picard Version: 2.21.9. 10:43:19.669 INFO LeftAlignIndels - HTSJDK Defaults.COMPRESSION_LE",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765
https://github.com/broadinstitute/gatk/issues/6765:6108,Security,validat,validateArg,6108,"5. 10:47:20.577 INFO ProgressMeter - chr1:211951736 4.0 17700000 4421996.7. 10:47:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765
https://github.com/broadinstitute/gatk/issues/6765:6187,Security,validat,validate,6187,"7:30.580 INFO ProgressMeter - chr1:220837654 4.2 18418000 4417386.9. 10:47:40.592 INFO ProgressMeter - chr1:229536819 4.3 19156000 4417642.0. 10:47:50.595 INFO ProgressMeter - chr1:237917173 4.5 19861000 4410598.8. 10:48:00.598 INFO ProgressMeter - chr1:246682719 4.7 20561000 4403066.6. 10:48:10.604 INFO ProgressMeter - chr2:6733404 4.8 21270000 4397838.6. 10:48:20.605 INFO ProgressMeter - chr2:15144861 5.0 21942000 4385607.8. 10:48:30.607 INFO ProgressMeter - chr2:24131740 5.2 22650000 4381143.4. 10:48:40.610 INFO ProgressMeter - chr2:32916253 5.3 23467000 4397382.8. 10:48:43.217 INFO LeftAlignIndels - Shutting down engine. [August 18, 2020 10:48:43 AM EDT] org.broadinstitute.hellbender.tools.LeftAlignIndels done. Elapsed time: 5.40 minutes. Runtime.totalMemory()=2076049408. java.lang.IllegalArgumentException: the range cannot contain negative indices. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.IndexRange.validate(IndexRange.java:108). at org.broadinstitute.hellbender.utils.IndexRange.shift(IndexRange.java:73). at org.broadinstitute.hellbender.utils.IndexRange.shiftLeft(IndexRange.java:77). at org.broadinstitute.hellbender.utils.read.AlignmentUtils.leftAlignIndels(AlignmentUtils.java:735). at org.broadinstitute.hellbender.tools.LeftAlignIndels.apply(LeftAlignIndels.java:78). at org.broadinstitute.hellbender.engine.ReadWalker.lambda$traverse$0(ReadWalker.java:96). at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175). at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193). at java.util.Iterator.forEachRemaining(Iterator.java:116). at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801). at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481). at java.util",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6765
https://github.com/broadinstitute/gatk/issues/6766:203,Availability,error,error,203,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - GATK 4.1.8.1 (Latest release as of 08/24/20). ### Description ; User is running CombineGVCFs and getting a java error java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52). This issue was discussed at the GATK Office Hours meeting. ### Associated forum post; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect wheth",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:1475,Availability,echo,echo,1475,"-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:1502,Availability,Error,Error,1502,"931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Serve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:1570,Availability,Redundant,Redundant,1570,"neGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 12:01:37.108 INFO CombineGVCFs - Start Date/Time: August 24, 202",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:5353,Availability,down,down,5353,"file:///paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz; 12:01:38.184 INFO FeatureManager - Using codec VCFCodec to read file file:///paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz; 12:01:38.311 INFO FeatureManager - Using codec VCFCodec to read file file:///paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz; 12:01:38.417 INFO FeatureManager - Using codec VCFCodec to read file file:///paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf; 12:01:49.097 INFO CombineGVCFs - Done initializing engine; 12:01:49.113 INFO ProgressMeter - Starting traversal; 12:01:49.113 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 12:01:49.492 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.annotator.alle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:112,Deployability,release,release,112,"## Bug Report. ### Affected tool(s) or class(es); CombineGVCFs. ### Affected version(s); - GATK 4.1.8.1 (Latest release as of 08/24/20). ### Description ; User is running CombineGVCFs and getting a java error java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52). This issue was discussed at the GATK Office Hours meeting. ### Associated forum post; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072644931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect wheth",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:6093,Energy Efficiency,Reduce,ReduceOps,6093,"92 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java:403",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:6103,Energy Efficiency,Reduce,ReduceOp,6103,"92 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java:403",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:6131,Energy Efficiency,Reduce,ReduceOps,6131,"nceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java:403); at org.broadinstitute",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:6029,Integrability,wrap,wrapAndCopyInto,6029,"ed Minutes Variants Processed Variants/Minute; 12:01:49.492 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); at org.broadinstitute.hellbender.tools.wal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:8228,Integrability,wrap,wrapAndCopyInto,8228,ender.tools.walkers.CombineGVCFs.apply(CombineGVCFs.java:162); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Mai,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:1703,Performance,Load,Loading,1703,"paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 12:01:37.108 INFO CombineGVCFs - Start Date/Time: August 24, 2020 12:01:36 PM HKT; 12:01:37.108 INFO CombineGVCFs - -------------------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:1570,Safety,Redund,Redundant,1570,"neGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 12:01:37.108 INFO CombineGVCFs - Start Date/Time: August 24, 202",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:1989,Safety,detect,detect,1989,"00313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_161-b12; 12:01:37.108 INFO CombineGVCFs - Start Date/Time: August 24, 2020 12:01:36 PM HKT; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.109 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 12:01:37.109 INFO CombineGVCFs - Picard Version: 2.22.8; 12:01:37.109 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:5152,Safety,Detect,Detected,5152,"ile file:///paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz; 12:01:38.062 INFO FeatureManager - Using codec VCFCodec to read file file:///paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz; 12:01:38.184 INFO FeatureManager - Using codec VCFCodec to read file file:///paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz; 12:01:38.311 INFO FeatureManager - Using codec VCFCodec to read file file:///paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz; 12:01:38.417 INFO FeatureManager - Using codec VCFCodec to read file file:///paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf; 12:01:49.097 INFO CombineGVCFs - Done initializing engine; 12:01:49.113 INFO ProgressMeter - Starting traversal; 12:01:49.113 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 12:01:49.492 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location chrM:63 the annotation MLEAC=[2, 0] was not a numerical value and was ignored; 12:01:49.505 INFO CombineGVCFs - Shutting down engine; [August 24, 2020 12:01:49 PM HKT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 0.21 minutes.; Runtime.totalMemory()=6277824512; java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1382); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/issues/6766:1508,Testability,Log,Log,1508,"931-Combine-GVCF-generate-java-lang-NullPointerException. Command:; time ""$gatk"" CombineGVCFs \; -G StandardAnnotation \; -G AS_StandardAnnotation \; -R ""$ref_gen""/ucsc.hg19.fasta \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200272.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200273.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200274.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200313.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200314.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/A200315.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-006.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/8_samples_20200819/gvcfs/PID20-007.HC.g.vcf.gz \; -V /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples.g.vcf \; -O /paedwy/disk1/yangyxt/wes/backup_gvcfs/all_wes_samples_plus_${sample_batch}.g.vcf.gz && echo ""Combine_gvcfs done"". Error Log:; ```; 12:01:36.798 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 12:01:36.824 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 24, 2020 12:01:37 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:37.108 INFO CombineGVCFs - ------------------------------------------------------------; 12:01:37.108 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:37.108 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:37.108 INFO CombineGVCFs - Executing as yangyxt@paedyl01 on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 12:01:37.108 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Serve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6766
https://github.com/broadinstitute/gatk/pull/6767:19,Energy Efficiency,reduce,reduce,19,"* It turns out Rdd.reduce crashes when it encounters empty data, use fold instead.; * Fix https://github.com/broadinstitute/gatk/issues/6319",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6767
https://github.com/broadinstitute/gatk/issues/6768:840,Availability,error,error,840,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - GATK v4.1.8.1. ### Description ; Hi, ; I am new to GATK so I hope this is not something trivial I overlooked. I called somatic variants using `Mutect2` (GATK v4.1.8.1) and wished to filter the results using `FilterMutectCalls`. I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introdu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768
https://github.com/broadinstitute/gatk/issues/6768:1302,Availability,down,down,1302," I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introduced by running the truncated input files?. Looking up online, it seems this seemed to be an issue in the previous versions of GATK:https://github.com/broadinstitute/gatk/issues/6102. Thanks!. #### Expected behavior; I would expect .vcf.stats to be automatically generated with the output. #### Actual behavior; N",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768
https://github.com/broadinstitute/gatk/issues/6768:1559,Availability,ERROR,ERROR,1559,"cker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introduced by running the truncated input files?. Looking up online, it seems this seemed to be an issue in the previous versions of GATK:https://github.com/broadinstitute/gatk/issues/6102. Thanks!. #### Expected behavior; I would expect .vcf.stats to be automatically generated with the output. #### Actual behavior; No .vcf.stats can be located",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768
https://github.com/broadinstitute/gatk/issues/6768:846,Integrability,message,message,846,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - GATK v4.1.8.1. ### Description ; Hi, ; I am new to GATK so I hope this is not something trivial I overlooked. I called somatic variants using `Mutect2` (GATK v4.1.8.1) and wished to filter the results using `FilterMutectCalls`. I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introdu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768
https://github.com/broadinstitute/gatk/issues/6768:726,Testability,test,test,726,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - GATK v4.1.8.1. ### Description ; Hi, ; I am new to GATK so I hope this is not something trivial I overlooked. I called somatic variants using `Mutect2` (GATK v4.1.8.1) and wished to filter the results using `FilterMutectCalls`. I am running GATK via a docker container as described here: https://gatk.broadinstitute.org/hc/en-us/articles/360035889991--How-to-Run-GATK-in-a-Docker-container. ``` bash; ./gatk Mutect2 -I:tumor 1st.chr1.bam -I:normal 2nd.chr1.bam -O variants.vcf.gz --min-pruning 8 -R reference.chr1.fa; ```; I repeated this three times, the last time to make sure whether the .vcf.stats is being generated or not. This was a test run using the input filtered for chr1 using `samtools view -b`. I though this was the reason for getting the error message about Contig 2 not being present. ```bash; ...; 18:39:03.207 INFO ProgressMeter - 1:282722440 448.7 1529870 3409.8; 18:39:06.592 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 19.218222963000002; 18:39:06.592 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 5376.604473962; 18:39:06.593 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 12201.77 sec; 18:39:06.594 INFO Mutect2 - Shutting down engine; [August 25, 2020 6:39:06 PM GMT] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 448.75 minutes.; Runtime.totalMemory()=12349079552; ***********************************************************************. A USER ERROR has occurred: Contig 2 not present in the sequence dictionary [1]. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace.; ```; Is there any way of getting around this and generating .vcf.stats without repeating a lengthy variant calling `Mutect2`? Is this a problem introdu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6768
https://github.com/broadinstitute/gatk/pull/6769:584,Deployability,configurat,configuration,584,Prevents a bug that occurs when a file path contains characters that are illegal in URIs. Specific example was when using `--tmp-dir file:///tmp/workflow#main` GATK would initially correctly interpret this as `/tmp/workflow#main` but then when setting the Java temp directory in `CommandLineProgram.java` line 164 it would send `/tmp/workflow#main` to `IOUtils.getAbsolutePathWithoutFileProtocol` which would then mangle it by turning it into a URI and then removing `file://` resulting in `/tmp/workflow%23main` which later causes issues when things like the Codecs attempt to write configuration files to the temp directory that doesn't exist. CWLTool often creates path names that contain `#` so workflows made by CWLTool and containing GATK can fail because of this bug.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6769
https://github.com/broadinstitute/gatk/pull/6769:584,Modifiability,config,configuration,584,Prevents a bug that occurs when a file path contains characters that are illegal in URIs. Specific example was when using `--tmp-dir file:///tmp/workflow#main` GATK would initially correctly interpret this as `/tmp/workflow#main` but then when setting the Java temp directory in `CommandLineProgram.java` line 164 it would send `/tmp/workflow#main` to `IOUtils.getAbsolutePathWithoutFileProtocol` which would then mangle it by turning it into a URI and then removing `file://` resulting in `/tmp/workflow%23main` which later causes issues when things like the Codecs attempt to write configuration files to the temp directory that doesn't exist. CWLTool often creates path names that contain `#` so workflows made by CWLTool and containing GATK can fail because of this bug.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6769
https://github.com/broadinstitute/gatk/pull/6770:364,Availability,mainten,maintenance,364,"Added .dockstore.yml file to the root directory of the gatk repo to allow automatic syncing to occur with workflows in [Dockstore](https://dockstore.org/organizations/BroadInstitute/collections/GATKWorkflows). ; **Problem:** ; The GATK workflows are currently organized in [Dockstore](https://dockstore.org/organizations/BroadInstitute/collections/GATKWorkflows), maintenance of the workflows requires manually refreshing the workflow profile in Dockstore in order to view the latest releases of the workflows. Also some workflows like germline_cnv fails to sync because Dockstore has trouble handling the number of branches/tags in the gatk repo.; **Solution:** ; Adding the dockstore yml file allows this syncing to happen automatically whenever there is a push to the gatk repo. This may also help focus which branches to sync and prevent Dockstore from failing during sync. . See [doc](https://docs.dockstore.org/en/develop/getting-started/github-apps/github-apps.html) for description.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6770
https://github.com/broadinstitute/gatk/pull/6770:484,Deployability,release,releases,484,"Added .dockstore.yml file to the root directory of the gatk repo to allow automatic syncing to occur with workflows in [Dockstore](https://dockstore.org/organizations/BroadInstitute/collections/GATKWorkflows). ; **Problem:** ; The GATK workflows are currently organized in [Dockstore](https://dockstore.org/organizations/BroadInstitute/collections/GATKWorkflows), maintenance of the workflows requires manually refreshing the workflow profile in Dockstore in order to view the latest releases of the workflows. Also some workflows like germline_cnv fails to sync because Dockstore has trouble handling the number of branches/tags in the gatk repo.; **Solution:** ; Adding the dockstore yml file allows this syncing to happen automatically whenever there is a push to the gatk repo. This may also help focus which branches to sync and prevent Dockstore from failing during sync. . See [doc](https://docs.dockstore.org/en/develop/getting-started/github-apps/github-apps.html) for description.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6770
https://github.com/broadinstitute/gatk/issues/6771:25,Modifiability,config,config,25,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:77,Modifiability,config,config,77,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:123,Modifiability,config,config,123,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:169,Modifiability,config,config,169,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:215,Modifiability,config,config,215,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:260,Modifiability,config,config,260,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:305,Modifiability,config,config,305,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:350,Modifiability,config,config,350,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6771:395,Modifiability,config,config,395,```; > ls -1 /tmp | grep config$; ...; tmp_read_resource_9070459585787683374.config; tmp_read_resource_9128464625731709220.config; tmp_read_resource_9145440961585524679.config; tmp_read_resource_9164235676580024644.config; tmp_read_resource_959850395283914212.config; tmp_read_resource_979816073947827397.config; tmp_read_resource_983369287551636047.config; tmp_read_resource_993654349410744404.config; ...; ```. Anybody else seeing these files being created but not deleted. I'm running thousands of samples via HaplotypeCaller/GenotypeGVCFs,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6771
https://github.com/broadinstitute/gatk/issues/6772:1306,Deployability,release,release,1306,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6772
https://github.com/broadinstitute/gatk/issues/6772:1376,Testability,test,test,1376,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6772
https://github.com/broadinstitute/gatk/issues/6772:1476,Testability,log,logs,1476,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6772
https://github.com/broadinstitute/gatk/issues/6774:173,Availability,error,errors,173,"A user has identified an issue with variants near regions of the reference with `N` bases:. https://gatk.broadinstitute.org/hc/en-us/community/posts/360072168572-Funcotator-errors-?page=1#community_comment_360012539271. If Funcotator gets to a codon sequence with `N` bases in it, right now it throws an exception because it cannot decode the `N` bases into a valid amino acid. Funcotator needs to be updated to provide a symbolic protein prediction stating that it was ambiguous because of reference IUPAC bases. The variant in question is from **HG19**:; ```; 4	9274640	.	A	ATCACTG,ATCCTG	.	.	BETA=0.989,0.141;FRACTION=0.022; ```. The reference around this variant is:. ![image](https://user-images.githubusercontent.com/11667487/91493420-4a1e1000-e885-11ea-97f5-820a44a054bc.png). ### Stack Trace:; ```; ***********************************************************************. A USER ERROR has occurred: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedFile: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN; 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequenceHelper(FuncotatorUtils.java:1195); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequence(FuncotatorUtils.java:1158); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.createProteinSequences(ProteinChangeInfo.java:125); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:52); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:371); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2045); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:887,Availability,ERROR,ERROR,887,"A user has identified an issue with variants near regions of the reference with `N` bases:. https://gatk.broadinstitute.org/hc/en-us/community/posts/360072168572-Funcotator-errors-?page=1#community_comment_360012539271. If Funcotator gets to a codon sequence with `N` bases in it, right now it throws an exception because it cannot decode the `N` bases into a valid amino acid. Funcotator needs to be updated to provide a symbolic protein prediction stating that it was ambiguous because of reference IUPAC bases. The variant in question is from **HG19**:; ```; 4	9274640	.	A	ATCACTG,ATCCTG	.	.	BETA=0.989,0.141;FRACTION=0.022; ```. The reference around this variant is:. ![image](https://user-images.githubusercontent.com/11667487/91493420-4a1e1000-e885-11ea-97f5-820a44a054bc.png). ### Stack Trace:; ```; ***********************************************************************. A USER ERROR has occurred: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedFile: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN; 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequenceHelper(FuncotatorUtils.java:1195); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequence(FuncotatorUtils.java:1158); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.createProteinSequences(ProteinChangeInfo.java:125); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:52); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:371); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2045); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:401,Deployability,update,updated,401,"A user has identified an issue with variants near regions of the reference with `N` bases:. https://gatk.broadinstitute.org/hc/en-us/community/posts/360072168572-Funcotator-errors-?page=1#community_comment_360012539271. If Funcotator gets to a codon sequence with `N` bases in it, right now it throws an exception because it cannot decode the `N` bases into a valid amino acid. Funcotator needs to be updated to provide a symbolic protein prediction stating that it was ambiguous because of reference IUPAC bases. The variant in question is from **HG19**:; ```; 4	9274640	.	A	ATCACTG,ATCCTG	.	.	BETA=0.989,0.141;FRACTION=0.022; ```. The reference around this variant is:. ![image](https://user-images.githubusercontent.com/11667487/91493420-4a1e1000-e885-11ea-97f5-820a44a054bc.png). ### Stack Trace:; ```; ***********************************************************************. A USER ERROR has occurred: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedFile: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN; 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequenceHelper(FuncotatorUtils.java:1195); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequence(FuncotatorUtils.java:1158); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.createProteinSequences(ProteinChangeInfo.java:125); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:52); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:371); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2045); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:3355,Energy Efficiency,Reduce,ReduceOps,3355,er.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:3365,Energy Efficiency,Reduce,ReduceOp,3365,er.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.fu,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:3393,Energy Efficiency,Reduce,ReduceOps,3393,Sources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngin,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:4879,Energy Efficiency,Reduce,ReduceOps,4879,ory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:4889,Energy Efficiency,Reduce,ReduceOp,4889,ory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:4917,Energy Efficiency,Reduce,ReduceOps,4917,roadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:3290,Integrability,wrap,wrapAndCopyInto,3290,otationFactory.java:1086); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationOnSingleTranscript(GencodeFuncotationFactory.java:1020); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:847); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsHelper(GencodeFuncotationFactory.java:831); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.lambda$createGencodeFuncotationsByAllTranscripts$0(GencodeFuncotationFactory.java:508); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationsByAllTranscripts(GencodeFuncotationFactory.java:509); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:4814,Integrability,wrap,wrapAndCopyInto,4814,Factory.createFuncotationsOnVariant(GencodeFuncotationFactory.java:564); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.determineFuncotations(DataSourceFuncotationFactory.java:243); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:211); 	at org.broadinstitute.hellbender.tools.funcotator.DataSourceFuncotationFactory.createFuncotations(DataSourceFuncotationFactory.java:182); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.lambda$createFuncotationMapForVariant$0(FuncotatorEngine.java:147); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at j,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:6088,Integrability,wrap,wrapAndCopyInto,6088,stitute.hellbender.tools.funcotator.FuncotatorEngine.createFuncotationMapForVariant(FuncotatorEngine.java:157); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.enqueueAndHandleVariant(Funcotator.java:904); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.apply(Funcotator.java:858); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6774:439,Safety,predict,prediction,439,"A user has identified an issue with variants near regions of the reference with `N` bases:. https://gatk.broadinstitute.org/hc/en-us/community/posts/360072168572-Funcotator-errors-?page=1#community_comment_360012539271. If Funcotator gets to a codon sequence with `N` bases in it, right now it throws an exception because it cannot decode the `N` bases into a valid amino acid. Funcotator needs to be updated to provide a symbolic protein prediction stating that it was ambiguous because of reference IUPAC bases. The variant in question is from **HG19**:; ```; 4	9274640	.	A	ATCACTG,ATCCTG	.	.	BETA=0.989,0.141;FRACTION=0.022; ```. The reference around this variant is:. ![image](https://user-images.githubusercontent.com/11667487/91493420-4a1e1000-e885-11ea-97f5-820a44a054bc.png). ### Stack Trace:; ```; ***********************************************************************. A USER ERROR has occurred: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException$MalformedFile: Unknown file is malformed: File contains a bad codon sequence that has no amino acid equivalent: CNN; 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequenceHelper(FuncotatorUtils.java:1195); 	at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.createAminoAcidSequence(FuncotatorUtils.java:1158); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.createProteinSequences(ProteinChangeInfo.java:125); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.<init>(ProteinChangeInfo.java:52); 	at org.broadinstitute.hellbender.tools.funcotator.ProteinChangeInfo.create(ProteinChangeInfo.java:371); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createSequenceComparison(GencodeFuncotationFactory.java:2045); 	at org.broad",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6774
https://github.com/broadinstitute/gatk/issues/6776:28,Availability,error,error,28,"A user reported seeing this error with SplitNCigarReads v4.8.1.0 -- ""contig must be non-null and not equal to *, and start must be >= 1"".; There was a similar issue ticket for the same exception a couple years back: https://github.com/broadinstitute/gatk/issues/3466. User bug report below:. This request was created from a contribution made by Giulia Corsi on August 19, 2020 15:26 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads-R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:465,Availability,Error,Error-in-SplitNCigarReads,465,"A user reported seeing this error with SplitNCigarReads v4.8.1.0 -- ""contig must be non-null and not equal to *, and start must be >= 1"".; There was a similar issue ticket for the same exception a couple years back: https://github.com/broadinstitute/gatk/issues/3466. User bug report below:. This request was created from a contribution made by Giulia Corsi on August 19, 2020 15:26 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads-R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:562,Availability,Error,Error-in-SplitNCigarReads,562,"A user reported seeing this error with SplitNCigarReads v4.8.1.0 -- ""contig must be non-null and not equal to *, and start must be >= 1"".; There was a similar issue ticket for the same exception a couple years back: https://github.com/broadinstitute/gatk/issues/3466. User bug report below:. This request was created from a contribution made by Giulia Corsi on August 19, 2020 15:26 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads-R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:615,Availability,error,error,615,"A user reported seeing this error with SplitNCigarReads v4.8.1.0 -- ""contig must be non-null and not equal to *, and start must be >= 1"".; There was a similar issue ticket for the same exception a couple years back: https://github.com/broadinstitute/gatk/issues/3466. User bug report below:. This request was created from a contribution made by Giulia Corsi on August 19, 2020 15:26 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads-R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:30972,Availability,down,down,30972,"- chrM:8920 58.4 62766000 1073951.1 ; ; 12:07:04.855 INFO ProgressMeter - chrM:9385 58.6 62814000 1071582.7 ; ; 12:07:14.867 INFO ProgressMeter - chrM:10083 58.8 62865000 1069408.5 ; ; 12:07:24.914 INFO ProgressMeter - chrM:10943 59.0 62904000 1067032.5 ; ; 12:07:34.942 INFO ProgressMeter - chrX:12975129 59.1 63028000 1066113.4 ; ; 12:07:44.971 INFO ProgressMeter - chrX:41349821 59.3 63179000 1065654.6 ; ; 12:07:54.982 INFO ProgressMeter - chrX:48923158 59.5 63296000 1064631.8 ; ; 12:08:05.013 INFO ProgressMeter - chrX:68535195 59.6 63444000 1064128.8 ; ; 12:08:15.047 INFO ProgressMeter - chrX:102632989 59.8 63592000 1063627.8 ; ; 12:08:25.159 INFO ProgressMeter - chrX:111294586 60.0 63723000 1062822.9 ; ; 12:08:35.207 INFO ProgressMeter - chrX:129516349 60.1 63932000 1063338.7 ; ; 12:08:45.361 INFO ProgressMeter - chrX:153743608 60.3 64037000 1062095.6 ; ; 12:08:56.075 INFO ProgressMeter - chrY:302910 60.5 64182000 1061357.1 ; ; 12:13:04.075 INFO SplitNCigarReads - Shutting down engine ; ; \[August 19, 2020 12:13:04 PM CEST\] org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads done. Elapsed time: 64.67 minutes. ; ; Runtime.totalMemory()=11648630784 ; ; java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1 ; ; at org.broadinstitute.hellbender.utils.read.SAMRecordToGATKReadAdapter.setMatePosition(SAMRecordToGATKReadAdapter.java:197) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.OverhangFixingManager.setPredictedMateInformation(OverhangFixingManager.java:445) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:212) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.lambda$traverseReads$1(SplitNCigarReads.java:181) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.lambda$forEachRead$0(MultiplePassReadWalker.java:60) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:2172,Deployability,release,release-,2172,"Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCigarReads - Executing as giulia@### on Linux v2.6.32-754.31.1.el6.x86\_64 amd64 ; ; 11:08:25.664 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12 ; ; 11:08:25.664 INFO SplitNCigarReads - Start Date/Time: August 19, 2020 11:08:24 AM CEST ; ; 11:08:25.664 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.664 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Version: 2.23.0 ; ; 11:08:25.668 INFO SplitNCigarReads - Picard Version: 2.22.8 ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.COMPRESSION\_LEVEL : 2 ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.USE\_ASYNC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 11:08:25.668 INFO SplitNCigarReads - Deflater: IntelDeflater ; ; 11:08:25.669 INFO SplitNCigarReads - Inflater: IntelInflater ; ; 11:08:25.669 INFO SplitNCigarReads - GCS max retries/re",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:32498,Integrability,wrap,wrapAndCopyInto,32498,hangFixingManager.java:445) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.splitNCigarRead(SplitNCigarReads.java:212) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.lambda$traverseReads$1(SplitNCigarReads.java:181) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.lambda$forEachRead$0(MultiplePassReadWalker.java:60) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175) ; ; at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193) ; ; at java.util.Iterator.forEachRemaining(Iterator.java:116) ; ; at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481) ; ; at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471) ; ; at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151) ; ; at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174) ; ; at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.forEachRead(MultiplePassReadWalker.java:58) ; ; at org.broadinstitute.hellbender.tools.walkers.rnaseq.SplitNCigarReads.traverseReads(SplitNCigarReads.java:180) ; ; at org.broadinstitute.hellbender.engine.MultiplePassReadWalker.traverse(MultiplePassReadWalker.java:74) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at o,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:1238,Performance,Load,Loading,1238,"roadinstitute/gatk/issues/3466. User bug report below:. This request was created from a contribution made by Giulia Corsi on August 19, 2020 15:26 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads-R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCigarReads - Executing as giulia@### on Linux v2.6.32-754.31.1.el6.x86\_64 amd64 ; ; 11:08:25.664 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12 ; ; 11:08:25.664 INFO SplitNCigarReads - Start D",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:1564,Safety,detect,detect,1564,"8271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads-R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCigarReads - Executing as giulia@### on Linux v2.6.32-754.31.1.el6.x86\_64 amd64 ; ; 11:08:25.664 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12 ; ; 11:08:25.664 INFO SplitNCigarReads - Start Date/Time: August 19, 2020 11:08:24 AM CEST ; ; 11:08:25.664 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.664 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.668 INFO SplitNCigarReads - HTSJDK Version: 2.23.0 ; ; 11:08:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6776:1192,Testability,log,log,1192,"ption a couple years back: https://github.com/broadinstitute/gatk/issues/3466. User bug report below:. This request was created from a contribution made by Giulia Corsi on August 19, 2020 15:26 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads](https://gatk.broadinstitute.org/hc/en-us/community/posts/360072548271-Error-in-SplitNCigarReads). \--. I get the following error with GATK 4.1.8.1 when running SplitNCigarReads after MarkDuplicates on RNA-seq data:. java.lang.IllegalArgumentException: contig must be non-null and not equal to \*, and start must be >= 1. The command I used was the following (I did not include the full path to the files):. gatk SplitNCigarReads-R /home/data/hg38\_GRCh38.97\_nobackup/hg38\_primary\_refseq.fa -I /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Dedup.bam -O /home/results/SOD1/results/5\_GATK\_dedupSplit/SOD1P\_A272C\_rep2/SOD1P\_A272C\_rep2.Split.bam. Here the log:. 11:08:24.240 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/results/SOD1/.snakemake/conda/93139e1d/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Aug 19, 2020 11:08:25 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 11:08:25.663 INFO SplitNCigarReads - ------------------------------------------------------------ ; ; 11:08:25.663 INFO SplitNCigarReads - The Genome Analysis Toolkit (GATK) v4.1.8.1 ; ; 11:08:25.663 INFO SplitNCigarReads - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 11:08:25.664 INFO SplitNCigarReads - Executing as giulia@### on Linux v2.6.32-754.31.1.el6.x86\_64 amd64 ; ; 11:08:25.664 INFO SplitNCigarReads - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_152-release-1056-b12 ;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6776
https://github.com/broadinstitute/gatk/issues/6777:114,Availability,redundant,redundant,114,There are places in the genome where IUPAC bases can actually be decoded because the amino acid code is partially redundant. Add this logic into getMitochondrialAminoAcidByCodon and getEukaryoticAminoAcidByCodon.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6777
https://github.com/broadinstitute/gatk/issues/6777:114,Safety,redund,redundant,114,There are places in the genome where IUPAC bases can actually be decoded because the amino acid code is partially redundant. Add this logic into getMitochondrialAminoAcidByCodon and getEukaryoticAminoAcidByCodon.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6777
https://github.com/broadinstitute/gatk/issues/6777:134,Testability,log,logic,134,There are places in the genome where IUPAC bases can actually be decoded because the amino acid code is partially redundant. Add this logic into getMitochondrialAminoAcidByCodon and getEukaryoticAminoAcidByCodon.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6777
https://github.com/broadinstitute/gatk/pull/6778:204,Testability,log,log,204,"- Added the ability to have IUPAC bases in either the ref/alt alleles OR; in the reference when calculating the amino acid sequence. In this case, the code will no longer throw a user exception, but will log a warning and will produce `?` amino acids in the case that they cannot be decoded from the amino acid table. Currently this will happen any time an `N` or IUPAC base is in the region to be coded into amino acids.; - Added AminoAcid.UNDECODABLE as a placeholder for any unknown /; undecodable amino acid (such as in the case of an ambiguous IUPAC base). Fixes #6774",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6778
https://github.com/broadinstitute/gatk/pull/6779:35,Availability,error,error,35,* Add contig and start position to error message in setMatePosition; * Extract the check to a shared method with setPosition so it's not inconsistent; * Improves the unhelpful error reported in https://github.com/broadinstitute/gatk/issues/6776,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779
https://github.com/broadinstitute/gatk/pull/6779:176,Availability,error,error,176,* Add contig and start position to error message in setMatePosition; * Extract the check to a shared method with setPosition so it's not inconsistent; * Improves the unhelpful error reported in https://github.com/broadinstitute/gatk/issues/6776,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779
https://github.com/broadinstitute/gatk/pull/6779:41,Integrability,message,message,41,* Add contig and start position to error message in setMatePosition; * Extract the check to a shared method with setPosition so it's not inconsistent; * Improves the unhelpful error reported in https://github.com/broadinstitute/gatk/issues/6776,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6779
https://github.com/broadinstitute/gatk/pull/6781:73,Integrability,message,message,73,* Replacing some cases of NPE with IllegalArgumentException with a clear message. This should help clarify the issue we talked about at the meeting today if it comes up again. I can't remember what the ticket was to link to though.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6781
https://github.com/broadinstitute/gatk/pull/6781:67,Usability,clear,clear,67,* Replacing some cases of NPE with IllegalArgumentException with a clear message. This should help clarify the issue we talked about at the meeting today if it comes up again. I can't remember what the ticket was to link to though.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6781
https://github.com/broadinstitute/gatk/issues/6783:271,Availability,Error,Error,271,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:3490,Availability,Avail,Available,3490," confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 17:08:13.200 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 17:08:13.206 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 17:08:13.227 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 17:08:13.228 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 17:08:13.260 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 17:08:13.260 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:3608,Availability,avail,available,3608,"ill be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 17:08:13.200 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 17:08:13.206 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 17:08:13.227 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 17:08:13.228 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 17:08:13.260 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 17:08:13.260 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:11:09 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 122.97 minutes",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:4461,Availability,down,down,4461,"0 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:11:09 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 122.97 minutes.; Runtime.totalMemory()=2764046336; java.lang.NullPointerException; at org.broadinstitute.hellbender.engine.AssemblyRegion.getReference(AssemblyRegion.java:309); at org.broadinstitute.hellbender.engine.AssemblyRegion.getAssemblyRegionReference(AssemblyRegion.java:330); at org.broadinstitute.hellbender.engine.AssemblyRegion.getAssemblyRegionReference(AssemblyRegion.java:316); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.createReferenceHaplotype(AssemblyBasedCallerUtils.java:175); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.referenceModelForNoVariation(HaplotypeCallerEngine.java:688); at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerEngine.callRegion(HaplotypeCallerEngine.java:522); at org.broadinstitute.hellbender.tools.walkers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:453,Performance,Load,Loading,453,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:3035,Performance,Load,Loading,3035,"NC_IO_WRITE_FOR_TRIBBLE : false; 17:08:12.040 INFO HaplotypeCaller - Deflater: IntelDeflater; 17:08:12.040 INFO HaplotypeCaller - Inflater: IntelInflater; 17:08:12.041 INFO HaplotypeCaller - GCS max retries/reopens: 20; 17:08:12.041 INFO HaplotypeCaller - Requester pays: disabled; 17:08:12.041 INFO HaplotypeCaller - Initializing engine; 17:08:13.144 INFO HaplotypeCaller - Done initializing engine; 17:08:13.147 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 17:08:13.200 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 17:08:13.206 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 17:08:13.227 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 17:08:13.228 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 17:08:13.260 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 17:08:13.260 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:3217,Performance,Load,Loading,3217,"ler - GCS max retries/reopens: 20; 17:08:12.041 INFO HaplotypeCaller - Requester pays: disabled; 17:08:12.041 INFO HaplotypeCaller - Initializing engine; 17:08:13.144 INFO HaplotypeCaller - Done initializing engine; 17:08:13.147 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 17:08:13.200 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 17:08:13.206 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 17:08:13.227 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 17:08:13.228 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 17:08:13.260 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 17:08:13.260 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.1903",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:3694,Performance,multi-thread,multi-threaded,3694,"tions have been disabled; 17:08:13.200 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 17:08:13.206 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 17:08:13.227 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_utils.so; 17:08:13.228 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 17:08:13.260 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 17:08:13.260 INFO IntelPairHmm - Available threads: 1; 17:08:13.260 INFO IntelPairHmm - Requested threads: 4; 17:08:13.261 WARN IntelPairHmm - Using 1 available threads, but 4 were requested; 17:08:13.261 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 17:08:13.346 INFO ProgressMeter - Starting traversal; 17:08:13.346 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 17:08:17.401 WARN InbreedingCoeff - InbreedingCoeff will not be calculated; at least 10 samples must have called genotypes. 17:08:43.866 INFO ProgressMeter - chr1:1053465 0.5 3780 7431.7. ...Many lines in between and then... 19:11:09.189 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 1.190328316; 19:11:09.189 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 398.5135636; 19:11:09.190 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 258.73 sec; 19:11:09.190 INFO HaplotypeCaller - Shutting down engine; [August 27, 2020 7:11:09 PM CDT] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 122.97 minutes.; Runtime.totalMemory()=2764046336; java.lang.NullPointerException; at org.broadinstitute.hell",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:736,Safety,detect,detect,736,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:352,Testability,test,test,352,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/issues/6783:364,Testability,test,test,364,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller GVCF mode. ### Affected version(s); GATK 4.1.8.0 . ### Description ; Discussed on the GATK forum: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072760032-HaplotypeCaller-NullPointerException-Error. Command: ; `gatk --java-options ""-Xmx4g"" HaplotypeCaller -R hg19.fa.gz -I test.bam -O test.g.vcf.gz -ERC GVCF`. #### Stack Trace. ```; 17:08:11.229 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 27, 2020 5:08:12 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 17:08:12.021 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.028 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.0; 17:08:12.028 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 17:08:12.038 INFO HaplotypeCaller - Executing as zepengmu@midway2-0243.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 17:08:12.038 INFO HaplotypeCaller - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 17:08:12.039 INFO HaplotypeCaller - Start Date/Time: August 27, 2020 5:08:11 PM CDT; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - ------------------------------------------------------------; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Version: 2.22.0; 17:08:12.039 INFO HaplotypeCaller - Picard Version: 2.22.8; 17:08:12.039 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 17:08:12.040 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 17:08:12.040 INFO HaplotypeCal",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6783
https://github.com/broadinstitute/gatk/pull/6788:0,Deployability,Update,Updated,0,Updated README to state that only 64-bit Linux distributions are supported. Made this edit under the Python dependencies section. Fix issue #6786,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6788
https://github.com/broadinstitute/gatk/pull/6788:108,Integrability,depend,dependencies,108,Updated README to state that only 64-bit Linux distributions are supported. Made this edit under the Python dependencies section. Fix issue #6786,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6788
https://github.com/broadinstitute/gatk/issues/6789:64,Availability,Down,Downloads,64,"I was running this following CML :; java -Xmx8G -jar /Users/mac/Downloads/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration \ -R /Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta \ -V /Users/mac/Desktop/NGS-/57variants.vcf \ -o /Users/mac/Desktop/NGS-/59varians_filt.vcf \ --filter-expression ""QD < 2.0 || MQ > 50"" \ --filter-name ""hard_filtering_snp and I get : A USER ERROR has occurred: Illegal argument value: Positional arguments were provided ', -R{/Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta{ -V{/Users/mac/Desktop/NGS-/57variants.vcf{ -o{/Users/mac/Desktop/NGS-/59varians_filt.vcf{ --filter-expression{QD < 2.0 || MQ > 50{ }' but no positional argument is defined for this tool; how should I fix it and get a filter files ?!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6789
https://github.com/broadinstitute/gatk/issues/6789:387,Availability,ERROR,ERROR,387,"I was running this following CML :; java -Xmx8G -jar /Users/mac/Downloads/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration \ -R /Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta \ -V /Users/mac/Desktop/NGS-/57variants.vcf \ -o /Users/mac/Desktop/NGS-/59varians_filt.vcf \ --filter-expression ""QD < 2.0 || MQ > 50"" \ --filter-name ""hard_filtering_snp and I get : A USER ERROR has occurred: Illegal argument value: Positional arguments were provided ', -R{/Users/mac/Desktop/LmjFwholegenome_20070731_V5.2.fasta{ -V{/Users/mac/Desktop/NGS-/57variants.vcf{ -o{/Users/mac/Desktop/NGS-/59varians_filt.vcf{ --filter-expression{QD < 2.0 || MQ > 50{ }' but no positional argument is defined for this tool; how should I fix it and get a filter files ?!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6789
https://github.com/broadinstitute/gatk/issues/6790:131,Availability,echo,echo,131,"CentOS Linux release 7.8.2003 (Core); JAVA: openjdk/14.0.1; GATK: 4.1.8.1. ---. I was running this following command:. intervals=$(echo ""$(seq 1 22) X Y"" | tr "" "" ""\n"" | sed 's/^/-L /' | xargs); ref_fasta=""/data1/GenomicDatabases/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:1610,Availability,down,down,1610,"tion --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.colle",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:13,Deployability,release,release,13,"CentOS Linux release 7.8.2003 (Core); JAVA: openjdk/14.0.1; GATK: 4.1.8.1. ---. I was running this following command:. intervals=$(echo ""$(seq 1 22) X Y"" | tr "" "" ""\n"" | sed 's/^/-L /' | xargs); ref_fasta=""/data1/GenomicDatabases/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:2423,Energy Efficiency,Reduce,ReduceOps,2423,".4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPrevious",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:2433,Energy Efficiency,Reduce,ReduceOp,2433,".4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPrevious",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:2461,Energy Efficiency,Reduce,ReduceOps,2461,".889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); 	at org.broadinstitute.hellbender.tools.walkers.CombineGVCFs.endPreviousStates(CombineGVCFs.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:2348,Integrability,wrap,wrapAndCopyInto,2348,"232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:913); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:578); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.makeRawAnnotationString(StrandBiasUtils.java:46); 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.AS_StrandBiasTest.combineRawData(AS_StrandBiasTest.java:115); 	at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotatorEngine.combineAnnotations(VariantAnnotatorEngine.java:210); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeAttributes(ReferenceConfidenceVariantContextMerger.java:318); 	at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:142); 	at ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:4679,Integrability,wrap,wrapAndCopyInto,4679,ender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgr,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:1169,Safety,Detect,Detected,1169,"es/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1624); 	at java.base",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:685,Testability,log,log,685,"CentOS Linux release 7.8.2003 (Core); JAVA: openjdk/14.0.1; GATK: 4.1.8.1. ---. I was running this following command:. intervals=$(echo ""$(seq 1 22) X Y"" | tr "" "" ""\n"" | sed 's/^/-L /' | xargs); ref_fasta=""/data1/GenomicDatabases/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:709,Testability,log,log,709,"CentOS Linux release 7.8.2003 (Core); JAVA: openjdk/14.0.1; GATK: 4.1.8.1. ---. I was running this following command:. intervals=$(echo ""$(seq 1 22) X Y"" | tr "" "" ""\n"" | sed 's/^/-L /' | xargs); ref_fasta=""/data1/GenomicDatabases/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:730,Testability,log,log,730,"CentOS Linux release 7.8.2003 (Core); JAVA: openjdk/14.0.1; GATK: 4.1.8.1. ---. I was running this following command:. intervals=$(echo ""$(seq 1 22) X Y"" | tr "" "" ""\n"" | sed 's/^/-L /' | xargs); ref_fasta=""/data1/GenomicDatabases/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6790:802,Testability,log,log,802,"CentOS Linux release 7.8.2003 (Core); JAVA: openjdk/14.0.1; GATK: 4.1.8.1. ---. I was running this following command:. intervals=$(echo ""$(seq 1 22) X Y"" | tr "" "" ""\n"" | sed 's/^/-L /' | xargs); ref_fasta=""/data1/GenomicDatabases/Human/GATK/b37/human_g1k_v37_decoy.fasta""; gvcfs=$(find hapcall -maxdepth 1 -name ""*_hapcall.g.vcf.gz"" -type f | xargs ls | sed 's/^/-V /' | xargs); /data1/software/gatk/4.1.8.1/gatk --java-options ""-XX:ParallelGCThreads=30 -Xms100g -Xmx100g -Djava.io.tmpdir=tmp"" CombineGVCFs -R ${ref_fasta} -O combine/human_combine.g.vcf.gz ${gvcfs} ${intervals} -G StandardAnnotation -G AS_StandardAnnotation --create-output-variant-index true > combine/human_combine.log 2>&1. ---. Here the log:; [human_combine.log](https://github.com/broadinstitute/gatk/files/5165640/human_combine.log). 09:10:26.647 INFO IntervalArgumentCollection - Processing 3095677412 bp from intervals; 09:10:26.694 INFO CombineGVCFs - Done initializing engine; 09:10:26.713 INFO ProgressMeter - Starting traversal; 09:10:26.714 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 09:10:30.685 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location 1:13021 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 09:10:39.543 INFO ProgressMeter - 1:232994 0.2 1000 4676.9; 09:10:51.253 INFO ProgressMeter - 1:688469 0.4 2000 4890.4; 09:11:01.889 INFO ProgressMeter - 1:809005 0.6 3000 5117.3; 09:11:13.838 INFO ProgressMeter - 1:818424 0.8 5000 6366.2; 09:11:16.811 INFO CombineGVCFs - Shutting down engine; [September 3, 2020 at 9:11:16 AM CST] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 1.20 minutes.; Runtime.totalMemory()=107374182400; java.lang.NullPointerException; 	at org.broadinstitute.hellbender.tools.walkers.annotator.allelespecific.StrandBiasUtils.encode(StrandBiasUtils.java:52); 	at java.base/java.util.stream.ReferencePipeline$3$1.accep",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6790
https://github.com/broadinstitute/gatk/issues/6793:205,Availability,Error,Error,205,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); -4.1.8.1, 4.1.6.0. ### Description ; Two users are running GenomicsDBImport and getting a Duplicate Sample Name Error and both have reported that they do not have duplicate sample names in their map files. @nalinigans @mlathara does this look like a user issue or bug with GenomicsDBImport?. ### First Example; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951--GenomicsDBException-Duplicate-sample-name-found-?page=1#community_comment_360012681791. `gatk --java-options ""-Xmx16g -Xms16g"" GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:8122,Availability,down,down,8122,"-DRB1*15:01:01:04 (11056 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:02:01 (10313 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:03:01:01 (11567 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:03:01:02 (11569 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*16:02:01 (11005 bp); 16:16:37.546 INFO IntervalArgumentCollection - Processing 28770581 bp from intervals; 16:16:37.548 INFO GenomicsDBImport - Done initializing engine; 16:16:37.548 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1/callset.json; 16:16:37.548 INFO GenomicsDBImport - Incrementally importing to array - /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1/genomicsdb_array; 16:16:37.549 INFO ProgressMeter - Starting traversal; 16:16:37.550 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 16:16:38.061 INFO GenomicsDBImport - Shutting down engine; [August 28, 2020 4:16:38 PM PDT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=16464216064; org.genomicsdb.exception.GenomicsDBException: Duplicate sample name found: SSC00007. Sample was originally in /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; at org.genomicsdb.importer.extensions.CallSetMapExtensions.checkDuplicateCallsetsForIncrementalImport(CallSetMapExtensions.java:270); at org.genomicsdb.importer.extensions.CallSetMapExtensions.mergeCallsetsForIncrementalImport(CallSetMapExtensions.java:241); at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:222); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:743); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(Co",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:9888,Availability,Error,Error,9888,"DBImporter.<init>(GenomicsDBImporter.java:222); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:743); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. ### Second Example; This user is running multiple chromosomes at a time in parallel; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072732791-Import-GVCFs-using-GenomicsDBImport-one-chromosome-at-a-time-and-parallel-the-jobs-encounter-a-Duplicate-Sample-Name-Error?page=1#community_comment_360012681711. `time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport --tmp-dir /paedwy/disk1/yangyxt/test_tmp --genomicsdb-update-workspace-path ${probe_dir}/genomicdbimport_chr${1} -R ${ref_gen}/ucsc.hg19.fasta --batch-size 0 --sample-name-map ${gvcf}/batch_cohort.sample_map --reader-threads 5 --intervals chr${1}`. ```; 01:07:01.704 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 29, 2020 1:07:01 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:07:02.001 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.002 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:07:02.002 INFO G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:13161,Availability,down,down,13161,"omicsDBImport - Initializing engine; 01:07:02.331 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 01:07:02.702 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; 01:07:02.868 INFO IntervalArgumentCollection - Processing 135534747 bp from intervals; 01:07:02.869 INFO GenomicsDBImport - Done initializing engine; 01:07:02.870 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10/callset.json; 01:07:02.870 INFO GenomicsDBImport - Incrementally importing to workspace - /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10; 01:07:02.871 INFO ProgressMeter - Starting traversal; 01:07:02.871 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 01:07:03.006 INFO GenomicsDBImport - Shutting down engine; [August 29, 2020 at 1:07:03 AM HKT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2147483648; org.genomicsdb.exception.GenomicsDBException: Duplicate sample name found: A130489. Sample was originally in /paedwy/disk1/yangyxt/wes/batch11_13/gvcfs/A130489.HC.g.vcf.gz; at org.genomicsdb.importer.extensions.CallSetMapExtensions.checkDuplicateCallsetsForIncrementalImport(CallSetMapExtensions.java:270); at org.genomicsdb.importer.extensions.CallSetMapExtensions.mergeCallsetsForIncrementalImport(CallSetMapExtensions.java:241); at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:252); at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:745); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:704,Deployability,update,update-workspace-path,704,"## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); -4.1.8.1, 4.1.6.0. ### Description ; Two users are running GenomicsDBImport and getting a Duplicate Sample Name Error and both have reported that they do not have duplicate sample names in their map files. @nalinigans @mlathara does this look like a user issue or bug with GenomicsDBImport?. ### First Example; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951--GenomicsDBException-Duplicate-sample-name-found-?page=1#community_comment_360012681791. `gatk --java-options ""-Xmx16g -Xms16g"" GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM s",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:1345,Deployability,update,update-workspace-path,1345,"info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072797951--GenomicsDBException-Duplicate-sample-name-found-?page=1#community_comment_360012681791. `gatk --java-options ""-Xmx16g -Xms16g"" GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:16:36.284 INFO GenomicsDBImport - ------------------------------------------------------------; 16:16:36.285 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.6.0; 16:16:36.285 INFO GenomicsDBImport - For support and documentation go to https://software.br",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4316,Deployability,Configurat,Configuration,4316,NFO GenomicsDBImport - HTSJDK Defaults.CREATE_MD5 : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:6237,Deployability,update,update-workspace-path,6237,"traJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 16:16:37.372 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 16:16:37.372 DEBUG GenomeLocParser - chr1 (248956422 bp); 16:16:37.373 DEBUG GenomeLocParser - chr2 (242193529 bp); 16:16:37.373 DEBUG GenomeLocParser - chr3 (198295559 bp); 16:16:37.373 DEBUG GenomeLocParser - chr4 (190214555 bp); 16:16:37.373 DEBUG GenomeLocParser - chr5 (181538259 bp); 16:16:37.373 DEBUG GenomeLocParser - chr6 (170805979 bp); 16:16:37.373 DEBUG GenomeLocParser - chr7 (159345973 bp); ...many lines here...; 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:01:01:01 (11080 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:01:01:02 (11571 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:01:01:03 (11056 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:01:01:04 (11056 bp); 16:16:37.524 DEBUG GenomeLocParser - HLA-DRB1*15:02:01 (10313 bp); 16:16:37.524 DEBUG Genom",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:10049,Deployability,update,update-workspace-path,10049,"l.doWork(GATKTool.java:1048); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. ### Second Example; This user is running multiple chromosomes at a time in parallel; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072732791-Import-GVCFs-using-GenomicsDBImport-one-chromosome-at-a-time-and-parallel-the-jobs-encounter-a-Duplicate-Sample-Name-Error?page=1#community_comment_360012681711. `time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport --tmp-dir /paedwy/disk1/yangyxt/test_tmp --genomicsdb-update-workspace-path ${probe_dir}/genomicdbimport_chr${1} -R ${ref_gen}/ucsc.hg19.fasta --batch-size 0 --sample-name-map ${gvcf}/batch_cohort.sample_map --reader-threads 5 --intervals chr${1}`. ```; 01:07:01.704 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 29, 2020 1:07:01 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:07:02.001 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.002 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:07:02.002 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:07:02.002 INFO GenomicsDBImport - Executing as yangyxt@paedwy01 on Linux v3.10.0-957.10.1.el7.x86_6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:12254,Deployability,update,update-workspace-path,12254,"---------------------------------------------------; 01:07:02.003 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.004 INFO GenomicsDBImport - HTSJDK Version: 2.23.0; 01:07:02.005 INFO GenomicsDBImport - Picard Version: 2.22.8; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 01:07:02.005 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 01:07:02.005 INFO GenomicsDBImport - Deflater: IntelDeflater; 01:07:02.005 INFO GenomicsDBImport - Inflater: IntelInflater; 01:07:02.006 INFO GenomicsDBImport - GCS max retries/reopens: 20; 01:07:02.006 INFO GenomicsDBImport - Requester pays: disabled; 01:07:02.006 INFO GenomicsDBImport - Initializing engine; 01:07:02.331 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 01:07:02.702 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; 01:07:02.868 INFO IntervalArgumentCollection - Processing 135534747 bp from intervals; 01:07:02.869 INFO GenomicsDBImport - Done initializing engine; 01:07:02.870 INFO GenomicsDBImport - Callset Map JSON file will be re-written to /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10/callset.json; 01:07:02.870 INFO GenomicsDBImport - Incrementally importing to workspace - /paedwy/disk1/yangyxt/wes/healthy_bams_for_CNV/using_v6_probe/genomicdbimport_chr10; 01:07:02.871 INFO ProgressMeter - Starting traversal; 01:07:02.871 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute; 01:07:03.006 INFO GenomicsDBImport - Shutting down engine; [August 29, 2020 at 1:07:03 AM HKT] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsD",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4300,Modifiability,Config,ConfigFactory,4300,NFO GenomicsDBImport - HTSJDK Defaults.CREATE_MD5 : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4316,Modifiability,Config,Configuration,4316,NFO GenomicsDBImport - HTSJDK Defaults.CREATE_MD5 : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extra,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4363,Modifiability,Config,ConfigFactory,4363,16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.CUSTOM_READER_FACTORY :; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_pac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4418,Modifiability,Config,ConfigFactory,4418,"READER_FACTORY :; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.DISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4483,Modifiability,Config,ConfigFactory,4483,"ISABLE_SNAPPY_COMPRESSOR : false; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4561,Modifiability,Config,ConfigFactory,4561,"omicsDBImport - HTSJDK Defaults.EBI_REFERENCE_SERVICE_URL_MASK : https://www.ebi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4639,Modifiability,Config,ConfigFactory,4639,"bi.ac.uk/ena/cram/md5/%s; 16:16:36.289 INFO GenomicsDBImport - HTSJDK Defaults.NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstit",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4717,Modifiability,Config,ConfigFactory,4717,".NON_ZERO_BUFFER_SIZE : 131072; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cl",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4795,Modifiability,Config,ConfigFactory,4795,"faults.REFERENCE_FASTA : null; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchB",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4860,Modifiability,Config,ConfigFactory,4860," - HTSJDK Defaults.SAM_FLAG_FIELD_FORMAT : DECIMAL; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIn",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:4935,Modifiability,Config,ConfigFactory,4935,"icsDBImport - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5002,Modifiability,Config,ConfigFactory,5002,"e; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5077,Modifiability,Config,ConfigFactory,5077,"FOR_SAMTOOLS : true; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5146,Modifiability,Config,ConfigFactory,5146,"ults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:16:36.290 INFO GenomicsDBImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5218,Modifiability,Config,ConfigFactory,5218,"BImport - HTSJDK Defaults.USE_CRAM_REF_DOWNLOAD : false; 16:16:36.290 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5286,Modifiability,Config,ConfigFactory,5286,"0 DEBUG ConfigFactory - Configuration file values:; 16:16:36.295 DEBUG ConfigFactory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified in",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5356,Modifiability,Config,ConfigFactory,5356,"ctory - gcsMaxRetries = 20; 16:16:36.295 DEBUG ConfigFactory - gcsProjectForRequesterPays =; 16:16:36.295 DEBUG ConfigFactory - gatk_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 16:16:3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5486,Modifiability,Config,ConfigFactory,5486,"_stacktrace_on_user_exception = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_read_samtools = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 16:16:37.372 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 16:16:37.372 DEBUG GenomeLocParser - chr1 (248956422 b",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5592,Modifiability,Config,ConfigFactory,5592,"ls = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_samtools = true; 16:16:36.296 DEBUG ConfigFactory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 16:16:37.372 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 16:16:37.372 DEBUG GenomeLocParser - chr1 (248956422 bp); 16:16:37.373 DEBUG GenomeLocParser - chr2 (242193529 bp); 16:16:37.373 DEBUG GenomeLocParser - chr3 (1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5706,Modifiability,Config,ConfigFactory,5706,"tory - samjdk.use_async_io_write_tribble = false; 16:16:36.296 DEBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 16:16:37.372 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 16:16:37.372 DEBUG GenomeLocParser - chr1 (248956422 bp); 16:16:37.373 DEBUG GenomeLocParser - chr2 (242193529 bp); 16:16:37.373 DEBUG GenomeLocParser - chr3 (198295559 bp); 16:16:37.373 DEBUG GenomeLocParser - chr4 (190214555 bp); 16:16:37.373 DEBUG GenomeLocParser - chr5 (181",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5767,Modifiability,Config,ConfigFactory,5767,"EBUG ConfigFactory - samjdk.compression_level = 2; 16:16:36.296 DEBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 16:16:37.372 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 16:16:37.372 DEBUG GenomeLocParser - chr1 (248956422 bp); 16:16:37.373 DEBUG GenomeLocParser - chr2 (242193529 bp); 16:16:37.373 DEBUG GenomeLocParser - chr3 (198295559 bp); 16:16:37.373 DEBUG GenomeLocParser - chr4 (190214555 bp); 16:16:37.373 DEBUG GenomeLocParser - chr5 (181538259 bp); 16:16:37.373 DEBUG GenomeLocParser - chr6 (17080597",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:5833,Modifiability,Config,ConfigFactory,5833,"EBUG ConfigFactory - spark.kryoserializer.buffer.max = 512m; 16:16:36.296 DEBUG ConfigFactory - spark.driver.maxResultSize = 0; 16:16:36.296 DEBUG ConfigFactory - spark.driver.userClassPathFirst = true; 16:16:36.296 DEBUG ConfigFactory - spark.io.compression.codec = lzf; 16:16:36.296 DEBUG ConfigFactory - spark.executor.memoryOverhead = 600; 16:16:36.297 DEBUG ConfigFactory - spark.driver.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - spark.executor.extraJavaOptions =; 16:16:36.297 DEBUG ConfigFactory - codec_packages = [htsjdk.variant, htsjdk.tribble, org.broadinstitute.hellbender.utils.codecs]; 16:16:36.297 DEBUG ConfigFactory - read_filter_packages = [org.broadinstitute.hellbender.engine.filters]; 16:16:36.297 DEBUG ConfigFactory - annotation_packages = [org.broadinstitute.hellbender.tools.walkers.annotator]; 16:16:36.297 DEBUG ConfigFactory - cloudPrefetchBuffer = 40; 16:16:36.297 DEBUG ConfigFactory - cloudIndexPrefetchBuffer = -1; 16:16:36.297 DEBUG ConfigFactory - createOutputBamIndex = true; 16:16:36.298 INFO GenomicsDBImport - Deflater: IntelDeflater; 16:16:36.298 INFO GenomicsDBImport - Inflater: IntelInflater; 16:16:36.298 INFO GenomicsDBImport - GCS max retries/reopens: 20; 16:16:36.298 INFO GenomicsDBImport - Requester pays: disabled; 16:16:36.298 INFO GenomicsDBImport - Initializing engine; 16:16:36.523 WARN GenomicsDBImport - genomicsdb-update-workspace-path was set, so ignoring specified intervals.The tool will use the intervals specified by the initial import; 16:16:37.372 DEBUG GenomeLocParser - Prepared reference sequence contig dictionary; 16:16:37.372 DEBUG GenomeLocParser - chr1 (248956422 bp); 16:16:37.373 DEBUG GenomeLocParser - chr2 (242193529 bp); 16:16:37.373 DEBUG GenomeLocParser - chr3 (198295559 bp); 16:16:37.373 DEBUG GenomeLocParser - chr4 (190214555 bp); 16:16:37.373 DEBUG GenomeLocParser - chr5 (181538259 bp); 16:16:37.373 DEBUG GenomeLocParser - chr6 (170805979 bp); 16:16:37.373 DEBUG GenomeLocParser - chr7 (159345973 bp); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:1668,Performance,Load,Loading,1668,"e 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz`. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:16:36.284 INFO GenomicsDBImport - ------------------------------------------------------------; 16:16:36.285 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.6.0; 16:16:36.285 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:16:36.285 INFO GenomicsDBImport - Executing as chuck@rooted3 on Linux v4.15.0-66-generic amd64; 16:16:36.285 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~16",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:10289,Performance,Load,Loading,10289,"stitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); at org.broadinstitute.hellbender.Main.main(Main.java:292); ```. ### Second Example; This user is running multiple chromosomes at a time in parallel; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072732791-Import-GVCFs-using-GenomicsDBImport-one-chromosome-at-a-time-and-parallel-the-jobs-encounter-a-Duplicate-Sample-Name-Error?page=1#community_comment_360012681711. `time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport --tmp-dir /paedwy/disk1/yangyxt/test_tmp --genomicsdb-update-workspace-path ${probe_dir}/genomicdbimport_chr${1} -R ${ref_gen}/ucsc.hg19.fasta --batch-size 0 --sample-name-map ${gvcf}/batch_cohort.sample_map --reader-threads 5 --intervals chr${1}`. ```; 01:07:01.704 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 29, 2020 1:07:01 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:07:02.001 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.002 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:07:02.002 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:07:02.002 INFO GenomicsDBImport - Executing as yangyxt@paedwy01 on Linux v3.10.0-957.10.1.el7.x86_64 amd64; 01:07:02.002 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v11.0.1+13-LTS; 01:07:02.003 INFO GenomicsDBImport - Start Date/Time: August 29, 2020 at 1:07:01 AM HKT; 01:07:02.003 INFO GenomicsDBImport - ------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:2105,Safety,detect,detect,2105,".use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -Xms16g -jar /afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar GenomicsDBImport --batch-size 24 --reader-threads 12 --genomicsdb-update-workspace-path /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/CPRs_100_proto/DB_chr1 --intervals chr1:118739963-147510543 --verbosity DEBUG -V /rooted3/langley/work/home/chuck/rad/SFARI/SSC_hg38/WGS/phase2_CPRs/SSC00007_CPR/SSC00007.haplotypeCalls.CPR.er.raw.vcf.gz; 16:16:35.954 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/afs/genomecenter.ucdavis.edu/software/gatk/4.1.6.0/lssc0-linux/gatk-package-4.1.6.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 16:16:36.003 DEBUG NativeLibraryLoader - Extracting libgkl_compression.so to /tmp/libgkl_compression5245166187604030095.so; Aug 28, 2020 4:16:36 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:16:36.284 INFO GenomicsDBImport - ------------------------------------------------------------; 16:16:36.285 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.6.0; 16:16:36.285 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:16:36.285 INFO GenomicsDBImport - Executing as chuck@rooted3 on Linux v4.15.0-66-generic amd64; 16:16:36.285 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~16.04-b01; 16:16:36.286 INFO GenomicsDBImport - Start Date/Time: August 28, 2020 4:16:35 PM PDT; 16:16:36.286 INFO GenomicsDBImport - ------------------------------------------------------------; 16:16:36.286 INFO GenomicsDBImport - ------------------------------------------------------------; 16:16:36.287 INFO GenomicsDBImport - HTSJDK Version: 2.21.2; 16:16:36.287 INFO GenomicsDBImport - Picard Version: 2.21.9; 16:16:36.289 INFO G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6793:10574,Safety,detect,detect,10574,"292); ```. ### Second Example; This user is running multiple chromosomes at a time in parallel; Please see this link for more info: https://gatk.broadinstitute.org/hc/en-us/community/posts/360072732791-Import-GVCFs-using-GenomicsDBImport-one-chromosome-at-a-time-and-parallel-the-jobs-encounter-a-Duplicate-Sample-Name-Error?page=1#community_comment_360012681711. `time ${gatk} --java-options ""-Xmx8g -Xms2g"" GenomicsDBImport --tmp-dir /paedwy/disk1/yangyxt/test_tmp --genomicsdb-update-workspace-path ${probe_dir}/genomicdbimport_chr${1} -R ${ref_gen}/ucsc.hg19.fasta --batch-size 0 --sample-name-map ${gvcf}/batch_cohort.sample_map --reader-threads 5 --intervals chr${1}`. ```; 01:07:01.704 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/yangyxt/software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Aug 29, 2020 1:07:01 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 01:07:02.001 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.002 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.8.1; 01:07:02.002 INFO GenomicsDBImport - For support and documentation go to https://software.broadinstitute.org/gatk/; 01:07:02.002 INFO GenomicsDBImport - Executing as yangyxt@paedwy01 on Linux v3.10.0-957.10.1.el7.x86_64 amd64; 01:07:02.002 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v11.0.1+13-LTS; 01:07:02.003 INFO GenomicsDBImport - Start Date/Time: August 29, 2020 at 1:07:01 AM HKT; 01:07:02.003 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.003 INFO GenomicsDBImport - ------------------------------------------------------------; 01:07:02.004 INFO GenomicsDBImport - HTSJDK Version: 2.23.0; 01:07:02.005 INFO GenomicsDBImport - Picard Version: 2.22.8; 01:07:02.005 INFO GenomicsDBI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6793
https://github.com/broadinstitute/gatk/issues/6794:5727,Availability,failure,failure,5727,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:90,Energy Efficiency,Power,PowerLinux,90,"Hello,. I'm trying to use GATK4 (4.1.8.1) on an Ubuntu (16.04) machine. The machine is a ""PowerLinux"" machine and I'm guessing that the most relevant info for the following problem is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:1111,Energy Efficiency,Power,Power,1111,"sing that the most relevant info for the following problem is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://sof",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:1644,Energy Efficiency,Power,Power,1644,"g libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le. 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09. 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:2210,Energy Efficiency,power,powerlinux,2210,"ompression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le. 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09. 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Version: 2.23.0. 16:17:05.844 INFO HaplotypeCaller - Picard Version: 2.22.8. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 16:17:05.844 INFO HaplotypeCaller - Deflater: JdkDeflater. 16:17:05.844 INFO ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4475,Energy Efficiency,Power,Power,4475,"upported, using Java.util.zip.Inflater. 16:17:05.932 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes qui",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:5151,Energy Efficiency,Power,Power,5151,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:261,Integrability,message,messages,261,"Hello,. I'm trying to use GATK4 (4.1.8.1) on an Ubuntu (16.04) machine. The machine is a ""PowerLinux"" machine and I'm guessing that the most relevant info for the following problem is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:5514,Integrability,message,messages,5514,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:5682,Integrability,message,messages,5682,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:649,Performance,Load,Loading,649,"Hello,. I'm trying to use GATK4 (4.1.8.1) on an Ubuntu (16.04) machine. The machine is a ""PowerLinux"" machine and I'm guessing that the most relevant info for the following problem is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:849,Performance,load,load,849,"Hello,. I'm trying to use GATK4 (4.1.8.1) on an Ubuntu (16.04) machine. The machine is a ""PowerLinux"" machine and I'm guessing that the most relevant info for the following problem is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:1086,Performance,load,load,1086,"tu (16.04) machine. The machine is a ""PowerLinux"" machine and I'm guessing that the most relevant info for the following problem is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:1182,Performance,Load,Loading,1182," is that it is a ppc64le system. When I use HaplotypeCaller, I see the following messages on the screen:. ```; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO Haplotyp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:1382,Performance,load,load,1382,"rite_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx50G -jar /home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar HaplotypeCaller -R ref.fa -I mybam.bam -O mycalls.vcf.gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le. 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09. 16:17",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:1619,Performance,load,load,1619,"gz -L snps.vcf -ip 100. 16:17:04.377 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.397 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le. 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09. 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4051,Performance,Load,Loading,4051," HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 16:17:05.844 INFO HaplotypeCaller - Deflater: JdkDeflater. 16:17:05.844 INFO HaplotypeCaller - Inflater: JdkInflater. 16:17:05.844 INFO HaplotypeCaller - GCS max retries/reopens: 20. 16:17:05.844 INFO HaplotypeCaller - Requester pays: disabled. 16:17:05.845 INFO HaplotypeCaller - Initializing engine. 16:17:05.928 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:05.932 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: c",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4239,Performance,load,load,4239," JdkInflater. 16:17:05.844 INFO HaplotypeCaller - GCS max retries/reopens: 20. 16:17:05.844 INFO HaplotypeCaller - Requester pays: disabled. 16:17:05.845 INFO HaplotypeCaller - Initializing engine. 16:17:05.928 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:05.932 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4450,Performance,load,load,4450,"ngine. 16:17:05.928 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:05.932 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4563,Performance,load,loaded,4563,"N IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4606,Performance,multi-thread,multi-threaded,4606,"17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slow",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4725,Performance,Load,Loading,4725,"st/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:4913,Performance,load,load,4913,"lotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl coul",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:5126,Performance,load,load,5126,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:5239,Performance,load,loaded,5239,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:5738,Performance,load,load,5738,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:5905,Performance,load,loaded,5905,"ce output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported. 16:17:06.589 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.590 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils6186849302609329058.so: /tmp/libgkl_utils6186849302609329058.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.590 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.591 **WARN** PairHMM - ***WARNING: Machine does not have the AVX instruction set support needed for the accelerated AVX PairHmm. Falling back to the MUCH slower LOGLESS_CACHING implementation!; ```. Since the calculation takes quite long, I checked the WARN messages of the output above. Especially the last one about the AVX instruction set where it says that a **MUCH** slower implementation will be used. From the few WARN messages it seems like the root cause is the failure to load libgkl and that again seems to be related to my platform. From another thread/topic I concluded that the instruction set problem might be gone if libgkl could be loaded. Does anyone know more about this issue or how to work around it?. Best regards,; Robert",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:1804,Safety,detect,detect,1804,"LibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression3825249225068031371.so: /tmp/libgkl_compression3825249225068031371.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:04.402 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so. 16:17:04.407 **WARN** NativeLibraryLoader - Unable to load libgkl_compression.so from native/libgkl_compression.so (/tmp/libgkl_compression7506152962158874866.so: /tmp/libgkl_compression7506152962158874866.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). Sep 04, 2020 4:17:05 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 16:17:05.842 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.8.1. 16:17:05.843 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/. 16:17:05.843 INFO HaplotypeCaller - Executing as robert@powerlinux on Linux v4.4.0-184-generic ppc64le. 16:17:05.843 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-8u252-b09-1~16.04-b09. 16:17:05.843 INFO HaplotypeCaller - Start Date/Time: September 4, 2020 4:17:04 PM UTC. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.843 INFO HaplotypeCaller - ------------------------------------------------------------. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Version: 2.23.0. 16:17:05.844 INFO HaplotypeCaller - Picard Version: 2.22.8. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6794:3718,Testability,test,test,3718," - HTSJDK Version: 2.23.0. 16:17:05.844 INFO HaplotypeCaller - Picard Version: 2.22.8. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true. 16:17:05.844 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 16:17:05.844 INFO HaplotypeCaller - Deflater: JdkDeflater. 16:17:05.844 INFO HaplotypeCaller - Inflater: JdkInflater. 16:17:05.844 INFO HaplotypeCaller - GCS max retries/reopens: 20. 16:17:05.844 INFO HaplotypeCaller - Requester pays: disabled. 16:17:05.845 INFO HaplotypeCaller - Initializing engine. 16:17:05.928 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:05.932 WARN IntelDeflaterFactory - IntelInflater is not supported, using Java.util.zip.Inflater. 16:17:06.503 INFO FeatureManager - Using codec VCFCodec to read file file:///home/robert/test/snps.vcf. 16:17:06.539 INFO IntervalArgumentCollection - Processing 61464 bp from intervals. 16:17:06.551 INFO HaplotypeCaller - Done initializing engine. 16:17:06.573 INFO HaplotypeCallerEngine - Disabling physical phasing, which is supported only for reference-model confidence output. 16:17:06.588 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/home/robert/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so. 16:17:06.589 **WARN** NativeLibraryLoader - Unable to load libgkl_utils.so from native/libgkl_utils.so (/tmp/libgkl_utils347167544598047196.so: /tmp/libgkl_utils347167544598047196.so: cannot open shared object file: No such file or directory (Possible cause: can't load AMD 64-bit .so on a Power PC 64 LE-bit platform)). 16:17:06.589 **WARN** IntelPairHmm - Intel GKL Utils not loaded. 16:17:06.589 INFO PairHMM - OpenMP multi-threaded AVX-accelerated native PairHMM implementation is not supported",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6794
https://github.com/broadinstitute/gatk/issues/6795:1320,Deployability,release,release,1320,"omething similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); gatk-4.1.8.1; - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I was running Concordance analysis via:. gatk Concordance -R human_g1k_v37.fasta -eval new.vcf --truth old.vcf --summary summary.tsv. my summary.tsv contains only this:. type TP FP FN RECALL PRECISION; SNP 285 1876867 2535060 0.0 0.0; INDEL 0 0 8542 0.0 0.0. Can you please tell me how I can interpret this?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6795
https://github.com/broadinstitute/gatk/issues/6795:1390,Testability,test,test,1390,"omething similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); gatk-4.1.8.1; - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I was running Concordance analysis via:. gatk Concordance -R human_g1k_v37.fasta -eval new.vcf --truth old.vcf --summary summary.tsv. my summary.tsv contains only this:. type TP FP FN RECALL PRECISION; SNP 285 1876867 2535060 0.0 0.0; INDEL 0 0 8542 0.0 0.0. Can you please tell me how I can interpret this?. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentatio",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6795
https://github.com/broadinstitute/gatk/issues/6796:56,Availability,Down,Downloads,56,"I was running this cmd : ; I get : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944. record positions. Printing Read-names as well.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010d32bea7, pid=1681, tid=6403; #; # JRE version: Java(TM) SE Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7875913179822684367.dylib+0x6ea7] deflate_medium+0x867; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mac/Desktop/NGS-/hs_err_pid1681.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6. how can I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796
https://github.com/broadinstitute/gatk/issues/6796:343,Availability,error,error,343,"I was running this cmd : ; I get : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944. record positions. Printing Read-names as well.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010d32bea7, pid=1681, tid=6403; #; # JRE version: Java(TM) SE Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7875913179822684367.dylib+0x6ea7] deflate_medium+0x867; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mac/Desktop/NGS-/hs_err_pid1681.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6. how can I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796
https://github.com/broadinstitute/gatk/issues/6796:896,Availability,error,error,896,"I was running this cmd : ; I get : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944. record positions. Printing Read-names as well.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010d32bea7, pid=1681, tid=6403; #; # JRE version: Java(TM) SE Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7875913179822684367.dylib+0x6ea7] deflate_medium+0x867; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mac/Desktop/NGS-/hs_err_pid1681.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6. how can I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796
https://github.com/broadinstitute/gatk/issues/6796:358,Safety,detect,detected,358,"I was running this cmd : ; I get : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944. record positions. Printing Read-names as well.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010d32bea7, pid=1681, tid=6403; #; # JRE version: Java(TM) SE Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7875913179822684367.dylib+0x6ea7] deflate_medium+0x867; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mac/Desktop/NGS-/hs_err_pid1681.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6. how can I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796
https://github.com/broadinstitute/gatk/issues/6796:1235,Safety,Abort,Abort,1235,"I was running this cmd : ; I get : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944. record positions. Printing Read-names as well.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010d32bea7, pid=1681, tid=6403; #; # JRE version: Java(TM) SE Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7875913179822684367.dylib+0x6ea7] deflate_medium+0x867; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mac/Desktop/NGS-/hs_err_pid1681.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6. how can I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796
https://github.com/broadinstitute/gatk/issues/6796:991,Testability,log,log,991,"I was running this cmd : ; I get : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944. record positions. Printing Read-names as well.; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x000000010d32bea7, pid=1681, tid=6403; #; # JRE version: Java(TM) SE Runtime Environment (8.0_65-b17) (build 1.8.0_65-b17); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.65-b01 mixed mode bsd-amd64 compressed oops); # Problematic frame:; # C [libgkl_compression7875913179822684367.dylib+0x6ea7] deflate_medium+0x867; #; # Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again; #; # An error report file with more information is saved as:; # /Users/mac/Desktop/NGS-/hs_err_pid1681.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #; Abort trap: 6. how can I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6796
https://github.com/broadinstitute/gatk/issues/6797:37,Availability,Down,Downloads,37,I was running : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 . I get :00:13:06.733 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/mac/Downloads/picard-2.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Sep 08 00:13:07 WEST 2020] AddOrReplaceReadGroups INPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam OUTPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Sep 08 00:13:07 WEST 2020] Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.23.0; INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Created read-group ID=C7BDWACXX.5 PL=Illumina LB=Lmj_A445_EP+3.2_run1 SM=NO8162944. INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Seen many non-increasing record positions. Printing Read-names as well.; fatal error . the first time is was sorting ana indexing when I do it again I get this error how should I fix it !!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6797
https://github.com/broadinstitute/gatk/issues/6797:370,Availability,Down,Downloads,370,I was running : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 . I get :00:13:06.733 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/mac/Downloads/picard-2.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Sep 08 00:13:07 WEST 2020] AddOrReplaceReadGroups INPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam OUTPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Sep 08 00:13:07 WEST 2020] Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.23.0; INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Created read-group ID=C7BDWACXX.5 PL=Illumina LB=Lmj_A445_EP+3.2_run1 SM=NO8162944. INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Seen many non-increasing record positions. Printing Read-names as well.; fatal error . the first time is was sorting ana indexing when I do it again I get this error how should I fix it !!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6797
https://github.com/broadinstitute/gatk/issues/6797:1120,Availability,avail,available,1120,I was running : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 . I get :00:13:06.733 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/mac/Downloads/picard-2.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Sep 08 00:13:07 WEST 2020] AddOrReplaceReadGroups INPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam OUTPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Sep 08 00:13:07 WEST 2020] Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.23.0; INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Created read-group ID=C7BDWACXX.5 PL=Illumina LB=Lmj_A445_EP+3.2_run1 SM=NO8162944. INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Seen many non-increasing record positions. Printing Read-names as well.; fatal error . the first time is was sorting ana indexing when I do it again I get this error how should I fix it !!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6797
https://github.com/broadinstitute/gatk/issues/6797:1414,Availability,error,error,1414,I was running : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 . I get :00:13:06.733 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/mac/Downloads/picard-2.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Sep 08 00:13:07 WEST 2020] AddOrReplaceReadGroups INPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam OUTPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Sep 08 00:13:07 WEST 2020] Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.23.0; INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Created read-group ID=C7BDWACXX.5 PL=Illumina LB=Lmj_A445_EP+3.2_run1 SM=NO8162944. INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Seen many non-increasing record positions. Printing Read-names as well.; fatal error . the first time is was sorting ana indexing when I do it again I get this error how should I fix it !!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6797
https://github.com/broadinstitute/gatk/issues/6797:1495,Availability,error,error,1495,I was running : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 . I get :00:13:06.733 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/mac/Downloads/picard-2.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Sep 08 00:13:07 WEST 2020] AddOrReplaceReadGroups INPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam OUTPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Sep 08 00:13:07 WEST 2020] Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.23.0; INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Created read-group ID=C7BDWACXX.5 PL=Illumina LB=Lmj_A445_EP+3.2_run1 SM=NO8162944. INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Seen many non-increasing record positions. Printing Read-names as well.; fatal error . the first time is was sorting ana indexing when I do it again I get this error how should I fix it !!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6797
https://github.com/broadinstitute/gatk/issues/6797:312,Performance,Load,Loading,312,I was running : java -jar /Users/mac/Downloads/picard-2.jar AddOrReplaceReadGroups I=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam O=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 . I get :00:13:06.733 INFO NativeLibraryLoader - Loading libgkl_compression.dylib from jar:file:/Users/mac/Downloads/picard-2.jar!/com/intel/gkl/native/libgkl_compression.dylib; [Tue Sep 08 00:13:07 WEST 2020] AddOrReplaceReadGroups INPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe.bam OUTPUT=/Users/mac/Desktop/NGS-/SRR6369642-pe-RG.bam RGID=C7BDWACXX.5 RGLB=Lmj_A445_EP+3.2_run1 RGPL=Illumina RGPU=C7BDWACXX.5 RGSM=NO8162944 VERBOSITY=INFO QUIET=false VALIDATION_STRINGENCY=STRICT COMPRESSION_LEVEL=5 MAX_RECORDS_IN_RAM=500000 CREATE_INDEX=false CREATE_MD5_FILE=false GA4GH_CLIENT_SECRETS=client_secrets.json USE_JDK_DEFLATER=false USE_JDK_INFLATER=false; [Tue Sep 08 00:13:07 WEST 2020] Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17; Deflater: Intel; Inflater: Intel; Provider GCS is not available; Picard version: 2.23.0; INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Created read-group ID=C7BDWACXX.5 PL=Illumina LB=Lmj_A445_EP+3.2_run1 SM=NO8162944. INFO	2020-09-08 00:13:08	AddOrReplaceReadGroups	Seen many non-increasing record positions. Printing Read-names as well.; fatal error . the first time is was sorting ana indexing when I do it again I get this error how should I fix it !!,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6797
https://github.com/broadinstitute/gatk/issues/6798:1783,Availability,ERROR,ERROR,1783,"4 HelpFormatter - Copyright (c) 2010-2016 The Broad Institute ; INFO 10:47:54,224 HelpFormatter - For support and documentation go to https://software.broadinstitute.org/gatk ; INFO 10:47:54,225 HelpFormatter - [Tue Sep 08 10:47:54 WEST 2020] Executing on Mac OS X 10.15.6 x86_64 ; INFO 10:47:54,225 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17 ; INFO 10:47:54,229 HelpFormatter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ----------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2017,Availability,ERROR,ERROR,2017,"tter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please chec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2408,Availability,Down,Downsampling,2408,".local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2434,Availability,down,downsampling,2434,".local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please d",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2630,Availability,ERROR,ERROR,2630,"---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No ove",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2734,Availability,ERROR,ERROR,2734,"---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No ove",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2747,Availability,ERROR,ERROR,2747,"---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No ove",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2802,Availability,ERROR,ERROR,2802,"gging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2815,Availability,ERROR,ERROR,2815,"gging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2907,Availability,ERROR,ERROR,2907,"isTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2917,Availability,error,error,2917,"isTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2975,Availability,ERROR,ERROR,2975,"entation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2988,Availability,ERROR,ERROR,2988,"entation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3084,Availability,ERROR,ERROR,3084,"entation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3189,Availability,ERROR,ERROR,3189,"meAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3202,Availability,ERROR,ERROR,3202,"meAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3287,Availability,ERROR,ERROR,3287,"meAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3366,Availability,ERROR,ERROR,3366,"pling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_2005",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3379,Availability,ERROR,ERROR,3379,"pling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_2005",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3409,Availability,error,error,3409,"pling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_2005",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3489,Availability,ERROR,ERROR,3489,"; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3502,Availability,ERROR,ERROR,3502,"; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3677,Availability,Error,Error,3677,"----------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, LmjF16_01_20050601_V5.2, LmjF17_01_20050601_V5.2, LmjF20_01_20050601_V5.2, LmjF22_01_20050601_V5.2, LmjF26_01_20050601_V5.2]; ##### ERROR reference contigs = [LmjLV39_01, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3729,Availability,ERROR,ERROR,3729,"ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, LmjF16_01_20050601_V5.2, LmjF17_01_20050601_V5.2, LmjF20_01_20050601_V5.2, LmjF22_01_20050601_V5.2, LmjF26_01_20050601_V5.2]; ##### ERROR reference contigs = [LmjLV39_01, LmjLV39_02, LmjLV39_03, LmjLV39_04, LmjLV39_05, Lm",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:4659,Availability,ERROR,ERROR,4659,,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:20585,Availability,ERROR,ERROR,20585,"V39_SCAF000680, LMJLV39_SCAF000681, LMJLV39_SCAF000682, LMJLV39_SCAF000683, LMJLV39_SCAF000684, LMJLV39_SCAF000685, LMJLV39_SCAF000686, LMJLV39_SCAF000687, LMJLV39_SCAF000688, LMJLV39_SCAF000689, LMJLV39_SCAF000690, LMJLV39_SCAF000691, LMJLV39_SCAF000692, LMJLV39_SCAF000693, LMJLV39_SCAF000694, LMJLV39_SCAF000695, LMJLV39_SCAF000696, LMJLV39_SCAF000697, LMJLV39_SCAF000698, LMJLV39_SCAF000699, LMJLV39_SCAF000700, LMJLV39_SCAF000701, LMJLV39_SCAF000702, LMJLV39_SCAF000703, LMJLV39_SCAF000704, LMJLV39_SCAF000705, LMJLV39_SCAF000706, LMJLV39_SCAF000707, LMJLV39_SCAF000708, LMJLV39_SCAF000709, LMJLV39_SCAF000710, LMJLV39_SCAF000711, LMJLV39_SCAF000712, LMJLV39_SCAF000713, LMJLV39_SCAF000714, LMJLV39_SCAF000715, LMJLV39_SCAF000716, LMJLV39_SCAF000717, LMJLV39_SCAF000718, LMJLV39_SCAF000719, LMJLV39_SCAF000720, LMJLV39_SCAF000721, LMJLV39_SCAF000722, LMJLV39_SCAF000723, LMJLV39_SCAF000724, LMJLV39_SCAF000725, LMJLV39_SCAF000726, LMJLV39_SCAF000727, LMJLV39_SCAF000728, LMJLV39_SCAF000729, LMJLV39_SCAF000730, LMJLV39_SCAF000731, LMJLV39_SCAF000732, LMJLV39_SCAF000733, LMJLV39_SCAF000734, LMJLV39_SCAF000735, LMJLV39_SCAF000736, LMJLV39_SCAF000737, LMJLV39_SCAF000738, LMJLV39_SCAF000739, LMJLV39_SCAF000740, LMJLV39_SCAF000741, LMJLV39_SCAF000742, LMJLV39_SCAF000743, LMJLV39_SCAF000744, LMJLV39_SCAF000745, LMJLV39_SCAF000746, LMJLV39_SCAF000747, LMJLV39_SCAF000748, LMJLV39_SCAF000749, LMJLV39_SCAF000750, LMJLV39_SCAF000751, LMJLV39_SCAF000752, LMJLV39_SCAF000753, LMJLV39_SCAF000754, LMJLV39_SCAF000755, LMJLV39_SCAF000756, LMJLV39_SCAF000757, LMJLV39_SCAF000758, LMJLV39_SCAF000759, LMJLV39_SCAF000760, LMJLV39_SCAF000761, LMJLV39_SCAF000762, LMJLV39_SCAF000763, LMJLV39_SCAF000764, LMJLV39_SCAF000765, LMJLV39_SCAF000766, LMJLV39_SCAF000767, LMJLV39_SCAF000768, LMJLV39_SCAF000769, LMJLV39_SCAF000770, LMJLV39_SCAF000771, LMJLV39_SCAF000772, LMJLV39_SCAF000773]; ##### ERROR ------------------------------------------------------------------------------------------; how should I fix it",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2923,Integrability,message,message,2923,"isTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3508,Integrability,MESSAGE,MESSAGE,3508,"; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.2, LmjF18_01_20050601_V5.2, LmjF02_01_20050601_V5.2, LmjF25_01_20050601_V5.2, LmjF27_01_20050601_V5.2, LmjF28_01_20050601_V5.2, LmjF29_01_20050601_V5.2, LmjF30_01_20050601_V5.2, LmjF31_01_20050601_V5.2, LmjF32_01_20050601_V5.3, LmjF33_01_20050601_V5.2, LmjF34_01_20050601_V5.2, LmjF35_01_20050601_V5.2, LmjF36_01_20050601_V5.2, LmjF07_01_20050601_V5.2, LmjF08_01_20050601_V5.2, LmjF09_01_20050601_V5.2, LmjF06_01_20050601_V5.2, LmjF12_01_20050601_V5.2, L",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:1836,Testability,log,logging,1836,"54,225 HelpFormatter - [Tue Sep 08 10:47:54 WEST 2020] Executing on Mac OS X 10.15.6 x86_64 ; INFO 10:47:54,225 HelpFormatter - Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17 ; INFO 10:47:54,229 HelpFormatter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2060,Testability,log,logging,2060,"tter - Program Args: -T IndelRealigner -R /Users/mac/Desktop/NGS-/TriTrypDB-47_LmajorLV39c5_Genome.fasta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please chec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2146,Testability,log,log,2146,"asta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:2130,Usability,Simpl,SimpleLogger,2130,"asta -I /Users/mac/Desktop/NGS-/marked_duplicates42-pe.bam -targetIntervals /Users/mac/Desktop/NGS-/42-pe-realigner.intervals -o /Users/mac/Desktop/NGS-/42-pe-idelsrealigner.bam ; INFO 10:47:54,492 HelpFormatter - Executing as mac@MacBook-Air-de-mac.local on Mac OS X 10.15.6 x86_64; Java HotSpot(TM) 64-Bit Server VM 1.8.0_65-b17. ; INFO 10:47:54,493 HelpFormatter - Date/Time: 2020/09/08 10:47:54 ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; INFO 10:47:54,494 HelpFormatter - ---------------------------------------------------------------------------------- ; ERROR StatusLogger Unable to create class org.apache.logging.log4j.core.impl.Log4jContextFactory specified in jar:file:/Users/mac/Desktop/GenomeAnalysisTK-3.8-0-ge9d806836%204/GenomeAnalysisTK.jar!/META-INF/log4j-provider.properties; ERROR StatusLogger Log4j2 could not find a logging implementation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/issues/6798:3071,Usability,guid,guide,3071,"entation. Please add log4j-core to the classpath. Using SimpleLogger to log to the console...; INFO 10:47:55,875 GenomeAnalysisEngine - Deflater: IntelDeflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Inflater: IntelInflater ; INFO 10:47:55,876 GenomeAnalysisEngine - Strictness is SILENT ; INFO 10:47:56,246 GenomeAnalysisEngine - Downsampling Settings: No downsampling ; INFO 10:47:56,255 SAMDataSource$SAMReaders - Initializing SAMRecords in serial ; INFO 10:47:56,333 SAMDataSource$SAMReaders - Done initializing BAM readers: total time 0.07 ; ##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-0-ge9d806836): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR MESSAGE: Input files reads and reference have incompatible contigs. Please see https://software.broadinstitute.org/gatk/documentation/article?id=63for more information. Error details: No overlapping contigs found.; ##### ERROR reads contigs = [LmjF04_01_20050601_V5.2, LmjF05_01_20050601_V5.2, LmjF24_01_20050601_V5.2, LmjF01_01_20050601_V5.2, LmjF03_01_20050601_V5.2, LmjF13_01_20050601_V5.2, LmjF14_01_20050601_V5.2, LmjF19_01_20050601_V5.2, LmjF21_01_20050601_V5.2, LmjF23_01_20050601_V5.2, LmjF10_01_20050601_V5.2, LmjF11_01_20050601_V5.2, LmjF15_01_20050601_V5.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6798
https://github.com/broadinstitute/gatk/pull/6799:0,Availability,Failure,Failures,0,"Failures now include the url:. `org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam?referenceName=chr1&start=23999999&end=25000000, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799
https://github.com/broadinstitute/gatk/pull/6799:244,Availability,error,error,244,"Failures now include the url:. `org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam?referenceName=chr1&start=23999999&end=25000000, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799
https://github.com/broadinstitute/gatk/pull/6799:261,Availability,error,error,261,"Failures now include the url:. `org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam?referenceName=chr1&start=23999999&end=25000000, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799
https://github.com/broadinstitute/gatk/pull/6799:283,Integrability,message,message,283,"Failures now include the url:. `org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam?referenceName=chr1&start=23999999&end=25000000, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6799
https://github.com/broadinstitute/gatk/pull/6800:195,Testability,test,test,195,The last commit adds WDL annotations to a number of new tools. Might be best to review that separately (or we can even move it to a separate PR - I just wanted it here to force increased WDL gen test coverage).,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6800
https://github.com/broadinstitute/gatk/issues/6801:156,Deployability,release,release,156,"## Bug Report. ### Affected tool(s) or class(es); org.broadinstitute.hellbender.utils.fragments.FragmentUtils. ### Affected version(s); - [x] Latest public release version 4.1.8.1; - [X] Latest master branch as of September 8th, 2020. ### Description ; At, https://github.com/broadinstitute/gatk/blob/12511551a3e273a1ad767253ccba9918d6eb45b9/src/main/java/org/broadinstitute/hellbender/utils/fragments/FragmentUtils.java#L93-L96. Both insertions and deletions use `getBaseInsertionQualities`. Deletions should instead use `getBaseDeletionQualities`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6801
https://github.com/broadinstitute/gatk/pull/6802:102,Deployability,Integrat,Integration,102,- Tool creates histograms to reflect differences in the composition reference blocks in GVCF files; - Integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802
https://github.com/broadinstitute/gatk/pull/6802:102,Integrability,Integrat,Integration,102,- Tool creates histograms to reflect differences in the composition reference blocks in GVCF files; - Integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802
https://github.com/broadinstitute/gatk/pull/6802:114,Testability,test,tests,114,- Tool creates histograms to reflect differences in the composition reference blocks in GVCF files; - Integration tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6802
https://github.com/broadinstitute/gatk/issues/6803:35,Availability,down,down,35,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:57,Availability,ping,ping,57,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:348,Availability,error,error,348,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:365,Availability,error,error,365,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:1481,Deployability,update,updated,1481,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:387,Integrability,message,message,387,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:41,Testability,test,tests,41,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:1221,Testability,test,testutils,1221,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:1374,Testability,test,testSuccessfulParameters,1374,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/issues/6803:1668,Testability,test,tests,1668,"The htsget.ga4gh.org appears to be down (tests get 404s, ping fails). This output is from my PR https://github.com/broadinstitute/gatk/pull/6799 that prints out the target URI:. ```; org.broadinstitute.hellbender.exceptions.UserException: Invalid request https://htsget.ga4gh.org/reads/A1-B000168-3_57_F-1-1_R2.mus.Aligned.out.sorted.bam, received error code: 404, error type: NotFound, message: The requested resource could not be associated with a registered data source; at org.broadinstitute.hellbender.tools.HtsgetReader.doWork(HtsgetReader.java:266); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:146); at org.broadinstitute.hellbender.Main.instanceMain(Main.java:187); at org.broadinstitute.hellbender.CommandLineProgramTest.runCommandLine(CommandLineProgramTest.java:27); at org.broadinstitute.hellbender.testutils.CommandLineProgramTester.runCommandLine(CommandLineProgramTester.java:111); at org.broadinstitute.hellbender.tools.HtsgetReaderIntegrationTest.testSuccessfulParameters(HtsgetReaderIntegrationTest.java:85); ```; Jermey (GA4GH dev) says:. > I recently updated the server, but my understanding was that the gatk build was spinning up a local server from an older image; > 11:41; > so htsget.ga4gh.org is using a newer image, while the gatk tests should pull an older image, spin it up locally, and then request from http://localhost. But based on the output above, it looks like we actually target `https://htsget.ga4gh.org/read...`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6803
https://github.com/broadinstitute/gatk/pull/6804:85,Testability,test,tests,85,Workaround https://github.com/broadinstitute/gatk/issues/6803. Temporarily disabling tests until this is resolved.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6804
https://github.com/broadinstitute/gatk/issues/6805:83,Testability,test,test,83,"The WDL auto-gen code includes code to generate a JSON input file with synthesized test data for every WDL, but the test generation code is not mutex-argument aware (the WDLs work fine on such tools; its just that we can't test such a tool using the autogenerated tests data). When this is fixed, the hard-coded work-around for the mutex arg present in all Spark tools ((`output-shard-tmp-dir`) in `GATKWDLWorkUnitHandler.testValueAsJSON` can be removed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6805
https://github.com/broadinstitute/gatk/issues/6805:116,Testability,test,test,116,"The WDL auto-gen code includes code to generate a JSON input file with synthesized test data for every WDL, but the test generation code is not mutex-argument aware (the WDLs work fine on such tools; its just that we can't test such a tool using the autogenerated tests data). When this is fixed, the hard-coded work-around for the mutex arg present in all Spark tools ((`output-shard-tmp-dir`) in `GATKWDLWorkUnitHandler.testValueAsJSON` can be removed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6805
https://github.com/broadinstitute/gatk/issues/6805:223,Testability,test,test,223,"The WDL auto-gen code includes code to generate a JSON input file with synthesized test data for every WDL, but the test generation code is not mutex-argument aware (the WDLs work fine on such tools; its just that we can't test such a tool using the autogenerated tests data). When this is fixed, the hard-coded work-around for the mutex arg present in all Spark tools ((`output-shard-tmp-dir`) in `GATKWDLWorkUnitHandler.testValueAsJSON` can be removed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6805
https://github.com/broadinstitute/gatk/issues/6805:264,Testability,test,tests,264,"The WDL auto-gen code includes code to generate a JSON input file with synthesized test data for every WDL, but the test generation code is not mutex-argument aware (the WDLs work fine on such tools; its just that we can't test such a tool using the autogenerated tests data). When this is fixed, the hard-coded work-around for the mutex arg present in all Spark tools ((`output-shard-tmp-dir`) in `GATKWDLWorkUnitHandler.testValueAsJSON` can be removed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6805
https://github.com/broadinstitute/gatk/issues/6805:422,Testability,test,testValueAsJSON,422,"The WDL auto-gen code includes code to generate a JSON input file with synthesized test data for every WDL, but the test generation code is not mutex-argument aware (the WDLs work fine on such tools; its just that we can't test such a tool using the autogenerated tests data). When this is fixed, the hard-coded work-around for the mutex arg present in all Spark tools ((`output-shard-tmp-dir`) in `GATKWDLWorkUnitHandler.testValueAsJSON` can be removed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6805
https://github.com/broadinstitute/gatk/pull/6807:82,Security,validat,validating,82,- Added max version check for data sources. This will automatically be; used when validating a data sources version for running. Fixes #6712,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6807
https://github.com/broadinstitute/gatk/issues/6808:2387,Availability,down,down,2387,"Caller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Tr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:2662,Availability,ERROR,ERROR,2662," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:154,Deployability,pipeline,pipeline,154,"Hello,. It seems the parameter `--sequence-dictionary` does not change the dictionary looked by **HaplotypeCaller**. ```; averdier@bioinfo:~/test/dna-seq-pipeline$ ./dna-seq-pipeline.pl -1 CACTTCGA-ACACGACC_S156_L003_R1_001.fastq.gz -2 CACTTCGA-ACACGACC_S156_L003_R2_001.fastq.gz -r Triticum_aestivum_Claire_EIv1.1.fa.gz -s ClaireTest --nb_threads 30; --mem_limit 100; Mapping; Mark Duplicates; Variants Calling; 09:54:54.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 11, 2020 9:54:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:54:54.730 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 09:54:54.731 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:54:54.731 INFO HaplotypeCaller - Executing as averdier@bioinfo on Linux v4.4.0-178-generic amd64; 09:54:54.731 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 09:54:54.731 INFO HaplotypeCaller - Start Date/Time: September 11, 2020 9:54:54 AM CEST; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:174,Deployability,pipeline,pipeline,174,"Hello,. It seems the parameter `--sequence-dictionary` does not change the dictionary looked by **HaplotypeCaller**. ```; averdier@bioinfo:~/test/dna-seq-pipeline$ ./dna-seq-pipeline.pl -1 CACTTCGA-ACACGACC_S156_L003_R1_001.fastq.gz -2 CACTTCGA-ACACGACC_S156_L003_R2_001.fastq.gz -r Triticum_aestivum_Claire_EIv1.1.fa.gz -s ClaireTest --nb_threads 30; --mem_limit 100; Mapping; Mark Duplicates; Variants Calling; 09:54:54.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 11, 2020 9:54:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:54:54.730 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 09:54:54.731 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:54:54.731 INFO HaplotypeCaller - Executing as averdier@bioinfo on Linux v4.4.0-178-generic amd64; 09:54:54.731 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 09:54:54.731 INFO HaplotypeCaller - Start Date/Time: September 11, 2020 9:54:54 AM CEST; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:2733,Deployability,pipeline,pipeline,2733," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:2828,Deployability,pipeline,pipeline,2828," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:453,Performance,Load,Loading,453,"Hello,. It seems the parameter `--sequence-dictionary` does not change the dictionary looked by **HaplotypeCaller**. ```; averdier@bioinfo:~/test/dna-seq-pipeline$ ./dna-seq-pipeline.pl -1 CACTTCGA-ACACGACC_S156_L003_R1_001.fastq.gz -2 CACTTCGA-ACACGACC_S156_L003_R2_001.fastq.gz -r Triticum_aestivum_Claire_EIv1.1.fa.gz -s ClaireTest --nb_threads 30; --mem_limit 100; Mapping; Mark Duplicates; Variants Calling; 09:54:54.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 11, 2020 9:54:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:54:54.730 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 09:54:54.731 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:54:54.731 INFO HaplotypeCaller - Executing as averdier@bioinfo on Linux v4.4.0-178-generic amd64; 09:54:54.731 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 09:54:54.731 INFO HaplotypeCaller - Start Date/Time: September 11, 2020 9:54:54 AM CEST; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:712,Safety,detect,detect,712,"Hello,. It seems the parameter `--sequence-dictionary` does not change the dictionary looked by **HaplotypeCaller**. ```; averdier@bioinfo:~/test/dna-seq-pipeline$ ./dna-seq-pipeline.pl -1 CACTTCGA-ACACGACC_S156_L003_R1_001.fastq.gz -2 CACTTCGA-ACACGACC_S156_L003_R2_001.fastq.gz -r Triticum_aestivum_Claire_EIv1.1.fa.gz -s ClaireTest --nb_threads 30; --mem_limit 100; Mapping; Mark Duplicates; Variants Calling; 09:54:54.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 11, 2020 9:54:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:54:54.730 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 09:54:54.731 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:54:54.731 INFO HaplotypeCaller - Executing as averdier@bioinfo on Linux v4.4.0-178-generic amd64; 09:54:54.731 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 09:54:54.731 INFO HaplotypeCaller - Start Date/Time: September 11, 2020 9:54:54 AM CEST; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:141,Testability,test,test,141,"Hello,. It seems the parameter `--sequence-dictionary` does not change the dictionary looked by **HaplotypeCaller**. ```; averdier@bioinfo:~/test/dna-seq-pipeline$ ./dna-seq-pipeline.pl -1 CACTTCGA-ACACGACC_S156_L003_R1_001.fastq.gz -2 CACTTCGA-ACACGACC_S156_L003_R2_001.fastq.gz -r Triticum_aestivum_Claire_EIv1.1.fa.gz -s ClaireTest --nb_threads 30; --mem_limit 100; Mapping; Mark Duplicates; Variants Calling; 09:54:54.531 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/gatk/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 11, 2020 9:54:54 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 09:54:54.730 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.7.0; 09:54:54.731 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 09:54:54.731 INFO HaplotypeCaller - Executing as averdier@bioinfo on Linux v4.4.0-178-generic amd64; 09:54:54.731 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 09:54:54.731 INFO HaplotypeCaller - Start Date/Time: September 11, 2020 9:54:54 AM CEST; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.731 INFO HaplotypeCaller - ------------------------------------------------------------; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Version: 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_A",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:2720,Testability,test,test,2720," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6808:2815,Testability,test,test,2815," 2.21.2; 09:54:54.732 INFO HaplotypeCaller - Picard Version: 2.21.9; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 09:54:54.732 INFO HaplotypeCaller - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 09:54:54.732 INFO HaplotypeCaller - Deflater: IntelDeflater; 09:54:54.732 INFO HaplotypeCaller - Inflater: IntelInflater; 09:54:54.732 INFO HaplotypeCaller - GCS max retries/reopens: 20; 09:54:54.732 INFO HaplotypeCaller - Requester pays: disabled; 09:54:54.732 INFO HaplotypeCaller - Initializing engine; 09:55:05.747 INFO HaplotypeCaller - Shutting down engine; [September 11, 2020 9:55:05 AM CEST] org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCaller done. Elapsed time: 0.19 minutes.; Runtime.totalMemory()=5152178176; ***********************************************************************. A USER ERROR has occurred: Fasta dict file file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.dict for reference file:///home/averdier/test/dna-seq-pipeline/Triticum_aestivum_Claire_EIv1.1.fa.gz does not exist.; Please see http://gatkforums.broadinstitute.org/discussion/1601/how-can-i-prepare-a-fasta-file-to-use-as-reference for help creating it. ***********************************************************************; Set the system property GATK_STACKTRACE_ON_USER_EXCEPTION (--java-options '-DGATK_STACKTRACE_ON_USER_EXCEPTION=true') to print the stack trace. Command 'java -Xmx100G -jar /opt/gatk/gatk-package-4.1.7.0-local.jar HaplotypeCaller -R Triticum_aestivum_Claire_EIv1.1.fa.gz --sequence-dictionary Triticum_aestivum_Claire_EIv1.1.fa.gz.dict -I ClaireTest_MD.bam -O ClaireTest_MD_NoInter; vals_Output.vcf --stand-call-conf 10 --native-pair-hmm-threads 30' failed with 512. ```. I'm using the local gatk of version 4.1.7.0",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6808
https://github.com/broadinstitute/gatk/issues/6811:5,Security,access,accessing,5,When accessing the help output for Picard tools (example MarkDuplicates) through the gatk launch script it seems that engine level Picard arguments are not showing up in the help output (example `--TMP_DIR`). The default behavior in picard itself is to hide those engine arguments from the help output behind a special help flag `--stdhelp` which adds all of those arguments back into the help output. We should reintroduce those arguments into the GATK help output for Picard tools.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6811
https://github.com/broadinstitute/gatk/pull/6812:6,Availability,down,down,6,"Pulls down a temp table of genotype counts, calculates excess het and call rate and writes them to a tsv for future upload.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6812
https://github.com/broadinstitute/gatk/pull/6816:805,Energy Efficiency,reduce,reduces,805,"This PR contains fixes aimed at improving the performance of HaplotypeCaller at sites with a spanning deletion. There are three main changes:. * Modified the behavior of the `use-posteriors-to-calculate-qual` method for calculating QUAL. This method is supposed to assign a QUAL based on the posterior probabilities of genotypes which do not include a variant allele. In most cases, this set of genotypes is limited to HOM-REF. However, if a `*` allele is present at the site, it does not represent a variant allele at the locus in question (its QUAL is computed upstream at the deletion start site). Therefore, `use-posteriors-to-calculate-qual` should use any genotype that is composed of combinations of REF and `*` -- in the diploid case this would be `REF/REF`, `*/REF`, and `*/*`. This dramatically reduces the QUAL of sites that have a spanning deletion, as often most of the reads that don't support the variants beginning at the site support the overlapping deletion, increasing the likelihood of `REF/*` and `REF/REF`. This summation parallels that computed by `VariationalAlleleFrequencyCalculator`, which also special-cases `*` as an allele which does not contribute to the the likelihood of a variant allele at the site in question.; * Fixed a bug in `VariationalAlleleFrequencyCalculator` relating to summing across non-site specific variant alleles as mentioned above. An indexing problem was causing the calculator to sum `REF/REF` and `REF/*` genotypes but not `*/*` genotypes (in the diploid case).; * Added an option `limit-spanning-events-to-called-variants` to HaplotypeCaller. If enabled, the current implementation of this method only allows the `*` allele to be included in genotyping and QUAL calculations if at least one of the variants found in haplotypes overlapping the locus matches a deletion that was actually called upstream (without this option HaplotypeCaller reverts to its current behavior, which is to allow any haplotype with a deletion overlapping the location ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6816
https://github.com/broadinstitute/gatk/pull/6816:46,Performance,perform,performance,46,"This PR contains fixes aimed at improving the performance of HaplotypeCaller at sites with a spanning deletion. There are three main changes:. * Modified the behavior of the `use-posteriors-to-calculate-qual` method for calculating QUAL. This method is supposed to assign a QUAL based on the posterior probabilities of genotypes which do not include a variant allele. In most cases, this set of genotypes is limited to HOM-REF. However, if a `*` allele is present at the site, it does not represent a variant allele at the locus in question (its QUAL is computed upstream at the deletion start site). Therefore, `use-posteriors-to-calculate-qual` should use any genotype that is composed of combinations of REF and `*` -- in the diploid case this would be `REF/REF`, `*/REF`, and `*/*`. This dramatically reduces the QUAL of sites that have a spanning deletion, as often most of the reads that don't support the variants beginning at the site support the overlapping deletion, increasing the likelihood of `REF/*` and `REF/REF`. This summation parallels that computed by `VariationalAlleleFrequencyCalculator`, which also special-cases `*` as an allele which does not contribute to the the likelihood of a variant allele at the site in question.; * Fixed a bug in `VariationalAlleleFrequencyCalculator` relating to summing across non-site specific variant alleles as mentioned above. An indexing problem was causing the calculator to sum `REF/REF` and `REF/*` genotypes but not `*/*` genotypes (in the diploid case).; * Added an option `limit-spanning-events-to-called-variants` to HaplotypeCaller. If enabled, the current implementation of this method only allows the `*` allele to be included in genotyping and QUAL calculations if at least one of the variants found in haplotypes overlapping the locus matches a deletion that was actually called upstream (without this option HaplotypeCaller reverts to its current behavior, which is to allow any haplotype with a deletion overlapping the location ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6816
https://github.com/broadinstitute/gatk/issues/6817:112,Deployability,release,release,112,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; I have a sample with a complex variant that could be modeled either as a 1bp deletion followed by a 2bp MNP, or more likely as a 3bp deletion followed by a 2bp insertion (or, if you will, the replacement of three reference bases with two other bases). The changes are clearly visible in the following screenshot. The top track is the aligned/deduped BAM, and the bottom track is the assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817
https://github.com/broadinstitute/gatk/issues/6817:181,Testability,test,test,181,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; I have a sample with a complex variant that could be modeled either as a 1bp deletion followed by a 2bp MNP, or more likely as a 3bp deletion followed by a 2bp insertion (or, if you will, the replacement of three reference bases with two other bases). The changes are clearly visible in the following screenshot. The top track is the aligned/deduped BAM, and the bottom track is the assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817
https://github.com/broadinstitute/gatk/issues/6817:1002,Testability,test,test-sample,1002,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; I have a sample with a complex variant that could be modeled either as a 1bp deletion followed by a 2bp MNP, or more likely as a 3bp deletion followed by a 2bp insertion (or, if you will, the replacement of three reference bases with two other bases). The changes are clearly visible in the following screenshot. The top track is the aligned/deduped BAM, and the bottom track is the assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817
https://github.com/broadinstitute/gatk/issues/6817:1600,Testability,test,test-sample,1600,"e assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried both with and without the `--linked-de-bruijn-graph` which doesn't appear to have any effect on this issue. #### Steps to reproduce; Run the following on the [attached BAM file](https://github.com/broadinstitute/gatk/files/5220715/missed-insertion-bam.zip) using your favorite HG19 reference:. ```; gatk HaplotypeCaller \; -I missed-insertion.bam \; -O missed-insertion.g.vcf \; -R hg19.fa \; -ERC GVCF \; -L chr13:32953865-32953905 \; --bam-output missed-insertion.assembly.bam \; ```. #### Expected behavior; I would actually have expected this to be output as a single variant in the ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817
https://github.com/broadinstitute/gatk/issues/6817:475,Usability,clear,clearly,475,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; I have a sample with a complex variant that could be modeled either as a 1bp deletion followed by a 2bp MNP, or more likely as a 3bp deletion followed by a 2bp insertion (or, if you will, the replacement of three reference bases with two other bases). The changes are clearly visible in the following screenshot. The top track is the aligned/deduped BAM, and the bottom track is the assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817
https://github.com/broadinstitute/gatk/issues/6817:859,Usability,clear,clearly,859,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [ ] Latest master branch as of [date of test?]. ### Description ; I have a sample with a complex variant that could be modeled either as a 1bp deletion followed by a 2bp MNP, or more likely as a 3bp deletion followed by a 2bp insertion (or, if you will, the replacement of three reference bases with two other bases). The changes are clearly visible in the following screenshot. The top track is the aligned/deduped BAM, and the bottom track is the assembly BAM generated by HaplotypeCaller:. ![missing-insertion igv-screenshot](https://user-images.githubusercontent.com/1609210/93133361-516e5780-f694-11ea-9b7d-7aa71f5623cc.png). When I call this region to generate a gVCF I get some fairly strange output despite HC clearly reconstructing the haplotype correctly (some annotations removed for readability):. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953865 . T <NON_REF> . . END=32953884 GT:DP:GQ:MIN_DP:PL 0/0:204:99:196:0,120,1800; chr13 32953885 . AGTT A,<NON_REF> 3110.60 . DP=213;MLEAC=1,0;MLEAF=0.500,0.00 GT:AD:DP:GQ:PL:SB 0/1:108,82,0:1; chr13 32953888 . T *,TAA,<NON_REF> 585.02 . DP=205;MLEAC=0,0,2;MLEAF=NaN,NaN,1.00;RAW_MQandDP=738000,205 GT:GQ:PL ./.:99:0,0,0,0,0,0,0,0,0,0; chr13 32953889 . A <NON_REF> . . END=32953905 GT:DP:GQ:MIN_DP:PL 0/0:211:99:205:0,120,1800; ```. When this is genotyped by `GenotypeGVCFs` the only resulting variant is the 3bp deletion:. ```; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT test-sample; chr13 32953885 . AGTT A 3110.60 . AC=1;AF=0.500;AN=2;BaseQRankSum=0.00;DP=213;ExcessHet=3.0103;FS=2.544;MLEAC=1;MLEAF=0.500;MQ=60.00;MQRankSum=0.00;QD=16.37;ReadPosRankSum=-4.360e-01;SOR=0.506 GT:AD:DP:GQ:PL 0/1:108,82:190:99:3118,0,4288; ```. I've tried this with GATK 4.1.4.1, and also 4.1.7.0 and 4.1.8.1 and they all have the same issue (output above is from 4.1.8.1). I've also tried",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6817
https://github.com/broadinstitute/gatk/pull/6823:170,Availability,redundant,redundant,170,"Closes #6686. @fleharty This option did nothing because a copy of the original reads was modified. By deleting the unnecessary mapping quality filtering (this is totally redundant with the M2 read filter), we finalize (and thereby discard soft clips if requested) an assembly region made from the original reads, not a copy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6823
https://github.com/broadinstitute/gatk/pull/6823:170,Safety,redund,redundant,170,"Closes #6686. @fleharty This option did nothing because a copy of the original reads was modified. By deleting the unnecessary mapping quality filtering (this is totally redundant with the M2 read filter), we finalize (and thereby discard soft clips if requested) an assembly region made from the original reads, not a copy.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6823
https://github.com/broadinstitute/gatk/pull/6824:386,Deployability,update,updates,386,"When extracting the overlapped bases of two reads, FragmentUtils miscalculates the starting position of the second read if there are softclipped bases at its head. This leads to misalignment of the two reads and incorrect updating of the base qualities. In some other cases, it may fail to detect overlapping bases if the first and second read both contain softclips. This pull request updates the position calculation and adds a unit test to demonstrate the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6824
https://github.com/broadinstitute/gatk/pull/6824:290,Safety,detect,detect,290,"When extracting the overlapped bases of two reads, FragmentUtils miscalculates the starting position of the second read if there are softclipped bases at its head. This leads to misalignment of the two reads and incorrect updating of the base qualities. In some other cases, it may fail to detect overlapping bases if the first and second read both contain softclips. This pull request updates the position calculation and adds a unit test to demonstrate the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6824
https://github.com/broadinstitute/gatk/pull/6824:435,Testability,test,test,435,"When extracting the overlapped bases of two reads, FragmentUtils miscalculates the starting position of the second read if there are softclipped bases at its head. This leads to misalignment of the two reads and incorrect updating of the base qualities. In some other cases, it may fail to detect overlapping bases if the first and second read both contain softclips. This pull request updates the position calculation and adds a unit test to demonstrate the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6824
https://github.com/broadinstitute/gatk/issues/6825:345,Availability,down,downloaded,345,"I wanted to detect variants with HaplotypeCallerGATK version 4.1.1.0, i run the program twice with two reference.fa, and i got so different results. The content of this two reference.fa is same and they are in the same version of soybean (Gmax_275_v2.0.fa). The differences of this two reference.fa are as below:; 1.This two reference.fa were downloaded from different databases;; 2.the order of scaffold is different, one is in the number order (just like scaffold_1, scaffold_2, scaffold_ 3, scaffold_4...),and the other one is in the dictionary order(just like scaffold_1002, scaffold_1005, scaffold_101, scaffold_1010...);; 3.the coding method is different, one was coded with upper and lower letters (like ATGGccatgataGGTCaatgca), and the other one was coded only with upper words (like ATGGCCATGATAGGTCAATGCA). . I compared the coding bases of this two reference.fa, totally same, but when i run HaplotypeCaller with this two reference.fa, i got a very different result, so i am wondering, if results of HaplotypeCaller can be affected by the the scaffold order and the lower or upper letters in the reference.fa file?. ### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any qu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6825
https://github.com/broadinstitute/gatk/issues/6825:2434,Deployability,release,release,2434,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6825
https://github.com/broadinstitute/gatk/issues/6825:12,Safety,detect,detect,12,"I wanted to detect variants with HaplotypeCallerGATK version 4.1.1.0, i run the program twice with two reference.fa, and i got so different results. The content of this two reference.fa is same and they are in the same version of soybean (Gmax_275_v2.0.fa). The differences of this two reference.fa are as below:; 1.This two reference.fa were downloaded from different databases;; 2.the order of scaffold is different, one is in the number order (just like scaffold_1, scaffold_2, scaffold_ 3, scaffold_4...),and the other one is in the dictionary order(just like scaffold_1002, scaffold_1005, scaffold_101, scaffold_1010...);; 3.the coding method is different, one was coded with upper and lower letters (like ATGGccatgataGGTCaatgca), and the other one was coded only with upper words (like ATGGCCATGATAGGTCAATGCA). . I compared the coding bases of this two reference.fa, totally same, but when i run HaplotypeCaller with this two reference.fa, i got a very different result, so i am wondering, if results of HaplotypeCaller can be affected by the the scaffold order and the lower or upper letters in the reference.fa file?. ### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any qu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6825
https://github.com/broadinstitute/gatk/issues/6825:2504,Testability,test,test,2504,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6825
https://github.com/broadinstitute/gatk/issues/6825:2604,Testability,log,logs,2604,"gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6825
https://github.com/broadinstitute/gatk/issues/6828:33,Deployability,Pipeline,Pipeline,33,## Feature request. Mitochondria Pipeline. ### Description; Many of the users on Terra that work with the GATK workflows get stuck working with requester-pays data. (e.g. [forum post](https://gatk.broadinstitute.org/hc/en-us/community/posts/360067820111/comments/360011055131)). This request asks that the workflow include the requester pays option like the [pathseq](https://github.com/broadinstitute/gatk/blob/5e5747b76fa98a3b6731dbc328e292fa941f269b/scripts/pathseq/wdl/pathseq_pipeline.wdl#L83) workflow.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6828
https://github.com/broadinstitute/gatk/issues/6832:58,Integrability,message,messages,58,"I thought we resolved these in e.g. #5082, but I see some messages are still appearing in e.g. https://gatk.broadinstitute.org/hc/en-us/community/posts/360073249712-Sample-does-not-have-a-positive-sample-median-when-running-DenoiseReadCounts-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6832
https://github.com/broadinstitute/gatk/pull/6835:145,Availability,error,error,145,"This seems to be a simple typo. The minimal data to calculate the segmentation cost should be `2 * windowSize`, rather than `windowSize`, as the error message indicates. In the current logic, the segmentation cost at a particular point is calculated as the difference between the sum of costs of two windows to the left and right of that point and the cost of a big window of size `2 * windowSize`. If the # of the data points is less than the `2 * windowSize`, the cost for the full window will be wrong in the circular buffer representation; it will get the wrong cost of a window of size `2 * windowSize - data_size`, instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6835
https://github.com/broadinstitute/gatk/pull/6835:151,Integrability,message,message,151,"This seems to be a simple typo. The minimal data to calculate the segmentation cost should be `2 * windowSize`, rather than `windowSize`, as the error message indicates. In the current logic, the segmentation cost at a particular point is calculated as the difference between the sum of costs of two windows to the left and right of that point and the cost of a big window of size `2 * windowSize`. If the # of the data points is less than the `2 * windowSize`, the cost for the full window will be wrong in the circular buffer representation; it will get the wrong cost of a window of size `2 * windowSize - data_size`, instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6835
https://github.com/broadinstitute/gatk/pull/6835:185,Testability,log,logic,185,"This seems to be a simple typo. The minimal data to calculate the segmentation cost should be `2 * windowSize`, rather than `windowSize`, as the error message indicates. In the current logic, the segmentation cost at a particular point is calculated as the difference between the sum of costs of two windows to the left and right of that point and the cost of a big window of size `2 * windowSize`. If the # of the data points is less than the `2 * windowSize`, the cost for the full window will be wrong in the circular buffer representation; it will get the wrong cost of a window of size `2 * windowSize - data_size`, instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6835
https://github.com/broadinstitute/gatk/pull/6835:19,Usability,simpl,simple,19,"This seems to be a simple typo. The minimal data to calculate the segmentation cost should be `2 * windowSize`, rather than `windowSize`, as the error message indicates. In the current logic, the segmentation cost at a particular point is calculated as the difference between the sum of costs of two windows to the left and right of that point and the cost of a big window of size `2 * windowSize`. If the # of the data points is less than the `2 * windowSize`, the cost for the full window will be wrong in the circular buffer representation; it will get the wrong cost of a window of size `2 * windowSize - data_size`, instead.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6835
https://github.com/broadinstitute/gatk/issues/6836:135,Availability,error,error,135,"I'm trying to get the container/image from spacecade7/tutorial_11682_11683/ to use the copy number alteration tutorial.; The following error comes up on both my macbook, and on a linux system. . $ docker pull spacecade7/tutorial_11682_11683; Using default tag: latest; Error response from daemon: manifest for spacecade7/tutorial_11682_11683:latest not found: manifest unknown: manifest unknown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6836
https://github.com/broadinstitute/gatk/issues/6836:269,Availability,Error,Error,269,"I'm trying to get the container/image from spacecade7/tutorial_11682_11683/ to use the copy number alteration tutorial.; The following error comes up on both my macbook, and on a linux system. . $ docker pull spacecade7/tutorial_11682_11683; Using default tag: latest; Error response from daemon: manifest for spacecade7/tutorial_11682_11683:latest not found: manifest unknown: manifest unknown",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6836
https://github.com/broadinstitute/gatk/issues/6837:675,Availability,down,down,675,"We need a tool to compare multiple references and spit out a TSV (or similar) detailing what the differences are. Additionally it should be able to spit out a liftover file that will properly move a variant from one reference to another. We should first compare the sequence dictionaries in the references to see if they have equal lengths and checksums - the names may differ and we should track this so we can definitively say which contigs are equivalent. After this, we should walk the references and find out specifically which bases differ between contigs that have different checksums (with some limits on the number of differences between them so we don't get bogged down by `hg19` vs `hg38` comparisons). ; Then it should create a liftover file from those comparisons so the data can be easily converted between the references given. . Additionally, it should be able to take a variant file and a set of references and say:. - whether the variant file ""belongs"" to one of the given references; - if it isn't exactly from one of the given references, which reference is closest; - _optionally_: a lifted-over version of that VCF to the closest reference (with a bunch of warnings, if applicable). This will finally lay to rest the questions raised by [my blog post about ""HG19""](https://gatk.broadinstitute.org/hc/en-us/articles/360035890711). I believe Adam Phillipy had created a perl script that does something similar to this, but a brief view of his github page doesn't show anything like that anymore (maybe it was called `refdiff` or similar). I created a bash script that does something similar to this (see attached), but it only looks at the sequence dictionaries. It produces a table similar to that in the above blog post. For example:. |MD5 | HG38(Homo_sapiens_assembly38.dict) | HG38_WEIRD(genome.hg38rg.fa.dict)|; | --- | --- | --- |; |1e95e047b98ed92148dd84d6c037158c|chr1_KI270708v1_random|1_KI270708v1_random|; |42f7a452b8b769d051ad738ee9f00631|chr1_KI270714v1_random|1_KI270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837
https://github.com/broadinstitute/gatk/issues/6837:344,Security,checksum,checksums,344,"We need a tool to compare multiple references and spit out a TSV (or similar) detailing what the differences are. Additionally it should be able to spit out a liftover file that will properly move a variant from one reference to another. We should first compare the sequence dictionaries in the references to see if they have equal lengths and checksums - the names may differ and we should track this so we can definitively say which contigs are equivalent. After this, we should walk the references and find out specifically which bases differ between contigs that have different checksums (with some limits on the number of differences between them so we don't get bogged down by `hg19` vs `hg38` comparisons). ; Then it should create a liftover file from those comparisons so the data can be easily converted between the references given. . Additionally, it should be able to take a variant file and a set of references and say:. - whether the variant file ""belongs"" to one of the given references; - if it isn't exactly from one of the given references, which reference is closest; - _optionally_: a lifted-over version of that VCF to the closest reference (with a bunch of warnings, if applicable). This will finally lay to rest the questions raised by [my blog post about ""HG19""](https://gatk.broadinstitute.org/hc/en-us/articles/360035890711). I believe Adam Phillipy had created a perl script that does something similar to this, but a brief view of his github page doesn't show anything like that anymore (maybe it was called `refdiff` or similar). I created a bash script that does something similar to this (see attached), but it only looks at the sequence dictionaries. It produces a table similar to that in the above blog post. For example:. |MD5 | HG38(Homo_sapiens_assembly38.dict) | HG38_WEIRD(genome.hg38rg.fa.dict)|; | --- | --- | --- |; |1e95e047b98ed92148dd84d6c037158c|chr1_KI270708v1_random|1_KI270708v1_random|; |42f7a452b8b769d051ad738ee9f00631|chr1_KI270714v1_random|1_KI270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837
https://github.com/broadinstitute/gatk/issues/6837:582,Security,checksum,checksums,582,"We need a tool to compare multiple references and spit out a TSV (or similar) detailing what the differences are. Additionally it should be able to spit out a liftover file that will properly move a variant from one reference to another. We should first compare the sequence dictionaries in the references to see if they have equal lengths and checksums - the names may differ and we should track this so we can definitively say which contigs are equivalent. After this, we should walk the references and find out specifically which bases differ between contigs that have different checksums (with some limits on the number of differences between them so we don't get bogged down by `hg19` vs `hg38` comparisons). ; Then it should create a liftover file from those comparisons so the data can be easily converted between the references given. . Additionally, it should be able to take a variant file and a set of references and say:. - whether the variant file ""belongs"" to one of the given references; - if it isn't exactly from one of the given references, which reference is closest; - _optionally_: a lifted-over version of that VCF to the closest reference (with a bunch of warnings, if applicable). This will finally lay to rest the questions raised by [my blog post about ""HG19""](https://gatk.broadinstitute.org/hc/en-us/articles/360035890711). I believe Adam Phillipy had created a perl script that does something similar to this, but a brief view of his github page doesn't show anything like that anymore (maybe it was called `refdiff` or similar). I created a bash script that does something similar to this (see attached), but it only looks at the sequence dictionaries. It produces a table similar to that in the above blog post. For example:. |MD5 | HG38(Homo_sapiens_assembly38.dict) | HG38_WEIRD(genome.hg38rg.fa.dict)|; | --- | --- | --- |; |1e95e047b98ed92148dd84d6c037158c|chr1_KI270708v1_random|1_KI270708v1_random|; |42f7a452b8b769d051ad738ee9f00631|chr1_KI270714v1_random|1_KI270",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6837
https://github.com/broadinstitute/gatk/issues/6839:350,Availability,error,error,350,"## Feature request. ### Tool(s) or class(es) involved; GATK PrintReads. ### Description; - Currently, this tool appears to consider reads independently of their mate, therefore if one partner is filtered and the other is not the SAM flags for the remaining read will be incorrect (indeed resulting BAMs from this tool fail GATK ValidateSamReads with error MATE_NOT_FOUND). ; - Here is a flagstat of one of these BAMs produced from this tool (note that there are no singleton reads listed, but they actually present -- you can even see this in the read1 and read2 counts; these counts should be equal if there are no supplementary, secondary, and/or singleton reads):. ```; 179466279 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 179466279 + 0 mapped (100.00% : N/A); 179466279 + 0 paired in sequencing; 89740338 + 0 read1; 89725941 + 0 read2; 179466279 + 0 properly paired (100.00% : N/A); 179466279 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. - I have two suggestions:; - Add a `--remove-mates` option that would ensure that if one read in a pair does not pass the read filters, the read pair will be filtered.; - Alternatively, add an `--update-flags` option that would update the filtered-in mate's SAM flags to be technically correct (i.e. if the read's partner was filtered, remove the 0x1, 0x2, 0x8, 0x20, 0x40, and 0x80 flags if they were present)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839
https://github.com/broadinstitute/gatk/issues/6839:1322,Deployability,update,update-flags,1322,"## Feature request. ### Tool(s) or class(es) involved; GATK PrintReads. ### Description; - Currently, this tool appears to consider reads independently of their mate, therefore if one partner is filtered and the other is not the SAM flags for the remaining read will be incorrect (indeed resulting BAMs from this tool fail GATK ValidateSamReads with error MATE_NOT_FOUND). ; - Here is a flagstat of one of these BAMs produced from this tool (note that there are no singleton reads listed, but they actually present -- you can even see this in the read1 and read2 counts; these counts should be equal if there are no supplementary, secondary, and/or singleton reads):. ```; 179466279 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 179466279 + 0 mapped (100.00% : N/A); 179466279 + 0 paired in sequencing; 89740338 + 0 read1; 89725941 + 0 read2; 179466279 + 0 properly paired (100.00% : N/A); 179466279 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. - I have two suggestions:; - Add a `--remove-mates` option that would ensure that if one read in a pair does not pass the read filters, the read pair will be filtered.; - Alternatively, add an `--update-flags` option that would update the filtered-in mate's SAM flags to be technically correct (i.e. if the read's partner was filtered, remove the 0x1, 0x2, 0x8, 0x20, 0x40, and 0x80 flags if they were present)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839
https://github.com/broadinstitute/gatk/issues/6839:1354,Deployability,update,update,1354,"## Feature request. ### Tool(s) or class(es) involved; GATK PrintReads. ### Description; - Currently, this tool appears to consider reads independently of their mate, therefore if one partner is filtered and the other is not the SAM flags for the remaining read will be incorrect (indeed resulting BAMs from this tool fail GATK ValidateSamReads with error MATE_NOT_FOUND). ; - Here is a flagstat of one of these BAMs produced from this tool (note that there are no singleton reads listed, but they actually present -- you can even see this in the read1 and read2 counts; these counts should be equal if there are no supplementary, secondary, and/or singleton reads):. ```; 179466279 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 179466279 + 0 mapped (100.00% : N/A); 179466279 + 0 paired in sequencing; 89740338 + 0 read1; 89725941 + 0 read2; 179466279 + 0 properly paired (100.00% : N/A); 179466279 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. - I have two suggestions:; - Add a `--remove-mates` option that would ensure that if one read in a pair does not pass the read filters, the read pair will be filtered.; - Alternatively, add an `--update-flags` option that would update the filtered-in mate's SAM flags to be technically correct (i.e. if the read's partner was filtered, remove the 0x1, 0x2, 0x8, 0x20, 0x40, and 0x80 flags if they were present)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839
https://github.com/broadinstitute/gatk/issues/6839:328,Security,Validat,ValidateSamReads,328,"## Feature request. ### Tool(s) or class(es) involved; GATK PrintReads. ### Description; - Currently, this tool appears to consider reads independently of their mate, therefore if one partner is filtered and the other is not the SAM flags for the remaining read will be incorrect (indeed resulting BAMs from this tool fail GATK ValidateSamReads with error MATE_NOT_FOUND). ; - Here is a flagstat of one of these BAMs produced from this tool (note that there are no singleton reads listed, but they actually present -- you can even see this in the read1 and read2 counts; these counts should be equal if there are no supplementary, secondary, and/or singleton reads):. ```; 179466279 + 0 in total (QC-passed reads + QC-failed reads); 0 + 0 secondary; 0 + 0 supplementary; 0 + 0 duplicates; 179466279 + 0 mapped (100.00% : N/A); 179466279 + 0 paired in sequencing; 89740338 + 0 read1; 89725941 + 0 read2; 179466279 + 0 properly paired (100.00% : N/A); 179466279 + 0 with itself and mate mapped; 0 + 0 singletons (0.00% : N/A); 0 + 0 with mate mapped to a different chr; 0 + 0 with mate mapped to a different chr (mapQ>=5); ```. - I have two suggestions:; - Add a `--remove-mates` option that would ensure that if one read in a pair does not pass the read filters, the read pair will be filtered.; - Alternatively, add an `--update-flags` option that would update the filtered-in mate's SAM flags to be technically correct (i.e. if the read's partner was filtered, remove the 0x1, 0x2, 0x8, 0x20, 0x40, and 0x80 flags if they were present)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6839
https://github.com/broadinstitute/gatk/issues/6845:671,Security,confidential,confidentially,671,"I have four phased variants in close proximity that have the following pattern:. ```; chrA 10 ... GT:PS 0|1:1; chrA 20 ... GT:PS 0|1:2; chrA 30 ... GT:PS 0|1:1; chrA 40 ... GT:PS 0|1:2; ```. These four variants are wholly contained in a single set of reads. There are of course other reads that partially span them. The first variant is a deletion, while the remaining three are SNVs.; Examining the reads, there are two haplotypes since:; 1. Alternate for the 1st and 3rd read; 2. Alternate for the 2nd and 4th read. I would have expected them all to have the same phase set (`PS`) value. I have a test case I can share privately (let me know a good email to send it to confidentially).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6845
https://github.com/broadinstitute/gatk/issues/6845:599,Testability,test,test,599,"I have four phased variants in close proximity that have the following pattern:. ```; chrA 10 ... GT:PS 0|1:1; chrA 20 ... GT:PS 0|1:2; chrA 30 ... GT:PS 0|1:1; chrA 40 ... GT:PS 0|1:2; ```. These four variants are wholly contained in a single set of reads. There are of course other reads that partially span them. The first variant is a deletion, while the remaining three are SNVs.; Examining the reads, there are two haplotypes since:; 1. Alternate for the 1st and 3rd read; 2. Alternate for the 2nd and 4th read. I would have expected them all to have the same phase set (`PS`) value. I have a test case I can share privately (let me know a good email to send it to confidentially).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6845
https://github.com/broadinstitute/gatk/issues/6846:240,Availability,avail,available,240,"hello; I can find ""Difference between QUAL and GQ annotations in germline variant calling"" on GATK web,but can't find how to calculate it. ; And I can find on **https://www.biostars.org/p/174075/** QUAL **is related to** the amount of data available (=depth of coverage at the site) (because we are more confident when we have more observations to rely on), the quality of the mapping of the reads and alignment of the bases (because if we are not sure the bases observed really belong there, they do not contribute much to our confidence), and the quality of the base calls (because if they look like machine errors, they also do not contribute much to our confidence),so the answer is right?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6846
https://github.com/broadinstitute/gatk/issues/6846:610,Availability,error,errors,610,"hello; I can find ""Difference between QUAL and GQ annotations in germline variant calling"" on GATK web,but can't find how to calculate it. ; And I can find on **https://www.biostars.org/p/174075/** QUAL **is related to** the amount of data available (=depth of coverage at the site) (because we are more confident when we have more observations to rely on), the quality of the mapping of the reads and alignment of the bases (because if we are not sure the bases observed really belong there, they do not contribute much to our confidence), and the quality of the base calls (because if they look like machine errors, they also do not contribute much to our confidence),so the answer is right?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6846
https://github.com/broadinstitute/gatk/pull/6847:69,Testability,test,tests,69,revert code back to previous code that did not throw NPE. Add 2 unit tests to guard against this.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6847
https://github.com/broadinstitute/gatk/pull/6848:53,Testability,test,test,53,"The docs claim that the HWE in htsjdk is a two-sided test, so this is actually what we want for arrays.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6848
https://github.com/broadinstitute/gatk/issues/6849:49,Integrability,depend,depends,49,GenomicsDBImport also has to be changed since it depends on some code in FixCallsetSampleOrdering,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6849
https://github.com/broadinstitute/gatk/issues/6850:293,Availability,error,error,293,"## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls and possibly Mutect2. ### Affected version(s); GATK 4.1.7.0, still occurs in 4.1.8.1. ### Description ; User running Mutect2 in mitochondrial mode and ERC BP_RESOLUTION. Mutect2 is successful, however filter mutect calls has error message; `java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN`. Possible similar issue: #6202 ; Complete stack trace:. ```; Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx22G -Djava.io.tmpdir=/nobackup/lnsingh/MTRNA/tmp -jar /nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar FilterMutectCalls --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityNotZeroReadFilter --disable-read-filter MappingQualityAvailableReadFilter --mitochondria-mode true -R /nobackup/lnsingh/MTRNA/lib/rCRS.fa -V /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz -L MT -O /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.filtered.gvcf.gz. 07:33:14.927 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityNotZeroReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:4281,Availability,down,down,4281,"s.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 07:33:15.362 INFO FilterMutectCalls - Deflater: IntelDeflater. 07:33:15.362 INFO FilterMutectCalls - Inflater: IntelInflater. 07:33:15.363 INFO FilterMutectCalls - GCS max retries/reopens: 20. 07:33:15.363 INFO FilterMutectCalls - Requester pays: disabled. 07:33:15.363 INFO FilterMutectCalls - Initializing engine. 07:33:16.008 INFO FeatureManager - Using codec VCFCodec to read file file:///nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz. 07:33:16.053 INFO IntervalArgumentCollection - Processing 16569 bp from intervals. 07:33:16.059 INFO FilterMutectCalls - Done initializing engine. 07:33:16.157 INFO ProgressMeter - Starting traversal. 07:33:16.157 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. 07:33:16.158 INFO FilterMutectCalls - Starting pass 0 through the variants. 07:33:17.341 INFO FilterMutectCalls - Finished pass 0 through the variants. 07:33:17.404 INFO FilterMutectCalls - Shutting down engine. [September 20, 2020 7:33:17 AM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:2519,Deployability,release,release-,2519,"r (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 07:33:15.360 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.361 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.7.0. 07:33:15.361 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/. 07:33:15.361 INFO FilterMutectCalls - Executing as lnsingh@pfe26 on Linux v4.12.14-122.23.1.20200609-nasa amd64. 07:33:15.361 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12. 07:33:15.361 INFO FilterMutectCalls - Start Date/Time: September 20, 2020 7:33:14 AM PDT. 07:33:15.361 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.361 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Version: 2.21.2. 07:33:15.362 INFO FilterMutectCalls - Picard Version: 2.21.9. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false. 07:33:15.362 INFO FilterMutectCalls - Deflater: IntelDeflater. 07:33:15.362 INFO FilterMutectCalls - Inflater: IntelInflater. 07:33:15.363 INFO FilterMutectCalls - GCS max retries/reopens: 20. 07:33:15.363 INFO Filt",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:299,Integrability,message,message,299,"## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls and possibly Mutect2. ### Affected version(s); GATK 4.1.7.0, still occurs in 4.1.8.1. ### Description ; User running Mutect2 in mitochondrial mode and ERC BP_RESOLUTION. Mutect2 is successful, however filter mutect calls has error message; `java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN`. Possible similar issue: #6202 ; Complete stack trace:. ```; Running:. java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx22G -Djava.io.tmpdir=/nobackup/lnsingh/MTRNA/tmp -jar /nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar FilterMutectCalls --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityNotZeroReadFilter --disable-read-filter MappingQualityAvailableReadFilter --mitochondria-mode true -R /nobackup/lnsingh/MTRNA/lib/rCRS.fa -V /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz -L MT -O /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.filtered.gvcf.gz. 07:33:14.927 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityNotZeroReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:1631,Performance,Load,Loading,1631,"ava.io.tmpdir=/nobackup/lnsingh/MTRNA/tmp -jar /nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar FilterMutectCalls --disable-read-filter MappingQualityReadFilter --disable-read-filter MappingQualityNotZeroReadFilter --disable-read-filter MappingQualityAvailableReadFilter --mitochondria-mode true -R /nobackup/lnsingh/MTRNA/lib/rCRS.fa -V /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz -L MT -O /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.filtered.gvcf.gz. 07:33:14.927 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityNotZeroReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 07:33:15.360 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.361 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.7.0. 07:33:15.361 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/. 07:33:15.361 INFO FilterMutectCalls - Executing as lnsingh@pfe26 on Linux v4.12.14-122.23.1.20200609-nasa amd64. 07:33:15.361 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12. 07:33:15.361 INFO FilterMutectCalls - Start Date/Time: September 20, 2020 7:33:14 AM PDT. 07",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:1962,Safety,detect,detect,1962,"de true -R /nobackup/lnsingh/MTRNA/lib/rCRS.fa -V /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz -L MT -O /nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.filtered.gvcf.gz. 07:33:14.927 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityNotZeroReadFilter) is not enabled by this tool. 07:33:14.928 WARN GATKReadFilterPluginDescriptor - Disabled filter (MappingQualityAvailableReadFilter) is not enabled by this tool. 07:33:15.003 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/nobackupp16/swbuild/hsp/COVID19/anaconda3/envs/COVIRT_GATK/share/gatk4-4.1.7.0-0/gatk-package-4.1.7.0-local.jar!/com/intel/gkl/native/libgkl_compression.so. Sep 20, 2020 7:33:15 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine. INFO: Failed to detect whether we are running on Google Compute Engine. 07:33:15.360 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.361 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.7.0. 07:33:15.361 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/. 07:33:15.361 INFO FilterMutectCalls - Executing as lnsingh@pfe26 on Linux v4.12.14-122.23.1.20200609-nasa amd64. 07:33:15.361 INFO FilterMutectCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12. 07:33:15.361 INFO FilterMutectCalls - Start Date/Time: September 20, 2020 7:33:14 AM PDT. 07:33:15.361 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.361 INFO FilterMutectCalls - ------------------------------------------------------------. 07:33:15.362 INFO FilterMutectCalls - HTSJDK Version: 2.21.2. 07:33:15.362 INFO FilterMutectCalls - Picard Version: 2.21.9. 07:33:15.362 INFO FilterMutect",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:4600,Security,validat,validateArg,4600,"ializing engine. 07:33:16.008 INFO FeatureManager - Using codec VCFCodec to read file file:///nobackup/lnsingh/MTRNA/out/COVSUBJ_0121_1_N_HA_filtered.humanspliced.gvcf.gz. 07:33:16.053 INFO IntervalArgumentCollection - Processing 16569 bp from intervals. 07:33:16.059 INFO FilterMutectCalls - Done initializing engine. 07:33:16.157 INFO ProgressMeter - Starting traversal. 07:33:16.157 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute. 07:33:16.158 INFO FilterMutectCalls - Starting pass 0 through the variants. 07:33:17.341 INFO FilterMutectCalls - Finished pass 0 through the variants. 07:33:17.404 INFO FilterMutectCalls - Shutting down engine. [September 20, 2020 7:33:17 AM PDT] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(Filte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:5309,Usability,learn,learnAndClearAccumulatedData,5309,roadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165). at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206). at org.broadinstitute.hellbender.Main.main(Main.java:292),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6850:5459,Usability,learn,learnParameters,5459,nstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.04 minutes. Runtime.totalMemory()=1256194048. java.lang.IllegalArgumentException: alpha must be greater than 0 but got NaN. at org.broadinstitute.hellbender.utils.Utils.validateArg(Utils.java:727). at org.broadinstitute.hellbender.utils.param.ParamUtils.isPositive(ParamUtils.java:165). at org.broadinstitute.hellbender.tools.walkers.readorientation.BetaDistributionShape.<init>(BetaDistributionShape.java:13). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.getFuzzyBinomial(BinomialCluster.java:43). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.BinomialCluster.<init>(BinomialCluster.java:17). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.initializeClusters(SomaticClusteringModel.java:184). at org.broadinstitute.hellbender.tools.walkers.mutect.clustering.SomaticClusteringModel.learnAndClearAccumulatedData(SomaticClusteringModel.java:325). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.learnParameters(Mutect2FilteringEngine.java:153). at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.afterNthPass(FilterMutectCalls.java:165). at org.broadinstitute.hellbender.engine.MultiplePassVariantWalker.traverse(MultiplePassVariantWalker.java:44). at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1048). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191). at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210). at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163). at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206). at org.broadinstitute.hellbender.Main.main(Main.java:292); ```,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6850
https://github.com/broadinstitute/gatk/issues/6851:403,Availability,error,error,403,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); 4.1.8.1. ### Description ; A user is getting a java.lang.NullPointerException when running Mutect2. As discussed at GATK Office Hours 09/28/20, it seems to be an issue where the BAM contigs are not present in the reference sequence dictionary. We discussed an improvement with either the filter for this problem or the error message. Complete stack trace:; ```; Using GATK jar GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -jar /GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar Mutect2 -R ref/Homo_sapiens_assembly38.fasta -I SRR_MM10_2pass_recal.bam --germline-resource /af-only-gnomad.hg38.vcf.gz --panel-of-normals ref/1000g_pon.hg38.vcf.gz -O SRR_somatic_mutect.vcf.gz; 13:24:08.400 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 25, 2020 1:24:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:24:08.556 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:24:08.557 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:24:08.557 INFO Mutect2 - Executing as xxx on Linux v3.10.0-1127.18.2.el7.x86_64 amd64; 13:24:08.557 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_192-b12; 13:24:08.557 INFO Mutect2 - Start Date/Time: September 25, 2020 1:24:08 PM BST; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:3601,Availability,Avail,Available,3601,":08.558 INFO Mutect2 - GCS max retries/reopens: 20; 13:24:08.558 INFO Mutect2 - Requester pays: disabled; 13:24:08.558 INFO Mutect2 - Initializing engine; 13:24:09.048 INFO FeatureManager - Using codec VCFCodec to read file file://ref/1000g_pon.hg38.vcf.gz; 13:24:09.207 INFO FeatureManager - Using codec VCFCodec to read file file://ref/af-only-gnomad.hg38.vcf.gz; 13:24:09.374 INFO Mutect2 - Done initializing engine; 13:24:09.435 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 13:24:09.438 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 13:24:09.472 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1047.646162184; 15:29:08.986 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1077.35 sec; 15:29:08.986 INFO Mutect2 - Shutting down engine; [September 25, 2020 3:29:08 PM BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 125.01 ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:4470,Availability,down,down,4470,"13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1047.646162184; 15:29:08.986 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1077.35 sec; 15:29:08.986 INFO Mutect2 - Shutting down engine; [September 25, 2020 3:29:08 PM BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 125.01 minutes.; Runtime.totalMemory()=7713325056; java.lang.NullPointerException; at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:98); at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:49); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:72); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceTo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:5667,Availability,down,downsampling,5667,eption; at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:98); at org.broadinstitute.hellbender.transformers.PalindromeArtifactClipReadTransformer.apply(PalindromeArtifactClipReadTransformer.java:49); at org.broadinstitute.hellbender.transformers.ReadTransformer.lambda$andThen$f85d1091$1(ReadTransformer.java:20); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:42); at org.broadinstitute.hellbender.utils.iterators.ReadTransformingIterator.next(ReadTransformingIterator.java:14); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.fillCache(PushToPullIterator.java:72); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.advanceToNextElement(PushToPullIterator.java:58); at org.broadinstitute.hellbender.utils.iterators.PushToPullIterator.<init>(PushToPullIterator.java:37); at org.broadinstitute.hellbender.utils.downsampling.ReadsDownsamplingIterator.<init>(ReadsDownsamplingIterator.java:21); at org.broadinstitute.hellbender.engine.MultiIntervalLocalReadShard.iterator(MultiIntervalLocalReadShard.java:149); at org.broadinstitute.hellbender.engine.AssemblyRegionIterator.<init>(AssemblyRegionIterator.java:86); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.processReadShard(AssemblyRegionWalker.java:188); at org.broadinstitute.hellbender.engine.AssemblyRegionWalker.traverse(AssemblyRegionWalker.java:173); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.he,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:409,Integrability,message,message,409,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); 4.1.8.1. ### Description ; A user is getting a java.lang.NullPointerException when running Mutect2. As discussed at GATK Office Hours 09/28/20, it seems to be an issue where the BAM contigs are not present in the reference sequence dictionary. We discussed an improvement with either the filter for this problem or the error message. Complete stack trace:; ```; Using GATK jar GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -jar /GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar Mutect2 -R ref/Homo_sapiens_assembly38.fasta -I SRR_MM10_2pass_recal.bam --germline-resource /af-only-gnomad.hg38.vcf.gz --panel-of-normals ref/1000g_pon.hg38.vcf.gz -O SRR_somatic_mutect.vcf.gz; 13:24:08.400 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 25, 2020 1:24:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:24:08.556 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:24:08.557 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:24:08.557 INFO Mutect2 - Executing as xxx on Linux v3.10.0-1127.18.2.el7.x86_64 amd64; 13:24:08.557 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_192-b12; 13:24:08.557 INFO Mutect2 - Start Date/Time: September 25, 2020 1:24:08 PM BST; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:1016,Performance,Load,Loading,1016," ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); 4.1.8.1. ### Description ; A user is getting a java.lang.NullPointerException when running Mutect2. As discussed at GATK Office Hours 09/28/20, it seems to be an issue where the BAM contigs are not present in the reference sequence dictionary. We discussed an improvement with either the filter for this problem or the error message. Complete stack trace:; ```; Using GATK jar GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -jar /GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar Mutect2 -R ref/Homo_sapiens_assembly38.fasta -I SRR_MM10_2pass_recal.bam --germline-resource /af-only-gnomad.hg38.vcf.gz --panel-of-normals ref/1000g_pon.hg38.vcf.gz -O SRR_somatic_mutect.vcf.gz; 13:24:08.400 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 25, 2020 1:24:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:24:08.556 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:24:08.557 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:24:08.557 INFO Mutect2 - Executing as xxx on Linux v3.10.0-1127.18.2.el7.x86_64 amd64; 13:24:08.557 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_192-b12; 13:24:08.557 INFO Mutect2 - Start Date/Time: September 25, 2020 1:24:08 PM BST; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - -----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:3065,Performance,Load,Loading,3065,---------; 13:24:08.557 INFO Mutect2 - HTSJDK Version: 2.23.0; 13:24:08.557 INFO Mutect2 - Picard Version: 2.22.8; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:24:08.558 INFO Mutect2 - Deflater: IntelDeflater; 13:24:08.558 INFO Mutect2 - Inflater: IntelInflater; 13:24:08.558 INFO Mutect2 - GCS max retries/reopens: 20; 13:24:08.558 INFO Mutect2 - Requester pays: disabled; 13:24:08.558 INFO Mutect2 - Initializing engine; 13:24:09.048 INFO FeatureManager - Using codec VCFCodec to read file file://ref/1000g_pon.hg38.vcf.gz; 13:24:09.207 INFO FeatureManager - Using codec VCFCodec to read file file://ref/af-only-gnomad.hg38.vcf.gz; 13:24:09.374 INFO Mutect2 - Done initializing engine; 13:24:09.435 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 13:24:09.438 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 13:24:09.472 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:3250,Performance,Load,Loading,3250,08.558 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:24:08.558 INFO Mutect2 - Deflater: IntelDeflater; 13:24:08.558 INFO Mutect2 - Inflater: IntelInflater; 13:24:08.558 INFO Mutect2 - GCS max retries/reopens: 20; 13:24:08.558 INFO Mutect2 - Requester pays: disabled; 13:24:08.558 INFO Mutect2 - Initializing engine; 13:24:09.048 INFO FeatureManager - Using codec VCFCodec to read file file://ref/1000g_pon.hg38.vcf.gz; 13:24:09.207 INFO FeatureManager - Using codec VCFCodec to read file file://ref/af-only-gnomad.hg38.vcf.gz; 13:24:09.374 INFO Mutect2 - Done initializing engine; 13:24:09.435 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 13:24:09.438 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 13:24:09.472 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:3724,Performance,multi-thread,multi-threaded,3724,"itializing engine; 13:24:09.048 INFO FeatureManager - Using codec VCFCodec to read file file://ref/1000g_pon.hg38.vcf.gz; 13:24:09.207 INFO FeatureManager - Using codec VCFCodec to read file file://ref/af-only-gnomad.hg38.vcf.gz; 13:24:09.374 INFO Mutect2 - Done initializing engine; 13:24:09.435 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 13:24:09.438 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 13:24:09.472 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 13:24:09.472 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 13:24:09.473 INFO IntelPairHmm - Available threads: 24; 13:24:09.473 INFO IntelPairHmm - Requested threads: 4; 13:24:09.473 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 13:24:09.501 INFO ProgressMeter - Starting traversal; 13:24:09.502 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 13:24:19.721 INFO ProgressMeter - chr1:634040 0.2 2460 14443.7; 13:24:29.736 INFO ProgressMeter - chr1:1564703 0.3 7220 21409.5; .; .; .; 15:28:55.286 INFO ProgressMeter - chrM:12891 124.8 11474080 91967.0; 15:29:08.985 INFO VectorLoglessPairHMM - Time spent in setup for JNI call : 10.162159898; 15:29:08.986 INFO PairHMM - Total compute time in PairHMM computeLogLikelihoods() : 1047.646162184; 15:29:08.986 INFO SmithWatermanAligner - Total compute time in java Smith-Waterman : 1077.35 sec; 15:29:08.986 INFO Mutect2 - Shutting down engine; [September 25, 2020 3:29:08 PM BST] org.broadinstitute.hellbender.tools.walkers.mutect.Mutect2 done. Elapsed time: 125.01 minutes.; Runtime.totalMemory()=7713325056; java.lang.NullPointerException; at org.broadinstitute.hellbender.transformers.PalindromeArtif",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/issues/6851:1302,Safety,detect,detect,1302,"reference sequence dictionary. We discussed an improvement with either the filter for this problem or the error message. Complete stack trace:; ```; Using GATK jar GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx16g -jar /GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar Mutect2 -R ref/Homo_sapiens_assembly38.fasta -I SRR_MM10_2pass_recal.bam --germline-resource /af-only-gnomad.hg38.vcf.gz --panel-of-normals ref/1000g_pon.hg38.vcf.gz -O SRR_somatic_mutect.vcf.gz; 13:24:08.400 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/GATK/4.1.8.1-GCCcore-9.3.0-Java-1.8/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Sep 25, 2020 1:24:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:24:08.556 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:24:08.557 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:24:08.557 INFO Mutect2 - Executing as xxx on Linux v3.10.0-1127.18.2.el7.x86_64 amd64; 13:24:08.557 INFO Mutect2 - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_192-b12; 13:24:08.557 INFO Mutect2 - Start Date/Time: September 25, 2020 1:24:08 PM BST; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - ------------------------------------------------------------; 13:24:08.557 INFO Mutect2 - HTSJDK Version: 2.23.0; 13:24:08.557 INFO Mutect2 - Picard Version: 2.22.8; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:24:08.558 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6851
https://github.com/broadinstitute/gatk/pull/6852:141,Deployability,release,release,141,This was an issue with propagating polymorphic std::exception code from the native library's logger utility and has been fixed in the [1.3.2 release ](https://mvnrepository.com/artifact/org.genomicsdb/genomicsdb/1.3.2) of the GenomicsDB library. Also note that using java option `GATK_STACKTRACE_ON_USER_EXCEPTION` with gatk will also output a C/C++ limited stacktrace as requested by @lbergelson.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6852
https://github.com/broadinstitute/gatk/pull/6852:35,Modifiability,polymorphi,polymorphic,35,This was an issue with propagating polymorphic std::exception code from the native library's logger utility and has been fixed in the [1.3.2 release ](https://mvnrepository.com/artifact/org.genomicsdb/genomicsdb/1.3.2) of the GenomicsDB library. Also note that using java option `GATK_STACKTRACE_ON_USER_EXCEPTION` with gatk will also output a C/C++ limited stacktrace as requested by @lbergelson.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6852
https://github.com/broadinstitute/gatk/pull/6852:93,Testability,log,logger,93,This was an issue with propagating polymorphic std::exception code from the native library's logger utility and has been fixed in the [1.3.2 release ](https://mvnrepository.com/artifact/org.genomicsdb/genomicsdb/1.3.2) of the GenomicsDB library. Also note that using java option `GATK_STACKTRACE_ON_USER_EXCEPTION` with gatk will also output a C/C++ limited stacktrace as requested by @lbergelson.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6852
https://github.com/broadinstitute/gatk/issues/6853:381,Deployability,integrat,integration,381,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:381,Integrability,integrat,integration,381,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:39,Testability,test,test,39,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:88,Testability,test,test,88,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:113,Testability,test,test,113,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:182,Testability,test,test,182,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:247,Testability,test,test,247,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:393,Testability,test,test,393,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:424,Testability,test,test,424,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6853:431,Testability,test,tests,431,The README suggests that. >You can use test.single when you just want to run a specific test class:; >`./gradlew test -Dtest.single=SomeSpecificTestClass`. But when I run `./gradlew test -Dtest.single=HaplotypeCallerIntegrationTest` or `./gradlew test -Dtest.single=org.broadinstitute.hellbender.tools.walkers.haplotypecaller.HaplotypeCallerIntegrationTest` gradle runs the entire integration test suite. Running `./gradlew test --tests *HaplotypeCallerIntegrationTest` does produce the desired result of running just `HaplotypeCallerIntegrationTest`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6853
https://github.com/broadinstitute/gatk/issues/6855:766,Availability,ERROR,ERROR,766,"## Feature request. ### Tool(s) or class(es) involved; _GATK VariantEval_. ### Description; Currently, if I provide a VCF to VariantEval together with a dbSNP file, but the input VCF does not variants on all chromosomes or contigs from the dbSNP, the tool will fail. ; The current solution is to always check the input VCF for all chromosomes/contigs where mutations exist, and then filter the dbSNP file to keep only the entries with those some chromosomes. ; Would it be possible to allow for the use of a full dbSNP file with GATK VariantEval, regardless of whether the input VCF has variants on all chromosomes that exist in the dbSNP or not?. More info on a forum post as well: ; https://gatk.broadinstitute.org/hc/en-us/community/posts/360072397571-VariatEval-ERROR-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6855
https://github.com/broadinstitute/gatk/pull/6856:8,Deployability,update,updates,8,"This PR updates the `--use-posteriors-to-calculate-qual` mode to properly treat the star allele as a non-variant (for that site) allele. With this change, if a spanning deletion is present, it is treated as a non-variant allele for that site, and the posterior of no variant allele being present becomes the sum of the posteriors of all genotypes composed of combinations of the reference allele and the star allele.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6856
https://github.com/broadinstitute/gatk/issues/6857:86,Deployability,release,release,86,"## Bug Report. ### Affected tool; Mutect2. ### Affected versions; - [x] Latest public release version 4.1.8.1; - [x] Latest master branch as of 9/20/2020. ### Description ; Mutect2s header defines `AS_FilterStatus` as follows:; ```text; ##INFO=<ID=AS_FilterStatus,Number=A,Type=String,Description=""Filter status for each allele, as assessed by ApplyRecalibration. Note that the VCF filter field will reflect the most lenient/sensitive status across all alleles."">; ```. `AS_FilterStatus` uses the pipe character `|` for per-allele concatenation and a comma `,` for filter concatenation. This causes records to have an incorrect number of values at sites with multiple filters or multiple alleles. Some examples:; ```text; chr1 826950 . G T . clustered_events;contamination;map_qual;strand_bias AS_FilterStatus=map_qual,strand_bias,contamination;AS_SB_TABLE=86,101|7,0;DP=199;ECNT=3;GERMQ=93;MBQ=35,34;MFRL=193,211;MMQ=33,27;MPOS=6;NALOD=1.28;NLOD=5.42;POPAF=1.39;ROQ=80;TLOD=8.79 GT:AD:AF:DP:F1R2:F2R1:SB 0/0:36,0:0.05:36:18,0:18,0:24,12,0,0 0/1:151,7:0.055:158:76,4:71,3:62,89,7,0; chr1 3633298 . GT G,GTT . contamination;multiallelic;normal_artifact;slippage;weak_evidence AS_FilterStatus=weak_evidence,contamination|weak_evidence,contamination;AS_SB_TABLE=89,7|7,0|7,0;DP=129;ECNT=1;GERMQ=67;MBQ=20,20,20;MFRL=0,0,0;MMQ=60,60,60;MPOS=17,31;NALOD=-0.2424,0.21;NLOD=6.4,6.36;POPAF=2.49,2.04;ROQ=93;RPA=11,10,12;RU=T;STR;STRQ=1;TLOD=3.04,4.6 GT:AD:AF:DP:F1R2:F2R1:SB 0/0:58,4,4:0.072,0.069:66:28,2,2:28,2,2:54,4,8,0 0/1/2:38,3,3:0.083,0.084:44:21,1,3:15,2,0:35,3,6,0; ```. A quick fix would be to define `Number=1` for `AS_FilterStatus` in the VCF header. Alternatively, using a pipe for filter concatenation and a comma for per-allele concatenation might be more compliant with the VCF specification.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6857
https://github.com/broadinstitute/gatk/pull/6859:373,Availability,error,error,373,"This fixes a bug in the `AlleleFrequencyCalculator` that was causing quality to be overestimated for sites with `*` alleles representing spanning deletions. The bug was causing the calculator to not include homozygous `*` genotypes in the sum of non-site specific variant allele probabilities that is the basis for the qual score. The bug was caused by an off-by-one index error: `IndexRange(0,2)` returns `[0,1]`, not `[0,1,2]` as intended. Not including this genotype inflated the quality score for these sites. . Due to interactions with QUAL-based variant and allele trimming, this causes slightly different behavior when HaplotyeCaller is run in modes where it is forced to emit variants for every locus, as can be seen in the `expected/gvcf.basepairResolution.includeNonVariantSites.vcf` test file for `GenotypeGVCFsIntegrationTest`: 1) Sites spanned by a deletion are now reported with a `*` alt allele and have QUAL 0 and a LowQual filter. Also added a mechanism to `GenotypeGCVFsIntegrationTest` to automatically update the expected result files, similar to what already exists in `HaplotypeCallerIntegrationTest` and `CombineGVCFsIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6859
https://github.com/broadinstitute/gatk/pull/6859:1022,Deployability,update,update,1022,"This fixes a bug in the `AlleleFrequencyCalculator` that was causing quality to be overestimated for sites with `*` alleles representing spanning deletions. The bug was causing the calculator to not include homozygous `*` genotypes in the sum of non-site specific variant allele probabilities that is the basis for the qual score. The bug was caused by an off-by-one index error: `IndexRange(0,2)` returns `[0,1]`, not `[0,1,2]` as intended. Not including this genotype inflated the quality score for these sites. . Due to interactions with QUAL-based variant and allele trimming, this causes slightly different behavior when HaplotyeCaller is run in modes where it is forced to emit variants for every locus, as can be seen in the `expected/gvcf.basepairResolution.includeNonVariantSites.vcf` test file for `GenotypeGVCFsIntegrationTest`: 1) Sites spanned by a deletion are now reported with a `*` alt allele and have QUAL 0 and a LowQual filter. Also added a mechanism to `GenotypeGCVFsIntegrationTest` to automatically update the expected result files, similar to what already exists in `HaplotypeCallerIntegrationTest` and `CombineGVCFsIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6859
https://github.com/broadinstitute/gatk/pull/6859:794,Testability,test,test,794,"This fixes a bug in the `AlleleFrequencyCalculator` that was causing quality to be overestimated for sites with `*` alleles representing spanning deletions. The bug was causing the calculator to not include homozygous `*` genotypes in the sum of non-site specific variant allele probabilities that is the basis for the qual score. The bug was caused by an off-by-one index error: `IndexRange(0,2)` returns `[0,1]`, not `[0,1,2]` as intended. Not including this genotype inflated the quality score for these sites. . Due to interactions with QUAL-based variant and allele trimming, this causes slightly different behavior when HaplotyeCaller is run in modes where it is forced to emit variants for every locus, as can be seen in the `expected/gvcf.basepairResolution.includeNonVariantSites.vcf` test file for `GenotypeGVCFsIntegrationTest`: 1) Sites spanned by a deletion are now reported with a `*` alt allele and have QUAL 0 and a LowQual filter. Also added a mechanism to `GenotypeGCVFsIntegrationTest` to automatically update the expected result files, similar to what already exists in `HaplotypeCallerIntegrationTest` and `CombineGVCFsIntegrationTest`.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6859
https://github.com/broadinstitute/gatk/pull/6860:429,Deployability,pipeline,pipeline,429,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860
https://github.com/broadinstitute/gatk/pull/6860:88,Testability,test,test,88,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860
https://github.com/broadinstitute/gatk/pull/6860:98,Testability,test,test,98,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860
https://github.com/broadinstitute/gatk/pull/6860:355,Testability,test,test,355,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860
https://github.com/broadinstitute/gatk/pull/6860:448,Testability,test,testing,448,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860
https://github.com/broadinstitute/gatk/pull/6860:505,Usability,feedback,feedback,505,"I moved the WDL for importing the array manifest from the variantstore repo and added a test. The test here only checks that the WDL succeeded, it doesn't look a the results (yet). It's ingesting the manifest to a dataset with a 7 day TTL, so the tables eventually get cleaned up. That might be too long for this case, since it adds a table each time the test is run (so on push and PR). . I plan to add more of the ""end-to-end"" pipeline with more testing in the future using a similar scheme, so welcome feedback on the structure.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6860
https://github.com/broadinstitute/gatk/pull/6861:26,Testability,test,test,26,@droazen Here's the other test.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6861
https://github.com/broadinstitute/gatk/issues/6862:192,Deployability,update,update,192,## Documentation request. ### Tool(s) or class(es) involved; LearnReadOrientationModel. ### Description ; The tool LearnReadOrientationModel does not appear in the tool docs. We would like to update the documentation for this tool so that it is included with the other tool docs when GATK is updated and is more visible to users.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6862
https://github.com/broadinstitute/gatk/issues/6862:292,Deployability,update,updated,292,## Documentation request. ### Tool(s) or class(es) involved; LearnReadOrientationModel. ### Description ; The tool LearnReadOrientationModel does not appear in the tool docs. We would like to update the documentation for this tool so that it is included with the other tool docs when GATK is updated and is more visible to users.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6862
https://github.com/broadinstitute/gatk/issues/6862:61,Usability,Learn,LearnReadOrientationModel,61,## Documentation request. ### Tool(s) or class(es) involved; LearnReadOrientationModel. ### Description ; The tool LearnReadOrientationModel does not appear in the tool docs. We would like to update the documentation for this tool so that it is included with the other tool docs when GATK is updated and is more visible to users.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6862
https://github.com/broadinstitute/gatk/issues/6862:115,Usability,Learn,LearnReadOrientationModel,115,## Documentation request. ### Tool(s) or class(es) involved; LearnReadOrientationModel. ### Description ; The tool LearnReadOrientationModel does not appear in the tool docs. We would like to update the documentation for this tool so that it is included with the other tool docs when GATK is updated and is more visible to users.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6862
https://github.com/broadinstitute/gatk/issues/6863:695,Availability,avail,available,695,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863
https://github.com/broadinstitute/gatk/issues/6863:1364,Modifiability,refactor,refactoring,1364,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863
https://github.com/broadinstitute/gatk/issues/6863:203,Performance,optimiz,optimized,203,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863
https://github.com/broadinstitute/gatk/issues/6863:1437,Security,expose,expose,1437,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863
https://github.com/broadinstitute/gatk/issues/6863:1489,Usability,simpl,simple,1489,"Any objections to exposing SW parameters to the command line? This looks like something we will want to explore for malaria. I'm also not convinced that our current parameters have been justified and/or optimized in any documented way. A few questions:. 1) There are 3 sets of parameters used in various ways, a) haplotype-to-reference alignment, b) read-to-haplotype alignment, and c) dangling ends. Any chance we can evaluate the effect of consolidating at least c), if not all sets? @emeryj I was told that you might be the one to ask about c) in particular; @davidbenjamin speculated that these might effectively yield STR-specific parameters. In general, if there are any quick and readily available evaluations (which ideally include variant normalization), I'd appreciate pointers to them. 2) Any suggestions on what the resulting command line should look like? I don't want to add 12 parameters, in the worst case. I also think that using integer arrays might be clunky. Perhaps I can suggest the use of args files in the doc string---although I don't think that those are expanded in the `##GATKCommandLine`, right?. 3) Should I touch `SWOverhangStrategy` at all? See e.g. https://github.com/broadinstitute/gatk/issues/6576. It looks like we thread both this and the `SWParameters` through many methods and classes, so the code could stand quite a bit of refactoring, but for now I will stick to the minimal changes required to expose. @droazen @ldgauthier any thoughts?. In some simple experiments of changing the a) parameters (from the somewhat questionable `NEW_SW_PARAMETERS = new SWParameters(200, -150, -260, -11)` back to `STANDARD_NGS = new SWParameters(25, -50, -110, -6)`), I've seen that there are non-negligible differences in the calls (beyond representation) at the few percent level, as well as changes in annotations.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6863
https://github.com/broadinstitute/gatk/issues/6865:454,Availability,error,error,454,"## Bug Report. ### Affected tool(s) or class(es); CollectReadCounts . ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [x] Latest master branch as of [10/6/2020]. ### Description ; GATK CollectReadCounts successfully processes some reads but then throws an ArrayIndexOutOfBoundsException in the middle of the file. Console output below. I was able to successfully run CollectReadCounts on ~16k other crams, but received the same error on 3 of them (although the last coordinate reported by ProgressMeter was different for each). The error does not occur if I subset out chromosome 6 reads from the main cram file and run CollectReadCounts on each file separately. I don't see any obvious formatting issue with my crams from a quick skim over lines immediately following the last reported coordinate. ; ```; > java -jar gatk-package-4.1.8.1-local.jar CollectReadCounts \; -I input.cram \; --read-index input.cram.crai \; -L my_intervals.bed \; --interval-merging-rule OVERLAPPING_ONLY \; --reference hg38.fa \; --format TSV \; -O output.tsv. 16:56:30.581 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.581 INFO CollectReadCounts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 16:56:30.581 INFO CollectReadCounts - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:56:30.582 INFO CollectReadCounts - Executing as isaac@LAPTOP-K5UOQS3A on Linux v4.19.104-microsoft-standard amd64; 16:56:30.582 INFO CollectReadCounts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v14.0.1+7; 16:56:30.582 INFO CollectReadCounts - Start Date/Time: October 6, 2020 at 4:56:30 PM EDT; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.583 INFO CollectReadCounts - HTSJDK Version: 2.23.0; 16:56:30.584 INFO CollectReadCounts - Picard Version: 2.22.8; 16:56:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:558,Availability,error,error,558,"## Bug Report. ### Affected tool(s) or class(es); CollectReadCounts . ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [x] Latest master branch as of [10/6/2020]. ### Description ; GATK CollectReadCounts successfully processes some reads but then throws an ArrayIndexOutOfBoundsException in the middle of the file. Console output below. I was able to successfully run CollectReadCounts on ~16k other crams, but received the same error on 3 of them (although the last coordinate reported by ProgressMeter was different for each). The error does not occur if I subset out chromosome 6 reads from the main cram file and run CollectReadCounts on each file separately. I don't see any obvious formatting issue with my crams from a quick skim over lines immediately following the last reported coordinate. ; ```; > java -jar gatk-package-4.1.8.1-local.jar CollectReadCounts \; -I input.cram \; --read-index input.cram.crai \; -L my_intervals.bed \; --interval-merging-rule OVERLAPPING_ONLY \; --reference hg38.fa \; --format TSV \; -O output.tsv. 16:56:30.581 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.581 INFO CollectReadCounts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 16:56:30.581 INFO CollectReadCounts - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:56:30.582 INFO CollectReadCounts - Executing as isaac@LAPTOP-K5UOQS3A on Linux v4.19.104-microsoft-standard amd64; 16:56:30.582 INFO CollectReadCounts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v14.0.1+7; 16:56:30.582 INFO CollectReadCounts - Start Date/Time: October 6, 2020 at 4:56:30 PM EDT; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.583 INFO CollectReadCounts - HTSJDK Version: 2.23.0; 16:56:30.584 INFO CollectReadCounts - Picard Version: 2.22.8; 16:56:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:4066,Availability,down,down,4066,"g traversal; 16:56:31.263 INFO ProgressMeter - Current Locus Elapsed Minutes Reads Processed Reads/Minute; 16:56:42.883 INFO ProgressMeter - 1:28433062 0.2 7000 36147.7; 16:56:53.532 INFO ProgressMeter - 1:94237401 0.4 13000 35026.3; 16:57:08.438 INFO ProgressMeter - 1:192716273 0.6 21000 33893.7; 16:57:19.009 INFO ProgressMeter - 2:24820506 0.8 31000 38957.0; 16:57:29.031 INFO ProgressMeter - 2:94856959 1.0 44000 45700.0; 16:57:39.223 INFO ProgressMeter - 2:136329636 1.1 59000 52089.5; 16:57:49.667 INFO ProgressMeter - 2:233747942 1.3 65000 49742.4; 16:58:01.608 INFO ProgressMeter - 3:57654674 1.5 71000 47152.6; 16:58:12.449 INFO ProgressMeter - 3:179974096 1.7 84000 49809.3; 16:58:23.282 INFO ProgressMeter - 4:82276408 1.9 98000 52491.1; 16:58:33.462 INFO ProgressMeter - 5:20304602 2.0 106000 52046.3; 16:58:44.217 INFO ProgressMeter - 5:141241407 2.2 114000 51446.4; 16:58:54.298 INFO ProgressMeter - 6:28447738 2.4 122000 51176.3; 16:59:03.028 INFO CollectReadCounts - Shutting down engine; [October 6, 2020 at 4:59:03 PM EDT] org.broadinstitute.hellbender.tools.copynumber.CollectReadCounts done. Elapsed time: 2.55 minutes.; Runtime.totalMemory()=981467136; java.lang.ArrayIndexOutOfBoundsException; at java.base/java.util.zip.CRC32.update(CRC32.java:76); at htsjdk.samtools.cram.io.CRC32InputStream.read(CRC32InputStream.java:54); at htsjdk.samtools.cram.io.InputStreamUtils.readFully(InputStreamUtils.java:75); at htsjdk.samtools.cram.structure.block.Block.read(Block.java:283); at htsjdk.samtools.cram.structure.SliceBlocks.<init>(SliceBlocks.java:75); at htsjdk.samtools.cram.structure.Slice.<init>(Slice.java:155); at htsjdk.samtools.cram.structure.Container.<init>(Container.java:154); at htsjdk.samtools.cram.build.CramSpanContainerIterator$Boundary.next(CramSpanContainerIterator.java:97); at htsjdk.samtools.cram.build.CramSpanContainerIterator.next(CramSpanContainerIterator.java:57); at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:97); at htsjdk.samtools.C",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:115,Deployability,release,release,115,"## Bug Report. ### Affected tool(s) or class(es); CollectReadCounts . ### Affected version(s); - [x] Latest public release version [4.1.8.1]; - [x] Latest master branch as of [10/6/2020]. ### Description ; GATK CollectReadCounts successfully processes some reads but then throws an ArrayIndexOutOfBoundsException in the middle of the file. Console output below. I was able to successfully run CollectReadCounts on ~16k other crams, but received the same error on 3 of them (although the last coordinate reported by ProgressMeter was different for each). The error does not occur if I subset out chromosome 6 reads from the main cram file and run CollectReadCounts on each file separately. I don't see any obvious formatting issue with my crams from a quick skim over lines immediately following the last reported coordinate. ; ```; > java -jar gatk-package-4.1.8.1-local.jar CollectReadCounts \; -I input.cram \; --read-index input.cram.crai \; -L my_intervals.bed \; --interval-merging-rule OVERLAPPING_ONLY \; --reference hg38.fa \; --format TSV \; -O output.tsv. 16:56:30.581 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.581 INFO CollectReadCounts - The Genome Analysis Toolkit (GATK) v4.1.8.1; 16:56:30.581 INFO CollectReadCounts - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:56:30.582 INFO CollectReadCounts - Executing as isaac@LAPTOP-K5UOQS3A on Linux v4.19.104-microsoft-standard amd64; 16:56:30.582 INFO CollectReadCounts - Java runtime: Java HotSpot(TM) 64-Bit Server VM v14.0.1+7; 16:56:30.582 INFO CollectReadCounts - Start Date/Time: October 6, 2020 at 4:56:30 PM EDT; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.582 INFO CollectReadCounts - ------------------------------------------------------------; 16:56:30.583 INFO CollectReadCounts - HTSJDK Version: 2.23.0; 16:56:30.584 INFO CollectReadCounts - Picard Version: 2.22.8; 16:56:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:4323,Deployability,update,update,4323,"ressMeter - 1:192716273 0.6 21000 33893.7; 16:57:19.009 INFO ProgressMeter - 2:24820506 0.8 31000 38957.0; 16:57:29.031 INFO ProgressMeter - 2:94856959 1.0 44000 45700.0; 16:57:39.223 INFO ProgressMeter - 2:136329636 1.1 59000 52089.5; 16:57:49.667 INFO ProgressMeter - 2:233747942 1.3 65000 49742.4; 16:58:01.608 INFO ProgressMeter - 3:57654674 1.5 71000 47152.6; 16:58:12.449 INFO ProgressMeter - 3:179974096 1.7 84000 49809.3; 16:58:23.282 INFO ProgressMeter - 4:82276408 1.9 98000 52491.1; 16:58:33.462 INFO ProgressMeter - 5:20304602 2.0 106000 52046.3; 16:58:44.217 INFO ProgressMeter - 5:141241407 2.2 114000 51446.4; 16:58:54.298 INFO ProgressMeter - 6:28447738 2.4 122000 51176.3; 16:59:03.028 INFO CollectReadCounts - Shutting down engine; [October 6, 2020 at 4:59:03 PM EDT] org.broadinstitute.hellbender.tools.copynumber.CollectReadCounts done. Elapsed time: 2.55 minutes.; Runtime.totalMemory()=981467136; java.lang.ArrayIndexOutOfBoundsException; at java.base/java.util.zip.CRC32.update(CRC32.java:76); at htsjdk.samtools.cram.io.CRC32InputStream.read(CRC32InputStream.java:54); at htsjdk.samtools.cram.io.InputStreamUtils.readFully(InputStreamUtils.java:75); at htsjdk.samtools.cram.structure.block.Block.read(Block.java:283); at htsjdk.samtools.cram.structure.SliceBlocks.<init>(SliceBlocks.java:75); at htsjdk.samtools.cram.structure.Slice.<init>(Slice.java:155); at htsjdk.samtools.cram.structure.Container.<init>(Container.java:154); at htsjdk.samtools.cram.build.CramSpanContainerIterator$Boundary.next(CramSpanContainerIterator.java:97); at htsjdk.samtools.cram.build.CramSpanContainerIterator.next(CramSpanContainerIterator.java:57); at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:97); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:204); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.getNextRecord(CRAMFileReader.java:527); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.next(CRAMFileReader.java:521); at htsjdk.samtools.CRAM",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:6425,Integrability,wrap,wrapAndCopyInto,6425,or.next(SamReader.java:574); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:553); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); at org.broadinstitute.hellbender.engine.ReadWalker.traverse(ReadWalker.java:94); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203);,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:5618,Performance,load,loadNextRecord,5618,va:75); at htsjdk.samtools.cram.structure.Slice.<init>(Slice.java:155); at htsjdk.samtools.cram.structure.Container.<init>(Container.java:154); at htsjdk.samtools.cram.build.CramSpanContainerIterator$Boundary.next(CramSpanContainerIterator.java:97); at htsjdk.samtools.cram.build.CramSpanContainerIterator.next(CramSpanContainerIterator.java:57); at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:97); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:204); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.getNextRecord(CRAMFileReader.java:527); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.next(CRAMFileReader.java:521); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.next(CRAMFileReader.java:472); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:574); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:553); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(Fo,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:5426,Testability,Assert,AssertingIterator,5426,k.samtools.cram.io.InputStreamUtils.readFully(InputStreamUtils.java:75); at htsjdk.samtools.cram.structure.block.Block.read(Block.java:283); at htsjdk.samtools.cram.structure.SliceBlocks.<init>(SliceBlocks.java:75); at htsjdk.samtools.cram.structure.Slice.<init>(Slice.java:155); at htsjdk.samtools.cram.structure.Container.<init>(Container.java:154); at htsjdk.samtools.cram.build.CramSpanContainerIterator$Boundary.next(CramSpanContainerIterator.java:97); at htsjdk.samtools.cram.build.CramSpanContainerIterator.next(CramSpanContainerIterator.java:57); at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:97); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:204); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.getNextRecord(CRAMFileReader.java:527); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.next(CRAMFileReader.java:521); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.next(CRAMFileReader.java:472); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:574); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:553); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapA,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/issues/6865:5499,Testability,Assert,AssertingIterator,5499,at htsjdk.samtools.cram.structure.block.Block.read(Block.java:283); at htsjdk.samtools.cram.structure.SliceBlocks.<init>(SliceBlocks.java:75); at htsjdk.samtools.cram.structure.Slice.<init>(Slice.java:155); at htsjdk.samtools.cram.structure.Container.<init>(Container.java:154); at htsjdk.samtools.cram.build.CramSpanContainerIterator$Boundary.next(CramSpanContainerIterator.java:97); at htsjdk.samtools.cram.build.CramSpanContainerIterator.next(CramSpanContainerIterator.java:57); at htsjdk.samtools.CRAMIterator.nextContainer(CRAMIterator.java:97); at htsjdk.samtools.CRAMIterator.hasNext(CRAMIterator.java:204); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.getNextRecord(CRAMFileReader.java:527); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.next(CRAMFileReader.java:521); at htsjdk.samtools.CRAMFileReader$CRAMIntervalIteratorBase.next(CRAMFileReader.java:472); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:574); at htsjdk.samtools.SamReader$AssertingIterator.next(SamReader.java:553); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.loadNextRecord(SamReaderQueryingIterator.java:114); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:151); at org.broadinstitute.hellbender.utils.iterators.SamReaderQueryingIterator.next(SamReaderQueryingIterator.java:29); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:27); at org.broadinstitute.hellbender.utils.iterators.SAMRecordToReadIterator.next(SAMRecordToReadIterator.java:13); at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); at java.base/java.util.stream.ForE,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6865
https://github.com/broadinstitute/gatk/pull/6866:164,Deployability,update,updated,164,"This is intended to alleviate transient issues with GermlineCNVCaller inference in which the ELBO converges to a NaN value, by calling the python gCNV code with an updated random seed input.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6866
https://github.com/broadinstitute/gatk/pull/6867:0,Deployability,update,update,0,update Dockerfile to reflect correct haplocheckCLI,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6867
https://github.com/broadinstitute/gatk/pull/6870:124,Security,access,access,124,Closes #6829; @mwalker174 Could you please review? . I only added `gcs_project_for_requester_pays` input to tasks that need access to BAMs. Do we also need it for the ones that require reference such as `PreprocessIntervals`?,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6870
https://github.com/broadinstitute/gatk/pull/6871:106,Deployability,release,release,106,"@fleharty This fixes #6744, deferring a more principled solution for later. Can we get it in for Friday's release?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6871
https://github.com/broadinstitute/gatk/issues/6875:8810,Availability,down,down,8810,"ast_3_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on mpcb006.cm.cluster:46741 (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 3 from newAPIHadoopFile at SamSource.java:108; 18:35:30.930 INFO FileInputFormat - Total input files to process : 1; 20/10/08 18:35:30 INFO SparkUI: Stopped Spark web UI at http://mpcb006.cm.cluster:4040; 20/10/08 18:35:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/10/08 18:35:30 INFO MemoryStore: MemoryStore cleared; 20/10/08 18:35:30 INFO BlockManager: BlockManager stopped; 20/10/08 18:35:30 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/08 18:35:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/08 18:35:30 INFO SparkContext: Successfully stopped SparkContext; 18:35:30.994 INFO MarkDuplicatesSpark - Shutting down engine; [October 8, 2020 at 6:35:30 PM CEST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2579496960. ### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expec",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2463,Deployability,release,release,2463,_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Suc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:10343,Deployability,release,release,10343," existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----; Thanks in advance!; ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2666,Performance,load,load,2666,ater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:196,Safety,detect,detect,196,"I am trying to run gatk4 4.1.8.1 and I went through this problem:. Oct 08, 2020 6:35:26 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 18:35:26.515 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 18:35:26.515 INFO MarkDuplicatesSpark - The Genome Analysis Toolkit (GATK) v4.1.8.1; 18:35:26.515 INFO MarkDuplicatesSpark - For support and documentation go to https://software.broadinstitute.org/gatk/; 18:35:26.515 INFO MarkDuplicatesSpark - Executing as wup@mpcb006 on Linux v3.10.0-514.el7.x86_64 amd64; 18:35:26.515 INFO MarkDuplicatesSpark - Java runtime: OpenJDK 64-Bit Server VM v11.0.2+9; 18:35:26.516 INFO MarkDuplicatesSpark - Start Date/Time: October 8, 2020 at 6:35:26 PM CEST; 18:35:26.516 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 18:35:26.516 INFO MarkDuplicatesSpark - ------------------------------------------------------------; 18:35:26.516 INFO MarkDuplicatesSpark - HTSJDK Version: 2.23.0; 18:35:26.516 INFO MarkDuplicatesSpark - Picard Version: 2.22.8; 18:35:26.516 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WA",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2054,Safety,unsafe,unsafe,2054,6.516 INFO MarkDuplicatesSpark - HTSJDK Version: 2.23.0; 18:35:26.516 INFO MarkDuplicatesSpark - Picard Version: 2.22.8; 18:35:26.516 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2277,Safety,unsafe,unsafe,2277,uplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view p,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:5493,Safety,detect,detect,5493,"10/08 18:35:29 INFO NettyBlockTransferService: Server created on mpcb006.cm.cluster:46741; 20/10/08 18:35:29 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 20/10/08 18:35:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 20/10/08 18:35:29 INFO BlockManagerMasterEndpoint: Registering block manager mpcb006.cm.cluster:46741 with 17.8 GB RAM, BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 20/10/08 18:35:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 20/10/08 18:35:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 18:35:29.255 INFO MarkDuplicatesSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 20/10/08 18:35:29 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; WARNING	2020-10-08 18:35:29	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; WARNING	2020-10-08 18:35:29	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; 20/10/08 18:35:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 231.0 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.5 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on mpcb006.cm.cluster:46741 (size: 15.5 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 0 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on mpcb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:5615,Safety,detect,detect,5615," Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy; 20/10/08 18:35:29 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 20/10/08 18:35:29 INFO BlockManagerMasterEndpoint: Registering block manager mpcb006.cm.cluster:46741 with 17.8 GB RAM, BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 20/10/08 18:35:29 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 20/10/08 18:35:29 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, mpcb006.cm.cluster, 46741, None); 18:35:29.255 INFO MarkDuplicatesSpark - Spark verbosity set to INFO (see --spark-verbosity argument); 20/10/08 18:35:29 INFO GoogleHadoopFileSystemBase: GHFS version: 1.6.3-hadoop2; WARNING	2020-10-08 18:35:29	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; WARNING	2020-10-08 18:35:29	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; 20/10/08 18:35:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 231.0 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 15.5 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on mpcb006.cm.cluster:46741 (size: 15.5 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 0 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on mpcb006.cm.cluster:46741 (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 1 from newAPIHadoo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:6979,Safety,detect,detect,6979,"oadcast_0_piece0 in memory on mpcb006.cm.cluster:46741 (size: 15.5 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 0 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on mpcb006.cm.cluster:46741 (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at SamSource.java:108; 20/10/08 18:35:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on mpcb006.cm.cluster:46741 in memory (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on mpcb006.cm.cluster:46741 in memory (size: 15.5 KB, free: 17.8 GB); WARNING	2020-10-08 18:35:30	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; WARNING	2020-10-08 18:35:30	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 231.0 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 15.5 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on mpcb006.cm.cluster:46741 (size: 15.5 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 2 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on mpcb00",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:7101,Safety,detect,detect,7101,"reated broadcast 0 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on mpcb006.cm.cluster:46741 (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at SamSource.java:108; 20/10/08 18:35:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on mpcb006.cm.cluster:46741 in memory (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Removed broadcast_0_piece0 on mpcb006.cm.cluster:46741 in memory (size: 15.5 KB, free: 17.8 GB); WARNING	2020-10-08 18:35:30	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; WARNING	2020-10-08 18:35:30	SamReaderFactory	Unable to detect file format from input URL or stream, assuming SAM format.; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 231.0 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 15.5 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on mpcb006.cm.cluster:46741 (size: 15.5 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 2 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on mpcb006.cm.cluster:46741 (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 3 from newAPIHadoo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:1968,Security,access,access,1968, INFO MarkDuplicatesSpark - ------------------------------------------------------------; 18:35:26.516 INFO MarkDuplicatesSpark - HTSJDK Version: 2.23.0; 18:35:26.516 INFO MarkDuplicatesSpark - Picard Version: 2.22.8; 18:35:26.516 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2027,Security,access,access,2027, INFO MarkDuplicatesSpark - ------------------------------------------------------------; 18:35:26.516 INFO MarkDuplicatesSpark - HTSJDK Version: 2.23.0; 18:35:26.516 INFO MarkDuplicatesSpark - Picard Version: 2.22.8; 18:35:26.516 INFO MarkDuplicatesSpark - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modi,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2317,Security,access,access,2317,_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Suc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2378,Security,access,access,2378,_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Suc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2418,Security,access,access,2418,_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 18:35:26.517 INFO MarkDuplicatesSpark - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 18:35:26.517 INFO MarkDuplicatesSpark - Deflater: IntelDeflater; 18:35:26.517 INFO MarkDuplicatesSpark - Inflater: IntelInflater; 18:35:26.517 INFO MarkDuplicatesSpark - GCS max retries/reopens: 20; 18:35:26.517 INFO MarkDuplicatesSpark - Requester pays: disabled; 18:35:26.517 INFO MarkDuplicatesSpark - Initializing engine; 18:35:26.517 INFO MarkDuplicatesSpark - Done initializing engine; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/user/wup/miniconda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Suc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2863,Security,Secur,SecurityManager,2863,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:2931,Security,Secur,SecurityManager,2931,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:3001,Security,Secur,SecurityManager,3001,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:3073,Security,Secur,SecurityManager,3073,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:3147,Security,Secur,SecurityManager,3147,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:3164,Security,Secur,SecurityManager,3164,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:3181,Security,authenticat,authentication,3181,conda3/envs/gatk/share/gatk4-4.1.8.1-0/gatk-package-4.1.8.1-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 20/10/08 18:35:27 INFO SparkContext: Running Spark version 2.4.5; 18:35:27.640 WARN NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 20/10/08 18:35:27 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls to: wup; 20/10/08 18:35:27 INFO SecurityManager: Changing view acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: Changing modify acls groups to: ; 20/10/08 18:35:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(wup); groups with view permissions: Set(); users with modify permissions: Set(wup); groups with modify permissions: Set(); 20/10/08 18:35:28 INFO Utils: Successfully started service 'sparkDriver' on port 44712.; 20/10/08 18:35:28 INFO SparkEnv: Registering MapOutputTracker; 20/10/08 18:35:28 INFO SparkEnv: Registering BlockManagerMaster; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 20/10/08 18:35:28 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 20/10/08 18:35:28 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-50a111b1-9241-4bc8-b711-cdb6d7054e70; 20/10/08 18:35:28 INFO MemoryStore: MemoryStore started with capacity 17.8 GB; 20/10/08 18:35:28 INFO SparkEnv: Registering OutputCommitCoordinator; 20/1,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:10413,Testability,test,test,10413," existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----; Thanks in advance!; ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:10513,Testability,log,logs,10513," existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----; Thanks in advance!; ## Bug Report. ### Affected tool(s) or class(es); _Tool/class name(s), special parameters?_. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; _Describe the problem below. Provide **screenshots** , **stacktrace** , **logs** where appropriate._. #### Steps to reproduce; _Tell us how to reproduce this issue. If possible, include command lines that reproduce the problem. (The support team may follow up to ask you to upload data to reproduce the issue.)_. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; _Tell us what happens instead_. ----. ## Feature request. ### Tool(s) or class(es) involved; _Tool/class name(s), special parameters?_. ### Description; _Specify whether you want a modification of an existing behavior or addition of a new capability._; _Provide **examples**, **screenshots**, where appropriate._. ----. ## Documentation request. ### Tool(s) or class(es) involved; _Tool/class name(s), parameters?_. ### Description ; _Describe what needs to be added or modified._. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6875:8436,Usability,clear,cleared,8436,"ze: 15.5 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 2 from broadcast at SamSource.java:78; 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 148.8 KB, free 17.8 GB); 20/10/08 18:35:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 25.4 KB, free 17.8 GB); 20/10/08 18:35:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on mpcb006.cm.cluster:46741 (size: 25.4 KB, free: 17.8 GB); 20/10/08 18:35:30 INFO SparkContext: Created broadcast 3 from newAPIHadoopFile at SamSource.java:108; 18:35:30.930 INFO FileInputFormat - Total input files to process : 1; 20/10/08 18:35:30 INFO SparkUI: Stopped Spark web UI at http://mpcb006.cm.cluster:4040; 20/10/08 18:35:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 20/10/08 18:35:30 INFO MemoryStore: MemoryStore cleared; 20/10/08 18:35:30 INFO BlockManager: BlockManager stopped; 20/10/08 18:35:30 INFO BlockManagerMaster: BlockManagerMaster stopped; 20/10/08 18:35:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 20/10/08 18:35:30 INFO SparkContext: Successfully stopped SparkContext; 18:35:30.994 INFO MarkDuplicatesSpark - Shutting down engine; [October 8, 2020 at 6:35:30 PM CEST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.08 minutes.; Runtime.totalMemory()=2579496960. ### Instructions. The github issue tracker is for bug reports, feature requests, and API documentation requests. General questions about how to use the GATK, how to interpret the output, etc. should be asked on the [official support forum](http://gatkforums.broadinstitute.org/gatk).; - Search the existing github issues to see if your issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6875
https://github.com/broadinstitute/gatk/issues/6876:109,Deployability,release,release,109,### Affected tool(s) or class(es); _EstimateDragstrParameters_. ### Affected version(s); - [ ] Latest public release version [version?]; - [X] Latest master branch as of [after PR 6634 has been merged in]. ### Description . Look for usages of ```Utils.runInParallel```. Change those to use Spark instead. There is a possibility of removing multi-threading all together if we change the way we decimate and filter sites.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6876
https://github.com/broadinstitute/gatk/issues/6876:340,Performance,multi-thread,multi-threading,340,### Affected tool(s) or class(es); _EstimateDragstrParameters_. ### Affected version(s); - [ ] Latest public release version [version?]; - [X] Latest master branch as of [after PR 6634 has been merged in]. ### Description . Look for usages of ```Utils.runInParallel```. Change those to use Spark instead. There is a possibility of removing multi-threading all together if we change the way we decimate and filter sites.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6876
https://github.com/broadinstitute/gatk/issues/6882:106,Deployability,release,release,106,"## Bug Report. ### Affected class; AssemblyBasedCallerUtils. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/10/2020. ### Description ; When adjusting the base quality of overlapping read pairs, the modifications are made in place. If the modified reads are later used in another active region, the results from the later active region will be changed by the earlier modification. We had previously fixed this issue in #4926. But it looks like the refactoring in https://github.com/broadinstitute/gatk/commit/1353e3201bb11e29039efd89359b0a4cfc11e5c0 reverted to the earlier behavior. `AssemblyBasedCallerUtilsUnitTest.testfinalizeRegion()` will fail due to this behavior if [line 67](https://github.com/broadinstitute/gatk/blob/master/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtilsUnitTest.java#L67) is changed from:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, false);; ```; to:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, true);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6882
https://github.com/broadinstitute/gatk/issues/6882:506,Modifiability,refactor,refactoring,506,"## Bug Report. ### Affected class; AssemblyBasedCallerUtils. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/10/2020. ### Description ; When adjusting the base quality of overlapping read pairs, the modifications are made in place. If the modified reads are later used in another active region, the results from the later active region will be changed by the earlier modification. We had previously fixed this issue in #4926. But it looks like the refactoring in https://github.com/broadinstitute/gatk/commit/1353e3201bb11e29039efd89359b0a4cfc11e5c0 reverted to the earlier behavior. `AssemblyBasedCallerUtilsUnitTest.testfinalizeRegion()` will fail due to this behavior if [line 67](https://github.com/broadinstitute/gatk/blob/master/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtilsUnitTest.java#L67) is changed from:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, false);; ```; to:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, true);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6882
https://github.com/broadinstitute/gatk/issues/6882:676,Testability,test,testfinalizeRegion,676,"## Bug Report. ### Affected class; AssemblyBasedCallerUtils. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/10/2020. ### Description ; When adjusting the base quality of overlapping read pairs, the modifications are made in place. If the modified reads are later used in another active region, the results from the later active region will be changed by the earlier modification. We had previously fixed this issue in #4926. But it looks like the refactoring in https://github.com/broadinstitute/gatk/commit/1353e3201bb11e29039efd89359b0a4cfc11e5c0 reverted to the earlier behavior. `AssemblyBasedCallerUtilsUnitTest.testfinalizeRegion()` will fail due to this behavior if [line 67](https://github.com/broadinstitute/gatk/blob/master/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtilsUnitTest.java#L67) is changed from:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, false);; ```; to:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, true);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6882
https://github.com/broadinstitute/gatk/issues/6882:797,Testability,test,test,797,"## Bug Report. ### Affected class; AssemblyBasedCallerUtils. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/10/2020. ### Description ; When adjusting the base quality of overlapping read pairs, the modifications are made in place. If the modified reads are later used in another active region, the results from the later active region will be changed by the earlier modification. We had previously fixed this issue in #4926. But it looks like the refactoring in https://github.com/broadinstitute/gatk/commit/1353e3201bb11e29039efd89359b0a4cfc11e5c0 reverted to the earlier behavior. `AssemblyBasedCallerUtilsUnitTest.testfinalizeRegion()` will fail due to this behavior if [line 67](https://github.com/broadinstitute/gatk/blob/master/src/test/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/AssemblyBasedCallerUtilsUnitTest.java#L67) is changed from:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, false);; ```; to:; ```; AssemblyBasedCallerUtils.finalizeRegion(activeRegion, false, false, minbq, header, sampleList, true);; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6882
https://github.com/broadinstitute/gatk/pull/6884:51,Deployability,update,update,51,"Mutect adopted natural logarithms in #5858. In the update, it looks like one base 10 log was missed. This PR updates the missed log.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6884
https://github.com/broadinstitute/gatk/pull/6884:109,Deployability,update,updates,109,"Mutect adopted natural logarithms in #5858. In the update, it looks like one base 10 log was missed. This PR updates the missed log.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6884
https://github.com/broadinstitute/gatk/pull/6884:23,Testability,log,logarithms,23,"Mutect adopted natural logarithms in #5858. In the update, it looks like one base 10 log was missed. This PR updates the missed log.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6884
https://github.com/broadinstitute/gatk/pull/6884:85,Testability,log,log,85,"Mutect adopted natural logarithms in #5858. In the update, it looks like one base 10 log was missed. This PR updates the missed log.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6884
https://github.com/broadinstitute/gatk/pull/6884:128,Testability,log,log,128,"Mutect adopted natural logarithms in #5858. In the update, it looks like one base 10 log was missed. This PR updates the missed log.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6884
https://github.com/broadinstitute/gatk/pull/6885:1210,Deployability,integrat,integration,1210,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885
https://github.com/broadinstitute/gatk/pull/6885:1210,Integrability,integrat,integration,1210,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885
https://github.com/broadinstitute/gatk/pull/6885:25,Security,expose,exposed,25,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885
https://github.com/broadinstitute/gatk/pull/6885:681,Testability,test,testing,681,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885
https://github.com/broadinstitute/gatk/pull/6885:1222,Testability,test,tests,1222,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885
https://github.com/broadinstitute/gatk/pull/6885:1203,Usability,simpl,simple,1203,"EDIT: Parameters are now exposed as individual arguments, so the following quoted text is outdated; see below for more details. > Adds the parameters `--dangling-end-smith-waterman-parameters-table <GATKPath>`, `--haplotype-to-reference-smith-waterman-parameters-table <GATKPath>`, and `--read-to-haplotype-smith-waterman-parameters-table <GATKPath>` to HaplotypeCaller and Mutect2. This allows for input via a TSV containing the column headers `MATCH_VALUE\tMISMATCH_PENALTY\tGAP_OPEN_PENALTY\tGAP_EXTEND_PENALTY` and one row of integers. Enables investigation of #2498 and #5564. Closes #6863 . Just opening this in case anyone wants to play around with it. I'll do some further testing on human and malaria data, but we have already found some cases in the latter for which changing some of the quizzical values to more reasonable ones yields immediate benefits. If anyone has any suggestions for possible evaluations, I'm all ears!. A few notes:. - I still need to add doc strings for the new arguments.; - Per https://github.com/broadinstitute/gatk/issues/6863#issuecomment-705081291, we can wait until after the DRAGEN-GATK dust settles to review/reevaluate/merge.; - At that time, I'll add a few simple integration tests to check that I've properly bubbled up each set of parameters.; - The reviewer might find the diagram at https://github.com/broadinstitute/gatk/issues/6863#issuecomment-707919816 useful.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6885
https://github.com/broadinstitute/gatk/issues/6889:6459,Availability,Avail,Available,6459,"03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 03:15:02.667 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:15:02.667 INFO IntelPairHmm - Available threads: 16; 03:15:02.667 INFO IntelPairHmm - Requested threads: 32; 03:15:02.667 WARN IntelPairHmm - Using 16 available threads, but 32 were requested; 03:15:02.667 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; ```. Any insight into what's going on and how to diagnose it would be greatly appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:6580,Availability,avail,available,6580,"03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 03:15:02.667 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:15:02.667 INFO IntelPairHmm - Available threads: 16; 03:15:02.667 INFO IntelPairHmm - Requested threads: 32; 03:15:02.667 WARN IntelPairHmm - Using 16 available threads, but 32 were requested; 03:15:02.667 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; ```. Any insight into what's going on and how to diagnose it would be greatly appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:2797,Performance,Load,Loading,2797,"ve a theory about what's going on, and I'm hoping someone who is more knowledgable can tell me if my theory is sensible or impossible, and if there's anything I can do to confirm it. My theory is this: that a) the one bad job got run on a compute instance that has a hardware issue that intermittently affects only AVX operations, b) that the Intel native PairHMM doesn't handle that situation gracefully but instead returns an empty likelihoods map and c) that's causing the warnings I'm seeing the discrepancies in the gVCFs. I'm at a bit of a loss for what to do here since I've tried multiple times to reproduce the issue and cannot. And therefore also can't try running with different GATK versions or options etc. But at the same time if it's possible for a hardware issue to cause these problems without crashing the GATK that's very scary. The following is the logging prior to traversal so you can see which versions of various things are in use:. ```; 03:15:01.986 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 3:15:02 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 03:15:02.169 INFO HaplotypeCaller - ------------------------------------------------------------; 03:15:02.170 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.4.1; 03:15:02.170 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 03:15:02.170 INFO HaplotypeCaller - Executing as <redacted> on Linux v4.4.0-1114-aws amd64; 03:15:02.170 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_144-b01; 03:15:02.170 INFO HaplotypeCaller - Start Date/Time: October <redacted>; 03:15:02.170 INFO HaplotypeCaller - ------------------------------------------------------------; 03:15:02.170 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:5315,Performance,Load,Loading,5315,"E_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 03:15:02.171 INFO HaplotypeCaller - Deflater: IntelDeflater; 03:15:02.171 INFO HaplotypeCaller - Inflater: IntelInflater; 03:15:02.171 INFO HaplotypeCaller - GCS max retries/reopens: 20; 03:15:02.171 INFO HaplotypeCaller - Requester pays: disabled; 03:15:02.171 INFO HaplotypeCaller - Initializing engine; 03:15:02.438 INFO FeatureManager - Using codec VCFCodec to read file dbsnp.vcf.gz; 03:15:02.563 INFO FeatureManager - Using codec BEDCodec to read file targets.bed; 03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:5492,Performance,Load,Loading,5492,"lotypeCaller - GCS max retries/reopens: 20; 03:15:02.171 INFO HaplotypeCaller - Requester pays: disabled; 03:15:02.171 INFO HaplotypeCaller - Initializing engine; 03:15:02.438 INFO FeatureManager - Using codec VCFCodec to read file dbsnp.vcf.gz; 03:15:02.563 INFO FeatureManager - Using codec BEDCodec to read file targets.bed; 03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 03:15:02.667 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:15:02.667 INFO IntelPairHmm - Available threads: 16; 03:15:02.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:6117,Performance,Load,Loading,6117,"03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 03:15:02.667 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:15:02.667 INFO IntelPairHmm - Available threads: 16; 03:15:02.667 INFO IntelPairHmm - Requested threads: 32; 03:15:02.667 WARN IntelPairHmm - Using 16 available threads, but 32 were requested; 03:15:02.667 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; ```. Any insight into what's going on and how to diagnose it would be greatly appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:6667,Performance,multi-thread,multi-threaded,6667,"03:15:02.578 INFO IntervalArgumentCollection - Processing <redacted> bp from intervals; 03:15:02.588 INFO HaplotypeCaller - Done initializing engine; 03:15:02.590 INFO HaplotypeCallerEngine - Tool is in reference confidence mode and the annotation, the following changes will be made to any specified annotations: 'StrandBiasBySample' will be enabled. 'ChromosomeCounts', 'FisherStrand', 'StrandOddsRatio' and 'QualByDepth' annotations have been disabled; 03:15:02.593 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 03:15:02.598 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 03:15:02.599 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 03:15:02.599 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 03:15:02.601 INFO HaplotypeCallerEngine - Standard Emitting and Calling confidence set to 0.0 for reference-model confidence output; 03:15:02.601 INFO HaplotypeCallerEngine - All sites annotated with PLs forced to true for reference-model confidence output; 03:15:02.623 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 03:15:02.667 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 03:15:02.667 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 03:15:02.667 INFO IntelPairHmm - Available threads: 16; 03:15:02.667 INFO IntelPairHmm - Requested threads: 32; 03:15:02.667 WARN IntelPairHmm - Using 16 available threads, but 32 were requested; 03:15:02.667 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; ```. Any insight into what's going on and how to diagnose it would be greatly appreciated.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:3074,Safety,detect,detect,3074,"e issue that intermittently affects only AVX operations, b) that the Intel native PairHMM doesn't handle that situation gracefully but instead returns an empty likelihoods map and c) that's causing the warnings I'm seeing the discrepancies in the gVCFs. I'm at a bit of a loss for what to do here since I've tried multiple times to reproduce the issue and cannot. And therefore also can't try running with different GATK versions or options etc. But at the same time if it's possible for a hardware issue to cause these problems without crashing the GATK that's very scary. The following is the logging prior to traversal so you can see which versions of various things are in use:. ```; 03:15:01.986 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 3:15:02 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 03:15:02.169 INFO HaplotypeCaller - ------------------------------------------------------------; 03:15:02.170 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.4.1; 03:15:02.170 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 03:15:02.170 INFO HaplotypeCaller - Executing as <redacted> on Linux v4.4.0-1114-aws amd64; 03:15:02.170 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_144-b01; 03:15:02.170 INFO HaplotypeCaller - Start Date/Time: October <redacted>; 03:15:02.170 INFO HaplotypeCaller - ------------------------------------------------------------; 03:15:02.170 INFO HaplotypeCaller - ------------------------------------------------------------; 03:15:02.170 INFO HaplotypeCaller - HTSJDK Version: 2.21.0; 03:15:02.170 INFO HaplotypeCaller - Picard Version: 2.21.2; 03:15:02.170 INFO HaplotypeCaller - HTSJDK Defaults.COMPRESSION_LEVEL : ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:307,Testability,log,logs,307,"This is more of a question than an outright bug report. I've observed something very strange today, that I cannot reproduce, and am looking for some help figuring out what's going on. The long and the short of it is that I'm operating on a commercial platform where I've run the same job 4 times. I can see logs and confirm that a) the exact same docker image is used for all four runs, b) the exact same GATK command is use for all 4 runs, and c) the exact same inputs are provided to each of the four runs. I can't share details (yet) but I'm 99.99% confident that I'm executing the exact same code on the exact same input data and getting quite different results. Specifically the first job produces output that is different from the remaining three jobs, which are all identical (except for datetimes in the headers of VCFs). The outlier run misses a number variants (about 10% vs. the other three runs). And the entries in the gVCF where the variants are missed are weird. E.g. there'll be a gVCF entry for a single base where if you believed the data in the gVCF here would be no reason to emit a separate block. And that entry will have high coverage (e.g. DP=800), assign all the coverage to the REF allele (the site is clearly about 50/50 het in IGV) and emit GQ=0 for GT=0/0. . One very noticeable difference is that the three ""good"" runs complete traversal without any warnings, but that ""bad"" run emits the following warning once:. ```; WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```. and the following warning many times (~350):. ```; 2020-10-08 21:15:12 bam_to_vcf STDERR 03:15:12.397 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```. I have a theory about what's going on, and I'm hoping someone who is more knowledgable can tell me if my theory is sensible or impossible, and if there's anything I can do to confirm it. My theory is this: that",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:2664,Testability,log,logging,2664,"Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```. I have a theory about what's going on, and I'm hoping someone who is more knowledgable can tell me if my theory is sensible or impossible, and if there's anything I can do to confirm it. My theory is this: that a) the one bad job got run on a compute instance that has a hardware issue that intermittently affects only AVX operations, b) that the Intel native PairHMM doesn't handle that situation gracefully but instead returns an empty likelihoods map and c) that's causing the warnings I'm seeing the discrepancies in the gVCFs. I'm at a bit of a loss for what to do here since I've tried multiple times to reproduce the issue and cannot. And therefore also can't try running with different GATK versions or options etc. But at the same time if it's possible for a hardware issue to cause these problems without crashing the GATK that's very scary. The following is the logging prior to traversal so you can see which versions of various things are in use:. ```; 03:15:01.986 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:conda/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 09, 2020 3:15:02 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 03:15:02.169 INFO HaplotypeCaller - ------------------------------------------------------------; 03:15:02.170 INFO HaplotypeCaller - The Genome Analysis Toolkit (GATK) v4.1.4.1; 03:15:02.170 INFO HaplotypeCaller - For support and documentation go to https://software.broadinstitute.org/gatk/; 03:15:02.170 INFO HaplotypeCaller - Executing as <redacted> on Linux v4.4.0-1114-aws amd64; 03:15:02.170 INFO HaplotypeCaller - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_144-b01; 03:15:02.170 INFO HaplotypeCaller - Start Date/Time: October <redacted>; 03:15:02.170 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6889:1228,Usability,clear,clearly,1228," operating on a commercial platform where I've run the same job 4 times. I can see logs and confirm that a) the exact same docker image is used for all four runs, b) the exact same GATK command is use for all 4 runs, and c) the exact same inputs are provided to each of the four runs. I can't share details (yet) but I'm 99.99% confident that I'm executing the exact same code on the exact same input data and getting quite different results. Specifically the first job produces output that is different from the remaining three jobs, which are all identical (except for datetimes in the headers of VCFs). The outlier run misses a number variants (about 10% vs. the other three runs). And the entries in the gVCF where the variants are missed are weird. E.g. there'll be a gVCF entry for a single base where if you believed the data in the gVCF here would be no reason to emit a separate block. And that entry will have high coverage (e.g. DP=800), assign all the coverage to the REF allele (the site is clearly about 50/50 het in IGV) and emit GQ=0 for GT=0/0. . One very noticeable difference is that the three ""good"" runs complete traversal without any warnings, but that ""bad"" run emits the following warning once:. ```; WARN DepthPerSampleHC - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```. and the following warning many times (~350):. ```; 2020-10-08 21:15:12 bam_to_vcf STDERR 03:15:12.397 WARN StrandBiasBySample - Annotation will not be calculated, genotype is not called or alleleLikelihoodMap is null; ```. I have a theory about what's going on, and I'm hoping someone who is more knowledgable can tell me if my theory is sensible or impossible, and if there's anything I can do to confirm it. My theory is this: that a) the one bad job got run on a compute instance that has a hardware issue that intermittently affects only AVX operations, b) that the Intel native PairHMM doesn't handle that situation gracefully but instead returns an e",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6889
https://github.com/broadinstitute/gatk/issues/6893:7,Testability,test,tests,7,Create tests data for and write tests for `testCohortWithAnnotatedIntervals` and `testCohortWithInputModel` tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6893
https://github.com/broadinstitute/gatk/issues/6893:32,Testability,test,tests,32,Create tests data for and write tests for `testCohortWithAnnotatedIntervals` and `testCohortWithInputModel` tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6893
https://github.com/broadinstitute/gatk/issues/6893:43,Testability,test,testCohortWithAnnotatedIntervals,43,Create tests data for and write tests for `testCohortWithAnnotatedIntervals` and `testCohortWithInputModel` tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6893
https://github.com/broadinstitute/gatk/issues/6893:82,Testability,test,testCohortWithInputModel,82,Create tests data for and write tests for `testCohortWithAnnotatedIntervals` and `testCohortWithInputModel` tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6893
https://github.com/broadinstitute/gatk/issues/6893:108,Testability,test,tests,108,Create tests data for and write tests for `testCohortWithAnnotatedIntervals` and `testCohortWithInputModel` tests,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6893
https://github.com/broadinstitute/gatk/issues/6897:281,Availability,Down,Downloads,281,"Hi,; I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:324,Availability,Down,Downloads,324,"Hi,; I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:475,Availability,Down,Downloads,475,"Hi,; I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:717,Availability,Down,Downloads,717,"Hi,; I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:802,Availability,Down,Downloads,802,"Hi,; I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:843,Availability,Down,Downloads,843,"Hi,; I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ----------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:1062,Availability,Down,Downloads,1062,"F file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ------------------------------------------------------------; 16:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:3016,Availability,Down,Downloads,3016,----------------------------------------------------------; 16:46:04.318 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.320 INFO VariantsToTable - HTSJDK Version: 2.23.0; 16:46:04.320 INFO VariantsToTable - Picard Version: 2.23.3; 16:46:04.320 INFO VariantsToTable - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:04.321 INFO VariantsToTable - Deflater: IntelDeflater; 16:46:04.322 INFO VariantsToTable - Inflater: IntelInflater; 16:46:04.322 INFO VariantsToTable - GCS max retries/reopens: 20; 16:46:04.322 INFO VariantsToTable - Requester pays: disabled; 16:46:04.322 INFO VariantsToTable - Initializing engine; 16:46:04.805 INFO FeatureManager - Using codec VCFCodec to read file file:///home/india/Downloads/Galaxy57-%5BMerged_file.vcf%5D.vcf; 16:46:04.896 INFO VariantsToTable - Done initializing engine; 16:46:04.917 WARN VariantsToTable - Allele-specific fields will only be split if splitting multi-allelic variants is specified (`--split-multi-allelic` or `-SMA`; 16:46:04.918 INFO ProgressMeter - Starting traversal; 16:46:04.918 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:46:05.217 INFO VariantsToTable - Shutting down engine; [16 October 2020 at 4:46:05 PM IST] org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=132120576; htsjdk.tribble.TribbleException: partial missing values for GL field; 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.parseDeprecatedGLString(GenotypeLikelihoods.java:269); 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.fromGLField(GenotypeLikelihoods.java:78); 	at htsjdk.variant.vcf.AbstractVCFCodec.cre,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:3486,Availability,down,down,3486,ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 16:46:04.321 INFO VariantsToTable - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 16:46:04.321 INFO VariantsToTable - Deflater: IntelDeflater; 16:46:04.322 INFO VariantsToTable - Inflater: IntelInflater; 16:46:04.322 INFO VariantsToTable - GCS max retries/reopens: 20; 16:46:04.322 INFO VariantsToTable - Requester pays: disabled; 16:46:04.322 INFO VariantsToTable - Initializing engine; 16:46:04.805 INFO FeatureManager - Using codec VCFCodec to read file file:///home/india/Downloads/Galaxy57-%5BMerged_file.vcf%5D.vcf; 16:46:04.896 INFO VariantsToTable - Done initializing engine; 16:46:04.917 WARN VariantsToTable - Allele-specific fields will only be split if splitting multi-allelic variants is specified (`--split-multi-allelic` or `-SMA`; 16:46:04.918 INFO ProgressMeter - Starting traversal; 16:46:04.918 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 16:46:05.217 INFO VariantsToTable - Shutting down engine; [16 October 2020 at 4:46:05 PM IST] org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable done. Elapsed time: 0.04 minutes.; Runtime.totalMemory()=132120576; htsjdk.tribble.TribbleException: partial missing values for GL field; 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.parseDeprecatedGLString(GenotypeLikelihoods.java:269); 	at htsjdk.variant.variantcontext.GenotypeLikelihoods.fromGLField(GenotypeLikelihoods.java:78); 	at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:817); 	at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:121); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.ensureSampleNameMap(LazyGenotypesContext.java:180); 	at htsjdk.variant.variantcontext.GenotypesContext.containsSample(GenotypesContext.java:659); 	at htsjdk.variant.variantcontext.VariantContext.hasGenotype(Varia,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:5630,Integrability,wrap,wrapAndCopyInto,5630,; 	at org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable.extractFields(VariantsToTable.java:362); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.VariantsToTable.apply(VariantsToTable.java:263); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177); 	at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195); 	at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133); 	at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484); 	at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474); 	at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEnt,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:1006,Performance,Load,Loading,1006," I am working on GATK VariantsToTable tool and my VCF file consists of 12 chromosomes but the output shows only one chromosome. Could you please help me out.; OS:-Ubuntu 20.04; GATK version:-4.1.9.0; Java:-open jdk version 11.0.8; Command:-gatk VariantsToTable -R '/home/india/Downloads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - -------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6897:1290,Safety,detect,detect,1290,"loads/Reference.fasta' -V '/home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf' -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table. Using GATK jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantsToTable -R /home/india/Downloads/Reference.fasta -V /home/india/Downloads/Galaxy57-[Merged_file.vcf].vcf -F CHROM -F POS -F REF -F ALT -GF AD -GF DP -GF GQ -GF PL -O bothbulks_new.table; 16:46:03.294 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/india/Downloads/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 16, 2020 4:46:04 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 16:46:04.315 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.316 INFO VariantsToTable - The Genome Analysis Toolkit (GATK) v4.1.9.0; 16:46:04.316 INFO VariantsToTable - For support and documentation go to https://software.broadinstitute.org/gatk/; 16:46:04.317 INFO VariantsToTable - Executing as india@india-HP-ProBook-445-G1 on Linux v5.4.0-26-generic amd64; 16:46:04.317 INFO VariantsToTable - Java runtime: OpenJDK 64-Bit Server VM v11.0.8+10-post-Ubuntu-0ubuntu120.04; 16:46:04.317 INFO VariantsToTable - Start Date/Time: 16 October 2020 at 4:46:02 PM IST; 16:46:04.318 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.318 INFO VariantsToTable - ------------------------------------------------------------; 16:46:04.320 INFO VariantsToTable - HTSJDK Version: 2.23.0; 16:46:04.320 INFO VariantsToTable - Picard Version: 2.23.3; 16:46:04.320 I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6897
https://github.com/broadinstitute/gatk/issues/6898:1361,Testability,test,tests,1361,"I have noticed in debugging an issue that there is an inconsistency in the overlaps methods in a somewhat pathological edge case that we should probably address somewhere in the future. In the case where a read (locatable) consumes no reference bases I see inconsistent behavior if the read is ""aligned"" to the last base in a simple interval. To demonstrate I have this read (which is all insertions): ; `<READNAME>	99	chr1	72515809	34	70I81H	=	72515809	70	ATATATGTATACATATATATGTACATATATATGTATACATATATGCACATATATATGTATACATATATAT	....`; and the simple interval: ; `chr1:72515804-72515808`; Calling the method `read.overlaps(simpleInterval)` returns true, whereas calling the method `simpleInterval.overlaps(read)` returns false. Doing a little digging into why this is, it appears that the `.overlaps()` method that gets called in the former case maps to the Locatable overlaps method which calls return `withinDistanceOf(other, 0);` which from what I can tell fails in this case because `<READNAME>.getEnd()` returns `72515808` for this all insertion read. The latter case seems to map to -> `overlapsWithMargin(other, 0);` which doesn't end up getting tripped by the `read.getEnd()` result. . This is a very marginal case and perhaps it is best addressed by making sure we aren't producing meaningless all insertion reads but we should probably add some better tests to the locatable/simpleInterval overlaps methods and change them so they are absolutely concordant in every pathological edge case so this doesn't cause issues for us in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898
https://github.com/broadinstitute/gatk/issues/6898:326,Usability,simpl,simple,326,"I have noticed in debugging an issue that there is an inconsistency in the overlaps methods in a somewhat pathological edge case that we should probably address somewhere in the future. In the case where a read (locatable) consumes no reference bases I see inconsistent behavior if the read is ""aligned"" to the last base in a simple interval. To demonstrate I have this read (which is all insertions): ; `<READNAME>	99	chr1	72515809	34	70I81H	=	72515809	70	ATATATGTATACATATATATGTACATATATATGTATACATATATGCACATATATATGTATACATATATAT	....`; and the simple interval: ; `chr1:72515804-72515808`; Calling the method `read.overlaps(simpleInterval)` returns true, whereas calling the method `simpleInterval.overlaps(read)` returns false. Doing a little digging into why this is, it appears that the `.overlaps()` method that gets called in the former case maps to the Locatable overlaps method which calls return `withinDistanceOf(other, 0);` which from what I can tell fails in this case because `<READNAME>.getEnd()` returns `72515808` for this all insertion read. The latter case seems to map to -> `overlapsWithMargin(other, 0);` which doesn't end up getting tripped by the `read.getEnd()` result. . This is a very marginal case and perhaps it is best addressed by making sure we aren't producing meaningless all insertion reads but we should probably add some better tests to the locatable/simpleInterval overlaps methods and change them so they are absolutely concordant in every pathological edge case so this doesn't cause issues for us in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898
https://github.com/broadinstitute/gatk/issues/6898:543,Usability,simpl,simple,543,"I have noticed in debugging an issue that there is an inconsistency in the overlaps methods in a somewhat pathological edge case that we should probably address somewhere in the future. In the case where a read (locatable) consumes no reference bases I see inconsistent behavior if the read is ""aligned"" to the last base in a simple interval. To demonstrate I have this read (which is all insertions): ; `<READNAME>	99	chr1	72515809	34	70I81H	=	72515809	70	ATATATGTATACATATATATGTACATATATATGTATACATATATGCACATATATATGTATACATATATAT	....`; and the simple interval: ; `chr1:72515804-72515808`; Calling the method `read.overlaps(simpleInterval)` returns true, whereas calling the method `simpleInterval.overlaps(read)` returns false. Doing a little digging into why this is, it appears that the `.overlaps()` method that gets called in the former case maps to the Locatable overlaps method which calls return `withinDistanceOf(other, 0);` which from what I can tell fails in this case because `<READNAME>.getEnd()` returns `72515808` for this all insertion read. The latter case seems to map to -> `overlapsWithMargin(other, 0);` which doesn't end up getting tripped by the `read.getEnd()` result. . This is a very marginal case and perhaps it is best addressed by making sure we aren't producing meaningless all insertion reads but we should probably add some better tests to the locatable/simpleInterval overlaps methods and change them so they are absolutely concordant in every pathological edge case so this doesn't cause issues for us in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898
https://github.com/broadinstitute/gatk/issues/6898:622,Usability,simpl,simpleInterval,622,"I have noticed in debugging an issue that there is an inconsistency in the overlaps methods in a somewhat pathological edge case that we should probably address somewhere in the future. In the case where a read (locatable) consumes no reference bases I see inconsistent behavior if the read is ""aligned"" to the last base in a simple interval. To demonstrate I have this read (which is all insertions): ; `<READNAME>	99	chr1	72515809	34	70I81H	=	72515809	70	ATATATGTATACATATATATGTACATATATATGTATACATATATGCACATATATATGTATACATATATAT	....`; and the simple interval: ; `chr1:72515804-72515808`; Calling the method `read.overlaps(simpleInterval)` returns true, whereas calling the method `simpleInterval.overlaps(read)` returns false. Doing a little digging into why this is, it appears that the `.overlaps()` method that gets called in the former case maps to the Locatable overlaps method which calls return `withinDistanceOf(other, 0);` which from what I can tell fails in this case because `<READNAME>.getEnd()` returns `72515808` for this all insertion read. The latter case seems to map to -> `overlapsWithMargin(other, 0);` which doesn't end up getting tripped by the `read.getEnd()` result. . This is a very marginal case and perhaps it is best addressed by making sure we aren't producing meaningless all insertion reads but we should probably add some better tests to the locatable/simpleInterval overlaps methods and change them so they are absolutely concordant in every pathological edge case so this doesn't cause issues for us in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898
https://github.com/broadinstitute/gatk/issues/6898:681,Usability,simpl,simpleInterval,681,"I have noticed in debugging an issue that there is an inconsistency in the overlaps methods in a somewhat pathological edge case that we should probably address somewhere in the future. In the case where a read (locatable) consumes no reference bases I see inconsistent behavior if the read is ""aligned"" to the last base in a simple interval. To demonstrate I have this read (which is all insertions): ; `<READNAME>	99	chr1	72515809	34	70I81H	=	72515809	70	ATATATGTATACATATATATGTACATATATATGTATACATATATGCACATATATATGTATACATATATAT	....`; and the simple interval: ; `chr1:72515804-72515808`; Calling the method `read.overlaps(simpleInterval)` returns true, whereas calling the method `simpleInterval.overlaps(read)` returns false. Doing a little digging into why this is, it appears that the `.overlaps()` method that gets called in the former case maps to the Locatable overlaps method which calls return `withinDistanceOf(other, 0);` which from what I can tell fails in this case because `<READNAME>.getEnd()` returns `72515808` for this all insertion read. The latter case seems to map to -> `overlapsWithMargin(other, 0);` which doesn't end up getting tripped by the `read.getEnd()` result. . This is a very marginal case and perhaps it is best addressed by making sure we aren't producing meaningless all insertion reads but we should probably add some better tests to the locatable/simpleInterval overlaps methods and change them so they are absolutely concordant in every pathological edge case so this doesn't cause issues for us in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898
https://github.com/broadinstitute/gatk/issues/6898:1384,Usability,simpl,simpleInterval,1384,"I have noticed in debugging an issue that there is an inconsistency in the overlaps methods in a somewhat pathological edge case that we should probably address somewhere in the future. In the case where a read (locatable) consumes no reference bases I see inconsistent behavior if the read is ""aligned"" to the last base in a simple interval. To demonstrate I have this read (which is all insertions): ; `<READNAME>	99	chr1	72515809	34	70I81H	=	72515809	70	ATATATGTATACATATATATGTACATATATATGTATACATATATGCACATATATATGTATACATATATAT	....`; and the simple interval: ; `chr1:72515804-72515808`; Calling the method `read.overlaps(simpleInterval)` returns true, whereas calling the method `simpleInterval.overlaps(read)` returns false. Doing a little digging into why this is, it appears that the `.overlaps()` method that gets called in the former case maps to the Locatable overlaps method which calls return `withinDistanceOf(other, 0);` which from what I can tell fails in this case because `<READNAME>.getEnd()` returns `72515808` for this all insertion read. The latter case seems to map to -> `overlapsWithMargin(other, 0);` which doesn't end up getting tripped by the `read.getEnd()` result. . This is a very marginal case and perhaps it is best addressed by making sure we aren't producing meaningless all insertion reads but we should probably add some better tests to the locatable/simpleInterval overlaps methods and change them so they are absolutely concordant in every pathological edge case so this doesn't cause issues for us in the future.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6898
https://github.com/broadinstitute/gatk/issues/6901:88,Deployability,release,release,88,"## Bug Report. ### Affected tool; Mutect2. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/19/2020. ### Description; It looks like there may be a typo in Mutect2Engine.java that was introduced before the most recent release, https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2Engine.java#L392. The line currently reads:; ```java; if (bestNormalAltAllele.getLeft() == bestNormalAltAllele.getLeft()) {; ```; It seems like this line should instead be:; ```java; if (bestNormalAltAllele.getLeft() == bestTumorAltAllele.getLeft()) {; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6901
https://github.com/broadinstitute/gatk/issues/6901:274,Deployability,release,release,274,"## Bug Report. ### Affected tool; Mutect2. ### Affected version(s); - [x] Latest public release version 4.1.9.0; - [x] Latest master branch as of 10/19/2020. ### Description; It looks like there may be a typo in Mutect2Engine.java that was introduced before the most recent release, https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/mutect/Mutect2Engine.java#L392. The line currently reads:; ```java; if (bestNormalAltAllele.getLeft() == bestNormalAltAllele.getLeft()) {; ```; It seems like this line should instead be:; ```java; if (bestNormalAltAllele.getLeft() == bestTumorAltAllele.getLeft()) {; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6901
https://github.com/broadinstitute/gatk/pull/6902:275,Deployability,update,update,275,"I made no changes to the copied files. @kcibul @ahaessly let me know if I'm missing anything. I left some of the demo bash scripts thinking that we didn't necessarily need to keep them now that we have WDLs, but let me know if you want me to move anything else. . The readme update here assumes that #6881 will get merged. I also turned off the tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6902
https://github.com/broadinstitute/gatk/pull/6902:345,Testability,test,tests,345,"I made no changes to the copied files. @kcibul @ahaessly let me know if I'm missing anything. I left some of the demo bash scripts thinking that we didn't necessarily need to keep them now that we have WDLs, but let me know if you want me to move anything else. . The readme update here assumes that #6881 will get merged. I also turned off the tests.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6902
https://github.com/broadinstitute/gatk/pull/6903:70,Deployability,update,updates,70,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:209,Deployability,update,update,209,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:235,Deployability,integrat,integration,235,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:622,Deployability,update,update,622,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:235,Integrability,integrat,integration,235,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:247,Testability,test,tests,247,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:358,Testability,test,testOnRealBam,358,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:444,Testability,test,tests,444,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/pull/6903:317,Usability,Learn,LearnReadOrientationModelIntegrationTest,317,"This PR makes two changes to Mutect2's filtering. 1. The first change updates `Math.min` to `Math.max` in `applyFiltersAndAccumulateOutputStats()`, which is probably the intended behavior. Unfortunately, this update breaks some of the integration tests at `org.broadinstitute.hellbender.tools.walkers.readorientation.LearnReadOrientationModelIntegrationTest.testOnRealBam`. I'm not quite sure how the dev team would prefer to handle the failed tests, so I thought I'd raise the issue here. 2. In `StrictStrandBiasFilter`, the argument `minReadsOnEachStrand` is not used in the `areAllelesArtifacts()` function. The second update turns on the `minReadsOnEachStrand` argument rather than using the default of 0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6903
https://github.com/broadinstitute/gatk/issues/6906:467,Deployability,deploy,deploy-mode,467,"Hi, ; when i test gatk4 MarkDuplicatesSpark command on yarn cluster, i encountered an issue ""non zero exit code 13"". How can i fix it ? . Here is my command and what i received from the terminal :; ****; gatk MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt -- --spark-runner SPARK --deploy-mode cluster --spark-master yarn; Using GATK jar /home/jacky/Exec/gatk/build/libs/gatk-spark.jar; Running:; /home/jacky/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.executor.memoryOverhead=600 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --deploy-mode cluster /home/jacky/Exec/gatk/build/libs/gatk-spark.jar MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt --spark-master yarn; 20/10/22 12:02:26 INFO client.RMProxy: Connecting to ResourceManager at /192.168.0.104:8032; 20/10/22 12:02:26 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 20/10/22 12:02:26 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container); 20/10/22 12:02:26 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:1307,Deployability,deploy,deploy-mode,1307,"://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt -- --spark-runner SPARK --deploy-mode cluster --spark-master yarn; Using GATK jar /home/jacky/Exec/gatk/build/libs/gatk-spark.jar; Running:; /home/jacky/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.executor.memoryOverhead=600 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --deploy-mode cluster /home/jacky/Exec/gatk/build/libs/gatk-spark.jar MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt --spark-master yarn; 20/10/22 12:02:26 INFO client.RMProxy: Connecting to ResourceManager at /192.168.0.104:8032; 20/10/22 12:02:26 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 20/10/22 12:02:26 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container); 20/10/22 12:02:26 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 20/10/22 12:02:26 INFO yarn.Client: Setting up container launch context for our AM; 20/10/22 12:02:26 INFO yarn.Client: Setting up the launch environment for our AM container; 20/10/22 12:02:26 INFO yarn.Client: Preparing resources for our ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:2021,Energy Efficiency,allocate,allocate,2021,"=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --deploy-mode cluster /home/jacky/Exec/gatk/build/libs/gatk-spark.jar MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt --spark-master yarn; 20/10/22 12:02:26 INFO client.RMProxy: Connecting to ResourceManager at /192.168.0.104:8032; 20/10/22 12:02:26 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 20/10/22 12:02:26 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container); 20/10/22 12:02:26 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead; 20/10/22 12:02:26 INFO yarn.Client: Setting up container launch context for our AM; 20/10/22 12:02:26 INFO yarn.Client: Setting up the launch environment for our AM container; 20/10/22 12:02:26 INFO yarn.Client: Preparing resources for our AM container; 20/10/22 12:02:26 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:4261,Performance,queue,queue,4261,20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:36 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:37 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:38 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:39 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:40 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:41 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:42 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:6625,Performance,concurren,concurrent,6625,".Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:40 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:41 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:42 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:43 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:44 INFO yarn.Client: Application report for application_1603353714322_0004 (state: FAILED); 20/10/22 12:02:44 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: Application application_1603353714322_0004 failed 2 times due to AM Container for appattempt_1603353714322_0004_000002 exited with exitCode: 13; For more detailed output, check application tracking page:http://jacky:8088/cluster/app/application_1603353714322_0004Then, click on links to logs of each attempt.; Diagnostics: Exception from container-launch.; Container id: container_1603353714322_0004_02_000001; Exit code: 13; Stack trace: ExitCodeException exitCode=13: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545); 	at org.apache.hadoop.util.Shell.run(Shell.java:456); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:6687,Performance,concurren,concurrent,6687,".Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:40 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:41 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:42 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:43 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:44 INFO yarn.Client: Application report for application_1603353714322_0004 (state: FAILED); 20/10/22 12:02:44 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: Application application_1603353714322_0004 failed 2 times due to AM Container for appattempt_1603353714322_0004_000002 exited with exitCode: 13; For more detailed output, check application tracking page:http://jacky:8088/cluster/app/application_1603353714322_0004Then, click on links to logs of each attempt.; Diagnostics: Exception from container-launch.; Container id: container_1603353714322_0004_02_000001; Exit code: 13; Stack trace: ExitCodeException exitCode=13: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545); 	at org.apache.hadoop.util.Shell.run(Shell.java:456); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:6772,Performance,concurren,concurrent,6772,".Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:40 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:41 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:42 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:43 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:44 INFO yarn.Client: Application report for application_1603353714322_0004 (state: FAILED); 20/10/22 12:02:44 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: Application application_1603353714322_0004 failed 2 times due to AM Container for appattempt_1603353714322_0004_000002 exited with exitCode: 13; For more detailed output, check application tracking page:http://jacky:8088/cluster/app/application_1603353714322_0004Then, click on links to logs of each attempt.; Diagnostics: Exception from container-launch.; Container id: container_1603353714322_0004_02_000001; Exit code: 13; Stack trace: ExitCodeException exitCode=13: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545); 	at org.apache.hadoop.util.Shell.run(Shell.java:456); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149); 	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624); 	at java.lang.Thread.run(Thread.java:748)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:3249,Security,Secur,SecurityManager,3249,"O yarn.Client: Preparing resources for our AM container; 20/10/22 12:02:26 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start ti",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:3325,Security,Secur,SecurityManager,3325,"RN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:80",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:3403,Security,Secur,SecurityManager,3403, back to uploading libraries under SPARK_HOME.; 20/10/22 12:02:29 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INF,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:3481,Security,Secur,SecurityManager,3481,ent: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_libs__7655440475844189559.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: AC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:3561,Security,Secur,SecurityManager,3561,lication_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:36 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:37 INFO yarn.Client: Application report ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:3578,Security,Secur,SecurityManager,3578,lication_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:36 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:37 INFO yarn.Client: Application report ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:3595,Security,authenticat,authentication,3595,lication_1603353714322_0004/__spark_libs__7655440475844189559.zip; 20/10/22 12:02:31 INFO yarn.Client: Uploading resource file:/home/jacky/Exec/gatk/build/libs/gatk-spark.jar -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/gatk-spark.jar; 20/10/22 12:02:33 INFO yarn.Client: Uploading resource file:/tmp/spark-28ab5ef4-82d1-425e-879f-5056e9b51e43/__spark_conf__3248804172036151699.zip -> hdfs://192.168.0.104:9000/user/jacky/.sparkStaging/application_1603353714322_0004/__spark_conf__.zip; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls to: jacky; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing view acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: Changing modify acls groups to: ; 20/10/22 12:02:33 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(jacky); groups with view permissions: Set(); users with modify permissions: Set(jacky); groups with modify permissions: Set(); 20/10/22 12:02:33 INFO yarn.Client: Submitting application application_1603353714322_0004 to ResourceManager; 20/10/22 12:02:33 INFO impl.YarnClientImpl: Submitted application application_1603353714322_0004; 20/10/22 12:02:34 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:34 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: N/A; 	 ApplicationMaster host: N/A; 	 ApplicationMaster RPC port: -1; 	 queue: default; 	 start time: 1603360953394; 	 final status: UNDEFINED; 	 tracking URL: http://jacky:8088/proxy/application_1603353714322_0004/; 	 user: jacky; 20/10/22 12:02:35 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:36 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:37 INFO yarn.Client: Application report ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:13,Testability,test,test,13,"Hi, ; when i test gatk4 MarkDuplicatesSpark command on yarn cluster, i encountered an issue ""non zero exit code 13"". How can i fix it ? . Here is my command and what i received from the terminal :; ****; gatk MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt -- --spark-runner SPARK --deploy-mode cluster --spark-master yarn; Using GATK jar /home/jacky/Exec/gatk/build/libs/gatk-spark.jar; Running:; /home/jacky/spark/bin/spark-submit --master yarn --conf spark.driver.userClassPathFirst=false --conf spark.io.compression.codec=lzf --conf spark.executor.memoryOverhead=600 --conf spark.executor.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.driver.extraJavaOptions=-DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=false -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 --conf spark.kryoserializer.buffer.max=512m --conf spark.driver.maxResultSize=0 --deploy-mode cluster /home/jacky/Exec/gatk/build/libs/gatk-spark.jar MarkDuplicatesSpark -I hdfs://192.168.0.104:9000/user/jacky/NA12878.mapped.illumina.mosaik.CEU.exome.20110411.bam -O hdfs://192.168.0.104:9000/user/jacky/marked_dup.bam -M hdfs://192.168.0.104:9000/user/jacky/marked_dup_metrics.txt --spark-master yarn; 20/10/22 12:02:26 INFO client.RMProxy: Connecting to ResourceManager at /192.168.0.104:8032; 20/10/22 12:02:26 INFO yarn.Client: Requesting a new application from cluster with 2 NodeManagers; 20/10/22 12:02:26 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (1536 MB per container); 20/10/22 12:02:26 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6906:5870,Testability,log,logs,5870,"353714322_0004 (state: ACCEPTED); 20/10/22 12:02:38 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:39 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:40 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:41 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:42 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:43 INFO yarn.Client: Application report for application_1603353714322_0004 (state: ACCEPTED); 20/10/22 12:02:44 INFO yarn.Client: Application report for application_1603353714322_0004 (state: FAILED); 20/10/22 12:02:44 INFO yarn.Client: ; 	 client token: N/A; 	 diagnostics: Application application_1603353714322_0004 failed 2 times due to AM Container for appattempt_1603353714322_0004_000002 exited with exitCode: 13; For more detailed output, check application tracking page:http://jacky:8088/cluster/app/application_1603353714322_0004Then, click on links to logs of each attempt.; Diagnostics: Exception from container-launch.; Container id: container_1603353714322_0004_02_000001; Exit code: 13; Stack trace: ExitCodeException exitCode=13: ; 	at org.apache.hadoop.util.Shell.runCommand(Shell.java:545); 	at org.apache.hadoop.util.Shell.run(Shell.java:456); 	at org.apache.hadoop.util.Shell$ShellCommandExecutor.execute(Shell.java:722); 	at org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor.launchContainer(DefaultContainerExecutor.java:211); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:302); 	at org.apache.hadoop.yarn.server.nodemanager.containermanager.launcher.ContainerLaunch.call(ContainerLaunch.java:82); 	at java.util.concurrent.FutureTask.run(FutureTask.java:266); 	at java.util.concurrent.ThreadPoolExecut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6906
https://github.com/broadinstitute/gatk/issues/6910:238,Availability,error,error,238,"Hello,. I am running GenotypeGVCFs using a GenomicsDB workspace with ~1200 WGS samples as input. We're running these jobs scattered on a slurm/lustre cluster, with each job given intervals. ~197/200 jobs finished, but several gave an odd error. I'm probably not giving you enough information to debug, but maybe this is enough to ask questions. the command is below:. ```. java8 -Xmx48g -Xms48g -Xss2m \; -jar GenomeAnalysisTK4.jar GenotypeGVCFs \; -R REF.fasta \; --variant gendb://<genomicsdb_path> \; -O OUTPUT.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 --max-alternate-alleles 12 \; -L <Repeated ~40 times for small contigs>. ```; ; The error is the following:. ```. 21:58:51.873 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location QNVO02001146.1:1343; --; 21:59:01.308 INFO ProgressMeter - QNVO02001146.1:1679 425.0 1264000 2974.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.825391631999999,Cpu time(s),6.825079531999995; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fcca9a2ea19, pid=36873, tid=140574431450880; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 ); # Problematic frame:; # C [libtiledbgenomicsdb3086049122144672414.so+0x3e3a19] ArraySchema::tile_num(void const*) const+0x79; #; # Core dump written. Default location: /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/core or core.36873; #; # An error report file with more information is saved as:; # /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/hs_err_pid36873.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910
https://github.com/broadinstitute/gatk/issues/6910:670,Availability,error,error,670,"Hello,. I am running GenotypeGVCFs using a GenomicsDB workspace with ~1200 WGS samples as input. We're running these jobs scattered on a slurm/lustre cluster, with each job given intervals. ~197/200 jobs finished, but several gave an odd error. I'm probably not giving you enough information to debug, but maybe this is enough to ask questions. the command is below:. ```. java8 -Xmx48g -Xms48g -Xss2m \; -jar GenomeAnalysisTK4.jar GenotypeGVCFs \; -R REF.fasta \; --variant gendb://<genomicsdb_path> \; -O OUTPUT.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 --max-alternate-alleles 12 \; -L <Repeated ~40 times for small contigs>. ```; ; The error is the following:. ```. 21:58:51.873 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location QNVO02001146.1:1343; --; 21:59:01.308 INFO ProgressMeter - QNVO02001146.1:1679 425.0 1264000 2974.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.825391631999999,Cpu time(s),6.825079531999995; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fcca9a2ea19, pid=36873, tid=140574431450880; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 ); # Problematic frame:; # C [libtiledbgenomicsdb3086049122144672414.so+0x3e3a19] ArraySchema::tile_num(void const*) const+0x79; #; # Core dump written. Default location: /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/core or core.36873; #; # An error report file with more information is saved as:; # /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/hs_err_pid36873.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910
https://github.com/broadinstitute/gatk/issues/6910:1092,Availability,error,error,1092,"b given intervals. ~197/200 jobs finished, but several gave an odd error. I'm probably not giving you enough information to debug, but maybe this is enough to ask questions. the command is below:. ```. java8 -Xmx48g -Xms48g -Xss2m \; -jar GenomeAnalysisTK4.jar GenotypeGVCFs \; -R REF.fasta \; --variant gendb://<genomicsdb_path> \; -O OUTPUT.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 --max-alternate-alleles 12 \; -L <Repeated ~40 times for small contigs>. ```; ; The error is the following:. ```. 21:58:51.873 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location QNVO02001146.1:1343; --; 21:59:01.308 INFO ProgressMeter - QNVO02001146.1:1679 425.0 1264000 2974.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.825391631999999,Cpu time(s),6.825079531999995; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fcca9a2ea19, pid=36873, tid=140574431450880; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 ); # Problematic frame:; # C [libtiledbgenomicsdb3086049122144672414.so+0x3e3a19] ArraySchema::tile_num(void const*) const+0x79; #; # Core dump written. Default location: /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/core or core.36873; #; # An error report file with more information is saved as:; # /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/hs_err_pid36873.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ```. Do you have an debugging suggestions based on this? Than",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910
https://github.com/broadinstitute/gatk/issues/6910:1693,Availability,error,error,1693,"ls. ~197/200 jobs finished, but several gave an odd error. I'm probably not giving you enough information to debug, but maybe this is enough to ask questions. the command is below:. ```. java8 -Xmx48g -Xms48g -Xss2m \; -jar GenomeAnalysisTK4.jar GenotypeGVCFs \; -R REF.fasta \; --variant gendb://<genomicsdb_path> \; -O OUTPUT.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 --max-alternate-alleles 12 \; -L <Repeated ~40 times for small contigs>. ```; ; The error is the following:. ```. 21:58:51.873 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location QNVO02001146.1:1343; --; 21:59:01.308 INFO ProgressMeter - QNVO02001146.1:1679 425.0 1264000 2974.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.825391631999999,Cpu time(s),6.825079531999995; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fcca9a2ea19, pid=36873, tid=140574431450880; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 ); # Problematic frame:; # C [libtiledbgenomicsdb3086049122144672414.so+0x3e3a19] ArraySchema::tile_num(void const*) const+0x79; #; # Core dump written. Default location: /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/core or core.36873; #; # An error report file with more information is saved as:; # /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/hs_err_pid36873.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ```. Do you have an debugging suggestions based on this? Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910
https://github.com/broadinstitute/gatk/issues/6910:1107,Safety,detect,detected,1107,"b given intervals. ~197/200 jobs finished, but several gave an odd error. I'm probably not giving you enough information to debug, but maybe this is enough to ask questions. the command is below:. ```. java8 -Xmx48g -Xms48g -Xss2m \; -jar GenomeAnalysisTK4.jar GenotypeGVCFs \; -R REF.fasta \; --variant gendb://<genomicsdb_path> \; -O OUTPUT.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 --max-alternate-alleles 12 \; -L <Repeated ~40 times for small contigs>. ```; ; The error is the following:. ```. 21:58:51.873 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location QNVO02001146.1:1343; --; 21:59:01.308 INFO ProgressMeter - QNVO02001146.1:1679 425.0 1264000 2974.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.825391631999999,Cpu time(s),6.825079531999995; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fcca9a2ea19, pid=36873, tid=140574431450880; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 ); # Problematic frame:; # C [libtiledbgenomicsdb3086049122144672414.so+0x3e3a19] ArraySchema::tile_num(void const*) const+0x79; #; # Core dump written. Default location: /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/core or core.36873; #; # An error report file with more information is saved as:; # /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/hs_err_pid36873.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ```. Do you have an debugging suggestions based on this? Than",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910
https://github.com/broadinstitute/gatk/issues/6910:1865,Testability,log,log,1865,"ls. ~197/200 jobs finished, but several gave an odd error. I'm probably not giving you enough information to debug, but maybe this is enough to ask questions. the command is below:. ```. java8 -Xmx48g -Xms48g -Xss2m \; -jar GenomeAnalysisTK4.jar GenotypeGVCFs \; -R REF.fasta \; --variant gendb://<genomicsdb_path> \; -O OUTPUT.vcf.gz \; --annotate-with-num-discovered-alleles \; -stand-call-conf 30 --max-alternate-alleles 12 \; -L <Repeated ~40 times for small contigs>. ```; ; The error is the following:. ```. 21:58:51.873 WARN MinimalGenotypingEngine - Attempting to genotype more than 50 alleles. Site will be skipped at location QNVO02001146.1:1343; --; 21:59:01.308 INFO ProgressMeter - QNVO02001146.1:1679 425.0 1264000 2974.3; GENOMICSDB_TIMER,GenomicsDB iterator next() timer,Wall-clock time(s),6.825391631999999,Cpu time(s),6.825079531999995; #; # A fatal error has been detected by the Java Runtime Environment:; #; # SIGSEGV (0xb) at pc=0x00007fcca9a2ea19, pid=36873, tid=140574431450880; #; # JRE version: Java(TM) SE Runtime Environment (8.0_60-b27) (build 1.8.0_60-b27); # Java VM: Java HotSpot(TM) 64-Bit Server VM (25.60-b23 mixed mode linux-amd64 ); # Problematic frame:; # C [libtiledbgenomicsdb3086049122144672414.so+0x3e3a19] ArraySchema::tile_num(void const*) const+0x79; #; # Core dump written. Default location: /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/core or core.36873; #; # An error report file with more information is saved as:; # /home/groups/MgapGenomicsDb/@files/sequenceOutputPipeline/SequenceOutput_2020-10-06_16-46-33/Job734/hs_err_pid36873.log; #; # If you would like to submit a bug report, please visit:; # http://bugreport.java.com/bugreport/crash.jsp; # The crash happened outside the Java Virtual Machine in native code.; # See problematic frame for where to report the bug.; #. ```. Do you have an debugging suggestions based on this? Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6910
https://github.com/broadinstitute/gatk/issues/6911:32,Availability,error,error,32,"Hi, I encountered the following error while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:3266,Availability,down,down,3266,"R_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:4926,Integrability,wrap,wrapAndCopyInto,4926,; 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$76/1710491273.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:163); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:206); 	at org.broadinstitut,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:758,Performance,Load,Loading,758,"Hi, I encountered the following error while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:3055,Performance,perform,performed,3055,"19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1041,Safety,detect,detect,1041,"r while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:182,Security,Validat,ValidateVariants,182,"Hi, I encountered the following error while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:604,Security,Validat,ValidateVariants,604,"Hi, I encountered the following error while running GATK.; It is hard for me to say what exactly is wrong, and extensive searching has not been helpul. Thanks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVarian",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1116,Security,Validat,ValidateVariants,1116,"ks in advance!. ```; gatk ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Default",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1215,Security,Validat,ValidateVariants,1215,".rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; Using GATK jar ~/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1297,Security,Validat,ValidateVariants,1297,"8.0/gatk-package-4.1.8.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1413,Security,Validat,ValidateVariants,1413,"ync_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: Intel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1541,Security,Validat,ValidateVariants,1541,"0/gatk-package-4.1.8.0-local.jar ValidateVariants -V ../../data/geno/phased/chr1-22.phased.rename.reheader.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1641,Security,Validat,ValidateVariants,1641,"er.vcf.gz -R ../../../../index/hg19.fa.gz; 19:53:34.379 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - I",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1728,Security,Validat,ValidateVariants,1728,"bgkl_compression.so from jar:file:/home/zepengmu/tools/gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1827,Security,Validat,ValidateVariants,1827,"/com/intel/gkl/native/libgkl_compression.so; Oct 25, 2020 7:53:34 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing en",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1926,Security,Validat,ValidateVariants,1926,"ed.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:1987,Security,Validat,ValidateVariants,1987,"runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN Valida",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2048,Security,Validat,ValidateVariants,2048,"e running on Google Compute Engine.; 19:53:34.606 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be perfor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2124,Security,Validat,ValidateVariants,2124,"----------------------------------------------------------; 19:53:34.606 INFO ValidateVariants - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2217,Security,Validat,ValidateVariants,2217,"s - The Genome Analysis Toolkit (GATK) v4.1.8.0; 19:53:34.606 INFO ValidateVariants - For support and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.6",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2310,Security,Validat,ValidateVariants,2310,"port and documentation go to https://software.broadinstitute.org/gatk/; 19:53:34.607 INFO ValidateVariants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2403,Security,Validat,ValidateVariants,2403,"ants - Executing as zepengmu@midway2-login1.rcc.local on Linux v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Run",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2465,Security,Validat,ValidateVariants,2465," v3.10.0-1127.8.2.el7.x86_64 amd64; 19:53:34.607 INFO ValidateVariants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBounds",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2527,Security,Validat,ValidateVariants,2527,"riants - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2593,Security,Validat,ValidateVariants,2593,"45-b14; 19:53:34.607 INFO ValidateVariants - Start Date/Time: October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2656,Security,Validat,ValidateVariants,2656," October 25, 2020 7:53:34 PM CDT; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - ------------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2829,Security,Validat,ValidateVariants,2829,"-------------------------------------------------------; 19:53:34.607 INFO ValidateVariants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadins",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2892,Security,Validat,ValidateVariants,2892,"Variants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2915,Security,validat,validation,2915,"Variants - HTSJDK Version: 2.22.0; 19:53:34.607 INFO ValidateVariants - Picard Version: 2.22.8; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.j",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:2995,Security,Validat,ValidateVariants,2995,"19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:3029,Security,validat,validations,3029,"19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:3238,Security,Validat,ValidateVariants,3238,"R_SAMTOOLS : true; 19:53:34.608 INFO ValidateVariants - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.h",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:3370,Security,Validat,ValidateVariants,3370,"se; 19:53:34.608 INFO ValidateVariants - Deflater: IntelDeflater; 19:53:34.608 INFO ValidateVariants - Inflater: IntelInflater; 19:53:34.608 INFO ValidateVariants - GCS max retries/reopens: 20; 19:53:34.608 INFO ValidateVariants - Requester pays: disabled; 19:53:34.608 INFO ValidateVariants - Initializing engine; 19:53:35.169 INFO FeatureManager - Using codec VCFCodec to read file file://chr1-22.phased.rename.reheader.vcf.gz; 19:53:35.594 INFO ValidateVariants - Done initializing engine; 19:53:35.594 WARN ValidateVariants - IDS validation cannot be done because no DBSNP file was provided; 19:53:35.594 WARN ValidateVariants - Other possible validations will still be performed; 19:53:35.594 INFO ProgressMeter - Starting traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$76/1710491273.accept(Unknown Source); 	at java.util.stream.ForEachOps",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:4100,Security,Validat,ValidateVariants,4100," traversal; 19:53:35.595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$76/1710491273.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluate",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6911:4123,Security,Validat,ValidateVariants,4123,".595 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 19:53:35.660 INFO ValidateVariants - Shutting down engine; [October 25, 2020 7:53:35 PM CDT] org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=2114453504; java.lang.ArrayIndexOutOfBoundsException: -87; 	at org.broadinstitute.hellbender.utils.BaseUtils.convertIUPACtoN(BaseUtils.java:123); 	at org.broadinstitute.hellbender.utils.fasta.CachingIndexedFastaSequenceFile.getSubsequenceAt(CachingIndexedFastaSequenceFile.java:340); 	at org.broadinstitute.hellbender.engine.ReferenceFileSource.queryAndPrefetch(ReferenceFileSource.java:78); 	at org.broadinstitute.hellbender.engine.ReferenceDataSource.queryAndPrefetch(ReferenceDataSource.java:64); 	at org.broadinstitute.hellbender.engine.ReferenceContext.getBases(ReferenceContext.java:197); 	at org.broadinstitute.hellbender.tools.walkers.variantutils.ValidateVariants.apply(ValidateVariants.java:236); 	at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104); 	at org.broadinstitute.hellbender.engine.VariantWalker$$Lambda$76/1710491273.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6911
https://github.com/broadinstitute/gatk/issues/6912:519,Availability,down,download,519,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912
https://github.com/broadinstitute/gatk/issues/6912:36,Deployability,release,release,36,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912
https://github.com/broadinstitute/gatk/issues/6912:111,Deployability,release,release,111,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912
https://github.com/broadinstitute/gatk/issues/6912:291,Deployability,update,update,291,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912
https://github.com/broadinstitute/gatk/issues/6912:298,Deployability,release,release,298,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912
https://github.com/broadinstitute/gatk/issues/6912:389,Deployability,update,updated,389,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912
https://github.com/broadinstitute/gatk/issues/6912:629,Deployability,release,release,629,"## Feature request. ### DRAGEN-GATK release?!!; Hello GATK team, ; - When will the DRAGEN-GATK version will be release officially? I have seen the online forum of Eric brans and Illumina head explaining GATK and DRAGEN about the open source version, a month back! I searched for DRAGEN-GATK update release in both the illumina website and GATK, couldn't find it? can anyone help me to get updated GATK.. and do I need dragen 3.4 for that? till 3.4.12 I haven't seen any mention of GATK in that.. which version I should download?. - Is there any feature in upcoming GATK to find STR variants.. If its in progress when it will get release?; ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6912
https://github.com/broadinstitute/gatk/issues/6913:211,Availability,error,error,211,"Hi, . I have the same issue reported here https://github.com/broadinstitute/gatk/issues/6766 that relates to CombineGVCFs. It was supposed to be fixed with the new version 4.1.9.0, however. I still get the same error when I tried it with the current version. . Here is the error report . > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/orange/reed/nhouse/Raw_seqs/SEQ9_samples/tmp; 11:30:50.248 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 11:30:50.478 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 26, 2020 11:30:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:30:50.791 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.791 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.9.0; 11:30:50.792 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:30:50.792 INFO CombineGVCFs - Executing as nwijewardena@c3a-s8.ufhpc on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 11:30:50.792 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 11:30:50.792 INFO CombineGVCFs - Start Date/Time: October 26, 2020 11:30:50 AM EDT; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.794 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 11:30:50.794 INFO CombineGVCFs - Picard Version: 2.23.3; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:273,Availability,error,error,273,"Hi, . I have the same issue reported here https://github.com/broadinstitute/gatk/issues/6766 that relates to CombineGVCFs. It was supposed to be fixed with the new version 4.1.9.0, however. I still get the same error when I tried it with the current version. . Here is the error report . > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/orange/reed/nhouse/Raw_seqs/SEQ9_samples/tmp; 11:30:50.248 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 11:30:50.478 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 26, 2020 11:30:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:30:50.791 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.791 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.9.0; 11:30:50.792 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:30:50.792 INFO CombineGVCFs - Executing as nwijewardena@c3a-s8.ufhpc on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 11:30:50.792 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 11:30:50.792 INFO CombineGVCFs - Start Date/Time: October 26, 2020 11:30:50 AM EDT; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.794 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 11:30:50.794 INFO CombineGVCFs - Picard Version: 2.23.3; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:430,Availability,Redundant,Redundant,430,"Hi, . I have the same issue reported here https://github.com/broadinstitute/gatk/issues/6766 that relates to CombineGVCFs. It was supposed to be fixed with the new version 4.1.9.0, however. I still get the same error when I tried it with the current version. . Here is the error report . > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/orange/reed/nhouse/Raw_seqs/SEQ9_samples/tmp; 11:30:50.248 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 11:30:50.478 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 26, 2020 11:30:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:30:50.791 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.791 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.9.0; 11:30:50.792 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:30:50.792 INFO CombineGVCFs - Executing as nwijewardena@c3a-s8.ufhpc on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 11:30:50.792 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 11:30:50.792 INFO CombineGVCFs - Start Date/Time: October 26, 2020 11:30:50 AM EDT; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.794 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 11:30:50.794 INFO CombineGVCFs - Picard Version: 2.23.3; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:7146,Availability,down,down,7146,"nager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS184_1.raw_variants.g.vcf; 11:30:53.894 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS201_1.raw_variants.g.vcf; 11:30:54.000 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS209_1.raw_variants.g.vcf; 11:34:25.030 INFO CombineGVCFs - Done initializing engine; 11:34:25.154 INFO ProgressMeter - Starting traversal; 11:34:25.155 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:34:25.473 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location DS235882:44 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 11:34:25.944 INFO CombineGVCFs - Shutting down engine; [October 26, 2020 11:34:25 AM EDT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 3.59 minutes.; Runtime.totalMemory()=3738173440; java.lang.NumberFormatException: empty String; 	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842); 	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); 	at java.lang.Double.parseDouble(Double.java:538); 	at htsjdk.variant.vcf.VCFUtils.parseVcfDouble(VCFUtils.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:808); 	at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:121); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.ensureSampleNameMap(LazyGenotypesContext.java:180); 	at htsjdk.variant.variantcontext.GenotypesContext.getSampleNames(GenotypesContext.java:646); 	at htsjdk.variant.variantcontext.VariantContex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:11165,Availability,error,error,11165,"erencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar. I was planning on Combining 25 samples at a time (per library), out of 250 (Not sure if this was even the right move). But the issue comes up for only certain libraries. All the samples (250) were processed exactly the same way. Not sure what is causing it to throw out this error for some only.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:9631,Integrability,wrap,wrapAndCopyInto,9631,lkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:131); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.apply(MultiVariantWalkerGroupedOnStart.java:106); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker$$Lambda$110/1374115041.accept(Unknown Source); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); 	at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); 	at java.util.Iterator.forEachRemaining(Iterator.java:116); 	at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); 	at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); 	at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); 	at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150); 	at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173); 	at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); 	at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); 	at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); 	at org.broadinstitute.hellbender.engine.MultiVariantWalkerGroupedOnStart.traverse(MultiVariantWalkerGroupedOnStart.java:163); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:563,Performance,Load,Loading,563,"Hi, . I have the same issue reported here https://github.com/broadinstitute/gatk/issues/6766 that relates to CombineGVCFs. It was supposed to be fixed with the new version 4.1.9.0, however. I still get the same error when I tried it with the current version. . Here is the error report . > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/orange/reed/nhouse/Raw_seqs/SEQ9_samples/tmp; 11:30:50.248 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 11:30:50.478 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 26, 2020 11:30:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:30:50.791 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.791 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.9.0; 11:30:50.792 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:30:50.792 INFO CombineGVCFs - Executing as nwijewardena@c3a-s8.ufhpc on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 11:30:50.792 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 11:30:50.792 INFO CombineGVCFs - Start Date/Time: October 26, 2020 11:30:50 AM EDT; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.794 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 11:30:50.794 INFO CombineGVCFs - Picard Version: 2.23.3; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:430,Safety,Redund,Redundant,430,"Hi, . I have the same issue reported here https://github.com/broadinstitute/gatk/issues/6766 that relates to CombineGVCFs. It was supposed to be fixed with the new version 4.1.9.0, however. I still get the same error when I tried it with the current version. . Here is the error report . > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/orange/reed/nhouse/Raw_seqs/SEQ9_samples/tmp; 11:30:50.248 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 11:30:50.478 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 26, 2020 11:30:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:30:50.791 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.791 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.9.0; 11:30:50.792 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:30:50.792 INFO CombineGVCFs - Executing as nwijewardena@c3a-s8.ufhpc on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 11:30:50.792 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 11:30:50.792 INFO CombineGVCFs - Start Date/Time: October 26, 2020 11:30:50 AM EDT; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.794 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 11:30:50.794 INFO CombineGVCFs - Picard Version: 2.23.3; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:832,Safety,detect,detect,832,"Hi, . I have the same issue reported here https://github.com/broadinstitute/gatk/issues/6766 that relates to CombineGVCFs. It was supposed to be fixed with the new version 4.1.9.0, however. I still get the same error when I tried it with the current version. . Here is the error report . > Picked up _JAVA_OPTIONS: -Djava.io.tmpdir=/orange/reed/nhouse/Raw_seqs/SEQ9_samples/tmp; 11:30:50.248 WARN GATKAnnotationPluginDescriptor - Redundant enabled annotation group (StandardAnnotation) is enabled for this tool by default; 11:30:50.478 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/apps/gatk/4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 26, 2020 11:30:50 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 11:30:50.791 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.791 INFO CombineGVCFs - The Genome Analysis Toolkit (GATK) v4.1.9.0; 11:30:50.792 INFO CombineGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 11:30:50.792 INFO CombineGVCFs - Executing as nwijewardena@c3a-s8.ufhpc on Linux v3.10.0-1062.18.1.el7.x86_64 amd64; 11:30:50.792 INFO CombineGVCFs - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 11:30:50.792 INFO CombineGVCFs - Start Date/Time: October 26, 2020 11:30:50 AM EDT; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.793 INFO CombineGVCFs - ------------------------------------------------------------; 11:30:50.794 INFO CombineGVCFs - HTSJDK Version: 2.23.0; 11:30:50.794 INFO CombineGVCFs - Picard Version: 2.23.3; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 11:30:50.794 INFO CombineGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRI",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6913:6941,Safety,Detect,Detected,6941,"dec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS02_1.raw_variants.g.vcf; 11:30:53.805 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS184_1.raw_variants.g.vcf; 11:30:53.894 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS201_1.raw_variants.g.vcf; 11:30:54.000 INFO FeatureManager - Using codec VCFCodec to read file file:///orange/reed/nhouse/Raw_seqs/SEQ1_samples/SEQ1_gvcf/renamed_seq1trimq10_LHA_AS209_1.raw_variants.g.vcf; 11:34:25.030 INFO CombineGVCFs - Done initializing engine; 11:34:25.154 INFO ProgressMeter - Starting traversal; 11:34:25.155 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 11:34:25.473 WARN ReferenceConfidenceVariantContextMerger - Detected invalid annotations: When trying to merge variant contexts at location DS235882:44 the annotation MLEAC=[1, 0] was not a numerical value and was ignored; 11:34:25.944 INFO CombineGVCFs - Shutting down engine; [October 26, 2020 11:34:25 AM EDT] org.broadinstitute.hellbender.tools.walkers.CombineGVCFs done. Elapsed time: 3.59 minutes.; Runtime.totalMemory()=3738173440; java.lang.NumberFormatException: empty String; 	at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1842); 	at sun.misc.FloatingDecimal.parseDouble(FloatingDecimal.java:110); 	at java.lang.Double.parseDouble(Double.java:538); 	at htsjdk.variant.vcf.VCFUtils.parseVcfDouble(VCFUtils.java:262); 	at htsjdk.variant.vcf.AbstractVCFCodec.createGenotypeMap(AbstractVCFCodec.java:808); 	at htsjdk.variant.vcf.AbstractVCFCodec$LazyVCFGenotypesParser.parse(AbstractVCFCodec.java:121); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.decode(LazyGenotypesContext.java:158); 	at htsjdk.variant.variantcontext.LazyGenotypesContext.ensureSampleNameMap(LazyGenotypesContex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6913
https://github.com/broadinstitute/gatk/issues/6915:0,Availability,Error,Error,0,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6915:97,Availability,error,error,97,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6915:583,Availability,error,error,583,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6915:778,Availability,error,error,778,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6915:6,Integrability,Message,Message,6,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6915:103,Integrability,message,message,103,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6915:1974,Integrability,wrap,wrapAndCopyInto,1974,tute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:474) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:150) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:173) ; ; at java.base/java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234) ; ; at java.base/java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:497) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.traverse(VariantWalker.java:102) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211) ; ; at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160) ; ; at org.broadinstitute.h,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6915:784,Testability,log,log,784,"Error Message from VariantAnnotator is a NullPointerException. The user found the issue, but the error message could be improved. The issue involves the sample names from the VCF not existing in the BAM file. . This request was created from a contribution made by Wout Megchelenbrink on October 21, 2020 12:29 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException](https://gatk.broadinstitute.org/hc/en-us/community/posts/360073989631-VariantAnnotator-returns-NullPointerException). \--. If you are seeing an error, please provide(REQUIRED) : ; ; **a) GATK version used:**. 4.1.8.1. **b) Exact command used:**. gatk VariantAnnotator -V WES.vcf.gz -I WES.bam --output WES\_VA.vcf -A Coverage. **c) Entire error log:**. java.lang.NullPointerException ; ; at org.broadinstitute.hellbender.tools.walkers.haplotypecaller.AssemblyBasedCallerUtils.splitReadsBySample(AssemblyBasedCallerUtils.java:162) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.makeLikelihoods(VariantAnnotator.java:244) ; ; at org.broadinstitute.hellbender.tools.walkers.annotator.VariantAnnotator.apply(VariantAnnotator.java:234) ; ; at org.broadinstitute.hellbender.engine.VariantWalker.lambda$traverse$0(VariantWalker.java:104) ; ; at java.base/java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:183) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:177) ; ; at java.base/java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:195) ; ; at java.base/java.util.Iterator.forEachRemaining(Iterator.java:133) ; ; at java.base/java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801) ; ; at java.base/java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:484) ; ; at java.base/java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPip",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6915
https://github.com/broadinstitute/gatk/issues/6916:173,Deployability,integrat,integrated,173,"To support running CARROT tests from PR comments, it's necessary that the [carrot-publish-github-action ](https://github.com/broadinstitute/carrot-publish-github-action) be integrated following the instructions in the README for that repo, so that PR comments will be processed by the GitHub action. This also requires that secrets be set for the pubsub topic and SA key for sending the messages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6916
https://github.com/broadinstitute/gatk/issues/6916:173,Integrability,integrat,integrated,173,"To support running CARROT tests from PR comments, it's necessary that the [carrot-publish-github-action ](https://github.com/broadinstitute/carrot-publish-github-action) be integrated following the instructions in the README for that repo, so that PR comments will be processed by the GitHub action. This also requires that secrets be set for the pubsub topic and SA key for sending the messages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6916
https://github.com/broadinstitute/gatk/issues/6916:387,Integrability,message,messages,387,"To support running CARROT tests from PR comments, it's necessary that the [carrot-publish-github-action ](https://github.com/broadinstitute/carrot-publish-github-action) be integrated following the instructions in the README for that repo, so that PR comments will be processed by the GitHub action. This also requires that secrets be set for the pubsub topic and SA key for sending the messages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6916
https://github.com/broadinstitute/gatk/issues/6916:26,Testability,test,tests,26,"To support running CARROT tests from PR comments, it's necessary that the [carrot-publish-github-action ](https://github.com/broadinstitute/carrot-publish-github-action) be integrated following the instructions in the README for that repo, so that PR comments will be processed by the GitHub action. This also requires that secrets be set for the pubsub topic and SA key for sending the messages.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6916
https://github.com/broadinstitute/gatk/pull/6917:364,Integrability,message,messages,364,"Added a workflow file for enabling the GitHub Action which processes PR comments to determine if they are meant to trigger and CARROT test, and then processes them if they are formatted in that way. BIG IMPORTANT NOTE: Before this is merged, we need to set two secrets for this repo:; - `CARROT_TOPIC_NAME`, which is the name of the Google Cloud PubSub topic that messages will be sent to if a comment should trigger a run, and; - `CARROT_SA_KEY`, which is the service account key JSON for the service account that has write access to the PubSub topic.; If this is merged before those are set, I'm fairly confident we're just gonna get an email saying the action failed each time someone posts a PR comment (CARROT or otherwise), which would be less than ideal. Closes #6916",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6917
https://github.com/broadinstitute/gatk/pull/6917:525,Security,access,access,525,"Added a workflow file for enabling the GitHub Action which processes PR comments to determine if they are meant to trigger and CARROT test, and then processes them if they are formatted in that way. BIG IMPORTANT NOTE: Before this is merged, we need to set two secrets for this repo:; - `CARROT_TOPIC_NAME`, which is the name of the Google Cloud PubSub topic that messages will be sent to if a comment should trigger a run, and; - `CARROT_SA_KEY`, which is the service account key JSON for the service account that has write access to the PubSub topic.; If this is merged before those are set, I'm fairly confident we're just gonna get an email saying the action failed each time someone posts a PR comment (CARROT or otherwise), which would be less than ideal. Closes #6916",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6917
https://github.com/broadinstitute/gatk/pull/6917:134,Testability,test,test,134,"Added a workflow file for enabling the GitHub Action which processes PR comments to determine if they are meant to trigger and CARROT test, and then processes them if they are formatted in that way. BIG IMPORTANT NOTE: Before this is merged, we need to set two secrets for this repo:; - `CARROT_TOPIC_NAME`, which is the name of the Google Cloud PubSub topic that messages will be sent to if a comment should trigger a run, and; - `CARROT_SA_KEY`, which is the service account key JSON for the service account that has write access to the PubSub topic.; If this is merged before those are set, I'm fairly confident we're just gonna get an email saying the action failed each time someone posts a PR comment (CARROT or otherwise), which would be less than ideal. Closes #6916",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6917
https://github.com/broadinstitute/gatk/issues/6919:958,Usability,simpl,simply,958,"## Bug Report. ### Affected tool(s) or class(es); FindMendelianViolations. ### Affected version(s); Version:4.1.8.1 and several earlier versions. ### Description ; Using the gatk FindMendelianViolations --help command to obtain information about this tool produces the following for the default XPAR regions:; --PSEUDO_AUTOSOMAL_REGIONS:String; List of chr:start-end for pseudo-autosomal regions on the female sex chromosome. Defaults; to HG19/b37 & HG38 coordinates. This argument may be specified 0 or more times. Default; value: [chrX:10000-2781479, X:10001-2649520, chrX:155701382-156030895,; X:59034050-59373566]. . These co-ordinates are also replicated in the output file. From the GRC site the co-ordinates for the b37 regions should be X:600001-2699520 and X:154931044-155260560 whereas those used by default seem to correspond to the Y chromosome values for b37.; When trying to correct this issue by using the --PSEUDO_AUTOSOMAL_REGIONS option it simply adds the newly defined regions to the command rather than replacing the defaults.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6919
https://github.com/broadinstitute/gatk/pull/6920:18,Deployability,update,update,18,- Creating PR for update to Funcotator documentation and to show off CARROT integration.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6920
https://github.com/broadinstitute/gatk/pull/6920:76,Deployability,integrat,integration,76,- Creating PR for update to Funcotator documentation and to show off CARROT integration.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6920
https://github.com/broadinstitute/gatk/pull/6920:76,Integrability,integrat,integration,76,- Creating PR for update to Funcotator documentation and to show off CARROT integration.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6920
https://github.com/broadinstitute/gatk/issues/6922:1138,Deployability,update,update,1138,"s users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the images owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are anonymous and will be rate limited based on IP address rather than user ID. For more information on authenticating image pulls, please see this docs page.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922
https://github.com/broadinstitute/gatk/issues/6922:1553,Deployability,update,updates,1553,"s users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the images owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are anonymous and will be rate limited based on IP address rather than user ID. For more information on authenticating image pulls, please see this docs page.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922
https://github.com/broadinstitute/gatk/issues/6922:1541,Energy Efficiency,consumption,consumption-updates,1541,"s users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the images owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are anonymous and will be rate limited based on IP address rather than user ID. For more information on authenticating image pulls, please see this docs page.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922
https://github.com/broadinstitute/gatk/issues/6922:665,Security,authenticat,authenticated,665,"Evidently docker is changing their policy around anonymous users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the images owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are anonymous and will be rate limited based on IP address rather than user ID. For more information on aut",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922
https://github.com/broadinstitute/gatk/issues/6922:1998,Security,authenticat,authenticating,1998,"s users pulling from all docker repos (regardless of the tier for the owner of the repository being pulled from). This might or might not affect us since it looks like travis is pulling from our GCR repo for builds but we should be mindful of workflows that might rely on pulling hundreds of docker images from docker-hub through anonymous web VMs:; ```; On Monday, November 2, 2020 at 9am Pacific Standard Time, Docker will begin enforcing rate limits on container pulls for Anonymous and Free users. Anonymous (unauthenticated) users will be limited to 100 container image pulls every six hours, and Free (authenticated) users will be limited to 200 container image pulls every six hours, when enforcement is fully implemented. Docker Pro and Team subscribers can pull container images from Docker Hub without restriction, as long as the quantities are not excessive or abusive.; In addition, we are pausing enforcement of the changes to our image-retention policies until mid-2021, when we anticipate incorporating them into usage-based pricing. Two months ago, we announced an update to Docker image-retention policies. As originally stated, this change, which was set to take effect on November 1, 2020, would result in the deletion of images for free Docker account users after six months of inactivity. Today's announcement means Docker will not enforce image expiration on November 1, 2020.; ```; This is farther clarified on their FAQ https://www.docker.com/pricing/resource-consumption-updates:; ```; Rate limits for Docker image pulls are based on the account type of the user requesting the image - not the account type of the images owner. These are defined on the pricing page.; The highest entitlement a user has, based on their personal account and any orgs they belong to, will be used. Unauthenticated pull requests are anonymous and will be rate limited based on IP address rather than user ID. For more information on authenticating image pulls, please see this docs page.; ```",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6922
https://github.com/broadinstitute/gatk/issues/6924:250,Availability,error,error,250,"#6055 Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls. ### Affected version(s); 4.1.8.1. ### Description ; Process of calling copy number segments and consolidate sample results with PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order.""; I tried to detect germline copy number in cohort mode on 73 wgs samples by [this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For supp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:628,Availability,error,error,628,"#6055 Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls. ### Affected version(s); 4.1.8.1. ### Description ; Process of calling copy number segments and consolidate sample results with PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order.""; I tried to detect germline copy number in cohort mode on 73 wgs samples by [this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For supp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:4996,Availability,down,down,4996,":43:34.915 INFO PostprocessGermlineCNVCalls - Writing intervals VCF file to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.vcf...; 12:43:34.916 INFO PostprocessGermlineCNVCalls - Analyzing shard 1 / 3...; 12:43:37.965 INFO PostprocessGermlineCNVCalls - Analyzing shard 2 / 3...; 12:43:40.679 INFO PostprocessGermlineCNVCalls - Analyzing shard 3 / 3...; 12:43:43.248 INFO PostprocessGermlineCNVCalls - Generating segments VCF file...; 12:44:50.045 INFO PostprocessGermlineCNVCalls - Writing segments VCF file to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.segments.vcf...; 12:44:50.129 INFO PostprocessGermlineCNVCalls - Generating denoised copy ratios...; 12:44:50.928 INFO PostprocessGermlineCNVCalls - Writing denoised copy ratios to /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19/vcfs/sample.copy_ratios.tsv...; 12:44:51.493 INFO PostprocessGermlineCNVCalls - PostprocessGermlineCNVCalls complete.; 12:44:51.493 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 12:44:51 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 1.40 minutes.; Runtime.totalMemory()=4294443008; Using GATK jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar PostprocessGermlineCNVCalls --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_10/cohort-model/ --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0002_of_10/cohort-model/ --model-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0003_of_10/cohort-model/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:6906,Availability,error,error,6906,"mp_0003_of_10/cohort-model/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0001_of_10/cohort-calls/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0002_of_10/cohort-calls/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0003_of_10/cohort-calls/ --allosomal-contig chrX --allosomal-contig chrY --contig-ploidy-calls /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_ploidy//cohort-calls/ --sample-index 16 --output-genotyped-intervals /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.intervals.vcf --output-genotyped-segments /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.segments.vcf --sequence-dictionary /home/lmbs02/bio/databases/referenses/hg19_37/ucsc/hg19.dict --output-denoised-copy-ratios /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.copy_ratios.tsv `. In the same time, if you use the first 4 or the third and 4 at the same time, an error pops up.; `12:49:08.552 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:49:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:49:08.687 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:49:08.687 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:49:08.687 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Executing as lmbs02@Lmbs01 on Linux v5.4.0-48-generic amd64; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:9239,Availability,down,down,9239,"lls - HTSJDK Version: 2.23.0; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Picard Version: 2.22.8; 12:49:08.688 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:49:08.688 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:49:08.688 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:49:08.688 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Deflater: IntelDeflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Inflater: IntelInflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Requester pays: disabled; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Initializing engine; 12:49:12.598 INFO PostprocessGermlineCNVCalls - Done initializing engine; 12:49:15.678 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 12:49:15 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2457862144; java.lang.IllegalArgumentException: Records were not strictly sorted in dictionary order.; 	at org.broadinstitute.hellbender.tools.copynumber.arguments.CopyNumberArgumentValidationUtils.validateIntervals(CopyNumberArgumentValidationUtils.java:60); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.AbstractLocatableCollection.getShardedCollectionSortOrder(AbstractLocatableCollection.java:142); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:297); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParse",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:1392,Performance,Load,Loading,1392,"[this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:43:27.439 INFO PostprocessGermlineCNVCalls - Executing as lmbs02@Lmbs01 on Linux v5.4.0-48-generic amd64; 12:43:27.439 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 12:43:27.439 INFO PostprocessGermlineCNVCalls - Start Date/Time: October 29, 2020",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:6963,Performance,Load,Loading,6963,"ome_hg19//cohort_calls//temp_0001_of_10/cohort-calls/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0002_of_10/cohort-calls/ --calls-shard-path /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_calls//temp_0003_of_10/cohort-calls/ --allosomal-contig chrX --allosomal-contig chrY --contig-ploidy-calls /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_ploidy//cohort-calls/ --sample-index 16 --output-genotyped-intervals /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.intervals.vcf --output-genotyped-segments /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.segments.vcf --sequence-dictionary /home/lmbs02/bio/databases/referenses/hg19_37/ucsc/hg19.dict --output-denoised-copy-ratios /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.copy_ratios.tsv `. In the same time, if you use the first 4 or the third and 4 at the same time, an error pops up.; `12:49:08.552 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:49:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:49:08.687 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:49:08.687 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:49:08.687 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Executing as lmbs02@Lmbs01 on Linux v5.4.0-48-generic amd64; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Start Date/Time: October 29, 2020",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:238,Safety,abort,aborts,238,"#6055 Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls. ### Affected version(s); 4.1.8.1. ### Description ; Process of calling copy number segments and consolidate sample results with PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order.""; I tried to detect germline copy number in cohort mode on 73 wgs samples by [this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For supp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:326,Safety,detect,detect,326,"#6055 Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls. ### Affected version(s); 4.1.8.1. ### Description ; Process of calling copy number segments and consolidate sample results with PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order.""; I tried to detect germline copy number in cohort mode on 73 wgs samples by [this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For supp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:616,Safety,abort,aborts,616,"#6055 Bug Report. ### Affected tool(s) or class(es); PostprocessGermlineCNVCalls. ### Affected version(s); 4.1.8.1. ### Description ; Process of calling copy number segments and consolidate sample results with PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order.""; I tried to detect germline copy number in cohort mode on 73 wgs samples by [this](https://gatk.broadinstitute.org/hc/en-us/articles/360035531152--How-to-Call-common-and-rare-germline-copy-number-variants) tutorial.To do this, i split genome into 10 parts.At the last stage PostprocessGermlineCNVCalls aborts with error : ""Records were not strictly sorted in dictionary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For supp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:1685,Safety,detect,detect,1685,"ary order"", when i use all parts.; [scattered.1-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457466/scattered.1-10.interval_list.txt); [scattered.2-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457467/scattered.2-10.interval_list.txt); [scattered.3-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457468/scattered.3-10.interval_list.txt); [scattered.4-10.interval_list.txt](https://github.com/broadinstitute/gatk/files/5457469/scattered.4-10.interval_list.txt); [hg19.dict.txt](https://github.com/broadinstitute/gatk/files/5457474/hg19.dict.txt). But if you use the first three, the program works out. - ; `12:43:27.310 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:43:27 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:43:27.439 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:43:27.439 INFO PostprocessGermlineCNVCalls - Executing as lmbs02@Lmbs01 on Linux v5.4.0-48-generic amd64; 12:43:27.439 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 12:43:27.439 INFO PostprocessGermlineCNVCalls - Start Date/Time: October 29, 2020 12:43:27 PM MSK; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.439 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:43:27.440 INFO PostprocessGermlineCNVCalls - HTSJ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:7256,Safety,detect,detect,7256,"somal-contig chrX --allosomal-contig chrY --contig-ploidy-calls /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//cohort_ploidy//cohort-calls/ --sample-index 16 --output-genotyped-intervals /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.intervals.vcf --output-genotyped-segments /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.segments.vcf --sequence-dictionary /home/lmbs02/bio/databases/referenses/hg19_37/ucsc/hg19.dict --output-denoised-copy-ratios /home/lmbs02/bio/work/gatk_cnv/genomed_genome_hg19//vcfs//sample.copy_ratios.tsv `. In the same time, if you use the first 4 or the third and 4 at the same time, an error pops up.; `12:49:08.552 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Oct 29, 2020 12:49:08 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:49:08.687 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:49:08.687 INFO PostprocessGermlineCNVCalls - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:49:08.687 INFO PostprocessGermlineCNVCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Executing as lmbs02@Lmbs01 on Linux v5.4.0-48-generic amd64; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-8u265-b01-0ubuntu2~18.04-b01; 12:49:08.687 INFO PostprocessGermlineCNVCalls - Start Date/Time: October 29, 2020 12:49:08 PM MSK; 12:49:08.687 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:49:08.687 INFO PostprocessGermlineCNVCalls - ------------------------------------------------------------; 12:49:08.688 INFO PostprocessGermlineCNVCalls - HTSJ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6924:9617,Security,validat,validateIntervals,9617,":08.688 INFO PostprocessGermlineCNVCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Deflater: IntelDeflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Inflater: IntelInflater; 12:49:08.688 INFO PostprocessGermlineCNVCalls - GCS max retries/reopens: 20; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Requester pays: disabled; 12:49:08.688 INFO PostprocessGermlineCNVCalls - Initializing engine; 12:49:12.598 INFO PostprocessGermlineCNVCalls - Done initializing engine; 12:49:15.678 INFO PostprocessGermlineCNVCalls - Shutting down engine; [October 29, 2020 12:49:15 PM MSK] org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls done. Elapsed time: 0.12 minutes.; Runtime.totalMemory()=2457862144; java.lang.IllegalArgumentException: Records were not strictly sorted in dictionary order.; 	at org.broadinstitute.hellbender.tools.copynumber.arguments.CopyNumberArgumentValidationUtils.validateIntervals(CopyNumberArgumentValidationUtils.java:60); 	at org.broadinstitute.hellbender.tools.copynumber.formats.collections.AbstractLocatableCollection.getShardedCollectionSortOrder(AbstractLocatableCollection.java:142); 	at org.broadinstitute.hellbender.tools.copynumber.PostprocessGermlineCNVCalls.onTraversalStart(PostprocessGermlineCNVCalls.java:297); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Using GATK jar /home/lmbs02/bio/biosoft/gatk/gatk-4.1.8.1/gat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6924
https://github.com/broadinstitute/gatk/issues/6926:325,Availability,down,download,325,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [ ] Latest public release version GATK 4.1.9.0 with data version funcotator_dataSources.v1.7.20200521g. ### Description . #### Steps to reproduce. I'm trying to run GATK Funcotator using the funcotator_dataSources.v1.7.20200521g data download. The command line that I'm using is:; ```; gatk Funcotator \; --variant cohort.vcf.gz \; --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa \; --ref-version hg38 \; --data-sources-path funcotator_dataSources.v1.7.20200521g \; --output cohort.funcotator.vcf.gz \; --output-file-format VCF; ```. If I run that command line without the `gnomad_*.tar.gz`'s expanded, it works fine and annotates my `cohort.vcf.gz` into `cohort.funcotator.vcf.gz`. . Following the directions at [Funcotator Information and Tutorial - 1.1.2.2.1: enabling gnomAD](https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#1.1.2.2.1), if I expand both `gnomAD_exome.tar.gz` and `gnomAD_genome.tar.gz`, funcotator dies at startup with a `400 Bad Request` error. This also happens if I expand either one of the `gnomad_*.tar.gz` files individually. . #### Expected behavior; Funcotator annotates my VCF and includes gnomAD annotations in the output VCF. . #### Actual behavior. Crash with 400 Bad Request:. ```; Using GATK jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar Funcotator --variant cohort.vcf.gz --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521g --output cohort.funcotator.vcf.gz --output-file-format VCF; 14:24:33.589 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/share/gatk4-4.1.9.0-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:1096,Availability,error,error,1096,"fected version(s); - [ ] Latest public release version GATK 4.1.9.0 with data version funcotator_dataSources.v1.7.20200521g. ### Description . #### Steps to reproduce. I'm trying to run GATK Funcotator using the funcotator_dataSources.v1.7.20200521g data download. The command line that I'm using is:; ```; gatk Funcotator \; --variant cohort.vcf.gz \; --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa \; --ref-version hg38 \; --data-sources-path funcotator_dataSources.v1.7.20200521g \; --output cohort.funcotator.vcf.gz \; --output-file-format VCF; ```. If I run that command line without the `gnomad_*.tar.gz`'s expanded, it works fine and annotates my `cohort.vcf.gz` into `cohort.funcotator.vcf.gz`. . Following the directions at [Funcotator Information and Tutorial - 1.1.2.2.1: enabling gnomAD](https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#1.1.2.2.1), if I expand both `gnomAD_exome.tar.gz` and `gnomAD_genome.tar.gz`, funcotator dies at startup with a `400 Bad Request` error. This also happens if I expand either one of the `gnomad_*.tar.gz` files individually. . #### Expected behavior; Funcotator annotates my VCF and includes gnomAD annotations in the output VCF. . #### Actual behavior. Crash with 400 Bad Request:. ```; Using GATK jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar Funcotator --variant cohort.vcf.gz --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521g --output cohort.funcotator.vcf.gz --output-file-format VCF; 14:24:33.589 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compress",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:7254,Availability,down,down,7254,"var_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runW",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:7469,Availability,error,error,7469,"P_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:7646,Availability,error,error,7646,"72a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); 	at java.nio.file.Files.exists(Files.java:2385); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.assertPathFilePropertiesField(DataSourceUtil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:9758,Availability,error,error,9758,"pertiesAreValid(DataSourceUtils.java:841); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.getAndValidateDataSourcesFromPaths(DataSourceUtils.java:216); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.onTraversalStart(Funcotator.java:776); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: shaded.cloud_nio.com.google.api.client.http.HttpResponseException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at shaded.cloud_nio.com.google.api.client.http.HttpRequest.execute(HttpRequest.java:1097); 	at shaded.cloud_nio.com.google.auth.oauth2.UserCredentials.refreshAccessToken(UserCredentials.java:197); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.refresh(OAuth2Credentials.java:157); 	at shaded.cloud_nio.com.google.auth.oauth2.OAuth2Credentials.getRequestMetadata(OAuth2Credentials.java:145); 	at shaded.cloud_nio.com.google.auth.http.HttpCredentialsAdapter.initialize(HttpCredentialsAdapter.java:91); 	at shaded.cloud_nio.com.google.cloud.http.HttpTransportOptions$1.initialize(HttpTransportOptions.java:159); 	at shaded.cloud_nio.com.google.cloud.http.CensusHttpModule$CensusHttpRequestInitializer.initialize(CensusHttpModule.java:109); 	at shaded.cloud_nio.com.google.api.client.http.HttpRequestFactory.buildRequest(HttpRequestFactory.java:88); 	at shaded.cloud_nio.com.google.api.client.googleapis.services.AbstractGoogleClientReques",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:109,Deployability,release,release,109,"## Bug Report. ### Affected tool(s) or class(es); _Funcotator_. ### Affected version(s); - [ ] Latest public release version GATK 4.1.9.0 with data version funcotator_dataSources.v1.7.20200521g. ### Description . #### Steps to reproduce. I'm trying to run GATK Funcotator using the funcotator_dataSources.v1.7.20200521g data download. The command line that I'm using is:; ```; gatk Funcotator \; --variant cohort.vcf.gz \; --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa \; --ref-version hg38 \; --data-sources-path funcotator_dataSources.v1.7.20200521g \; --output cohort.funcotator.vcf.gz \; --output-file-format VCF; ```. If I run that command line without the `gnomad_*.tar.gz`'s expanded, it works fine and annotates my `cohort.vcf.gz` into `cohort.funcotator.vcf.gz`. . Following the directions at [Funcotator Information and Tutorial - 1.1.2.2.1: enabling gnomAD](https://gatk.broadinstitute.org/hc/en-us/articles/360035889931-Funcotator-Information-and-Tutorial#1.1.2.2.1), if I expand both `gnomAD_exome.tar.gz` and `gnomAD_genome.tar.gz`, funcotator dies at startup with a `400 Bad Request` error. This also happens if I expand either one of the `gnomad_*.tar.gz` files individually. . #### Expected behavior; Funcotator annotates my VCF and includes gnomAD annotations in the output VCF. . #### Actual behavior. Crash with 400 Bad Request:. ```; Using GATK jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar Funcotator --variant cohort.vcf.gz --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521g --output cohort.funcotator.vcf.gz --output-file-format VCF; 14:24:33.589 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/share/gatk4-4.1.9.0-",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:7439,Integrability,message,message,7439,"P_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); 	at",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:1926,Performance,Load,Loading,1926,"9931-Funcotator-Information-and-Tutorial#1.1.2.2.1), if I expand both `gnomAD_exome.tar.gz` and `gnomAD_genome.tar.gz`, funcotator dies at startup with a `400 Bad Request` error. This also happens if I expand either one of the `gnomad_*.tar.gz` files individually. . #### Expected behavior; Funcotator annotates my VCF and includes gnomAD annotations in the output VCF. . #### Actual behavior. Crash with 400 Bad Request:. ```; Using GATK jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar Funcotator --variant cohort.vcf.gz --reference GRCh38.d1.vd1/GRCh38.d1.vd1.fa --ref-version hg38 --data-sources-path funcotator_dataSources.v1.7.20200521g --output cohort.funcotator.vcf.gz --output-file-format VCF; 14:24:33.589 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/opt/conda/share/gatk4-4.1.9.0-0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 14:24:33.842 INFO Funcotator - ------------------------------------------------------------; 14:24:33.842 INFO Funcotator - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:24:33.842 INFO Funcotator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:24:33.843 INFO Funcotator - Executing as alanh@r820-2-0.local on Linux v3.10.0-1062.el7.x86_64 amd64; 14:24:33.843 INFO Funcotator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_265-b11; 14:24:33.843 INFO Funcotator - Start Date/Time: October 29, 2020 2:24:33 PM UTC; 14:24:33.843 INFO Funcotator - ------------------------------------------------------------; 14:24:33.843 INFO Funcotator - ------------------------------------------------------------; 14:24:33.844 INFO Funcotator - HTSJDK Version: 2.23.0; 14:24:33.844 INFO Funcotator - Picard Version: 2.23.3",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:3839,Security,Validat,Validating,3839, - HTSJDK Version: 2.23.0; 14:24:33.844 INFO Funcotator - Picard Version: 2.23.3; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:24:33.844 INFO Funcotator - Deflater: IntelDeflater; 14:24:33.844 INFO Funcotator - Inflater: IntelInflater; 14:24:33.844 INFO Funcotator - GCS max retries/reopens: 20; 14:24:33.844 INFO Funcotator - Requester pays: disabled; 14:24:33.844 INFO Funcotator - Initializing engine; 14:24:34.321 INFO FeatureManager - Using codec VCFCodec to read file file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/cohort.vcf.gz; 14:24:34.510 INFO Funcotator - Done initializing engine; 14:24:34.511 INFO Funcotator - Validating sequence dictionaries...; 14:24:34.550 INFO Funcotator - Processing user transcripts/defaults/overrides...; 14:24:34.551 INFO Funcotator - Initializing data sources...; 14:24:34.554 INFO DataSourceUtils - Initializing data sources from directory: funcotator_dataSources.v1.7.20200521g; 14:24:34.560 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 14:24:34.560 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-e,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:3669,Testability,test,test,3669,FO Funcotator - ------------------------------------------------------------; 14:24:33.843 INFO Funcotator - ------------------------------------------------------------; 14:24:33.844 INFO Funcotator - HTSJDK Version: 2.23.0; 14:24:33.844 INFO Funcotator - Picard Version: 2.23.3; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:24:33.844 INFO Funcotator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:24:33.844 INFO Funcotator - Deflater: IntelDeflater; 14:24:33.844 INFO Funcotator - Inflater: IntelInflater; 14:24:33.844 INFO Funcotator - GCS max retries/reopens: 20; 14:24:33.844 INFO Funcotator - Requester pays: disabled; 14:24:33.844 INFO Funcotator - Initializing engine; 14:24:34.321 INFO FeatureManager - Using codec VCFCodec to read file file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/cohort.vcf.gz; 14:24:34.510 INFO Funcotator - Done initializing engine; 14:24:34.511 INFO Funcotator - Validating sequence dictionaries...; 14:24:34.550 INFO Funcotator - Processing user transcripts/defaults/overrides...; 14:24:34.551 INFO Funcotator - Initializing data sources...; 14:24:34.554 INFO DataSourceUtils - Initializing data sources from directory: funcotator_dataSources.v1.7.20200521g; 14:24:34.560 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 14:24:34.560 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinfor,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:4658,Testability,test,test,4658,5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/cohort.vcf.gz; 14:24:34.510 INFO Funcotator - Done initializing engine; 14:24:34.511 INFO Funcotator - Validating sequence dictionaries...; 14:24:34.550 INFO Funcotator - Processing user transcripts/defaults/overrides...; 14:24:34.551 INFO Funcotator - Initializing data sources...; 14:24:34.554 INFO DataSourceUtils - Initializing data sources from directory: funcotator_dataSources.v1.7.20200521g; 14:24:34.560 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 14:24:34.560 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:4827,Testability,test,test,4827,- Validating sequence dictionaries...; 14:24:34.550 INFO Funcotator - Processing user transcripts/defaults/overrides...; 14:24:34.551 INFO Funcotator - Initializing data sources...; 14:24:34.554 INFO DataSourceUtils - Initializing data sources from directory: funcotator_dataSources.v1.7.20200521g; 14:24:34.560 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 14:24:34.560 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_te,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:5113,Testability,test,test,5113,ctory: funcotator_dataSources.v1.7.20200521g; 14:24:34.560 INFO DataSourceUtils - Data sources version: 1.7.2020521g; 14:24:34.560 INFO DataSourceUtils - Data sources source: ftp://gsapubftp-anonymous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///da,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:5275,Testability,test,test,5275,mous@ftp.broadinstitute.org/bundle/funcotator/funcotator_dataSources.v1.7.20200521g.tar.gz; 14:24:34.561 INFO DataSourceUtils - Data sources alternate source: gs://broad-public-datasets/funcotator/funcotator_dataSources.v1.7.20200521.tar.gz; 14:24:34.587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf;,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:5554,Testability,test,test,5554,587 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:5710,Testability,test,test,5710,e4f3/gencode.v34.annotation.REORDERED.gtf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.annotation.REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:5984,Testability,test,test,5984,REORDERED.gtf; 14:24:34.591 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:6142,Testability,test,test,6142,62c695472a59dfab47a87afe4f3/gencode.v34.pc_transcripts.fa -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/gencode/hg38/gencode.v34.pc_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funco,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:6417,Testability,test,test,6417,"_transcripts.fa; 14:24:34.599 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg59_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.total",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:6617,Testability,test,test,6617,"_test_cleaned.txt -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_rec/hg38/acmg59_test_cleaned.txt; 14:24:34.608 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:6936,Testability,test,test,6936,"le path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/clinvar_20180429_hg38.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.Storag",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:7081,Testability,test,test,7081,"astore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/clinvar/hg38/clinvar_20180429_hg38.vcf; 14:24:34.614 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/lmm_known/hg38/LMM_Path_LP_VUS5-variants-6-12-18.sorted_liftover_b38.corrected.vcf; 14:24:34.617 INFO DataSourceUtils - Resolved data source file path: file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/acmg_lof.tsv -> file:///datastore/nextgenout5/share/labs/bioinformatics/alanh/test/nf-germline-exome_sim4/work/3f/5c862c695472a59dfab47a87afe4f3/funcotator_dataSources.v1.7.20200521g/acmg_lof/hg38/acmg_lof.tsv; 14:24:35.311 INFO Funcotator - Shutting down engine; [October 29, 2020 2:24:35 PM UTC] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.03 minutes.; Runtime.totalMemory()=2055733248; code: 400; message: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; reason: null; location: null; retryable: false; com.google.cloud.storage.StorageException: 400 Bad Request; {; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:8619,Testability,assert,assertPathFilePropertiesField,8619,"{; ""error"": ""invalid_grant"",; ""error_description"": ""Bad Request""; }; 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.translate(HttpStorageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); 	at java.nio.file.Files.exists(Files.java:2385); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.assertPathFilePropertiesField(DataSourceUtils.java:938); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.assertConfigFilePropertiesAreValid(DataSourceUtils.java:841); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.getAndValidateDataSourcesFromPaths(DataSourceUtils.java:216); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.onTraversalStart(Funcotator.java:776); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6926:8755,Testability,assert,assertConfigFilePropertiesAreValid,8755,"ageRpc.java:229); 	at com.google.cloud.storage.spi.v1.HttpStorageRpc.get(HttpStorageRpc.java:439); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:244); 	at com.google.cloud.storage.StorageImpl$5.call(StorageImpl.java:241); 	at shaded.cloud_nio.com.google.api.gax.retrying.DirectRetryingExecutor.submit(DirectRetryingExecutor.java:105); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.run(RetryHelper.java:76); 	at shaded.cloud_nio.com.google.cloud.RetryHelper.runWithRetries(RetryHelper.java:50); 	at com.google.cloud.storage.StorageImpl.get(StorageImpl.java:240); 	at com.google.cloud.storage.contrib.nio.CloudStorageFileSystemProvider.checkAccess(CloudStorageFileSystemProvider.java:736); 	at java.nio.file.Files.exists(Files.java:2385); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.assertPathFilePropertiesField(DataSourceUtils.java:938); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.assertConfigFilePropertiesAreValid(DataSourceUtils.java:841); 	at org.broadinstitute.hellbender.tools.funcotator.dataSources.DataSourceUtils.getAndValidateDataSourcesFromPaths(DataSourceUtils.java:216); 	at org.broadinstitute.hellbender.tools.funcotator.Funcotator.onTraversalStart(Funcotator.java:776); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: shaded.cloud_nio.com.google.api.client.http.HttpResponseException: 400 Bad Request; {; ""error"": ""invalid_grant""",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6926
https://github.com/broadinstitute/gatk/issues/6927:127,Deployability,update,update,127,"I think hdfview might be broken for e.g. some Ubuntu distributions. Just need to change some tool docs, but might also want to update tutorials. See context in #6924.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6927
https://github.com/broadinstitute/gatk/issues/6929:334,Integrability,depend,depends,334,"Hello - in GATK3 we wrote a variety of custom VariantAnnotation classes, and created a GATK3 fork / custom JAR with those classes. We run VariantAnnotator using that. I am hoping you might comment on whether this plan seems reasonable:. I am going to try to implement this in our DISCVRseq package, which is a standalone package that depends on GATK4. I am currently expecting that I would need to be a separate tool, like ""VariantAnnotationExtended"" in our code. My tool can make an instance of VariantAnnotatorEngine, passing whatever annotationList I see fit. It seems like I will either be able to use GATKTool.makeVariantAnnotations() as-is, or override it to search custom classpaths (not currently clear if that's needed). In the end, my new tool should be able to function like core GATK4 VariantAnnotator, picking up your core annotations and whatever new ones I make. The latter is useful so I dont need to execute two annotation commands if I want to use a combination of annotations. . Is there a better way to implement custom VariantAnnotations in GATK4?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929
https://github.com/broadinstitute/gatk/issues/6929:705,Usability,clear,clear,705,"Hello - in GATK3 we wrote a variety of custom VariantAnnotation classes, and created a GATK3 fork / custom JAR with those classes. We run VariantAnnotator using that. I am hoping you might comment on whether this plan seems reasonable:. I am going to try to implement this in our DISCVRseq package, which is a standalone package that depends on GATK4. I am currently expecting that I would need to be a separate tool, like ""VariantAnnotationExtended"" in our code. My tool can make an instance of VariantAnnotatorEngine, passing whatever annotationList I see fit. It seems like I will either be able to use GATKTool.makeVariantAnnotations() as-is, or override it to search custom classpaths (not currently clear if that's needed). In the end, my new tool should be able to function like core GATK4 VariantAnnotator, picking up your core annotations and whatever new ones I make. The latter is useful so I dont need to execute two annotation commands if I want to use a combination of annotations. . Is there a better way to implement custom VariantAnnotations in GATK4?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6929
https://github.com/broadinstitute/gatk/issues/6930:170,Energy Efficiency,reduce,reduced,170,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6930:903,Energy Efficiency,efficient,efficiently,903,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6930:607,Modifiability,plugin,plugin,607,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6930:966,Modifiability,plugin,plugin,966,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6930:1082,Modifiability,plugin,plugins,1082,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6930:326,Security,access,access,326,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6930:852,Security,access,access,852,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6930:213,Usability,simpl,simplify,213,"I'm looking into migrating custom GATK3 variant Info/GenotypeAnnotations to GATK4. The annotate() method in GATK3 was passed a sizable amount of context. This is greatly reduced in GATK4. I understand a desire to simplify, such as not passing the Walker. FeatureContext in particular would be helpful, is there another way to access that from VariantAnnotations?. Stepping back: the one scenario I want to support is to annotate genotype concordance between the input VCF and a reference VCF. In our GATK3 implementation, the user supplied that VCF on the command line when executing VariantAnnotator. This plugin used GATK3's walker.getResourceRodBindings(), which seems analogous to GATK4 FeatureContext, to find that binding. It then queries that VCF to find any VariantContext from the current site. . I realize this is raising a couple issues: a) access FeatureContext from within annotate(), , b) efficiently query VariantContext from another resource, and c) plugin that would ideally provide its own command-line argument. . Are there any existing GATK annotations or other plugins that deal with these issues?. Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6930
https://github.com/broadinstitute/gatk/issues/6931:1407,Security,validat,validator,1407," already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Mutect2/FilterMutectCalls. ### Affected version(s); Both 4.1.6 and 4.1.9 were affected. Other version may be affected as well, but I have not tested them. ### Description . Output from vcf-validator:. 7 .. INFO field at chr1:160882084 .. INFO tag [AS_SB_TABLE=719,346|0,47] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence,base_qual,strand_bias] expected different number of values (expected 1, found 3); 7 .. INFO field at chr1:230995820 .. INFO tag [AS_SB_TABLE=444,391|4,6|5,6] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence|weak_evidence] expected different number of values (expected 2, found 1); 6 .. INFO field at chr2:169905124 .. INFO tag [AS_SB_TABLE=387,312|2,2] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence,base_qual] expected different number of values (expected 1, found 2); 6 .. INFO field at chr3:42210085 .. INFO tag [AS_SB_TABLE=15,24|3,2|206,188|174,140|3,1] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence|SITE|SITE|weak_evidence] expected different number of values (expected 4, found 1); 5 .. INFO field at chr1:82186950 .. INFO tag ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6931
https://github.com/broadinstitute/gatk/issues/6931:1360,Testability,test,tested,1360,"sue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); Mutect2/FilterMutectCalls. ### Affected version(s); Both 4.1.6 and 4.1.9 were affected. Other version may be affected as well, but I have not tested them. ### Description . Output from vcf-validator:. 7 .. INFO field at chr1:160882084 .. INFO tag [AS_SB_TABLE=719,346|0,47] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence,base_qual,strand_bias] expected different number of values (expected 1, found 3); 7 .. INFO field at chr1:230995820 .. INFO tag [AS_SB_TABLE=444,391|4,6|5,6] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence|weak_evidence] expected different number of values (expected 2, found 1); 6 .. INFO field at chr2:169905124 .. INFO tag [AS_SB_TABLE=387,312|2,2] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence,base_qual] expected different number of values (expected 1, found 2); 6 .. INFO field at chr3:42210085 .. INFO tag [AS_SB_TABLE=15,24|3,2|206,188|174,140|3,1] expected different number of values (1),INFO tag [AS_FilterStatus=weak_evidence|SITE|SITE|weak_evidence] expected different number of values (ex",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6931
https://github.com/broadinstitute/gatk/issues/6932:24,Availability,down,download,24,"In the README, the full download size when downloading large files using Git LFS is reported to be 2 GB in one section and several hundred MB in another section, when it is actually ~4.81 GB in size. ![git_lfs](https://user-images.githubusercontent.com/52426291/97712898-5d38a080-1abf-11eb-8070-d71d63d5add1.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6932
https://github.com/broadinstitute/gatk/issues/6932:43,Availability,down,downloading,43,"In the README, the full download size when downloading large files using Git LFS is reported to be 2 GB in one section and several hundred MB in another section, when it is actually ~4.81 GB in size. ![git_lfs](https://user-images.githubusercontent.com/52426291/97712898-5d38a080-1abf-11eb-8070-d71d63d5add1.png)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6932
https://github.com/broadinstitute/gatk/pull/6933:44,Availability,down,download,44,Fixing README.md to reflect current Git LFS download size as approximately 5 GB. Fixes #6932,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6933
https://github.com/broadinstitute/gatk/pull/6937:1171,Availability,down,downstream,1171,"code, the `phaseGT` in the code and `PGT` format field on each genotype can be interpreted as being an indicator of which of the two phased haplotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but neve",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:1856,Deployability,integrat,integration,1856,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:2066,Deployability,update,updated,2066,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:2285,Deployability,update,update,2285,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:1818,Energy Efficiency,reduce,reduce,1818,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:1856,Integrability,integrat,integration,1856,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:1399,Testability,log,logic,1399,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:1868,Testability,test,test,1868,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/pull/6937:1890,Testability,test,test,1890,"plotypes in the sample contains the site-specific alternate allele at the site (ie. excluding `*` which represents variation that beings upstream of the current variant. NB that this results in cases where `PGT` is not the same as the phased `GT` field. For example, in the case of a spanned SNP site with REF allele `A` and alt alleles `C` and `*`, `GT` may be set to `1|2` to represent the spanned SNP, while PGT would be set to `1|0` to represent the fact that it is the first haplotype in the pair of phased haplotypes that contains the site-specific alt allele (in this case `C`). If reviewers agree with this interpretation, I think we should create a new ticket to clarify documentation around the PGT and PID tags to reflect it. . After discussions with @ldgauthier I believe that there may be downstream issues in preserving phasing after passing gVCFs through CombineGVCFs, GenomicsDBImport, and/or GenotypeGVCFs, especially if the gVCFs are emitted without GT fields. In that case, `GenotypeGVCFs` should probably have logic to reconstruct the phased genotype for each sample based on the PGT and PID tags when possible. I will create a new ticket describing the issue. There still may be cases where HaplotypeCaller does not emit phasing information for spanning deletions due to the presence of extra haplotypes that contradict diploid phasing, as in https://github.com/broadinstitute/gatk/issues/6845. A fix to that issue would likely reduce the number of those cases. The integration test result file `src/test/resources/org/broadinstitute/hellbender/tools/walkers/GenotypeGVCFs/withOxoGReadCounts.vcf` does not have any changes that have to do with this PR -- it was automatically updated by GenotypeGVCFsIntegrationTest, which included some new jitter in QUAL scores as described in https://github.com/broadinstitute/gatk/pull/6859, but never got checked in with that PR. I figure that it's best to update it now so that the results reflect the current expected behavior of the tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6937
https://github.com/broadinstitute/gatk/issues/6938:1392,Availability,down,downstream,1392," already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCF. ### Affected version(s); 4.1.7; 4.1.8; 4.1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938
https://github.com/broadinstitute/gatk/issues/6938:1676,Availability,down,downstream,1676,"er addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCF. ### Affected version(s); 4.1.7; 4.1.8; 4.1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.7.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodR",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938
https://github.com/broadinstitute/gatk/issues/6938:2427,Availability,down,downstream,2427,"1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.7.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,.:68:12,15,.:21,18,.:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. The above 4.1.7 site matches 4.1.8 and 4.1.9. For 4.1.7, The first sample in the VCF lists the 'AF' as ""0.515,."", while in version 4.1.6, AF is represented as ""0.515,0""; ----. ## Feature request. Can the most recent build of 4.1.9 be changed to represent these AF annotations with '0' instead of '.'?. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938
https://github.com/broadinstitute/gatk/issues/6938:1430,Deployability,pipeline,pipeline,1430," already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); GenotypeGVCF. ### Affected version(s); 4.1.7; 4.1.8; 4.1.9. ### Description ; Starting with GATK4.1.7, the AF annotation in the changed from '0' to '.'. This change is cause downstream issues with our processing pipeline. #### Steps to reproduce; CMD using 4.1.6:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.6.HC.vcf.gz. Looking at one of the sites causing this downstream issue:; CMD; gzcat proband_mother_duo_GATK4.1.6.HC.vcf.gz | grep 83598622; OUTPUT:; chr4 83598622 . AT ATT,A 1337.45 . AC=1,1;AF=0.250,0.250;AN=4;BaseQRankSum=1.26;ClippingRankSum=0.074;DP=145;ExcessHet=4.7712;FS=5.235;GQ_MEAN=625.00;LikelihoodRankSum=1.34;MLEAC=1,1;MLEAF=0.250,0.250;MQ=60.00;MQ0=0;MQRankSum=0.00;NCC=0;NCount=0;QD=10.06;ReadPosRankSum=1.56;SOR=0.375 GT:AD:AF:DP:F1R2:F2R1:GQ:PL 0/2:33,0,35:0.515,0:68:12,15,0:21,18,0:99:713,812,1542,0,731,625 0/1:32,33,0:0.493,0.00:67:9,23,0:19,8,0:99:640,0,588,728,747,1569. CMD using 4.1.7:; gatk GenotypeGVCFs --variant proband_mother_duo.HC.g.vcf.gz -R hs38DH.fa --dbsnp dbsnp151_common.hg38.vcf.gz -O proband_mother_duo_GATK4.1.7.HC.vcf.gz. Looking at one of t",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6938
https://github.com/broadinstitute/gatk/pull/6939:50,Modifiability,variab,variable,50,"I'm not sure how this worked before, but adding a variable fixes it. @ahaessly, let me know what you think!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6939
https://github.com/broadinstitute/gatk/issues/6941:308,Availability,down,down,308,"Hello, I use GATK tools quite often in my daily work life. I use quite a lot of sample data every time I use it. The fact that GATK tools use a single core causes analysis processes to take quite a long time. Although I command --java-options ""-Xmx32G -XX:ParallelGCThreads=8"" to GATK tools, GATK tools slow down the process by using only one thread instead of using 8 threads. How can I get GATK tools to use 8 threads? Thank you.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6941
https://github.com/broadinstitute/gatk/pull/6943:15,Testability,test,test,15,This fixes the test that was accidentally disabled (when we added a flag for overlapping read adjustment we forgot to set it correctly for the test) and reinstated something like the code from #4926. It should now necessarily be the case that the finalize() method calls read.copy() at least once for every read (though many multiples of once are still quite possible). Fixes #6882,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6943
https://github.com/broadinstitute/gatk/pull/6943:143,Testability,test,test,143,This fixes the test that was accidentally disabled (when we added a flag for overlapping read adjustment we forgot to set it correctly for the test) and reinstated something like the code from #4926. It should now necessarily be the case that the finalize() method calls read.copy() at least once for every read (though many multiples of once are still quite possible). Fixes #6882,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6943
https://github.com/broadinstitute/gatk/pull/6945:222,Availability,error,error,222,"When I ingested more non- allele specific GVCFs, I ran into some edge cases. Most of these missing annotations occurred at weird sites where the GQ was 0 (but it wasn't a ref block). These changes keep it from throwing an error when it hits these sites.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6945
https://github.com/broadinstitute/gatk/issues/6946:57,Availability,down,downloads,57,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946
https://github.com/broadinstitute/gatk/issues/6946:218,Availability,down,downloaded,218,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946
https://github.com/broadinstitute/gatk/issues/6946:260,Availability,down,download,260,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946
https://github.com/broadinstitute/gatk/issues/6946:494,Availability,down,downloads,494,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946
https://github.com/broadinstitute/gatk/issues/6946:865,Availability,down,download,865,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946
https://github.com/broadinstitute/gatk/issues/6946:102,Deployability,release,release-stats,102,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946
https://github.com/broadinstitute/gatk/issues/6946:206,Deployability,release,release,206,"1. We need a script to take snapshots of the [GATK total downloads page](https://somsubhra.com/github-release-stats/?username=broadinstitute&repository=gatk) every month and report the number of times each release was downloaded.; 2. We should change the GATK download link on [this page of the GATK website](https://gatk.broadinstitute.org/hc/en-us) and have it point at a script that records the IP addresses of users before redirecting to github. That way we can have another source of GATK downloads metrics.; 3. Github reports the traffic on GATK repo [here](https://github.com/broadinstitute/gatk/graphs/traffic). It tracks the number of clones and the number of visitors. However, github saves this data only for one week, so we will need an automated script to take snapshots of the page and store the metrics.; 4. In the same way track the total number of download from bioconda from [this](https://anaconda.org/bioconda/gatk4) page.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6946
https://github.com/broadinstitute/gatk/issues/6948:2757,Availability,down,down,2757,"libratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.722 INFO VariantRecalibrator - Building MQRankSum x ReadPosRankSum plot...; 15:51:16.722 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:17.819 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:18.045 INFO VariantRecalibrator - Executing: Rscript /gss1/home/ldl20190322/a_haoxiaoshuai/a_project/WGS_Z/e_vqsr_plot/Ztem.gatk.snp.plots.R; 15:51:38.589 INFO VariantRecalibrator - Executing: Rscript (resource)org/broadinstitute/hellbender/tools/walkers/vqsr/plot_Tranches.R /gss1/home/ldl20190322/a_haoxiaoshuai/a_project/WGS_Z/e_vqsr_plot/Ztem.gatk.snp.tranches 2.15; 15:51:39.227 INFO VariantRecalibrator - Shutting down engine; [November 9, 2020 3:51:39 PM CST] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 9.43 minutes.; Runtime.totalMemory()=2029518848; Exception in thread ""Thread-1"" htsjdk.samtools.util.RuntimeIOException: java.nio.file.NoSuchFileException: /gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir/Rlib.7359270660945146060; 	at htsjdk.samtools.util.IOUtil.recursiveDelete(IOUtil.java:1346); 	at org.broadinstitute.hellbender.utils.io.IOUtils.deleteRecursively(IOUtils.java:1061); 	at org.broadinstitute.hellbender.utils.io.DeleteRecursivelyOnExitPathHook.runHooks(DeleteRecursivelyOnExitPathHook.java:56); 	at java.lang.Thread.run(Thread.java:748); Caused by: java.nio.file.NoSuchFileException: /gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir/Rlib.7359270660945146060; 	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); 	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); 	at sun.nio.fs.UnixException.rethrowAsIOEx",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6948:148,Deployability,release,release,148,"## Bug Report. ### Affected tool(s) or class(es); GATK version: 4.1.1.0-VariantRecalibrator-ApplyVQSR. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I am doing VQSR with gatk-VariantRecalibrator-ApplyVQSR, and i got some mistakes in the log file and i dont konw what was wrong with my script,. #### Steps to reproduce; Below are my complete scripts:; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6948:1552,Integrability,message,message,1552,"ware/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.722 INFO VariantRecalibrator - Building MQRankSum x ReadPosRankSum plot...; 15:51:16.722 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:17.819 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:18.045 INFO VariantRecalibrator - Executing: Rscript /gss1/home/ldl20190322/a_haoxiaoshuai/a_project/WGS_Z/e_vqsr_plot/Ztem.gatk.snp.plots.R; 15:51:38.589 INFO VariantRecalibrator - Executing: Rscript (resource)org/broadinstitute/hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6948:4552,Performance,Load,Loading,4552,"359270660945146060; 	at sun.nio.fs.UnixException.translateToIOException(UnixException.java:86); 	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:102); 	at sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:107); 	at sun.nio.fs.UnixFileAttributeViews$Basic.readAttributes(UnixFileAttributeViews.java:55); 	at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144); 	at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.Files.walkFileTree(Files.java:2662); 	at java.nio.file.Files.walkFileTree(Files.java:2742); 	at htsjdk.samtools.util.IOUtil.recursiveDelete(IOUtil.java:1344); 	... 3 more; 15:51:41.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 09, 2020 3:51:43 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:51:43.109 INFO ApplyVQSR - ------------------------------------------------------------; 15:51:43.109 INFO ApplyVQSR - The Genome Analysis Toolkit (GATK) v4.1.1.0; 15:51:43.109 INFO ApplyVQSR - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:51:43.109 INFO ApplyVQSR - Executing as ldl20190322@compute20 on Linux v2.6.32-642.el6.x86_64 amd64; 15:51:43.109 INFO ApplyVQSR - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_261-b12; 15:51:43.109 INFO ApplyVQSR - Start Date/Time: November 9, 2020 3:51:41 PM CST; 15:51:43.109 INFO ApplyVQSR - -----------------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6948:4868,Safety,detect,detect,4868,"AttributeViews.java:55); 	at sun.nio.fs.UnixFileSystemProvider.readAttributes(UnixFileSystemProvider.java:144); 	at sun.nio.fs.LinuxFileSystemProvider.readAttributes(LinuxFileSystemProvider.java:99); 	at java.nio.file.Files.readAttributes(Files.java:1737); 	at java.nio.file.FileTreeWalker.getAttributes(FileTreeWalker.java:219); 	at java.nio.file.FileTreeWalker.visit(FileTreeWalker.java:276); 	at java.nio.file.FileTreeWalker.walk(FileTreeWalker.java:322); 	at java.nio.file.Files.walkFileTree(Files.java:2662); 	at java.nio.file.Files.walkFileTree(Files.java:2742); 	at htsjdk.samtools.util.IOUtil.recursiveDelete(IOUtil.java:1344); 	... 3 more; 15:51:41.426 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 09, 2020 3:51:43 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 15:51:43.109 INFO ApplyVQSR - ------------------------------------------------------------; 15:51:43.109 INFO ApplyVQSR - The Genome Analysis Toolkit (GATK) v4.1.1.0; 15:51:43.109 INFO ApplyVQSR - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:51:43.109 INFO ApplyVQSR - Executing as ldl20190322@compute20 on Linux v2.6.32-642.el6.x86_64 amd64; 15:51:43.109 INFO ApplyVQSR - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_261-b12; 15:51:43.109 INFO ApplyVQSR - Start Date/Time: November 9, 2020 3:51:41 PM CST; 15:51:43.109 INFO ApplyVQSR - ------------------------------------------------------------; 15:51:43.109 INFO ApplyVQSR - ------------------------------------------------------------; 15:51:43.110 INFO ApplyVQSR - HTSJDK Version: 2.19.0; 15:51:43.110 INFO ApplyVQSR - Picard Version: 2.19.0; 15:51:43.110 INFO ApplyVQSR - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 15:51:43.110 INFO Apply",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6948:218,Testability,test,test,218,"## Bug Report. ### Affected tool(s) or class(es); GATK version: 4.1.1.0-VariantRecalibrator-ApplyVQSR. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I am doing VQSR with gatk-VariantRecalibrator-ApplyVQSR, and i got some mistakes in the log file and i dont konw what was wrong with my script,. #### Steps to reproduce; Below are my complete scripts:; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6948:332,Testability,log,log,332,"## Bug Report. ### Affected tool(s) or class(es); GATK version: 4.1.1.0-VariantRecalibrator-ApplyVQSR. ### Affected version(s); - [ ] Latest public release version [version?]; - [ ] Latest master branch as of [date of test?]. ### Description ; I am doing VQSR with gatk-VariantRecalibrator-ApplyVQSR, and i got some mistakes in the log file and i dont konw what was wrong with my script,. #### Steps to reproduce; Below are my complete scripts:; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INF",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6948:1626,Testability,log,log,1626,"ware/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar VariantRecalibrator -R Gmax_275_v2.0.fa --variant Ztem.gatk.vcf.gz --resource:hapmap,known=false,training=true,truth=true,prior=10.0 final.intersected.snp.vcf.gz -an QD -an MQ -an MQRankSum -an ReadPosRankSum -an FS -an SOR -an DP -mode SNP -O Ztem.gatk.snp.recal --tranches-file Ztem.gatk.snp.tranches --rscript-file Ztem.gatk.snp.plots.R -tranche 90.0 -tranche 92.0 -tranche 94.0 -tranche 96.0 -tranche 97.0 -tranche 98.0 -tranche 99.0 -tranche 99.9; java -Xmx3990m -Djava.io.tmpdir=/gss1/home/ldl20190322/a_haoxiaoshuai/JavaTmpDir -jar /gss1/home/ldl20190322/a_haoxiaoshuai/z_software/gatk/gatk-4.1.1.0/gatk-package-4.1.1.0-local.jar ApplyVQSR -R Gmax_275_v2.0.fa -V Ztem.gatk.vcf.gz --truth-sensitivity-filter-level 99.0 --tranches-file Ztem.gatk.snp.tranches --recal-file Ztem.gatk.snp.recal -mode SNP -O Ztem.gatk.snp.vcf.gz. #### Expected behavior; _Tell us what should happen_. #### Actual behavior; Below is the message of the mistakes and i just omitted some no use information in the log file:; .; .; .; 15:51:14.040 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.156 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:15.373 INFO VariantRecalibrator - Building FS x ReadPosRankSum plot...; 15:51:15.374 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.493 INFO VariantRecalibratorEngine - Evaluating full set of 3660 variants...; 15:51:16.722 INFO VariantRecalibrator - Building MQRankSum x ReadPosRankSum plot...; 15:51:16.722 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:17.819 INFO VariantRecalibratorEngine - Evaluating full set of 3600 variants...; 15:51:18.045 INFO VariantRecalibrator - Executing: Rscript /gss1/home/ldl20190322/a_haoxiaoshuai/a_project/WGS_Z/e_vqsr_plot/Ztem.gatk.snp.plots.R; 15:51:38.589 INFO VariantRecalibrator - Executing: Rscript (resource)org/broadinstitute/hellbender",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6948
https://github.com/broadinstitute/gatk/issues/6950:235,Availability,Error,Error,235,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:293,Availability,error,error,293,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:476,Availability,Error,Error,476,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:535,Availability,Error,Error,535,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:593,Availability,error,error,593,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:801,Availability,Error,Error,801,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:1102,Availability,Error,Error,1102,ion [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:1139,Availability,Failure,Failure,1139,ion [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/s,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:1332,Availability,Error,Error,1332,".tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImp",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:1574,Availability,Error,Error,1574,"7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scr",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:1896,Availability,Error,Error,1896,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:1964,Availability,error,error,1964,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:2001,Availability,Error,Error,2001,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:2059,Availability,Error,Error,2059,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:2117,Availability,error,error,2117,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:2674,Availability,avail,available,2674,"rror: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories with more than enough storage space and yet it seems to fail. Any help will be greatly appreciated. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:2742,Availability,avail,available,2742,"rror: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories with more than enough storage space and yet it seems to fail. Any help will be greatly appreciated. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:2825,Availability,error,error,2825,"rror: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories with more than enough storage space and yet it seems to fail. Any help will be greatly appreciated. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:119,Deployability,release,release,119,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:1970,Integrability,message,message,1970,"6913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:2831,Integrability,message,message,2831,"rror: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] Error: Cannot write segment to file; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); #### Steps to reproduce; Below code ran on a cluster; ```; gatk --java-options ""-Xmx100g -Xms100g"" GenomicsDBImport \; -V sample1.g.vcf.gz -V sample2.g.vcf.gz -V sample3.g.vcf.gz -V sample4.g.vcf.gz \; -L chr13.bed \; --genomicsdb-workspace-path /storage/home/data/gendb/chr13\; --tmp-dir /storage/home/scratch/tmp; ```. #### Expected behavior; Over 1TB of scratch space available for temporary directory and around 500GB of storage space available to hold outputs of GenomicsDBImport outputs. #### Actual behavior; Above error message indicating that disk quota has exceeded. I'm not exactly sure what's going on here as I am directing the outputs of the GenomicsDBImport runs to directories with more than enough storage space and yet it seems to fail. Any help will be greatly appreciated. Thanks!",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6950:188,Testability,test,test,188,----. ## Bug Report. ### Affected tool(s) or class(es); GenomicsDBImport. ### Affected version(s); - [X] Latest public release version [4.1.9.0]; - [ ] Latest master branch as of [date of test?]. ### Description ; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/RAW_MQandDP.tdb; errno=122(Disk quota exceede; d); [TileDB::WriteState] Error: Cannot write segment to file.; [TileDB::FileSystem] Error: (write_to_file) Cannot write to file; File opening error; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; errno=122(Disk quota e; xceeded); [TileDB::utils] Error: (write_to_file_after_compression) Could not write compressed bytes to internal buffer; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz; ; errno=122(Disk quota exceeded); [TileDB::BookKeeping] Error: Cannot finalize book-keeping; Failure to write to file /storage/home/data/gendb/chr13/chr13$32310639$32310731/.__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__book_keeping.tdb.gz.; [TileDB::FileSystem] Error: (create_file) Failed to create file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087/__tiledb_fragment.tdb; errno=122(Disk quota exceeded); [TileDB::utils] Error: (create_fragment_file) Failed to create fragment file; path=/storage/home/data/gendb/chr13/chr13$32310639$32310731/__7a3cf8dc-ea9d-4bf9-9e33-c87b91d94b0546913384130304_1605025432087; errno=122(Disk quota exceeded); 11:23:52.390 erro NativeGenomicsDB - pid=57964 tid=57984 VariantStorageManagerException exception : Error while finalizing TileDB array chr13$32310639$32310731; TileDB error message : [TileDB::WriteState] ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6950
https://github.com/broadinstitute/gatk/issues/6954:0,Deployability,Update,Update,0,Update the PGT FORMAT header as discussed in #6937:. PGT format field on each genotype can be interpreted as being an indicator of which of the two phased haplotypes in the sample contains the site-specific alternate allele at the site. See also #6220 and #6952,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6954
https://github.com/broadinstitute/gatk/pull/6955:177,Deployability,integrat,integration,177,"It looks like the conda env recently started resolving h5py to v3.1.0, which in turn appears to be incompatible with the keras version we're using, causing the CNNScoreVariants integration tests to fail when keras tries to load the model file (see https://github.com/tensorflow/tensorflow/issues/44467). This PR pins the version to the version used by the last build I could find that succeeded, which is 2.10.0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955
https://github.com/broadinstitute/gatk/pull/6955:177,Integrability,integrat,integration,177,"It looks like the conda env recently started resolving h5py to v3.1.0, which in turn appears to be incompatible with the keras version we're using, causing the CNNScoreVariants integration tests to fail when keras tries to load the model file (see https://github.com/tensorflow/tensorflow/issues/44467). This PR pins the version to the version used by the last build I could find that succeeded, which is 2.10.0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955
https://github.com/broadinstitute/gatk/pull/6955:223,Performance,load,load,223,"It looks like the conda env recently started resolving h5py to v3.1.0, which in turn appears to be incompatible with the keras version we're using, causing the CNNScoreVariants integration tests to fail when keras tries to load the model file (see https://github.com/tensorflow/tensorflow/issues/44467). This PR pins the version to the version used by the last build I could find that succeeded, which is 2.10.0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955
https://github.com/broadinstitute/gatk/pull/6955:189,Testability,test,tests,189,"It looks like the conda env recently started resolving h5py to v3.1.0, which in turn appears to be incompatible with the keras version we're using, causing the CNNScoreVariants integration tests to fail when keras tries to load the model file (see https://github.com/tensorflow/tensorflow/issues/44467). This PR pins the version to the version used by the last build I could find that succeeded, which is 2.10.0.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6955
https://github.com/broadinstitute/gatk/issues/6957:51,Security,validat,validation,51,"Now that there's more rigorous sequence dictionary validation a bunch of dictionaries don't jive with the reference, especially files of the form src/test/resources/org/broadinstitute/hellbender/tools/copynumber/gcnv-postprocess/shard_0-calls/interval_list.tsv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6957
https://github.com/broadinstitute/gatk/issues/6957:150,Testability,test,test,150,"Now that there's more rigorous sequence dictionary validation a bunch of dictionaries don't jive with the reference, especially files of the form src/test/resources/org/broadinstitute/hellbender/tools/copynumber/gcnv-postprocess/shard_0-calls/interval_list.tsv",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6957
https://github.com/broadinstitute/gatk/pull/6959:234,Integrability,wrap,wrapper,234,"Sharded output is extremely useful for pipelining. This adds the option `--max-variants-per-shard` to `GATKTool` to let users easily split out VCFs. The functionality is implemented in the `ShardingVCFWriter` class, which is a simple wrapper around `VariantContextWriter` that basically creates a new writer whenever the max shard size is reached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6959
https://github.com/broadinstitute/gatk/pull/6959:227,Usability,simpl,simple,227,"Sharded output is extremely useful for pipelining. This adds the option `--max-variants-per-shard` to `GATKTool` to let users easily split out VCFs. The functionality is implemented in the `ShardingVCFWriter` class, which is a simple wrapper around `VariantContextWriter` that basically creates a new writer whenever the max shard size is reached.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6959
https://github.com/broadinstitute/gatk/issues/6960:3782,Availability,down,down,3782,"tFiltration - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 12:01:06.399 INFO VariantFiltration - Start Date/Time: November 15, 2020 12:01:06 MST PM; 12:01:06.399 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.399 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.399 INFO VariantFiltration - HTSJDK Version: 2.23.0; 12:01:06.400 INFO VariantFiltration - Picard Version: 2.22.8; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:01:06.400 INFO VariantFiltration - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:01:06.400 INFO VariantFiltration - Deflater: IntelDeflater; 12:01:06.400 INFO VariantFiltration - Inflater: IntelInflater; 12:01:06.400 INFO VariantFiltration - GCS max retries/reopens: 20; 12:01:06.400 INFO VariantFiltration - Requester pays: disabled; 12:01:06.400 INFO VariantFiltration - Initializing engine; 12:01:06.830 INFO FeatureManager - Using codec VCFCodec to read file file:///work/mtgraovac_lab/matthew/c_elegans/COOVAR/VCFS/haplotypecaller.vcf; 12:01:06.851 INFO VariantFiltration - Done initializing engine; 12:01:06.928 INFO ProgressMeter - Starting traversal; 12:01:06.928 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 12:01:07.147 INFO ProgressMeter - unmapped 0.0 926 253698.6; 12:01:07.147 INFO ProgressMeter - Traversal complete. Processed 926 total variants in 0.0 minutes.; 12:01:07.172 INFO VariantFiltration - Shutting down engine; [November 15, 2020 12:01:07 MST PM] org.broadinstitute.hellbender.tools.walkers.filters.VariantFiltration done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=209715200. ```. However, the same record remains in the output file, despite it's `MQ=30.51`?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6960
https://github.com/broadinstitute/gatk/issues/6960:1278,Performance,Load,Loading,1278,"ke:. ```; ##source=HaplotypeCaller; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT MTG324; I 1355499 . A G 127.14 . AC=2;AF=1.00;AN=2;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=30.51;QD=31.79;SOR=1.609 GT:AD:DP:GQ:PL 1/1:0,4:4:12:141,12,0; ```; The following filter is applied:. ```; $ gatk VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O test.vcf.gz --filter-expression ""MQ > 90.0"" --filter-name ""my_filters"". Using GATK jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O sanic.vcf.gz --filter-expression MQ > 90.0 --filter-name my_filters; 12:01:06.183 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 15, 2020 12:01:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:06.398 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.398 INFO VariantFiltration - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:06.398 INFO VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:06.398 INFO VariantFiltration - Executing as moldach@arc on Linux v3.10.0-1127.el7.x86_64 amd64; 12:01:06.399 INFO VariantFiltration - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 12:01:06.399 INFO VariantFiltration - Start Date/Time: November 15, 2020 12:01:06 MST PM; 12:01:06.399 INFO VariantFiltration - ----------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6960
https://github.com/broadinstitute/gatk/issues/6960:1567,Safety,detect,detect,1567,". ```; $ gatk VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O test.vcf.gz --filter-expression ""MQ > 90.0"" --filter-name ""my_filters"". Using GATK jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O sanic.vcf.gz --filter-expression MQ > 90.0 --filter-name my_filters; 12:01:06.183 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 15, 2020 12:01:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:06.398 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.398 INFO VariantFiltration - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:06.398 INFO VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:06.398 INFO VariantFiltration - Executing as moldach@arc on Linux v3.10.0-1127.el7.x86_64 amd64; 12:01:06.399 INFO VariantFiltration - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_252-b09; 12:01:06.399 INFO VariantFiltration - Start Date/Time: November 15, 2020 12:01:06 MST PM; 12:01:06.399 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.399 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.399 INFO VariantFiltration - HTSJDK Version: 2.23.0; 12:01:06.400 INFO VariantFiltration - Picard Version: 2.22.8; 12:01:06.400 INFO VariantFil",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6960
https://github.com/broadinstitute/gatk/issues/6960:671,Testability,test,test,671,"## Bug Report. ### Affected tool(s) or class(es). `VariantFiltration` not working on `HaplotypeCaller` VCF. ### Affected version(s). > Using GATK jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar. ### Description . Where a line of the VCF file looks like:. ```; ##source=HaplotypeCaller; #CHROM POS ID REF ALT QUAL FILTER INFO FORMAT MTG324; I 1355499 . A G 127.14 . AC=2;AF=1.00;AN=2;DP=4;ExcessHet=3.0103;FS=0.000;MLEAC=2;MLEAF=1.00;MQ=30.51;QD=31.79;SOR=1.609 GT:AD:DP:GQ:PL 1/1:0,4:4:12:141,12,0; ```; The following filter is applied:. ```; $ gatk VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O test.vcf.gz --filter-expression ""MQ > 90.0"" --filter-name ""my_filters"". Using GATK jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar VariantFiltration -R refs/c_elegans.PRJNA13758.WS265.genomic.fa -V VCFS/haplotypecaller.vcf -O sanic.vcf.gz --filter-expression MQ > 90.0 --filter-name my_filters; 12:01:06.183 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/work/mtgraovac_lab/tools/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 15, 2020 12:01:06 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:01:06.398 INFO VariantFiltration - ------------------------------------------------------------; 12:01:06.398 INFO VariantFiltration - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:01:06.398 INFO VariantFiltration - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:01:06.398 INFO VariantFiltration - Executing as moldach@arc on Linux v3.10",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6960
https://github.com/broadinstitute/gatk/issues/6962:1407,Availability,error,errors,1407,"## Feature request. ### Tool(s) or class(es) involved. [ReferenceConfidenceVariantContextMerger](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java). ### Description. In the case that VariantContexts with too many alternate alleles are passed to the joint genotyper, the genotype calculator used in the merger can experience an OOM:; ```; java.lang.OutOfMemoryError: Java heap space at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculator.genotypeIndexMap(GenotypeLikelihoodCalculator.java:522); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:541); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:116); ```. For a ~ reasonable number of alternate alleles, this site is filtered by the [genotyping engine](https://github.com/broadinstitute/gatk/blob/48afe160c9cfba5a82e40a6be9c8a555066271d1/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L380-L388), but it would be helpful if the merger also had a limit to avoid fatal errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6962
https://github.com/broadinstitute/gatk/issues/6962:1395,Safety,avoid,avoid,1395,"## Feature request. ### Tool(s) or class(es) involved. [ReferenceConfidenceVariantContextMerger](https://github.com/broadinstitute/gatk/blob/master/src/main/java/org/broadinstitute/hellbender/tools/walkers/ReferenceConfidenceVariantContextMerger.java). ### Description. In the case that VariantContexts with too many alternate alleles are passed to the joint genotyper, the genotype calculator used in the merger can experience an OOM:; ```; java.lang.OutOfMemoryError: Java heap space at org.broadinstitute.hellbender.tools.walkers.genotyper.GenotypeLikelihoodCalculator.genotypeIndexMap(GenotypeLikelihoodCalculator.java:522); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.mergeRefConfidenceGenotypes(ReferenceConfidenceVariantContextMerger.java:541); at org.broadinstitute.hellbender.tools.walkers.ReferenceConfidenceVariantContextMerger.merge(ReferenceConfidenceVariantContextMerger.java:130); at org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFsEngine.callRegion(GenotypeGVCFsEngine.java:116); ```. For a ~ reasonable number of alternate alleles, this site is filtered by the [genotyping engine](https://github.com/broadinstitute/gatk/blob/48afe160c9cfba5a82e40a6be9c8a555066271d1/src/main/java/org/broadinstitute/hellbender/tools/walkers/genotyper/GenotypingEngine.java#L380-L388), but it would be helpful if the merger also had a limit to avoid fatal errors.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6962
https://github.com/broadinstitute/gatk/issues/6963:196,Availability,error,error,196,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:678,Availability,error,error,678,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:1684,Availability,Error,Error,1684,"n/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:6303,Availability,down,down,6303,"37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz; 14:58:11.090 INFO FeatureManager - Using codec VCFCodec to read file file://~/projects/test2/temp/vatiant_germline/sites.only.vcf.gz; 14:58:11.139 INFO VariantRecalibrator - Done initializing engine; 14:58:11.142 INFO TrainingSet - Found mills track: Known = false Training = true Truth = true Prior = Q12.0; 14:58:11.142 INFO TrainingSet - Found dbsnp track: Known = true Training = false Truth = false Prior = Q2.0; 14:58:11.142 INFO TrainingSet - Found axiomPoly track: Known = false Training = true Truth = false Prior = Q10.0; 14:58:11.167 INFO ProgressMeter - Starting traversal; 14:58:11.168 INFO ProgressMeter - Current Locus Elapsed Minutes Variants Processed Variants/Minute; 14:58:21.182 INFO ProgressMeter - 2:23974966 0.2 22000 131828.6; 14:58:31.703 INFO ProgressMeter - 3:171904490 0.3 46000 134404.7; 14:58:41.753 INFO ProgressMeter - 6:18264210 0.5 67000 131441.3; 14:58:42.144 INFO VariantRecalibrator - Shutting down engine; [November 12, 2020 2:58:42 PM CST] org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator done. Elapsed time: 0.53 minutes.; Runtime.totalMemory()=29244260352; java.lang.IllegalStateException: The provided reference alleles do not appear to represent the same position, AC* vs. AA*; at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.determineReferenceAllele(GATKVariantContextUtils.java:209); at org.broadinstitute.hellbender.utils.variant.GATKVariantContextUtils.isAlleleInList(GATKVariantContextUtils.java:164); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.doAllelesMatch(VariantDataManager.java:424); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantDataManager.parseTrainingSets(VariantDataManager.java:399); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addDatum(VariantRecalibrator.java:614); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.addVariantDatum(VariantRe",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:3790,Deployability,release,release-,3790,"own=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:58:10.555 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.555 INFO VariantRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:58:10.555 INFO VariantRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:58:10.555 INFO VariantRecalibrator - Executing as y@c001 on Linux v3.10.0-957.el7.x86_64 amd64; 14:58:10.555 INFO VariantRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 14:58:10.556 INFO VariantRecalibrator - Start Date/Time: November 12, 2020 2:58:10 PM CST; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Version: 2.23.0; 14:58:10.556 INFO VariantRecalibrator - Picard Version: 2.23.3; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:58:10.556 INFO VariantRecalibrator - Deflater: IntelDeflater; 14:58:10.556 INFO VariantRecalibrator - Inflater: IntelInflater; 14:58:10.556 INFO VariantRecalibrator - GCS max retries/reopens: 20; 14:5",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:202,Integrability,message,message,202,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:1690,Integrability,Message,Message,1690,"n/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_su",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:8427,Integrability,wrap,wrapAndCopyInto,8427,calibrator.java:542); at java.util.ArrayList.forEach(ArrayList.java:1251); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.consumeQueuedVariants(VariantRecalibrator.java:542); at org.broadinstitute.hellbender.tools.walkers.vqsr.VariantRecalibrator.apply(VariantRecalibrator.java:521); at org.broadinstitute.hellbender.engine.MultiVariantWalker.lambda$traverse$1(MultiVariantWalker.java:120); at java.util.stream.ForEachOps$ForEachOp$OfRef.accept(ForEachOps.java:184); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.stream.ReferencePipeline$2$1.accept(ReferencePipeline.java:175); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.Iterator.forEachRemaining(Iterator.java:116); at java.util.Spliterators$IteratorSpliterator.forEachRemaining(Spliterators.java:1801); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ForEachOps$ForEachOp.evaluateSequential(ForEachOps.java:151); at java.util.stream.ForEachOps$ForEachOp$OfRef.evaluateSequential(ForEachOps.java:174); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.forEach(ReferencePipeline.java:418); at org.broadinstitute.hellbender.engine.MultiVariantWalker.traverse(MultiVariantWalker.java:118); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:933,Modifiability,polymorphi,polymorphic,933,"## Bug Report. ### Affected tool(s) or class(es); VariantRecalibrator; ; ### Affected version(s); -All versions after 4.1.4.1, including 4.1.9.0. ### Description ; A user on the forum reported an error message that does not give position information when reporting an allele problem in the reference. A similar issue in FilterVariantTranches was previously discussed at #6701 however the fix only changed FilterVariantTranches. We discussed adding a change with VariantRecalibrator that would also fix other GATK tools when this issue comes up. ; Forum Link: https://gatk.broadinstitute.org/hc/en-us/community/posts/360074618292-New-version-of-GATK-leads-to-VariantRecalibrator-error-. #### Command; `~/bin/gatk-4.1.9.0/gatk --java-options -Xms24g VariantRecalibrator -V temp/vartiant_germline/sites.only.vcf.gz -O temp/vartiant_germline/recaliberation.indel.vcf --tranches-file temp/vartiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.ja",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:2185,Modifiability,polymorphi,polymorphic,2185,"RankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz --use-allele-specific-annotations`. #### Error Message; ```; Using GATK jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xms24g -jar ~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz --use-allele-specific-annotations -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCred",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:2970,Performance,Load,Loading,2970,"9.0/gatk-package-4.1.9.0-local.jar VariantRecalibrator -V temp/vatiant_germline/sites.only.vcf.gz -O temp/vatiant_germline/recaliberation.indel.vcf --tranches-file temp/vatiant_germline/tranches.indel.txt --trust-all-polymorphic -tranche 100.0 -tranche 99.95 -tranche 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz --use-allele-specific-annotations -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:58:10.555 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.555 INFO VariantRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:58:10.555 INFO VariantRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:58:10.555 INFO VariantRecalibrator - Executing as y@c001 on Linux v3.10.0-957.el7.x86_64 amd64; 14:58:10.555 INFO VariantRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 14:58:10.556 INFO VariantRecalibrator - Start Date/Time: November 12, 2020 2:58:10 PM CST; 14:58:10.556 INFO VariantRecalibrator - -----------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6963:3238,Safety,detect,detect,3238,"he 99.9 -tranche 99.5 -tranche 99.0 -tranche 97.0 -tranche 96.0 -tranche 95.0 -tranche 94.0 -tranche 93.5 -tranche 93.0 -tranche 92.0 -tranche 91.0 -tranche 90.0 -an DP -an FS -an MQRankSum -an QD -an ReadPosRankSum -an SOR -mode INDEL --max-gaussians 4 -resource:mills,known=false,training=true,truth=true,prior=12 ~/db/mutect2_support/b37/Mills_and_1000G_gold_standard.indels.b37.sites.vcf.gz -resource:dbsnp,known=true,training=false,truth=false,prior=2 ~/db/mutect2_support/b37/hg19_v0_dbsnp_138.b37.vcf.gz --use-allele-specific-annotations -resource:axiomPoly,known=false,training=true,truth=false,prior=10 ~/db/mutect2_support/b37/Axiom_Exome_Plus.genotypes.all_populations.poly.b37.vcf.gz. 14:58:10.389 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:~/bin/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; Nov 12, 2020 2:58:10 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 14:58:10.555 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.555 INFO VariantRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:58:10.555 INFO VariantRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:58:10.555 INFO VariantRecalibrator - Executing as y@c001 on Linux v3.10.0-957.el7.x86_64 amd64; 14:58:10.555 INFO VariantRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_152-release-1056-b12; 14:58:10.556 INFO VariantRecalibrator - Start Date/Time: November 12, 2020 2:58:10 PM CST; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - ------------------------------------------------------------; 14:58:10.556 INFO VariantRecalibrator - HTSJDK Version: 2.23.0; 14:58:10.556 INFO VariantRecalibrator - Picard Version: 2.23.3; 14",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6963
https://github.com/broadinstitute/gatk/issues/6965:204,Deployability,update,update,204,"## Documentation request. ### Tool(s) or class(es) involved. In the document `docs/mutect/mutect.pdf` there are many references to filter names that have either changed or used shorthand names. We should update the documentation to reflect the actual filter names used in Mutect2. Some examples:; ""fragment_length"" in the document refers to ""fragment"" filter.; ""duplicate_evidence"" as ""duplicates""; ""base_quality"" as ""base_qual"". There are probably a number of other differences, we should ensure all are up to date.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6965
https://github.com/broadinstitute/gatk/pull/6971:55,Testability,test,testing,55,I think this is ready for initial review while I start testing it on larger scale data. I've left adding in the full VQSR tranche filtering as TODOs for now.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6971
https://github.com/broadinstitute/gatk/issues/6972:127,Deployability,release,release,127,"#6329 Bug Report. ### Affected tool(s) or class(es); Mutect2 / FilterMutectCalls. ### Affected version(s); - [x] Latest public release version [version?]. ### Description . Variants with alternative representations in gnomad are not recognized as being the same as called variants in some cases. This results in variants that are called and not filtered, but they should be filtered by ""germline"". As an example of this, in gnomad the site hg19 16:72991715 is represented as:; 16	72991715	.	ACCG	GCCG,*,AGCCGCCG	14986622.13	PASS	AC=33700,10,4;AF=0.83,2.463E-4,9.852E-5. But in M2 it is called as:; A->G. Although ACCG->GCCG and A->G are equivalent, they are not recognized as identical. #### Expected behavior; Mutect2 should filter these variants as germline. #### Actual behavior; Mutect2 does not filter these variants.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6972
https://github.com/broadinstitute/gatk/pull/6973:460,Energy Efficiency,reduce,reduce,460,"@cmnbroad This is related to discussion on issue 5439. This is not a final product yet. I'm opening the PR to see how it works on travis and to push discussion here. This PR is not trying to fix all issues with VariantEval. It's trying to address these:. 1) Switch to MultiVariantWalkerGroupedOnStart, primarily to avoid the constant re-querying of variants per site that took place in VariantEvalUtils.bindVariantContexts(). I believe this will substantially reduce the number of instance in which featureContext.getValues() is called. 2) I tried to move, but not full fix, some of the tight linkage between the VariantEval Walker class and the plugin classes. I also made a VariantEvalArgumentCollection to start separating these. Toward this objective, this PR does: a) makes a VariantEvalContext class, which is what gets passed to the VariantStratifier classes, and b) I try to reduce exposing the walker class directly to VariantStratifier and VariantEvaluator. The latter is not completely done, but I think this is moving it in that direction. At several points I stopped for the sake of keeping changes in one PR manageable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973
https://github.com/broadinstitute/gatk/pull/6973:883,Energy Efficiency,reduce,reduce,883,"@cmnbroad This is related to discussion on issue 5439. This is not a final product yet. I'm opening the PR to see how it works on travis and to push discussion here. This PR is not trying to fix all issues with VariantEval. It's trying to address these:. 1) Switch to MultiVariantWalkerGroupedOnStart, primarily to avoid the constant re-querying of variants per site that took place in VariantEvalUtils.bindVariantContexts(). I believe this will substantially reduce the number of instance in which featureContext.getValues() is called. 2) I tried to move, but not full fix, some of the tight linkage between the VariantEval Walker class and the plugin classes. I also made a VariantEvalArgumentCollection to start separating these. Toward this objective, this PR does: a) makes a VariantEvalContext class, which is what gets passed to the VariantStratifier classes, and b) I try to reduce exposing the walker class directly to VariantStratifier and VariantEvaluator. The latter is not completely done, but I think this is moving it in that direction. At several points I stopped for the sake of keeping changes in one PR manageable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973
https://github.com/broadinstitute/gatk/pull/6973:646,Modifiability,plugin,plugin,646,"@cmnbroad This is related to discussion on issue 5439. This is not a final product yet. I'm opening the PR to see how it works on travis and to push discussion here. This PR is not trying to fix all issues with VariantEval. It's trying to address these:. 1) Switch to MultiVariantWalkerGroupedOnStart, primarily to avoid the constant re-querying of variants per site that took place in VariantEvalUtils.bindVariantContexts(). I believe this will substantially reduce the number of instance in which featureContext.getValues() is called. 2) I tried to move, but not full fix, some of the tight linkage between the VariantEval Walker class and the plugin classes. I also made a VariantEvalArgumentCollection to start separating these. Toward this objective, this PR does: a) makes a VariantEvalContext class, which is what gets passed to the VariantStratifier classes, and b) I try to reduce exposing the walker class directly to VariantStratifier and VariantEvaluator. The latter is not completely done, but I think this is moving it in that direction. At several points I stopped for the sake of keeping changes in one PR manageable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973
https://github.com/broadinstitute/gatk/pull/6973:315,Safety,avoid,avoid,315,"@cmnbroad This is related to discussion on issue 5439. This is not a final product yet. I'm opening the PR to see how it works on travis and to push discussion here. This PR is not trying to fix all issues with VariantEval. It's trying to address these:. 1) Switch to MultiVariantWalkerGroupedOnStart, primarily to avoid the constant re-querying of variants per site that took place in VariantEvalUtils.bindVariantContexts(). I believe this will substantially reduce the number of instance in which featureContext.getValues() is called. 2) I tried to move, but not full fix, some of the tight linkage between the VariantEval Walker class and the plugin classes. I also made a VariantEvalArgumentCollection to start separating these. Toward this objective, this PR does: a) makes a VariantEvalContext class, which is what gets passed to the VariantStratifier classes, and b) I try to reduce exposing the walker class directly to VariantStratifier and VariantEvaluator. The latter is not completely done, but I think this is moving it in that direction. At several points I stopped for the sake of keeping changes in one PR manageable.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6973
https://github.com/broadinstitute/gatk/pull/6974:18,Deployability,install,installation,18,"Our travis gcloud installation scripts relied on piping interactive responses; into the stdin of the installer, which is brittle. This patch changes our script to instead run the installer in non-interactive mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974
https://github.com/broadinstitute/gatk/pull/6974:101,Deployability,install,installer,101,"Our travis gcloud installation scripts relied on piping interactive responses; into the stdin of the installer, which is brittle. This patch changes our script to instead run the installer in non-interactive mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974
https://github.com/broadinstitute/gatk/pull/6974:135,Deployability,patch,patch,135,"Our travis gcloud installation scripts relied on piping interactive responses; into the stdin of the installer, which is brittle. This patch changes our script to instead run the installer in non-interactive mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974
https://github.com/broadinstitute/gatk/pull/6974:179,Deployability,install,installer,179,"Our travis gcloud installation scripts relied on piping interactive responses; into the stdin of the installer, which is brittle. This patch changes our script to instead run the installer in non-interactive mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6974
https://github.com/broadinstitute/gatk/pull/6976:80,Testability,test,tests,80,"Fixing a bug I noticed while spot checking sites. We should eventually add some tests that check expected outputs, but I'll save that for another day. We were accidentally applying filters to alleles in the filtering table that didn't exist in the cohort that was pulled out. Now we're only looking at VQSLODs in the filter table for alleles that are present in the output VCF.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6976
https://github.com/broadinstitute/gatk/issues/6978:3,Deployability,Update,Update,3,"## Update numpy\scipy\pymc3 python package. ### Tool(s) or class(es) involved. python\gcnvkernel; python\vqsr_cnn. ### Description; want to use the newer numpy 1.19.4, but I found that gatk uses conda-force to install the older numpy 1.17.5, and it is not allowed to upgrade numpy because of scipy version restrictions. And scipy cannot be upgraded because of the version limitation of pymc3. I think we should use the new version of the software (in the new version, some bugs are fixed, the performance is better), we need to deal with the difficulties and help the software upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978
https://github.com/broadinstitute/gatk/issues/6978:210,Deployability,install,install,210,"## Update numpy\scipy\pymc3 python package. ### Tool(s) or class(es) involved. python\gcnvkernel; python\vqsr_cnn. ### Description; want to use the newer numpy 1.19.4, but I found that gatk uses conda-force to install the older numpy 1.17.5, and it is not allowed to upgrade numpy because of scipy version restrictions. And scipy cannot be upgraded because of the version limitation of pymc3. I think we should use the new version of the software (in the new version, some bugs are fixed, the performance is better), we need to deal with the difficulties and help the software upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978
https://github.com/broadinstitute/gatk/issues/6978:267,Deployability,upgrade,upgrade,267,"## Update numpy\scipy\pymc3 python package. ### Tool(s) or class(es) involved. python\gcnvkernel; python\vqsr_cnn. ### Description; want to use the newer numpy 1.19.4, but I found that gatk uses conda-force to install the older numpy 1.17.5, and it is not allowed to upgrade numpy because of scipy version restrictions. And scipy cannot be upgraded because of the version limitation of pymc3. I think we should use the new version of the software (in the new version, some bugs are fixed, the performance is better), we need to deal with the difficulties and help the software upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978
https://github.com/broadinstitute/gatk/issues/6978:340,Deployability,upgrade,upgraded,340,"## Update numpy\scipy\pymc3 python package. ### Tool(s) or class(es) involved. python\gcnvkernel; python\vqsr_cnn. ### Description; want to use the newer numpy 1.19.4, but I found that gatk uses conda-force to install the older numpy 1.17.5, and it is not allowed to upgrade numpy because of scipy version restrictions. And scipy cannot be upgraded because of the version limitation of pymc3. I think we should use the new version of the software (in the new version, some bugs are fixed, the performance is better), we need to deal with the difficulties and help the software upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978
https://github.com/broadinstitute/gatk/issues/6978:577,Deployability,upgrade,upgrade,577,"## Update numpy\scipy\pymc3 python package. ### Tool(s) or class(es) involved. python\gcnvkernel; python\vqsr_cnn. ### Description; want to use the newer numpy 1.19.4, but I found that gatk uses conda-force to install the older numpy 1.17.5, and it is not allowed to upgrade numpy because of scipy version restrictions. And scipy cannot be upgraded because of the version limitation of pymc3. I think we should use the new version of the software (in the new version, some bugs are fixed, the performance is better), we need to deal with the difficulties and help the software upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978
https://github.com/broadinstitute/gatk/issues/6978:493,Performance,perform,performance,493,"## Update numpy\scipy\pymc3 python package. ### Tool(s) or class(es) involved. python\gcnvkernel; python\vqsr_cnn. ### Description; want to use the newer numpy 1.19.4, but I found that gatk uses conda-force to install the older numpy 1.17.5, and it is not allowed to upgrade numpy because of scipy version restrictions. And scipy cannot be upgraded because of the version limitation of pymc3. I think we should use the new version of the software (in the new version, some bugs are fixed, the performance is better), we need to deal with the difficulties and help the software upgrade.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6978
https://github.com/broadinstitute/gatk/issues/6984:573,Usability,simpl,simply,573,"Originally reported as https://github.com/broadinstitute/gatk-tool-wdls/issues/1. Tracking this here until we figure out the governance and permissions for the [gatk-tool-wdls](https://github.com/broadinstitute/gatk-tool-wdls/) repo:. For example in CombineGVCFs.wdl one can see indexOutput as optional input argument:. ```; # Required Arguments; String output_arg; String? outputIndex; ```; (first of all, outputIndex is not required, since it's a String?....but this is semantics). but more importantly, this argument (a String) is not used in the command section, which simply reads. ```; ~{gatk} CombineGVCFs \; --output ~{sep=' --output ' output_arg} \; --reference ~{sep=' --reference ' reference} \; --variant ~{sep=' --variant ' variant} \; ```; and the where is does appear is in the output section where the String? is converted to a File?. ```; File? CombineGVCFs_outputIndex = outputIndex; ```; which effectively means that the user needs to know in advance what will be the name of the index that is generated, if they want to delocalize it. This seems to be cumbersome. I would think that a tool that generates an index should be able to figure out the name of this index and provide it to the user rather then expect the user to know the name. I understand that there are idx/tbi issues, but these are issues we should tackle, rather than leave them to the user to tackle. Can write a small GATK/htsjdk commandline tool that for every filename provides the name of its natural index, and call to that in order to find the name of the index...",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6984
https://github.com/broadinstitute/gatk/pull/6986:82,Security,access,access,82,"New version allows restricting which users can trigger carrot jobs based on their access to the repository. In this case, I've set it to restrict to only users who have at least write access.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6986
https://github.com/broadinstitute/gatk/pull/6986:184,Security,access,access,184,"New version allows restricting which users can trigger carrot jobs based on their access to the repository. In this case, I've set it to restrict to only users who have at least write access.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6986
https://github.com/broadinstitute/gatk/issues/6988:6,Availability,down,downloaded,6,"hi, I downloaded the hg38 database from the following URL two months ago, which contains some known sites of vcf files such as snp and indel;; https://gatk.broadinstitute.org/hc/en-us/articles/360035890811GATK resource bundle; But now I found that the contents of these vcf files cannot be viewed. I think the vcf files should be viewed under normal circumstances; now I want to restart download the data; but the official website was updated two days ago, can you give me a website to download the data?; thanks. the error for view is:; 1000G_phase1.snps.high_confidence.hg38.vcf may be a binary file;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6988
https://github.com/broadinstitute/gatk/issues/6988:388,Availability,down,download,388,"hi, I downloaded the hg38 database from the following URL two months ago, which contains some known sites of vcf files such as snp and indel;; https://gatk.broadinstitute.org/hc/en-us/articles/360035890811GATK resource bundle; But now I found that the contents of these vcf files cannot be viewed. I think the vcf files should be viewed under normal circumstances; now I want to restart download the data; but the official website was updated two days ago, can you give me a website to download the data?; thanks. the error for view is:; 1000G_phase1.snps.high_confidence.hg38.vcf may be a binary file;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6988
https://github.com/broadinstitute/gatk/issues/6988:487,Availability,down,download,487,"hi, I downloaded the hg38 database from the following URL two months ago, which contains some known sites of vcf files such as snp and indel;; https://gatk.broadinstitute.org/hc/en-us/articles/360035890811GATK resource bundle; But now I found that the contents of these vcf files cannot be viewed. I think the vcf files should be viewed under normal circumstances; now I want to restart download the data; but the official website was updated two days ago, can you give me a website to download the data?; thanks. the error for view is:; 1000G_phase1.snps.high_confidence.hg38.vcf may be a binary file;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6988
https://github.com/broadinstitute/gatk/issues/6988:519,Availability,error,error,519,"hi, I downloaded the hg38 database from the following URL two months ago, which contains some known sites of vcf files such as snp and indel;; https://gatk.broadinstitute.org/hc/en-us/articles/360035890811GATK resource bundle; But now I found that the contents of these vcf files cannot be viewed. I think the vcf files should be viewed under normal circumstances; now I want to restart download the data; but the official website was updated two days ago, can you give me a website to download the data?; thanks. the error for view is:; 1000G_phase1.snps.high_confidence.hg38.vcf may be a binary file;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6988
https://github.com/broadinstitute/gatk/issues/6988:436,Deployability,update,updated,436,"hi, I downloaded the hg38 database from the following URL two months ago, which contains some known sites of vcf files such as snp and indel;; https://gatk.broadinstitute.org/hc/en-us/articles/360035890811GATK resource bundle; But now I found that the contents of these vcf files cannot be viewed. I think the vcf files should be viewed under normal circumstances; now I want to restart download the data; but the official website was updated two days ago, can you give me a website to download the data?; thanks. the error for view is:; 1000G_phase1.snps.high_confidence.hg38.vcf may be a binary file;",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6988
https://github.com/broadinstitute/gatk/issues/6990:267,Availability,error,error,267,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990
https://github.com/broadinstitute/gatk/issues/6990:273,Integrability,message,message,273,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990
https://github.com/broadinstitute/gatk/issues/6990:288,Testability,log,logs,288,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990
https://github.com/broadinstitute/gatk/issues/6990:1205,Testability,log,log,1205,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990
https://github.com/broadinstitute/gatk/issues/6990:1293,Testability,log,log,1293,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990
https://github.com/broadinstitute/gatk/issues/6990:261,Usability,clear,clear,261,"I am running Gatk SelectVariant with -L and -ip options to filter out variants that are not inside my bed defined region +- interval padding. I am running gatk version 4.1.0.0 and for some of my task fails and returns ``` rc 1 (exit code 1) ``` but there is no clear error message on any logs. . ``` Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Dsamjdk.compression_level=5 -Xms100g -Xmx100g -jar /root/gatk.jar SelectVariants -L /cromwell_root/mybucket/ref/bed_files/mybedfile.bed -R /cromwell_root/mybucket2/NGS/ref/hg38/v0/Homo_sapiens_assembly38.fasta -V /cromwell_root/mybucket/cromwell-execution/mypipeline/2baacdb4-d3c5-4d98-afb2-6578c3ddcda9/call-MT2/calling.Mutect2/a4839059-9209-42da-b106-a91393c47546/call-Filter/input.vcf -ip 20 -O output.vcf --verbosity DEBUG ; ```. Task seems to end prematurely but I can not find out why. Also output file is generated but it only has variants from chr 1 even though my sample is whole exome, which also supports the premature end of task theory. Stdout is empty and stderr seems to end prematurely. [failing_SelectVariants-stderr.log](https://github.com/broadinstitute/gatk/files/5652756/failing_SelectVariants-stderr.log)",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6990
https://github.com/broadinstitute/gatk/issues/6992:240,Availability,down,down-engine-Encountering-a-large-genome,240,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992
https://github.com/broadinstitute/gatk/issues/6992:352,Availability,error,error,352,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992
https://github.com/broadinstitute/gatk/issues/6992:631,Availability,error,error,631,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992
https://github.com/broadinstitute/gatk/issues/6992:734,Availability,error,error,734,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992
https://github.com/broadinstitute/gatk/issues/6992:358,Integrability,message,message,358,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992
https://github.com/broadinstitute/gatk/issues/6992:740,Integrability,message,message,740,"## Bug Report. ### Affected tool(s) or class(es); HaplotypeCaller. ### Affected version(s); No version information yet, [here is the forum link](https://gatk.broadinstitute.org/hc/en-us/community/posts/360075181171-HaplotypeCaller-Shutting-down-engine-Encountering-a-large-genome) for information. ### Description ; A user wrote into the forum with an error message while HaplotypeCaller was creating the output variant index with an issue of how many bins needed to be created. They have a large genome with long contig(s). We discussed at the GATK Office Hours meeting about adding a check to find this issue so that there is an error or warning before running HaplotypeCaller instead of at the end of the process. A snippet of the error message can be found at the forum post.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6992
https://github.com/broadinstitute/gatk/issues/6994:789,Deployability,configurat,configuration,789,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:932,Deployability,configurat,configuration,932,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:85,Modifiability,config,configs,85,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:494,Modifiability,config,config,494,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:580,Modifiability,config,configs,580,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:789,Modifiability,config,configuration,789,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:932,Modifiability,config,configuration,932,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:1201,Modifiability,config,config,1201,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:28,Performance,perform,performs,28,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:1052,Performance,perform,performed,1052,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:853,Safety,risk,risk,853,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:996,Safety,risk,risk,996,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:300,Security,expose,exposed,300,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:1171,Security,expose,exposed,1171,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6994:1376,Security,expose,exposed,1376,"PostprocessGermlineCNVCalls performs a check of the denoising/calling hyperparameter configs used to generate the model in GermlineCNVCaller cohort mode against those used to generate the case-mode result passed to PostprocessGermlineCNVCalls. However, although some of these hyperparameters are not exposed in case mode (since they have no effect on the sample-level parameters inferred in case mode, e.g., `psi_t_scale`), their python default values are nevertheless written to the case-mode config. I think that this results in a spurious mismatch between the cohort/case mode configs, which causes PostprocessGermlineCNVCalls to emit the following warnings in case mode when non-default values are used:. ````; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different denoising configuration between model and calls -- proceeding at your own risk!; WARNING gcnvkernel.postprocess.viterbi_segmentation - Different calling configuration between model and calls -- proceeding at your own risk!; ````. I'm pretty sure that inference is actually performed correctly, but we may want to double check and clean up these warnings. We should probably just copy the non-exposed values from the model config on the python side when running GermlineCNVCaller in case mode. Not sure if there's any way to emit sensible warnings on the Java side. These hyperparameters are still exposed to the Java command line in case mode, they just aren't passed on to the python command line. So the user can change their values from their engine defaults without having any effect at all, but this is probably what we want. Perhaps we can document, though.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6994
https://github.com/broadinstitute/gatk/issues/6995:68,Modifiability,Variab,Variable,68,"For example, contig-ploidy disk space is exposed only in case mode. Variable names are somewhat inconsistent, too (`disk_space_*` vs. `disk_space_gb_*`).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6995
https://github.com/broadinstitute/gatk/issues/6995:41,Security,expose,exposed,41,"For example, contig-ploidy disk space is exposed only in case mode. Variable names are somewhat inconsistent, too (`disk_space_*` vs. `disk_space_gb_*`).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6995
https://github.com/broadinstitute/gatk/issues/6996:1366,Availability,error,error,1366,"r issue (or something similar) has already been reported. If the issue already exists, you may comment there to inquire about the progress.; - Determine whether your issue is a **bug report**, a **feature request**, or a **documentation request** (for tool/class javadoc only -- for forum docs please post there); - Consider if your ""issue"" is better addressed on the GATK forum: http://gatkforums.broadinstitute.org/gatk Post there if you have questions about expected tool behavior, output format, unexpected results, or generally any question that does not fit into the categories above; - Use a **concise** yet **descriptive** title; - Choose the corresponding template block below and fill it in, replacing or deleting text in italics (surrounded by `_`) as appropriate; - Delete the other template blocks and this header. ----. ## Bug Report. ### Affected tool(s) or class(es); FilterMutectCalls. ### Affected version(s); - gatk-4.1.9.0. ### Description ; When I was running FilterMutectCalls with one of my samples, I got an error as ""Duplicate key"". 14:50:59.201 INFO FilterMutectCalls - ------------------------------------------------------------; 14:50:59.202 INFO FilterMutectCalls - The Genome Analysis Toolkit (GATK) v4.1.9.0; 14:50:59.202 INFO FilterMutectCalls - For support and documentation go to https://software.broadinstitute.org/gatk/; 14:50:59.203 INFO FilterMutectCalls - Executing as mparment@her2-w110 on Linux v5.7.7-1.el7.elrepo.x86_64 amd64; 14:50:59.203 INFO FilterMutectCalls - Java runtime: Java HotSpot(TM) 64-Bit Server VM v1.8.0_31-b13; 14:50:59.203 INFO FilterMutectCalls - Start Date/Time: December 12, 2020 2:50:57 PM CET; 14:50:59.203 INFO FilterMutectCalls - ------------------------------------------------------------; 14:50:59.203 INFO FilterMutectCalls - ------------------------------------------------------------; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Version: 2.23.0; 14:50:59.204 INFO FilterMutectCalls - Picard Version: 2.23.3; 14:50:59.204 IN",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:3242,Availability,down,down,3242,"2.23.0; 14:50:59.204 INFO FilterMutectCalls - Picard Version: 2.23.3; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 14:50:59.204 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 14:50:59.205 INFO FilterMutectCalls - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 14:50:59.205 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:50:59.205 INFO FilterMutectCalls - Inflater: IntelInflater; 14:50:59.205 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:50:59.205 INFO FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:5584,Availability,error,error,5584,roadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); at org.broadinstitute.hellbender.Main.main(Main.java:289); srun: error: her2-w110: task 0: Exited with exit code 3. #### Steps to reproduce. cd /software/gatk-4.1.9.0. srun ./gatk FilterMutectCalls -R /CECI/proj/iribhm/tc_phylogeny/genome/resources_broad_hg38_v0_Homo_sapiens_assembly38.fasta -V /workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S5_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T4_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:8376,Availability,error,error,8376,"segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S1_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S5_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T3_segments.table --tumor-segmentation /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T4_segments.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T2_S5_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S2_PTC2_T4_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S1_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T2_S5_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T3_contamination.table --contamination-table /workdir/mparment/data/process/A2683/PTC2_N3_S4_PTC2_T4_contamination.table -ob-priors /workdir/mparment/data/process/A2683/PTC2_read-orientation-model.tar.gz -O /workdir/mparment/data/process/A2683/PTC2_filtered.vcf.gz. #### Actual behavior; It look like this error: https://github.com/broadinstitute/gatk/issues/3018. I followed GATK's good practice rules and I use Mutect2 in ""multisample"" mode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:3875,Energy Efficiency,Reduce,ReduceOps,3875,"O FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbend",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:3906,Energy Efficiency,Reduce,ReduceOps,3906,"- Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mute",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:4263,Energy Efficiency,Reduce,ReduceOps,4263,0 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:4273,Energy Efficiency,Reduce,ReduceOp,4273,0 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:4301,Energy Efficiency,Reduce,ReduceOps,4301,oadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); at org.broadinstitute,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:4199,Integrability,wrap,wrapAndCopyInto,4199,"lterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFiltersList(Mutect2FilteringEngine.java:290); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.<init>(Mutect2FilteringEngine.java:60); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls.onTraversalStart(FilterMutectCalls.java:138); at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1047); at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); at org.broadinstitute.hellbender.cmdline.CommandLineProg",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:3674,Security,Hash,HashMap,3674,"14:50:59.205 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:50:59.205 INFO FilterMutectCalls - Inflater: IntelInflater; 14:50:59.205 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:50:59.205 INFO FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6996:3688,Security,Hash,HashMap,3688,"5 INFO FilterMutectCalls - Deflater: IntelDeflater; 14:50:59.205 INFO FilterMutectCalls - Inflater: IntelInflater; 14:50:59.205 INFO FilterMutectCalls - GCS max retries/reopens: 20; 14:50:59.205 INFO FilterMutectCalls - Requester pays: disabled; 14:50:59.205 INFO FilterMutectCalls - Initializing engine; 14:51:00.692 INFO FeatureManager - Using codec VCFCodec to read file file:///workdir/mparment/data/process/A2683/PTC2_unfiltered.vcf.gz; 14:51:01.406 INFO FilterMutectCalls - Done initializing engine; 14:51:02.360 INFO FilterMutectCalls - Shutting down engine; [December 12, 2020 2:51:02 PM CET] org.broadinstitute.hellbender.tools.walkers.mutect.filtering.FilterMutectCalls done. Elapsed time: 0.07 minutes.; Runtime.totalMemory()=2385510400; java.lang.IllegalStateException: Duplicate key 7.395307178412063E-4; at java.util.stream.Collectors.lambda$throwingMerger$138(Collectors.java:133); at java.util.stream.Collectors$$Lambda$67/403388441.apply(Unknown Source); at java.util.HashMap.merge(HashMap.java:1245); at java.util.stream.Collectors.lambda$toMap$196(Collectors.java:1320); at java.util.stream.Collectors$$Lambda$69/854719230.accept(Unknown Source); at java.util.stream.ReduceOps$3ReducingSink.accept(ReduceOps.java:169); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:512); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:502); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.collect(ReferencePipeline.java:499); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.ContaminationFilter.<init>(ContaminationFilter.java:26); at org.broadinstitute.hellbender.tools.walkers.mutect.filtering.Mutect2FilteringEngine.buildFilte",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6996
https://github.com/broadinstitute/gatk/issues/6997:104,Modifiability,inherit,inherits,104,"The AlleleFrequencyQC tool subclasses VariantEval, but doesn't provide it's own tool annotations, so it inherits VariantEval's `@BetaFeature` status and command line description. It also appears to directly clobber several of the command line argument values provided by the user, including the name of the output file. It should have its own `@CommandLineProgramProperties` and `@BetaFeature/@Experimental` annotations, and preferably better argument handling. Longer term, when https://github.com/broadinstitute/gatk/issues/5439 is done, it should be refactored so it uses the `VariantEval` engine class that will be part of that work, instead of subclassing the VariantEval tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6997
https://github.com/broadinstitute/gatk/issues/6997:553,Modifiability,refactor,refactored,553,"The AlleleFrequencyQC tool subclasses VariantEval, but doesn't provide it's own tool annotations, so it inherits VariantEval's `@BetaFeature` status and command line description. It also appears to directly clobber several of the command line argument values provided by the user, including the name of the output file. It should have its own `@CommandLineProgramProperties` and `@BetaFeature/@Experimental` annotations, and preferably better argument handling. Longer term, when https://github.com/broadinstitute/gatk/issues/5439 is done, it should be refactored so it uses the `VariantEval` engine class that will be part of that work, instead of subclassing the VariantEval tool.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6997
https://github.com/broadinstitute/gatk/issues/6998:111,Deployability,release,release,111,"## Bug Report. ### Affected tool(s) or class(es); SelectVariants. ### Affected version(s); - [ ] Latest public release version [version?]; - [x] Latest master branch as of Dec 14, 2020. ### Description ; I believe SelectVariants doesn't handle multi-allelic sites, which have more than one value per INFO field. The problem seems to be in coercing values like 0.00022456 and 2.496e-05 (note the decimal and scientific notation) into doubles, which happens in the apache commons code. But the problem is not limited to decimal valuesit fails to coerce integers like 0 and 9 (see below). . #### Steps to reproduce; gnomad=gs://gatk-best-practices/somatic-hg38/af-only-gnomad.hg38.vcf.gz; java -jar $gatkjar SelectVariants -V $gnomad -select ""AF > 0.05"" -O af-only-gnomad.hg38.contamination.vcf.gz. This one fails with `java.lang.ArithmeticException: Double coercion: java.util.ArrayList:([0.0002246, 2.496e-05])`. Also fails with the expression ""AC > 3"":. javadebug -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar $gatkjar SelectVariants -V $gnomad -select ""AC > 3"" -O af-only-gnomad.hg38.contamination.vcf.gz. `java.lang.ArithmeticException: Long coercion: java.util.ArrayList:([9, 1])`. #### Expected behavior; The tool should run to completion. #### Actual behavior; It doesn't.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/6998
https://github.com/broadinstitute/gatk/pull/6999:100,Availability,avail,available,100,"Mutect2 matches called variants against known variants retrieved from the germline resource VCF (if available) for the POPAF annotation. While comparing the called allele to the germline resource variants, Mutect2 only takes into account the sequence of the alternate allele(s) while ignoring the reference allele sequence. This can cause incorrect annotations at sites with multiple alternate alleles (e.g. CT -> C/CTT in the germline resource while M2 calls C -> CT). This PR is a proposed fix along with some unit tests that demonstrate the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6999
https://github.com/broadinstitute/gatk/pull/6999:517,Testability,test,tests,517,"Mutect2 matches called variants against known variants retrieved from the germline resource VCF (if available) for the POPAF annotation. While comparing the called allele to the germline resource variants, Mutect2 only takes into account the sequence of the alternate allele(s) while ignoring the reference allele sequence. This can cause incorrect annotations at sites with multiple alternate alleles (e.g. CT -> C/CTT in the germline resource while M2 calls C -> CT). This PR is a proposed fix along with some unit tests that demonstrate the issue.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/6999
https://github.com/broadinstitute/gatk/issues/7001:527,Availability,heartbeat,heartbeatInterval,527,"Hi,; I run the code below to to skip optical duplicate detection during marking duplicate.; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=trueDsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:590,Availability,error,error,590,"Hi,; I run the code below to to skip optical duplicate detection during marking duplicate.; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=trueDsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:623,Availability,ERROR,ERROR,623,"Hi,; I run the code below to to skip optical duplicate detection during marking duplicate.; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=trueDsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:1293,Energy Efficiency,Reduce,ReduceOps,1293,arkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.Unsaf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:1303,Energy Efficiency,Reduce,ReduceOp,1303,arkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.Unsaf,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:1331,Energy Efficiency,Reduce,ReduceOps,1331,rk-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(Uns,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:1464,Energy Efficiency,reduce,reduce,1464,f spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTas,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:2375,Energy Efficiency,schedul,scheduler,2375,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:2454,Energy Efficiency,schedul,scheduler,2454,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:2533,Energy Efficiency,schedul,scheduler,2533,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:1229,Integrability,wrap,wrapAndCopyInto,1229,vel=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(It,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:2814,Performance,concurren,concurrent,2814,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:2898,Performance,concurren,concurrent,2898,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:55,Safety,detect,detection,55,"Hi,; I run the code below to to skip optical duplicate detection during marking duplicate.; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=trueDsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:492,Safety,timeout,timeout,492,"Hi,; I run the code below to to skip optical duplicate detection during marking duplicate.; `java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=trueDsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /gatk-4.1.8.0/gatk-package-4.1.8.0-local.jar MarkDuplicatesSpark --spark-master local[28] --conf spark.local.dir=/datatmp/ -I ./A.sort.bam -O ./A.sort.bam.Mdup.bam -M ./A.sort.bam.Md.metrics.txt --tmp-dir /datatmp/ --conf spark.network.timeout=200h --conf spark.executor.heartbeatInterval=100h --read-name-regex null`; It reports the error below.; `20/12/15 11:43:00 ERROR Executor: Exception in task 15.0 in stage 7.0 (TID 12538); java.lang.NullPointerException; at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$handleFragments$12(MarkDuplicatesSparkUtils.java:395); at java.util.stream.ReferencePipeline$11$1.accept(ReferencePipeline.java:372); at java.util.stream.ReferencePipeline$3$1.accept(ReferencePipeline.java:193); at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:2298,Safety,Unsafe,UnsafeShuffleWriter,2298,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7001:2324,Safety,Unsafe,UnsafeShuffleWriter,2324,"t$ArrayListSpliterator.forEachRemaining(ArrayList.java:1374); at java.util.stream.AbstractPipeline.copyInto(AbstractPipeline.java:481); at java.util.stream.AbstractPipeline.wrapAndCopyInto(AbstractPipeline.java:471); at java.util.stream.ReduceOps$ReduceOp.evaluateSequential(ReduceOps.java:708); at java.util.stream.AbstractPipeline.evaluate(AbstractPipeline.java:234); at java.util.stream.ReferencePipeline.reduce(ReferencePipeline.java:479); at java.util.stream.ReferencePipeline.max(ReferencePipeline.java:515); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.handleFragments(MarkDuplicatesSparkUtils.java:396); at org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSparkUtils.lambda$markDuplicateRecords$fa45b352$1(MarkDuplicatesSparkUtils.java:304); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at org.apache.spark.api.java.JavaRDDLike$$anonfun$fn$3$1.apply(JavaRDDLike.scala:143); at scala.collection.Iterator$$anon$12.nextCur(Iterator.scala:435); at scala.collection.Iterator$$anon$12.hasNext(Iterator.scala:441); at scala.collection.Iterator$$anon$11.hasNext(Iterator.scala:409); at org.apache.spark.shuffle.sort.UnsafeShuffleWriter.write(UnsafeShuffleWriter.java:187); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:99); at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:55); at org.apache.spark.scheduler.Task.run(Task.scala:123); at org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:408); at org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1360); at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:414); at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142); at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617); at java.lang.Thread.run(Thread.java:748); `. Can you give me some advice?; Thanks,; sun",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7001
https://github.com/broadinstitute/gatk/issues/7005:1900,Performance,optimiz,optimizations,1900," as the reference genotype for any site not present in the source workspace. In contrast, if you run a similar command with GenotypeGVCFs + --force-output + gVCF, the resulting VCF reports the correct reference base. In both cases we are passing the FASTA as -R to the tool. Here are two example outputs:. This is from GenotypeGVCFs with a GenomicsDB workspace as input. Note: 1565827 and 1565828 are wild-type in all samples, but are included b/c of --force-output. It reports N as REF:; #CHROM	POS	ID	REF	ALT; 1	1565827	.	N	.; 1	1565828	.	N	.; 1	1565829	.	T	TGATGGTGGC. This is from a similar command with a gVCF as input. The REF base is correct. Note, the ALT is different b/c of different samples in the inputs:; #CHROM	POS	ID	REF	ALT; 1	1565827	.	G	.; 1	1565828	.	A	.; 1	1565829	.	T	. But the key behavior difference is that if this is a site that would only get output b/c of --force-output, then when a gVCF is the source it gets the REF right, and when GenomicsDB is the source it reports N. I am happy to do some legwork digging into the code and proposing a fix, but it would be helpful to know if there's a known issue around this, and/or get any pointers into where in the GATK/HTSJDK layer I might start looking. An example command is something like:. ```; java8 -jar <JAR> GenotypeGVCFs \; 	-R $REF \; 	-O $OUTPUT \; 	--variant $GENOMICS_DB_WORKSPACE \; 	-L 1:1565827-1565829 \; 	-L 1:1699262-1699298 \; 	-L 6:14972856-14972872 \; 	-L X:135349386-135349395 \; 	-L Y:3491100-3491102 \; 	--only-output-calls-starting-in-intervals \; 	--genomicsdb-shared-posixfs-optimizations \; 	--force-output-intervals <BED_FILE>. ```. In this example, those -L positions were selected b/c they elicit the behavior. Those sites are present in the BED file used for --force-output-intervals. At least in our hands, the combination of calling from a GenomicsDB workspace and using --force-output-intervals to output some site that would not normally get output will result in the 'N' REFs.; Thanks,; Ben",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7005
https://github.com/broadinstitute/gatk/issues/7006:3474,Availability,down,down,3474,"MPRESSION_LEVEL : 2; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:57:16.776 INFO AnalyzeCovariates - Deflater: IntelDeflater; 12:57:16.776 INFO AnalyzeCovariates - Inflater: IntelInflater; 12:57:16.776 INFO AnalyzeCovariates - GCS max retries/reopens: 20; 12:57:16.776 INFO AnalyzeCovariates - Requester pays: disabled; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called gplots; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hel",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:4112,Availability,Error,Error,4112,"57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called gplots; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:130); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(Command",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:112,Deployability,pipeline,pipeline,112,"/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:224,Deployability,pipeline,pipeline,224,"/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:335,Deployability,pipeline,pipeline,335,"/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:811,Deployability,pipeline,pipeline,811,"/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:923,Deployability,pipeline,pipeline,923,"/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:1034,Deployability,pipeline,pipeline,1034,"4.1.8.1/gatk AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu1.18.04; 12:57:16.775 INFO AnalyzeCova",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:3357,Deployability,pipeline,pipeline,3357,"Version: 2.23.0; 12:57:16.776 INFO AnalyzeCovariates - Picard Version: 2.22.8; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 12:57:16.776 INFO AnalyzeCovariates - Deflater: IntelDeflater; 12:57:16.776 INFO AnalyzeCovariates - Inflater: IntelInflater; 12:57:16.776 INFO AnalyzeCovariates - GCS max retries/reopens: 20; 12:57:16.776 INFO AnalyzeCovariates - Requester pays: disabled; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called gplots; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:3934,Deployability,pipeline,pipeline,3934,"es - GCS max retries/reopens: 20; 12:57:16.776 INFO AnalyzeCovariates - Requester pays: disabled; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called gplots; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:130); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWor",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:4025,Deployability,pipeline,pipeline,4025,"ed; 12:57:16.776 INFO AnalyzeCovariates - Initializing engine; 12:57:16.776 INFO AnalyzeCovariates - Done initializing engine; 12:57:17.333 INFO AnalyzeCovariates - Generating csv file '/tmp/AnalyzeCovariates17353441228865531235.csv'; 12:57:17.414 INFO AnalyzeCovariates - Generating plots file '/home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf'; 12:57:17.829 INFO AnalyzeCovariates - Shutting down engine; [December 17, 2020 at 12:57:17 PM TRT] org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates done. Elapsed time: 0.02 minutes.; Runtime.totalMemory()=633339904; org.broadinstitute.hellbender.utils.R.RScriptExecutorException: ; Rscript exited with 1; Command Line: Rscript -e tempLibDir = '/tmp/Rlib.10272183847736955081';source('/tmp/BQSR.16251220439562120273.R'); /tmp/AnalyzeCovariates17353441228865531235.csv /home/detagen/Desktop/pipeline/playground/BACKUP/FMF-248_Backup/before.recal.FMF-248.table /home/detagen/Desktop/pipeline/playground/NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Stdout: ; Stderr: Error in library(gplots) : there is no package called gplots; Calls: source -> withVisible -> eval -> eval -> library; Execution halted. 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:80); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.getScriptException(RScriptExecutor.java:19); 	at org.broadinstitute.hellbender.utils.runtime.ScriptExecutor.executeCuratedArgs(ScriptExecutor.java:130); 	at org.broadinstitute.hellbender.utils.R.RScriptExecutor.exec(RScriptExecutor.java:126); 	at org.broadinstitute.hellbender.utils.recalibration.RecalUtils.generatePlots(RecalUtils.java:360); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.generatePlots(AnalyzeCovariates.java:329); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.AnalyzeCovariates.doWork(AnalyzeCovariates.java:341); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.r",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:1144,Performance,Load,Loading,1144,"F-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; Using GATK jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu1.18.04; 12:57:16.775 INFO AnalyzeCovariates - Start Date/Time: December 17, 2020 at 12:57:16 PM TRT; 12:57:16.775 INFO AnalyzeCovariates - -",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7006:1440,Safety,detect,detect,1440,"esktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -jar /home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar AnalyzeCovariates --before-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/before.recal.FMF-248.table --after-report-file /home/detagen/Desktop/pipeline/playground//BACKUP/FMF-248_Backup/after.recal.FMF-248.table --plots-report-file /home/detagen/Desktop/pipeline/playground//NECESSARY/FMF-248/AnalyzeCovariates.FMF-248.pdf; 12:57:16.643 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/home/detagen/Desktop/programlar/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 12:57:16 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 12:57:16.774 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - The Genome Analysis Toolkit (GATK) v4.1.8.1; 12:57:16.775 INFO AnalyzeCovariates - For support and documentation go to https://software.broadinstitute.org/gatk/; 12:57:16.775 INFO AnalyzeCovariates - Executing as detagen@detagen on Linux v5.4.0-58-generic amd64; 12:57:16.775 INFO AnalyzeCovariates - Java runtime: OpenJDK 64-Bit Server VM v11.0.9.1+1-Ubuntu-0ubuntu1.18.04; 12:57:16.775 INFO AnalyzeCovariates - Start Date/Time: December 17, 2020 at 12:57:16 PM TRT; 12:57:16.775 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.775 INFO AnalyzeCovariates - ------------------------------------------------------------; 12:57:16.776 INFO AnalyzeCovariates - HTSJDK Version: 2.23.0; 12:57:16.776 INFO AnalyzeCovariates - Picard Version: 2.22.8; 12:57:16",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7006
https://github.com/broadinstitute/gatk/issues/7007:540,Availability,error,error,540,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:174,Deployability,install,installed,174,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:312,Deployability,pipeline,pipeline,312,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:2740,Deployability,pipeline,pipeline,2740,"--------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:28:44.641 INFO GenotypeGVCFs - Deflater: IntelDeflater; 22:28:44.641 INFO GenotypeGVCFs - Inflater: IntelInflater; 22:28:44.641 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 22:28:44.641 INFO GenotypeGVCFs - Requester pays: disabled; 22:28:44.641 INFO GenotypeGVCFs - Initializing engine; ```. #### Steps to reproduce; I've followed the recommendation to process my genome in parallel, each chromosome at a time, so I created the commands based on the following pipeline:; ```; # HC; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample1.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample2.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample3.HC.gvcf -ERC GVCF. # GenomicsDBImport for Chr1; export TILEDB_DISABLE_FILE_LOCKING=1 ; gatk GenomicsDBImport --java-options ""-Xmx4g -Xms4g"" -V sample1.HC.gvcf -V sample2.HC.gvcf -V sample3.HC.gvcf --genomicsdb-workspace-path GenomicsDB_1 --tmp-dir /tmp -L 1. # GenotypeGVCFs; gatk GenotypeGVCFs --java-options ""-Xmx12g -Xms12g"" -R GRCh38.fasta -V gendb://GenomicsDB_1 --tmp-dir /tmp -O samples.1.vcf; ```; The jobs were send to the HPC scheduler and were allocated 2 CPUs and up to 16GB of RAM each. Everything till the last genotype calling step worked fine (and quite quickly) ; #### Expected behavior; The tool should call variants from the G",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:3473,Energy Efficiency,schedul,scheduler,3473,"FO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:28:44.641 INFO GenotypeGVCFs - Deflater: IntelDeflater; 22:28:44.641 INFO GenotypeGVCFs - Inflater: IntelInflater; 22:28:44.641 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 22:28:44.641 INFO GenotypeGVCFs - Requester pays: disabled; 22:28:44.641 INFO GenotypeGVCFs - Initializing engine; ```. #### Steps to reproduce; I've followed the recommendation to process my genome in parallel, each chromosome at a time, so I created the commands based on the following pipeline:; ```; # HC; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample1.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample2.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample3.HC.gvcf -ERC GVCF. # GenomicsDBImport for Chr1; export TILEDB_DISABLE_FILE_LOCKING=1 ; gatk GenomicsDBImport --java-options ""-Xmx4g -Xms4g"" -V sample1.HC.gvcf -V sample2.HC.gvcf -V sample3.HC.gvcf --genomicsdb-workspace-path GenomicsDB_1 --tmp-dir /tmp -L 1. # GenotypeGVCFs; gatk GenotypeGVCFs --java-options ""-Xmx12g -Xms12g"" -R GRCh38.fasta -V gendb://GenomicsDB_1 --tmp-dir /tmp -O samples.1.vcf; ```; The jobs were send to the HPC scheduler and were allocated 2 CPUs and up to 16GB of RAM each. Everything till the last genotype calling step worked fine (and quite quickly) ; #### Expected behavior; The tool should call variants from the GenomicsDB for the requested interval. #### Actual behavior; Runs indefinitely (or until walltime is reached), but never gets passed the ""Initializing engine"" step. (tried this with 2 different datasets).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:3492,Energy Efficiency,allocate,allocated,3492,"FO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 22:28:44.641 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 22:28:44.641 INFO GenotypeGVCFs - Deflater: IntelDeflater; 22:28:44.641 INFO GenotypeGVCFs - Inflater: IntelInflater; 22:28:44.641 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 22:28:44.641 INFO GenotypeGVCFs - Requester pays: disabled; 22:28:44.641 INFO GenotypeGVCFs - Initializing engine; ```. #### Steps to reproduce; I've followed the recommendation to process my genome in parallel, each chromosome at a time, so I created the commands based on the following pipeline:; ```; # HC; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample1.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample2.HC.gvcf -ERC GVCF; gatk HaplotypeCaller -R GRCh38.fasta -I sample.dedup.rg.csorted.bam -O sample3.HC.gvcf -ERC GVCF. # GenomicsDBImport for Chr1; export TILEDB_DISABLE_FILE_LOCKING=1 ; gatk GenomicsDBImport --java-options ""-Xmx4g -Xms4g"" -V sample1.HC.gvcf -V sample2.HC.gvcf -V sample3.HC.gvcf --genomicsdb-workspace-path GenomicsDB_1 --tmp-dir /tmp -L 1. # GenotypeGVCFs; gatk GenotypeGVCFs --java-options ""-Xmx12g -Xms12g"" -R GRCh38.fasta -V gendb://GenomicsDB_1 --tmp-dir /tmp -O samples.1.vcf; ```; The jobs were send to the HPC scheduler and were allocated 2 CPUs and up to 16GB of RAM each. Everything till the last genotype calling step worked fine (and quite quickly) ; #### Expected behavior; The tool should call variants from the GenomicsDB for the requested interval. #### Actual behavior; Runs indefinitely (or until walltime is reached), but never gets passed the ""Initializing engine"" step. (tried this with 2 different datasets).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:675,Performance,Load,Loading,675,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:988,Safety,detect,detect,988,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7007:431,Testability,log,log,431,"## Bug Report; GenotypeGVCFs stuck indefinitely at ""Initializing engine"" step. ### Affected tool(s) or class(es); gatk GenotypeGVCFs; ### Affected version(s); GATK v4.1.4.1 (installed in a `conda` convironment from the bioconda channel), on a RHEL server 7.6 (Maipo). ### Description ; Following the recommended pipeline of HaplotypeCaller, GenomicsDBImport and then GenotypeGVCFs, the last command hangs indefinitely and from the log file, it seems like it doesn't get past the ""Initialize engine"" step. This is an example of the standard error stream (after the `GenotypeGVCFs` job reached 20 hours wall time and was killed) :; ```; 22:28:44.293 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/export/user/home/miniconda3/envs/aDNA/share/gatk4-4.1.4.1-1/gatk-package-4.1.4.1-local.; jar!/com/intel/gkl/native/libgkl_compression.so; Dec 17, 2020 10:28:44 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 22:28:44.639 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.4.1; 22:28:44.640 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 22:28:44.640 INFO GenotypeGVCFs - Executing as user@gc-prd-hpcn002 on Linux v3.10.0-957.27.2.el7.x86_64 amd64; 22:28:44.640 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_192-b01; 22:28:44.640 INFO GenotypeGVCFs - Start Date/Time: December 17, 2020 10:28:44 PM AEST; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - ------------------------------------------------------------; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Version: 2.21.0; 22:28:44.640 INFO GenotypeGVCFs - Picard Version: 2.21.2; 22:28:44.640 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7007
https://github.com/broadinstitute/gatk/issues/7008:158,Availability,down,down,158,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008
https://github.com/broadinstitute/gatk/issues/7008:174,Availability,error,error,174,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008
https://github.com/broadinstitute/gatk/issues/7008:348,Availability,error,error,348,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008
https://github.com/broadinstitute/gatk/issues/7008:552,Deployability,release,release-,552,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008
https://github.com/broadinstitute/gatk/issues/7008:363,Safety,detect,detected,363,"## Bug Report; When I use output files of CombineGVCFs to run GenotypeGVCFs, it seems no problem at beginning. However, several hours later, it suddenly shot down. The fatal error occur. ### Affected tool(s) or class(es); GenotypeGVCFs, only use arguments: -R, -V, -O, -all-sites. ### Affected version(s); GATK4 v4.1.9.0. ### Description . A fatal error has been detected by the Java Runtime Environment:. SIGBUS (0x7) at pc=0x00002acb0aee41d3, pid=14508, tid=0x00002acb0f80b700. JRE version: OpenJDK Runtime Environment (8.0_152-b12) (build 1.8.0_152-release-1056-b12); Java VM: OpenJDK 64-Bit Server VM (25.152-b12 mixed mode linux-amd64 compressed oops); Problematic frame:; C [libc.so.6+0x1501d3] __memmove_ssse3_back+0x1a13. Failed to write core dump. Core dumps have been disabled. To enable core dumping, try ""ulimit -c unlimited"" before starting Java again. If you would like to submit a bug report, please visit:; http://bugreport.java.com/bugreport/crash.jsp. --------------- T H R E A D ---------------. Current thread (0x00002acb10021800): GCTaskThread [stack: 0x00002acb0f70b000,0x00002acb0f80c000] [id=14511]. siginfo: si_signo: 7 (SIGBUS), si_code: 2 (BUS_ADRERR), si_addr: 0x00000003ea598000. Registers:; RAX=0x00000003ea593600, RBX=0x00002acb0f80aa00, RCX=0x00000000000059c8, RDX=0x0000000000000f48; RSP=0x00002acb0f80a928, RBP=0x00002acb0f80a950, RSI=0x000000044246f290, RDI=0x00000003ea597fa0; R8 =0x00000003ea593600, R9 =0x0000000057ed72f0, R10=0x00000003c0000000, R11=0x00002acb0af16b50; R12=0x0000000000000b3d, R13=0x00000000000059e8, R14=0x00002acb0f80aa00, R15=0x0000000010490000; RIP=0x00002acb0aee41d3, EFLAGS=0x0000000000010206, CSGSFS=0x0000000000000033, ERR=0x0000000000000006; TRAPNO=0x000000000000000e. Top of Stack: (sp=0x00002acb0f80a928); 0x00002acb0f80a928: 00002acb0ba575c6 00000003c5a14ae8; 0x00002acb0f80a938: 0000000000412400 000000001048e05a; 0x00002acb0f80a948: 00002acb0c077d00 00002acb0f80a9a0; 0x00002acb0f80a958: 00002acb0ba155e8 00002acb0c03f148; 0x00002a",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7008
https://github.com/broadinstitute/gatk/pull/7010:371,Availability,error,error,371,"Fixes a bug that was exposed in https://gatk.broadinstitute.org/hc/en-us/community/posts/360075631171-BQSR-no-output-table-found. The issue is that bytes are signed in java, and yet we were treating them as unsigned and directly indexing an array with them.....this works as long as you don't have weird characters in your bam/reference...but if you do you get an access error that is non-informative.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7010
https://github.com/broadinstitute/gatk/pull/7010:21,Security,expose,exposed,21,"Fixes a bug that was exposed in https://gatk.broadinstitute.org/hc/en-us/community/posts/360075631171-BQSR-no-output-table-found. The issue is that bytes are signed in java, and yet we were treating them as unsigned and directly indexing an array with them.....this works as long as you don't have weird characters in your bam/reference...but if you do you get an access error that is non-informative.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7010
https://github.com/broadinstitute/gatk/pull/7010:364,Security,access,access,364,"Fixes a bug that was exposed in https://gatk.broadinstitute.org/hc/en-us/community/posts/360075631171-BQSR-no-output-table-found. The issue is that bytes are signed in java, and yet we were treating them as unsigned and directly indexing an array with them.....this works as long as you don't have weird characters in your bam/reference...but if you do you get an access error that is non-informative.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7010
https://github.com/broadinstitute/gatk/issues/7011:762,Availability,down,downstream,762,"Funcotator will only write alt/ref counts to a MAF inferred from the AD field if the genotype (GT) field is also present in the somatic VCF:. https://github.com/broadinstitute/gatk/blob/febd7cbbd1fc2a631fa9d7dcde52383e3134e88c/src/main/java/org/broadinstitute/hellbender/tools/funcotator/mafOutput/CustomMafFuncotationCreator.java#L74-L76. However, requiring that the GT field be present is unnecessary, since the comma-delimited values of the AD field have no bearing on the contents of the GT field. Indeed, the majority of somatic callers either output `0/1` for every single GT field (e.g. MuTect) or nothing at all (e.g. Strelka), since somatic zygosity (usually called ""multiplicity"") is generally not calculated by a short variant caller, but rather by a downstream tool that computes overall tumor purity/absolute copy number. I came across this bug when trying to convert a Strelka VCF to MAF and noticed that alt/ref counts are not output by Funcotator to the MAF, since Strelka does not write a GT field to its VCFs. Luckily, this is an extremely easy fix. I'm happy to contribute a tiny PR changing the three offending lines above.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7011
https://github.com/broadinstitute/gatk/issues/7012:322,Availability,error,error,322,"Hello, ; I have been using he GenotypeGVCFs function to call variants on roughly 300 whole genome sequenced individuals. I have not run into any issue when calling variants for these same individuals using the majority of chromosomes, however when I use the same script for chromosomes 1, 2 and 3 of the species I get the error ""Couldn't create GenomicsDBFeatureReader"" as in issue #6616 although I believe our issues may differ because I also have the errors ""Cannot read from buffer"" and ""cannot load book-keeping; Reading-tiles offset"". . Below is the computer output: . Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar GenotypeGVCFs --reference /data1/EquCab/_ECA30/Equus_caballus.EquCab3.0.dna_sm.toplevel.fa/ -V gendb://ECA3_GenomicsDB_260/1 -O ECA3_GenomicsDB_260.1.g.vcf.gz; 13:56:51.939 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 21, 2020 1:56:52 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:56:52.185 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.186 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:56:52.186 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:56:52.186 INFO GenotypeGVCFs - Executing as ccastane9@andersserver-01.cvm.tamu.edu on Linux v3.10.0-1127.19.1.el7.x86_64 amd64; 13:56:52.186 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_275-b01; 13:56:52.186 INFO Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:453,Availability,error,errors,453,"Hello, ; I have been using he GenotypeGVCFs function to call variants on roughly 300 whole genome sequenced individuals. I have not run into any issue when calling variants for these same individuals using the majority of chromosomes, however when I use the same script for chromosomes 1, 2 and 3 of the species I get the error ""Couldn't create GenomicsDBFeatureReader"" as in issue #6616 although I believe our issues may differ because I also have the errors ""Cannot read from buffer"" and ""cannot load book-keeping; Reading-tiles offset"". . Below is the computer output: . Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar GenotypeGVCFs --reference /data1/EquCab/_ECA30/Equus_caballus.EquCab3.0.dna_sm.toplevel.fa/ -V gendb://ECA3_GenomicsDB_260/1 -O ECA3_GenomicsDB_260.1.g.vcf.gz; 13:56:51.939 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 21, 2020 1:56:52 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:56:52.185 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.186 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:56:52.186 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:56:52.186 INFO GenotypeGVCFs - Executing as ccastane9@andersserver-01.cvm.tamu.edu on Linux v3.10.0-1127.19.1.el7.x86_64 amd64; 13:56:52.186 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_275-b01; 13:56:52.186 INFO Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:3120,Availability,Error,Error,3120,"--------------------------; 13:56:52.186 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellb",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:3198,Availability,Error,Error,3198,"---------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:3304,Availability,down,down,3304,"; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBa",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:3559,Availability,ERROR,ERROR,3559,".USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:5074,Availability,Error,Error,5074,"ants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:5218,Availability,error,error,5218,"ants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:5256,Availability,Error,Error,5256,"ants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:6402,Availability,error,error,6402,"rogram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the database for these chromosomes (still using the same scripts as other chromosomes where variant calling was successful) to see if perhaps something went wrong during the initial database creation. I still received this error when I was trying to call variants. ; What is most confusing to me is that this issue isn't happening for every chromosome, just the first 3. Any advice to get over this hump is greatly appreciated, and let me know if there is more information you need to help trouble shoot. . Thanks, ; Caitlin",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:5224,Integrability,message,message,5224,"ants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:498,Performance,load,load,498,"Hello, ; I have been using he GenotypeGVCFs function to call variants on roughly 300 whole genome sequenced individuals. I have not run into any issue when calling variants for these same individuals using the majority of chromosomes, however when I use the same script for chromosomes 1, 2 and 3 of the species I get the error ""Couldn't create GenomicsDBFeatureReader"" as in issue #6616 although I believe our issues may differ because I also have the errors ""Cannot read from buffer"" and ""cannot load book-keeping; Reading-tiles offset"". . Below is the computer output: . Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar GenotypeGVCFs --reference /data1/EquCab/_ECA30/Equus_caballus.EquCab3.0.dna_sm.toplevel.fa/ -V gendb://ECA3_GenomicsDB_260/1 -O ECA3_GenomicsDB_260.1.g.vcf.gz; 13:56:51.939 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 21, 2020 1:56:52 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:56:52.185 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.186 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:56:52.186 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:56:52.186 INFO GenotypeGVCFs - Executing as ccastane9@andersserver-01.cvm.tamu.edu on Linux v3.10.0-1127.19.1.el7.x86_64 amd64; 13:56:52.186 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_275-b01; 13:56:52.186 INFO Gen",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:1136,Performance,Load,Loading,1136,"n into any issue when calling variants for these same individuals using the majority of chromosomes, however when I use the same script for chromosomes 1, 2 and 3 of the species I get the error ""Couldn't create GenomicsDBFeatureReader"" as in issue #6616 although I believe our issues may differ because I also have the errors ""Cannot read from buffer"" and ""cannot load book-keeping; Reading-tiles offset"". . Below is the computer output: . Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar GenotypeGVCFs --reference /data1/EquCab/_ECA30/Equus_caballus.EquCab3.0.dna_sm.toplevel.fa/ -V gendb://ECA3_GenomicsDB_260/1 -O ECA3_GenomicsDB_260.1.g.vcf.gz; 13:56:51.939 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 21, 2020 1:56:52 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:56:52.185 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.186 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:56:52.186 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:56:52.186 INFO GenotypeGVCFs - Executing as ccastane9@andersserver-01.cvm.tamu.edu on Linux v3.10.0-1127.19.1.el7.x86_64 amd64; 13:56:52.186 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_275-b01; 13:56:52.186 INFO GenotypeGVCFs - Start Date/Time: December 21, 2020 1:56:51 PM CST; 13:56:52.186 INFO GenotypeGVCFs - -----------------------------------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:3212,Performance,load,load,3212,"---------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 13:56:52.187 INFO GenotypeGVCFs - Deflater: IntelDeflater; 13:56:52.188 INFO GenotypeGVCFs - Inflater: IntelInflater; 13:56:52.188 INFO GenotypeGVCFs - GCS max retries/reopens: 20; 13:56:52.188 INFO GenotypeGVCFs - Requester pays: disabled; 13:56:52.188 INFO GenotypeGVCFs - Initializing engine; 13:56:53.115 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.0-e701905; [TileDB::Buffer] Error: Cannot read from buffer; End of buffer reached.; [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed.; 13:57:15.762 INFO GenotypeGVCFs - Shutting down engine; [December 21, 2020 1:57:15 PM CST] org.broadinstitute.hellbender.tools.walkers.GenotypeGVCFs done. Elapsed time: 0.40 minutes.; Runtime.totalMemory()=2119696384; ***********************************************************************. A USER ERROR has occurred: Couldn't create GenomicsDBFeatureReader. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Couldn't create GenomicsDBFeatureReader; 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:410); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getFeatureReader(FeatureDataSource.java:326); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.<init>(FeatureDataSource.java:282); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.initializeDrivingVariants(VariantLocusWalker.java:76",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:5270,Performance,load,load,5270,"ants(VariantLocusWalker.java:76); 	at org.broadinstitute.hellbender.engine.VariantWalkerBase.initializeFeatures(VariantWalkerBase.java:67); 	at org.broadinstitute.hellbender.engine.GATKTool.onStartup(GATKTool.java:709); 	at org.broadinstitute.hellbender.engine.VariantLocusWalker.onStartup(VariantLocusWalker.java:63); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:138); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:211); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:160); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:203); 	at org.broadinstitute.hellbender.Main.main(Main.java:289); Caused by: java.io.IOException: GenomicsDB JNI Error: VariantQueryProcessorException : Could not open array 1$1$188260577 at workspace: /data1/EquCab/GenomicsDB/ECA3_GenomicsDB_260/1; TileDB error message : [TileDB::BookKeeping] Error: Cannot load book-keeping; Reading tile offsets failed; 	at org.genomicsdb.reader.GenomicsDBQueryStream.jniGenomicsDBInit(Native Method); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:209); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:182); 	at org.genomicsdb.reader.GenomicsDBQueryStream.<init>(GenomicsDBQueryStream.java:91); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.generateHeadersForQuery(GenomicsDBFeatureReader.java:200); 	at org.genomicsdb.reader.GenomicsDBFeatureReader.<init>(GenomicsDBFeatureReader.java:85); 	at org.broadinstitute.hellbender.engine.FeatureDataSource.getGenomicsDBFeatureReader(FeatureDataSource.java:407); 	... 12 more. I'm assuming it is something in the array 1$1$188260577 files, and possibly the _book_keep.tbs.gz file, although I'm not sure how to go about trouble shooting the issue. I also recreated the dat",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7012:1415,Safety,detect,detect,1415," issues may differ because I also have the errors ""Cannot read from buffer"" and ""cannot load book-keeping; Reading-tiles offset"". . Below is the computer output: . Using GATK jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -Xmx16g -jar /data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar GenotypeGVCFs --reference /data1/EquCab/_ECA30/Equus_caballus.EquCab3.0.dna_sm.toplevel.fa/ -V gendb://ECA3_GenomicsDB_260/1 -O ECA3_GenomicsDB_260.1.g.vcf.gz; 13:56:51.939 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/data1/_software/gatk-4.1.8.1/gatk-package-4.1.8.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Dec 21, 2020 1:56:52 PM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 13:56:52.185 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.186 INFO GenotypeGVCFs - The Genome Analysis Toolkit (GATK) v4.1.8.1; 13:56:52.186 INFO GenotypeGVCFs - For support and documentation go to https://software.broadinstitute.org/gatk/; 13:56:52.186 INFO GenotypeGVCFs - Executing as ccastane9@andersserver-01.cvm.tamu.edu on Linux v3.10.0-1127.19.1.el7.x86_64 amd64; 13:56:52.186 INFO GenotypeGVCFs - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_275-b01; 13:56:52.186 INFO GenotypeGVCFs - Start Date/Time: December 21, 2020 1:56:51 PM CST; 13:56:52.186 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.186 INFO GenotypeGVCFs - ------------------------------------------------------------; 13:56:52.187 INFO GenotypeGVCFs - HTSJDK Version: 2.23.0; 13:56:52.187 INFO GenotypeGVCFs - Picard Version: 2.22.8; 13:56:52.187 INFO GenotypeGVCFs - HTS",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7012
https://github.com/broadinstitute/gatk/issues/7015:6353,Availability,avail,available,6353,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015
https://github.com/broadinstitute/gatk/issues/7015:6367,Availability,down,download,6367,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015
https://github.com/broadinstitute/gatk/issues/7015:166,Performance,perform,performance,166,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] 4.1.1.0..4.1.9.0. ### Description ; I am evaluating Mutect2 variant calling performance in GiaB mixtures (target capture, no UMI, 2000x avg coverage). In particular, I am comparing 4.0.12.0 against 4.1.9.0 with default parameters. Below, I am providing data from a representative sample.; 4.1.9.0 misses variants that 4.0.12.0 was able to call. When feeding a reference VCF with option `--alleles` the variants are detected with decent quality scores. It is unclear why 4.1.9.0 does not make these variant calls and if this could be changed by modifying input parameters. Unlike in this issue https://github.com/broadinstitute/gatk/issues/6724 the variants were not called with the option `--force-active`. . These are the variants that are only called by 4.1.9.0 when the reference VCF is fed as input:. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample; 2	25458546	.	C	T	.	.	AS_SB_TABLE=723,503|25,14;DP=1302;ECNT=1;MBQ=20,20;MFRL=189,190;MMQ=60,60;MPOS=36;POPAF=7.3;TLOD=61.58	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:1226,39:0.033:1265:576,19:554,19:723,503,25,14; 4	55152040	.	C	T	.	.	AS_SB_TABLE=1102,1078|15,13;DP=2349;ECNT=2;MBQ=20,20;MFRL=180,164;MMQ=60,60;MPOS=35;POPAF=7.3;TLOD=31.85	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:2180,28:0.012:2208:1003,16:1104,10:1102,1078,15,13; 5	170833472	.	AAT	A	.	.	AS_SB_TABLE=201,501|7,17;DP=750;ECNT=1;MBQ=20,26;MFRL=203,209;MMQ=60,60;MPOS=20;POPAF=7.3;RPA=2,1;RU=AT;STR;TLOD=45.4	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:702,24:0.035:726:329,12:311,12:201,501,7,17; 7	101844851	.	A	G	.	.	AS_SB_TABLE=1022,1178|25,25;DP=2406;ECNT=1;MBQ=20,20;MFRL=189,198;MMQ=60,60;MPOS=46;POPAF=7.3;TLOD=65.52	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:2200,50:0.021:2250:854,29:906,19:1022,1178,25,25; 7	101916798	.	C	A	.	.	AS_SB_TABLE=91,916|1,37;DP=1060;ECNT=1;MBQ=32,32;MFRL=213,195;MMQ=60,60;MPOS=26;POPAF=7.3;TLOD=54.92	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:1007,38:0.033:1045:438,17:511,18:91,916,1,37; 7	148506396	.	A	C	.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015
https://github.com/broadinstitute/gatk/issues/7015:505,Safety,detect,detected,505,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); - [x] 4.1.1.0..4.1.9.0. ### Description ; I am evaluating Mutect2 variant calling performance in GiaB mixtures (target capture, no UMI, 2000x avg coverage). In particular, I am comparing 4.0.12.0 against 4.1.9.0 with default parameters. Below, I am providing data from a representative sample.; 4.1.9.0 misses variants that 4.0.12.0 was able to call. When feeding a reference VCF with option `--alleles` the variants are detected with decent quality scores. It is unclear why 4.1.9.0 does not make these variant calls and if this could be changed by modifying input parameters. Unlike in this issue https://github.com/broadinstitute/gatk/issues/6724 the variants were not called with the option `--force-active`. . These are the variants that are only called by 4.1.9.0 when the reference VCF is fed as input:. ```; #CHROM	POS	ID	REF	ALT	QUAL	FILTER	INFO	FORMAT	Sample; 2	25458546	.	C	T	.	.	AS_SB_TABLE=723,503|25,14;DP=1302;ECNT=1;MBQ=20,20;MFRL=189,190;MMQ=60,60;MPOS=36;POPAF=7.3;TLOD=61.58	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:1226,39:0.033:1265:576,19:554,19:723,503,25,14; 4	55152040	.	C	T	.	.	AS_SB_TABLE=1102,1078|15,13;DP=2349;ECNT=2;MBQ=20,20;MFRL=180,164;MMQ=60,60;MPOS=35;POPAF=7.3;TLOD=31.85	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:2180,28:0.012:2208:1003,16:1104,10:1102,1078,15,13; 5	170833472	.	AAT	A	.	.	AS_SB_TABLE=201,501|7,17;DP=750;ECNT=1;MBQ=20,26;MFRL=203,209;MMQ=60,60;MPOS=20;POPAF=7.3;RPA=2,1;RU=AT;STR;TLOD=45.4	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:702,24:0.035:726:329,12:311,12:201,501,7,17; 7	101844851	.	A	G	.	.	AS_SB_TABLE=1022,1178|25,25;DP=2406;ECNT=1;MBQ=20,20;MFRL=189,198;MMQ=60,60;MPOS=46;POPAF=7.3;TLOD=65.52	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:2200,50:0.021:2250:854,29:906,19:1022,1178,25,25; 7	101916798	.	C	A	.	.	AS_SB_TABLE=91,916|1,37;DP=1060;ECNT=1;MBQ=32,32;MFRL=213,195;MMQ=60,60;MPOS=26;POPAF=7.3;TLOD=54.92	GT:AD:AF:DP:F1R2:F2R1:SB	0/1:1007,38:0.033:1045:438,17:511,18:91,916,1,37; 7	148506396	.	A	C	.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015
https://github.com/broadinstitute/gatk/issues/7015:5837,Security,validat,validation-stringency,5837,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015
https://github.com/broadinstitute/gatk/issues/7015:6107,Security,validat,validation-stringency,6107,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015
https://github.com/broadinstitute/gatk/issues/7015:6396,Security,validat,validation,6396,"DP=1399;ECNT=1;MBQ=36,36;MFRL=209,211;MMQ=60,60;MPOS=34;POPAF=7.3;TLOD=42.57	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1327,27:0.019:1354:672,12:655,15:0.02,0.02,0.02:0.0007239,0.005058,0.994; 11	108175462	.	G	A	.	.	DP=972;ECNT=1;MBQ=36,36;MFRL=209,206;MMQ=60,60;MPOS=37;POPAF=7.3;TLOD=15.55	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:898,12:0.013:910:446,6:452,6:0.01,0.01,0.013:0.002966,0.0009292,0.996; 12	12037318	.	C	G	.	.	DP=975;ECNT=1;MBQ=36,36;MFRL=205,218;MMQ=60,60;MPOS=48;POPAF=7.3;TLOD=15.41	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:893,12:0.013:905:438,4:455,8:0.01,0.01,0.013:0.004146,0.0007942,0.995; 15	66679819	.	G	C	.	.	DP=870;ECNT=1;MBQ=36,36;MFRL=215,211;MMQ=60,60;MPOS=52;POPAF=7.3;TLOD=25.62	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:797,17:0.022:814:384,11:413,6:0.02,0.02,0.021:0.004622,0.001165,0.994; 18	42532923	.	T	C	.	.	DP=1402;ECNT=1;MBQ=36,36;MFRL=197,222;MMQ=60,60;MPOS=51;POPAF=7.3;TLOD=41.21	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1312,25:0.019:1337:681,13:631,12:0.02,0.01,0.019:0.0009167,0.002842,0.996; 20	31019360	.	AT	A	.	.	DP=1530;ECNT=1;MBQ=36,36;MFRL=198,199;MMQ=60,60;MPOS=44;POPAF=7.3;RPA=7,6;RU=T;STR;TLOD=30.65	GT:AD:AF:DP:F1R2:F2R1:SAAF:SAPP	0/1:1424,34:0.022:1458:673,20:751,14:0.02,0.02,0.023:0.003063,0.0009654,0.996; ```. #### Steps to reproduce; ```; # Call without --alleles option does not produce the variants.; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_noalleles.vcf.gz; # Call with --alleles option produces the variants with presumably high quality scores; gatk Mutect2 --reference GRCh37.fa --read-validation-stringency LENIENT -I subset_properheader.bam -L enrichment.bed --interval-set-rule INTERSECTION -O unfiltered_alleles.vcf.gz --alleles truth_small_variants_NA12878-NA24385-mix_sorted.vcf.gz; ```; The BAM, BED and output VCF files are available for download [here](https://gatk-validation.s3-eu-west-1.amazonaws.com/mutect2-4.1.9.0.zip).",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7015
https://github.com/broadinstitute/gatk/issues/7016:1922,Usability,feedback,feedbacking,1922,"## Bug Report; Hello, I have a question about Mutect2 in GATK4(version 4.1.9.0). I wonder that the AF result is not exact. ### Affected version(s); GATK4 version 4.1.9.0. ### Description ; I got the result for the below site:; chr17 41244376 . T C . . AS_SB_TABLE=575,531|23,21;DP=1192;ECNT=1;MBQ=30,30;MFRL=242,275;MMQ=60,60;MPOS=37;POPAF=7.30;TLOD=69.90 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:1106,44:0.044:1150:531,27:571,17:575,531,23,21. I wander that the AF is higher then expected. Because the AF <= 0.038(44/1150). Could you tell me what's wrong with it? Or the tenominator is lower than 1150? . #### Steps to reproduce; My command lines is describled as below:; /software/GATK4/gatk-4.1.9.0/gatk --java-options ""-XX:ParallelGCThreads=4 -Xmx20G -Djava.io.tmpdir=./tmp"" Mutect2 -L chr17.bed --pcr-indel-model CONSERVATIVE -I samples-FFPE.recal.bam -tumor samples-FFPE -R ucsc.hg19.fasta --native-pair-hmm-threads 4 --min-base-quality-score 15 -germline-resource /Gatk_bundles/af-only-gnomad.raw.sites.hg19.vcf.gz --panel-of-normals PoN.vcf.gz --f1r2-tar-gz chr17.f1r2.tar.gz -O samples-FFPE.chr17.raw.vcf. #### Expected behavior; So I used the gatk-4.1.3.0 for analysis the same date with the same input . In the INFO , we can find than all result is consistent except AF(0.038).; chr17 41244376 . T C . . DP=1192;ECNT=1;MBQ=30,30;MFRL=242,275;MMQ=60,60;MPOS=37;POPAF=7.30;TLOD=59.10 GT:AD:AF:DP:F1R2:F2R1:SB 0/1:1106,44:0.038:1150:531,27:571,17:575,531,23,21. My command lines is describled as below:; /software/gatk/gatk-4.1.3.0/gatk --java-options ""-XX:ParallelGCThreads=4 -Xmx20G -Djava.io.tmpdir=./tmp"" Mutect2 -L chr17.bed --pcr-indel-model CONSERVATIVE -I samples-FFPE.recal.bam -tumor samples-FFPE -R ucsc.hg19.fasta --native-pair-hmm-threads 4 --min-base-quality-score 15 -germline-resource af-only-gnomad.raw.sites.hg19.vcf.gz --panel-of-normals PoN.vcf.gz -O samples-FFPE.chr17.raw.vcf. ### Description ; Hope for feedbacking me the reason causing the difference.; Thanks so much!!. ----",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7016
https://github.com/broadinstitute/gatk/issues/7017:254,Deployability,update,update,254,As per the discussion on #6780 our temp file code calls out to `createTempFileInDirectory()` which itself has a list of hard-coded index extensions that it appends to the file. This seems brittle and could leak tmp files onto disk if we don't diligently update that method with all new side outputs. . We should change this method to create a tmp directory that is in its entirety marked as `deleteOnExit()` so we don't have to worry about hard coded side outputs being insufficient.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7017
https://github.com/broadinstitute/gatk/pull/7019:877,Availability,down,downstream,877,"This PR addresses two phasing bugs, https://github.com/broadinstitute/gatk/issues/6463 and https://github.com/broadinstitute/gatk/issues/6845. https://github.com/broadinstitute/gatk/issues/6463 identified a bug in the phasing algorithm which caused the wrong phase information to be output for scenarios where the first variant in a phase set is homozygous variant and it is followed by het variants in opposite phase. Without this change the het variants were incorrectly placed on the same phase strand because the phase set was tied to the hom var variant, and the algorithm assumed that each het variant could be put in the same phase strand as it because it was on all haplotypes. I've modified the algorithm to keep track, for variants that occur on all haplotypes, of which of the haplotypes have already been used for phasing an upstream ""comp"" variant so that further downstream variants can be checked against the remaining set. https://github.com/broadinstitute/gatk/issues/6845 showed an example of phase sets being disrupted by the presence of an alternate haplotype that supported an additional, uncalled, variant in the region. In this case there was an alternate haplotype supported by two reads that supported a SNP downstream of two pairs of SNPs in alternate phase. The presence of an additional haplotype causes the phasing algorithm to break the phase sets in the region. I've modified the algorithm to only use haplotypes that support the alternate alleles present in called variants in phasing by modifying the number that we pass as `AssemblyBasedCallerUtils.constructPhaseSetMapping()`'s `totalAvailableHaplotypes` parameter. In my opinion this ; fix produces output that is still correct and is much easier to understand (since it only depends on sites that are visible in the output VCF), but if anyone objects to this change please let me know. . Non-test code changes for this PR are in two different commits to try to make it easier to understand the scope of the two cha",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7019
https://github.com/broadinstitute/gatk/pull/7019:1233,Availability,down,downstream,1233,"R addresses two phasing bugs, https://github.com/broadinstitute/gatk/issues/6463 and https://github.com/broadinstitute/gatk/issues/6845. https://github.com/broadinstitute/gatk/issues/6463 identified a bug in the phasing algorithm which caused the wrong phase information to be output for scenarios where the first variant in a phase set is homozygous variant and it is followed by het variants in opposite phase. Without this change the het variants were incorrectly placed on the same phase strand because the phase set was tied to the hom var variant, and the algorithm assumed that each het variant could be put in the same phase strand as it because it was on all haplotypes. I've modified the algorithm to keep track, for variants that occur on all haplotypes, of which of the haplotypes have already been used for phasing an upstream ""comp"" variant so that further downstream variants can be checked against the remaining set. https://github.com/broadinstitute/gatk/issues/6845 showed an example of phase sets being disrupted by the presence of an alternate haplotype that supported an additional, uncalled, variant in the region. In this case there was an alternate haplotype supported by two reads that supported a SNP downstream of two pairs of SNPs in alternate phase. The presence of an additional haplotype causes the phasing algorithm to break the phase sets in the region. I've modified the algorithm to only use haplotypes that support the alternate alleles present in called variants in phasing by modifying the number that we pass as `AssemblyBasedCallerUtils.constructPhaseSetMapping()`'s `totalAvailableHaplotypes` parameter. In my opinion this ; fix produces output that is still correct and is much easier to understand (since it only depends on sites that are visible in the output VCF), but if anyone objects to this change please let me know. . Non-test code changes for this PR are in two different commits to try to make it easier to understand the scope of the two changes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7019
https://github.com/broadinstitute/gatk/pull/7019:1762,Integrability,depend,depends,1762,"R addresses two phasing bugs, https://github.com/broadinstitute/gatk/issues/6463 and https://github.com/broadinstitute/gatk/issues/6845. https://github.com/broadinstitute/gatk/issues/6463 identified a bug in the phasing algorithm which caused the wrong phase information to be output for scenarios where the first variant in a phase set is homozygous variant and it is followed by het variants in opposite phase. Without this change the het variants were incorrectly placed on the same phase strand because the phase set was tied to the hom var variant, and the algorithm assumed that each het variant could be put in the same phase strand as it because it was on all haplotypes. I've modified the algorithm to keep track, for variants that occur on all haplotypes, of which of the haplotypes have already been used for phasing an upstream ""comp"" variant so that further downstream variants can be checked against the remaining set. https://github.com/broadinstitute/gatk/issues/6845 showed an example of phase sets being disrupted by the presence of an alternate haplotype that supported an additional, uncalled, variant in the region. In this case there was an alternate haplotype supported by two reads that supported a SNP downstream of two pairs of SNPs in alternate phase. The presence of an additional haplotype causes the phasing algorithm to break the phase sets in the region. I've modified the algorithm to only use haplotypes that support the alternate alleles present in called variants in phasing by modifying the number that we pass as `AssemblyBasedCallerUtils.constructPhaseSetMapping()`'s `totalAvailableHaplotypes` parameter. In my opinion this ; fix produces output that is still correct and is much easier to understand (since it only depends on sites that are visible in the output VCF), but if anyone objects to this change please let me know. . Non-test code changes for this PR are in two different commits to try to make it easier to understand the scope of the two changes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7019
https://github.com/broadinstitute/gatk/pull/7019:1879,Testability,test,test,1879,"R addresses two phasing bugs, https://github.com/broadinstitute/gatk/issues/6463 and https://github.com/broadinstitute/gatk/issues/6845. https://github.com/broadinstitute/gatk/issues/6463 identified a bug in the phasing algorithm which caused the wrong phase information to be output for scenarios where the first variant in a phase set is homozygous variant and it is followed by het variants in opposite phase. Without this change the het variants were incorrectly placed on the same phase strand because the phase set was tied to the hom var variant, and the algorithm assumed that each het variant could be put in the same phase strand as it because it was on all haplotypes. I've modified the algorithm to keep track, for variants that occur on all haplotypes, of which of the haplotypes have already been used for phasing an upstream ""comp"" variant so that further downstream variants can be checked against the remaining set. https://github.com/broadinstitute/gatk/issues/6845 showed an example of phase sets being disrupted by the presence of an alternate haplotype that supported an additional, uncalled, variant in the region. In this case there was an alternate haplotype supported by two reads that supported a SNP downstream of two pairs of SNPs in alternate phase. The presence of an additional haplotype causes the phasing algorithm to break the phase sets in the region. I've modified the algorithm to only use haplotypes that support the alternate alleles present in called variants in phasing by modifying the number that we pass as `AssemblyBasedCallerUtils.constructPhaseSetMapping()`'s `totalAvailableHaplotypes` parameter. In my opinion this ; fix produces output that is still correct and is much easier to understand (since it only depends on sites that are visible in the output VCF), but if anyone objects to this change please let me know. . Non-test code changes for this PR are in two different commits to try to make it easier to understand the scope of the two changes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7019
https://github.com/broadinstitute/gatk/pull/7020:68,Availability,echo,echo,68,"If a core dump is produced while running tests on travis, this will echo the log file to the travis log (ie., it was triggered [here](https://api.travis-ci.com/v3/job/468677651/log.txt) by the pair hmm seg fault) so the java and native thread stacks can be inspected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020
https://github.com/broadinstitute/gatk/pull/7020:206,Availability,fault,fault,206,"If a core dump is produced while running tests on travis, this will echo the log file to the travis log (ie., it was triggered [here](https://api.travis-ci.com/v3/job/468677651/log.txt) by the pair hmm seg fault) so the java and native thread stacks can be inspected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020
https://github.com/broadinstitute/gatk/pull/7020:41,Testability,test,tests,41,"If a core dump is produced while running tests on travis, this will echo the log file to the travis log (ie., it was triggered [here](https://api.travis-ci.com/v3/job/468677651/log.txt) by the pair hmm seg fault) so the java and native thread stacks can be inspected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020
https://github.com/broadinstitute/gatk/pull/7020:77,Testability,log,log,77,"If a core dump is produced while running tests on travis, this will echo the log file to the travis log (ie., it was triggered [here](https://api.travis-ci.com/v3/job/468677651/log.txt) by the pair hmm seg fault) so the java and native thread stacks can be inspected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020
https://github.com/broadinstitute/gatk/pull/7020:100,Testability,log,log,100,"If a core dump is produced while running tests on travis, this will echo the log file to the travis log (ie., it was triggered [here](https://api.travis-ci.com/v3/job/468677651/log.txt) by the pair hmm seg fault) so the java and native thread stacks can be inspected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020
https://github.com/broadinstitute/gatk/pull/7020:177,Testability,log,log,177,"If a core dump is produced while running tests on travis, this will echo the log file to the travis log (ie., it was triggered [here](https://api.travis-ci.com/v3/job/468677651/log.txt) by the pair hmm seg fault) so the java and native thread stacks can be inspected.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7020
https://github.com/broadinstitute/gatk/pull/7021:81,Deployability,integrat,integrating,81,Added the new VariantContext comparison functionality from #6417 but without yet integrating it into any existing tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7021
https://github.com/broadinstitute/gatk/pull/7021:81,Integrability,integrat,integrating,81,Added the new VariantContext comparison functionality from #6417 but without yet integrating it into any existing tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7021
https://github.com/broadinstitute/gatk/pull/7021:114,Testability,test,tests,114,Added the new VariantContext comparison functionality from #6417 but without yet integrating it into any existing tests.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7021
https://github.com/broadinstitute/gatk/issues/7024:294,Modifiability,config,config,294,"## Documentation request. ### Description ; This involves the Tool Docs pages. When sharing the link to a tool docs page, the link description shows the PHP code from the old website. . For example, ; **SelectVariants**; _include '../../../../common/include/common.php'; include_once '../../../config.php'; $module = modules::GATK; $name = docSN::toolDocs; printHeader($module, $name, topSN::guide); ..._. This PHP code does not appear in the actual Tool Docs, so there is no visible problem on the website.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7024
https://github.com/broadinstitute/gatk/issues/7024:392,Usability,guid,guide,392,"## Documentation request. ### Description ; This involves the Tool Docs pages. When sharing the link to a tool docs page, the link description shows the PHP code from the old website. . For example, ; **SelectVariants**; _include '../../../../common/include/common.php'; include_once '../../../config.php'; $module = modules::GATK; $name = docSN::toolDocs; printHeader($module, $name, topSN::guide); ..._. This PHP code does not appear in the actual Tool Docs, so there is no visible problem on the website.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7024
https://github.com/broadinstitute/gatk/pull/7026:192,Deployability,pipeline,pipeline,192,"Adds a new tool that prints any of the SV evidence file types: read count (RD), discordant pair (PE), split-read (SR), or B-allele frequency (BAF). This tool is used frequently in the gatk-sv pipeline for retrieving subsets of evidence records from a bucket over specific intervals. Evidence file formats comply with the current specifications in the existing gatk-sv pipeline. The tool is implemented as a FeatureWalker, which needed to be modified slightly to retrieve the Feature file header. Thus each evidence type has its own classes implementing a Feature and a codec. There are also new OutputStream classes for conveniently writing Features in compressed (and indexed) or plain text formats. The existing PairedEndAndSplitReadEvidenceCollection tool has been modified to use these OutputStream classes. The IntegrationSpec class can now also check for the existence of expected index file output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026
https://github.com/broadinstitute/gatk/pull/7026:368,Deployability,pipeline,pipeline,368,"Adds a new tool that prints any of the SV evidence file types: read count (RD), discordant pair (PE), split-read (SR), or B-allele frequency (BAF). This tool is used frequently in the gatk-sv pipeline for retrieving subsets of evidence records from a bucket over specific intervals. Evidence file formats comply with the current specifications in the existing gatk-sv pipeline. The tool is implemented as a FeatureWalker, which needed to be modified slightly to retrieve the Feature file header. Thus each evidence type has its own classes implementing a Feature and a codec. There are also new OutputStream classes for conveniently writing Features in compressed (and indexed) or plain text formats. The existing PairedEndAndSplitReadEvidenceCollection tool has been modified to use these OutputStream classes. The IntegrationSpec class can now also check for the existence of expected index file output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026
https://github.com/broadinstitute/gatk/pull/7026:816,Deployability,Integrat,IntegrationSpec,816,"Adds a new tool that prints any of the SV evidence file types: read count (RD), discordant pair (PE), split-read (SR), or B-allele frequency (BAF). This tool is used frequently in the gatk-sv pipeline for retrieving subsets of evidence records from a bucket over specific intervals. Evidence file formats comply with the current specifications in the existing gatk-sv pipeline. The tool is implemented as a FeatureWalker, which needed to be modified slightly to retrieve the Feature file header. Thus each evidence type has its own classes implementing a Feature and a codec. There are also new OutputStream classes for conveniently writing Features in compressed (and indexed) or plain text formats. The existing PairedEndAndSplitReadEvidenceCollection tool has been modified to use these OutputStream classes. The IntegrationSpec class can now also check for the existence of expected index file output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026
https://github.com/broadinstitute/gatk/pull/7026:816,Integrability,Integrat,IntegrationSpec,816,"Adds a new tool that prints any of the SV evidence file types: read count (RD), discordant pair (PE), split-read (SR), or B-allele frequency (BAF). This tool is used frequently in the gatk-sv pipeline for retrieving subsets of evidence records from a bucket over specific intervals. Evidence file formats comply with the current specifications in the existing gatk-sv pipeline. The tool is implemented as a FeatureWalker, which needed to be modified slightly to retrieve the Feature file header. Thus each evidence type has its own classes implementing a Feature and a codec. There are also new OutputStream classes for conveniently writing Features in compressed (and indexed) or plain text formats. The existing PairedEndAndSplitReadEvidenceCollection tool has been modified to use these OutputStream classes. The IntegrationSpec class can now also check for the existence of expected index file output.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7026
https://github.com/broadinstitute/gatk/issues/7030:1366,Integrability,depend,depending,1366,"fined intervals. We have a final job that merges the resulting VCFs into one end file. That's great for VCF-creating tools, but does not work for VariantEval, since a) it aggregates data across the genome and therefore summaries per interval dont make sense, and b) it does produce an easily aggregatable product. In #6973 I authored some changes to VariantEval, which include switching it to use MultiVariantWalkerGroupedOnStart, and also creating a separate VariantEvalEngine, which contains the guts of VariantEval. I would like to do one more change, but @cmnbroad suggested I run this proposal by others here first. The core idea is to make it possible to run VariantEval over a defined set of interval(s), and then make it save that state to disk. A separate step would read those files, combine, and then do the actual aggregation step. My use case is to enable this in VariantEvalEngine and then use that capability in our non-GATK VariantQC tool. I'd be happy to enable that in the VariantEval walker or not, depending on your thoughts. Here is what happens now: VariantEval/VariantEvalEngine iterates the input VCF(s) and tracks values in StratificationManager. Once traversal is complete, onTraveralSuccess() will call finalizeReport(), which essentially takes the pre-aggregated information from StratificationManager and finalizes to make the output. Therefore if one could scatter jobs per interval, store the data from StratificationManager, and then restore/aggregate it, we could execute VariantEval/VariantQC scatter/gathered. Here is the proposal:; ; - This assumes my PR to separate VariantEvalEngine has been merged.; - In StratificationManager, create a SerializedStratificationState class. This class is responsible for gathering the relevant state of StratificationManager and would get serialized to disk using Jackson.; - StratificationManager would have a saveToDisk(), and a new constructor that accepts the Path to a serialized SerializedStratificationState object. The i",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030
https://github.com/broadinstitute/gatk/issues/7030:3527,Performance,load,loads,3527,"bs per interval, store the data from StratificationManager, and then restore/aggregate it, we could execute VariantEval/VariantQC scatter/gathered. Here is the proposal:; ; - This assumes my PR to separate VariantEvalEngine has been merged.; - In StratificationManager, create a SerializedStratificationState class. This class is responsible for gathering the relevant state of StratificationManager and would get serialized to disk using Jackson.; - StratificationManager would have a saveToDisk(), and a new constructor that accepts the Path to a serialized SerializedStratificationState object. The implementation of saving/restoring would basically be private to StratificationManager.; - In VariantEvalEngine, make a public method for saveToDisk(), which saves StratificationManager and any potential other needed information to disk, serializing with Jackson.; - StratificationManager already has a concept of combineStrats() and Combiner. This needs to be fully implemented across the VariantEval classes; however, I propose to build off this to allow VariantEvaluators and VariantStratifiers to be combined. ; - If the above works, then it is possible to take N serialized SerializedStratificationState objects, restore and combine to create one StratificationManager that represents the data from across the genome.; - With the above steps, the core capabilities I need should be present. As far as how that's exposed in existing GATK tools, I dont have strong opinions. If you want this exposed in VariantEval, I'm happy to make an new argument for --save-state-to-disk-only, which would save the result of VariantEval's interation to a serialized file and skip the reports. To be useful, we need a companion walker to ""MergeVariantEvals"", which takes N serialized files, loads/aggregates and makes the actual report. Does anyone have thoughts or concerns on this proposal? Is this something you think you'd accept as a PR to GATK/VariantEvalEngine/StratificationManager? Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030
https://github.com/broadinstitute/gatk/issues/7030:3164,Security,expose,exposed,3164,"bs per interval, store the data from StratificationManager, and then restore/aggregate it, we could execute VariantEval/VariantQC scatter/gathered. Here is the proposal:; ; - This assumes my PR to separate VariantEvalEngine has been merged.; - In StratificationManager, create a SerializedStratificationState class. This class is responsible for gathering the relevant state of StratificationManager and would get serialized to disk using Jackson.; - StratificationManager would have a saveToDisk(), and a new constructor that accepts the Path to a serialized SerializedStratificationState object. The implementation of saving/restoring would basically be private to StratificationManager.; - In VariantEvalEngine, make a public method for saveToDisk(), which saves StratificationManager and any potential other needed information to disk, serializing with Jackson.; - StratificationManager already has a concept of combineStrats() and Combiner. This needs to be fully implemented across the VariantEval classes; however, I propose to build off this to allow VariantEvaluators and VariantStratifiers to be combined. ; - If the above works, then it is possible to take N serialized SerializedStratificationState objects, restore and combine to create one StratificationManager that represents the data from across the genome.; - With the above steps, the core capabilities I need should be present. As far as how that's exposed in existing GATK tools, I dont have strong opinions. If you want this exposed in VariantEval, I'm happy to make an new argument for --save-state-to-disk-only, which would save the result of VariantEval's interation to a serialized file and skip the reports. To be useful, we need a companion walker to ""MergeVariantEvals"", which takes N serialized files, loads/aggregates and makes the actual report. Does anyone have thoughts or concerns on this proposal? Is this something you think you'd accept as a PR to GATK/VariantEvalEngine/StratificationManager? Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030
https://github.com/broadinstitute/gatk/issues/7030:3242,Security,expose,exposed,3242,"bs per interval, store the data from StratificationManager, and then restore/aggregate it, we could execute VariantEval/VariantQC scatter/gathered. Here is the proposal:; ; - This assumes my PR to separate VariantEvalEngine has been merged.; - In StratificationManager, create a SerializedStratificationState class. This class is responsible for gathering the relevant state of StratificationManager and would get serialized to disk using Jackson.; - StratificationManager would have a saveToDisk(), and a new constructor that accepts the Path to a serialized SerializedStratificationState object. The implementation of saving/restoring would basically be private to StratificationManager.; - In VariantEvalEngine, make a public method for saveToDisk(), which saves StratificationManager and any potential other needed information to disk, serializing with Jackson.; - StratificationManager already has a concept of combineStrats() and Combiner. This needs to be fully implemented across the VariantEval classes; however, I propose to build off this to allow VariantEvaluators and VariantStratifiers to be combined. ; - If the above works, then it is possible to take N serialized SerializedStratificationState objects, restore and combine to create one StratificationManager that represents the data from across the genome.; - With the above steps, the core capabilities I need should be present. As far as how that's exposed in existing GATK tools, I dont have strong opinions. If you want this exposed in VariantEval, I'm happy to make an new argument for --save-state-to-disk-only, which would save the result of VariantEval's interation to a serialized file and skip the reports. To be useful, we need a companion walker to ""MergeVariantEvals"", which takes N serialized files, loads/aggregates and makes the actual report. Does anyone have thoughts or concerns on this proposal? Is this something you think you'd accept as a PR to GATK/VariantEvalEngine/StratificationManager? Thanks in advance.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7030
https://github.com/broadinstitute/gatk/issues/7031:3779,Availability,down,down,3779,"aseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 15:46:27.296 INFO BaseRecalibrator - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 15:46:27.296 INFO BaseRecalibrator - Deflater: IntelDeflater; 15:46:27.296 INFO BaseRecalibrator - Inflater: IntelInflater; 15:46:27.296 INFO BaseRecalibrator - GCS max retries/reopens: 20; 15:46:27.296 INFO BaseRecalibrator - Requester pays: disabled; 15:46:27.297 INFO BaseRecalibrator - Initializing engine; 15:46:28.062 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/dbsnp_146.hg38.vcf; 15:46:28.075 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf; 15:46:28.127 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf; 15:46:28.213 INFO BaseRecalibrator - Done initializing engine; 15:46:28.216 INFO BaseRecalibrator - Shutting down engine; [202118 034628] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.52 minutes.; Runtime.totalMemory()=1488977920; ***********************************************************************. A USER ERROR has occurred: Number of read groups must be >= 1, but is 0. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Number of read groups must be >= 1, but is 0; 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.<init>(BaseRecalibrationEngine.java:96); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.onTraversalStart(BaseRecalibrator.java:144); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLine",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031
https://github.com/broadinstitute/gatk/issues/7031:4031,Availability,ERROR,ERROR,4031,"telInflater; 15:46:27.296 INFO BaseRecalibrator - GCS max retries/reopens: 20; 15:46:27.296 INFO BaseRecalibrator - Requester pays: disabled; 15:46:27.297 INFO BaseRecalibrator - Initializing engine; 15:46:28.062 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/dbsnp_146.hg38.vcf; 15:46:28.075 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf; 15:46:28.127 INFO FeatureManager - Using codec VCFCodec to read file file:///data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf; 15:46:28.213 INFO BaseRecalibrator - Done initializing engine; 15:46:28.216 INFO BaseRecalibrator - Shutting down engine; [202118 034628] org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator done. Elapsed time: 0.52 minutes.; Runtime.totalMemory()=1488977920; ***********************************************************************. A USER ERROR has occurred: Number of read groups must be >= 1, but is 0. ***********************************************************************; org.broadinstitute.hellbender.exceptions.UserException: Number of read groups must be >= 1, but is 0; 	at org.broadinstitute.hellbender.utils.recalibration.BaseRecalibrationEngine.<init>(BaseRecalibrationEngine.java:96); 	at org.broadinstitute.hellbender.tools.walkers.bqsr.BaseRecalibrator.onTraversalStart(BaseRecalibrator.java:144); 	at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1046); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:139); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:191); 	at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMain(CommandLineProgram.java:210); 	at org.broadinstitute.hellbender.Main.runCommandLineProgram(Main.java:162); 	at org.broadinstitute.hellbender.Main.mainEntry(Main.java:205); 	at org.broadi",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031
https://github.com/broadinstitute/gatk/issues/7031:1554,Performance,Load,Loading,1554,andard.indels.hg38.vcf 1>/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.BaseRecalibrator.log 2>&1. Using GATK jar /usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx12G -Djava.io.tmpdir=/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/tmp -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar BaseRecalibrator -R /data/nws/WES/reference/Homo_sapiens_assembly38.fasta -I /data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.sorted.marked.bam -O recal_data.table --known-sites /data/nws/WES/reference/dbsnp_146.hg38.vcf --known-sites /data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf --known-sites /data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf; 15:45:57.013 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:12.281 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:12.282 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.3.0; 15:46:12.282 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:46:27.292 INFO BaseRecalibrator - Executing as nws@cuckoolab on Linux v3.10.0-1127.19.1.el7.x86_64 amd64; 15:46:27.292 INFO BaseRecalibrator - Java runtime: OpenJDK 64-Bit Server VM v1.8.0_262-b10; 15:46:27.294 INFO BaseRecalibrator - Start Date/Time: 202118 034556; 15:46:27.294 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:27.294 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:27.295 INFO BaseRecalibrator - HTSJDK Version: 2.20.1; 15:46:27.295 INFO Ba,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031
https://github.com/broadinstitute/gatk/issues/7031:667,Testability,log,log,667,"### Instructions; gatk --java-options ""-Xmx12G -Djava.io.tmpdir=/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/tmp -DGATK_STACKTRACE_ON_USER_EXCEPTION=true"" BaseRecalibrator -R /data/nws/WES/reference/Homo_sapiens_assembly38.fasta -I /data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.sorted.marked.bam -O recal_data.table --known-sites /data/nws/WES/reference/dbsnp_146.hg38.vcf --known-sites /data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf --known-sites /data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf 1>/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.BaseRecalibrator.log 2>&1. Using GATK jar /usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar; Running:; java -Dsamjdk.use_async_io_read_samtools=false -Dsamjdk.use_async_io_write_samtools=true -Dsamjdk.use_async_io_write_tribble=false -Dsamjdk.compression_level=2 -Xmx12G -Djava.io.tmpdir=/data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/tmp -DGATK_STACKTRACE_ON_USER_EXCEPTION=true -jar /usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar BaseRecalibrator -R /data/nws/WES/reference/Homo_sapiens_assembly38.fasta -I /data/nws/WES/1align_out/200919_A00682_0446_AHCVMJDSXY/Set12-3_L1_361361.sorted.marked.bam -O recal_data.table --known-sites /data/nws/WES/reference/dbsnp_146.hg38.vcf --known-sites /data/nws/WES/reference/1000G_phase1.snps.high_confidence.hg38.vcf --known-sites /data/nws/WES/reference/Mills_and_1000G_gold_standard.indels.hg38.vcf; 15:45:57.013 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/local/gatk-4.1.3.0/gatk-package-4.1.3.0-local.jar!/com/intel/gkl/native/libgkl_compression.so; 15:46:12.281 INFO BaseRecalibrator - ------------------------------------------------------------; 15:46:12.282 INFO BaseRecalibrator - The Genome Analysis Toolkit (GATK) v4.1.3.0; 15:46:12.282 INFO BaseRecalibrator - For support and documentation go to https://software.broadinstitute.org/gatk/; 15:46:",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7031
https://github.com/broadinstitute/gatk/issues/7032:4189,Availability,Avail,Available,4189,tCollection - Processing 170805979 bp from intervals; 10:29:22.613 INFO Mutect2 - Done initializing engine; 10:29:22.622 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:29:22.624 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 10:29:22.625 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 10:29:22.625 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 10:29:22.631 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:29:22.660 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 10:29:22.660 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:29:22.660 INFO IntelPairHmm - Available threads: 40; 10:29:22.660 INFO IntelPairHmm - Requested threads: 4; 10:29:22.660 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 10:29:22.688 INFO ProgressMeter - Starting traversal; 10:29:22.688 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 10:29:32.698 INFO ProgressMeter - 6:378640 0.2 1420 8512.3; 10:29:42.723 INFO ProgressMeter - 6:1034304 0.3 3810 11410.0; 10:29:52.736 INFO ProgressMeter - 6:1705479 0.5 6270 12520.4; 10:30:02.745 INFO ProgressMeter - 6:2543064 0.7 9270 13885.2; 10:30:12.776 INFO ProgressMeter - 6:3144654 0.8 11520 13799.7; 10:30:22.791 INFO ProgressMeter - 6:3912571 1.0 14330 14305.4; 10:30:32.792 INFO ProgressMeter - 6:4678136 1.2 17120 14652.7; 10:30:42.803 INFO ProgressMeter - 6:5436632 1.3 19900 14903.6; 10:30:52.831 INFO ProgressMeter - 6:6213304 1.5 22710 15116.0; 10:31:02.837 INFO ProgressMeter - 6:7019025 1.7 25670 15379.2; 10:31:12.906 INFO ProgressMeter - 6:7571523,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:1419,Performance,Load,Loading,1419," to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:29:22.408 INFO Mutect2 - Executing as spim@992fbecc5b50 on Linux v3.10.0-693.el7.x86_64 amd64; 10:29:22.408 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v11.0.6+10-post-Debian-1deb10u1; 10:29:22.408 INFO Mutect2 - Start Date/Time: January 6, 2021 at 10:29:22 AM UTC; 10:29:22.408 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - --------",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:3341,Performance,Load,Loading,3341,-------------------------------------------; 10:29:22.408 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.409 INFO Mutect2 - HTSJDK Version: 2.21.0; 10:29:22.409 INFO Mutect2 - Picard Version: 2.21.2; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:29:22.409 INFO Mutect2 - Deflater: IntelDeflater; 10:29:22.409 INFO Mutect2 - Inflater: IntelInflater; 10:29:22.409 INFO Mutect2 - GCS max retries/reopens: 20; 10:29:22.409 INFO Mutect2 - Requester pays: disabled; 10:29:22.409 INFO Mutect2 - Initializing engine; 10:29:22.609 INFO IntervalArgumentCollection - Processing 170805979 bp from intervals; 10:29:22.613 INFO Mutect2 - Done initializing engine; 10:29:22.622 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:29:22.624 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 10:29:22.625 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 10:29:22.625 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 10:29:22.631 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:29:22.660 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 10:29:22.660 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:29:22.660 INFO IntelPairHmm - Available threads: 40; 10:29:22.660 INFO IntelPairHmm - Requested threads: 4; 10:29:22.660 INFO PairHMM - Using the OpenMP multi-threaded AVX-accel,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:3505,Performance,Load,Loading,3505,K Version: 2.21.0; 10:29:22.409 INFO Mutect2 - Picard Version: 2.21.2; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_READ_FOR_SAMTOOLS : false; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_SAMTOOLS : true; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.USE_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:29:22.409 INFO Mutect2 - Deflater: IntelDeflater; 10:29:22.409 INFO Mutect2 - Inflater: IntelInflater; 10:29:22.409 INFO Mutect2 - GCS max retries/reopens: 20; 10:29:22.409 INFO Mutect2 - Requester pays: disabled; 10:29:22.409 INFO Mutect2 - Initializing engine; 10:29:22.609 INFO IntervalArgumentCollection - Processing 170805979 bp from intervals; 10:29:22.613 INFO Mutect2 - Done initializing engine; 10:29:22.622 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:29:22.624 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 10:29:22.625 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 10:29:22.625 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 10:29:22.631 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:29:22.660 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 10:29:22.660 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:29:22.660 INFO IntelPairHmm - Available threads: 40; 10:29:22.660 INFO IntelPairHmm - Requested threads: 4; 10:29:22.660 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 10:29:22.688 INFO ProgressMeter - Starting traversal; 10:29:22.688 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Proc,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:3859,Performance,Load,Loading,3859,_ASYNC_IO_WRITE_FOR_TRIBBLE : false; 10:29:22.409 INFO Mutect2 - Deflater: IntelDeflater; 10:29:22.409 INFO Mutect2 - Inflater: IntelInflater; 10:29:22.409 INFO Mutect2 - GCS max retries/reopens: 20; 10:29:22.409 INFO Mutect2 - Requester pays: disabled; 10:29:22.409 INFO Mutect2 - Initializing engine; 10:29:22.609 INFO IntervalArgumentCollection - Processing 170805979 bp from intervals; 10:29:22.613 INFO Mutect2 - Done initializing engine; 10:29:22.622 INFO NativeLibraryLoader - Loading libgkl_utils.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:29:22.624 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 10:29:22.625 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 10:29:22.625 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 10:29:22.631 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:29:22.660 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 10:29:22.660 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:29:22.660 INFO IntelPairHmm - Available threads: 40; 10:29:22.660 INFO IntelPairHmm - Requested threads: 4; 10:29:22.660 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 10:29:22.688 INFO ProgressMeter - Starting traversal; 10:29:22.688 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 10:29:32.698 INFO ProgressMeter - 6:378640 0.2 1420 8512.3; 10:29:42.723 INFO ProgressMeter - 6:1034304 0.3 3810 11410.0; 10:29:52.736 INFO ProgressMeter - 6:1705479 0.5 6270 12520.4; 10:30:02.745 INFO ProgressMeter - 6:2543064 0.7 9270 13885.2; 10:30:12.776 INFO ProgressMeter - 6:3144654 0.8 11520 13799.7; 10:30:22.791 INFO Prog,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:4312,Performance,multi-thread,multi-threaded,4312,aryLoader - Loading libgkl_utils.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_utils.so; 10:29:22.624 INFO NativeLibraryLoader - Loading libgkl_smithwaterman.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_smithwaterman.so; 10:29:22.625 INFO IntelSmithWaterman - Using CPU-supported AVX-512 instructions; 10:29:22.625 INFO SmithWatermanAligner - Using AVX accelerated SmithWaterman implementation; 10:29:22.631 INFO NativeLibraryLoader - Loading libgkl_pairhmm_omp.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_pairhmm_omp.so; 10:29:22.660 INFO IntelPairHmm - Using CPU-supported AVX-512 instructions; 10:29:22.660 INFO IntelPairHmm - Flush-to-zero (FTZ) is enabled when running PairHMM; 10:29:22.660 INFO IntelPairHmm - Available threads: 40; 10:29:22.660 INFO IntelPairHmm - Requested threads: 4; 10:29:22.660 INFO PairHMM - Using the OpenMP multi-threaded AVX-accelerated native PairHMM implementation; 10:29:22.688 INFO ProgressMeter - Starting traversal; 10:29:22.688 INFO ProgressMeter - Current Locus Elapsed Minutes Regions Processed Regions/Minute; 10:29:32.698 INFO ProgressMeter - 6:378640 0.2 1420 8512.3; 10:29:42.723 INFO ProgressMeter - 6:1034304 0.3 3810 11410.0; 10:29:52.736 INFO ProgressMeter - 6:1705479 0.5 6270 12520.4; 10:30:02.745 INFO ProgressMeter - 6:2543064 0.7 9270 13885.2; 10:30:12.776 INFO ProgressMeter - 6:3144654 0.8 11520 13799.7; 10:30:22.791 INFO ProgressMeter - 6:3912571 1.0 14330 14305.4; 10:30:32.792 INFO ProgressMeter - 6:4678136 1.2 17120 14652.7; 10:30:42.803 INFO ProgressMeter - 6:5436632 1.3 19900 14903.6; 10:30:52.831 INFO ProgressMeter - 6:6213304 1.5 22710 15116.0; 10:31:02.837 INFO ProgressMeter - 6:7019025 1.7 25670 15379.2; 10:31:12.906 INFO ProgressMeter - 6:7571523 1.8 27750 15106.4; 10:31:22.944 INFO ProgressMeter - 6:8170235 2.0 29950 14943.2; 10:31:32.976 INFO ProgressMeter - 6:8918329 2.2 32620 ,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:1685,Safety,detect,detect,1685,".; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.org/gatk/; 10:29:22.408 INFO Mutect2 - Executing as spim@992fbecc5b50 on Linux v3.10.0-693.el7.x86_64 amd64; 10:29:22.408 INFO Mutect2 - Java runtime: OpenJDK 64-Bit Server VM v11.0.6+10-post-Debian-1deb10u1; 10:29:22.408 INFO Mutect2 - Start Date/Time: January 6, 2021 at 10:29:22 AM UTC; 10:29:22.408 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.409 INFO Mutect2 - HTSJDK Version: 2.21.0; 10:29:22.409 INFO Mutect2 - Picard Version: 2.21.2; 10:29:22.409 INFO Mutect2 - HTSJDK Defaults.COMPRESSION_LEVEL : 2; 10:29:22.409 INFO Mutect2 - HTSJDK Def",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:964,Security,confidential,confidentiality,964,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); gatk:4.1.4.1; ### Description ; Hello, I have an issue when i run Mutect2. Indeed it's seems to be a RAM issue (you will find 2 different log behind). To be aware of the context, I am using Mutect2 in production and in the new version which I use, approximately 1% of my Mutect2 failed. I first try to understand the log and it seems to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:222,Testability,log,log,222,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); gatk:4.1.4.1; ### Description ; Hello, I have an issue when i run Mutect2. Indeed it's seems to be a RAM issue (you will find 2 different log behind). To be aware of the context, I am using Mutect2 in production and in the new version which I use, approximately 1% of my Mutect2 failed. I first try to understand the log and it seems to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:401,Testability,log,log,401,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); gatk:4.1.4.1; ### Description ; Hello, I have an issue when i run Mutect2. Indeed it's seems to be a RAM issue (you will find 2 different log behind). To be aware of the context, I am using Mutect2 in production and in the new version which I use, approximately 1% of my Mutect2 failed. I first try to understand the log and it seems to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:492,Testability,test,test,492,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); gatk:4.1.4.1; ### Description ; Hello, I have an issue when i run Mutect2. Indeed it's seems to be a RAM issue (you will find 2 different log behind). To be aware of the context, I am using Mutect2 in production and in the new version which I use, approximately 1% of my Mutect2 failed. I first try to understand the log and it seems to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:695,Testability,test,test,695,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); gatk:4.1.4.1; ### Description ; Hello, I have an issue when i run Mutect2. Indeed it's seems to be a RAM issue (you will find 2 different log behind). To be aware of the context, I am using Mutect2 in production and in the new version which I use, approximately 1% of my Mutect2 failed. I first try to understand the log and it seems to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:825,Testability,log,log,825,"## Bug Report. ### Affected tool(s) or class(es); Mutect2. ### Affected version(s); gatk:4.1.4.1; ### Description ; Hello, I have an issue when i run Mutect2. Indeed it's seems to be a RAM issue (you will find 2 different log behind). To be aware of the context, I am using Mutect2 in production and in the new version which I use, approximately 1% of my Mutect2 failed. I first try to understand the log and it seems to me that the issue is due to memory management. Then I realized several test, by increasing both Java machine memory and docker job memory (10G) wich seems enough for mutect2 and my job was still failling. I also try to change CPU parameters but nothing change.; We did more test and try to run the same command with 2 others version of gatk (4.1.9.0 and 4.1.0.0). The job failed in 4.1.9.0 with the same log than 4.1.4.0 but the version 4.1.0.0 ran successfully. #### Steps to reproduce; you will find the command below. I'am not aware of the confidentiality about my input. If i can i will send it to you if needed.; `java -Xmx4000m -Xms4000m -XX:ParallelGCThreads=1 -XX:+AggressiveHeap -jar /usr/share/java/gatk-package-4.1.4.1-local.jar Mutect2 --smith-waterman FASTEST_AVAILABLE -I WES-T_S7_chr_1_bqsr.bam -I WGS-C_S12_chr_1_bqsr.bam -normal WGS-C -L 1 -O OUTPUT -R GRCh38.92.fa`; #### Expected behavior; _Tell us what should happen_. ### Description. > 10:29:22.302 INFO NativeLibraryLoader - Loading libgkl_compression.so from jar:file:/usr/share/java/gatk-package-4.1.4.1-local.jar!/com/intel/gkl/native/libgkl_compression.so; Jan 06, 2021 10:29:22 AM shaded.cloud_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine; INFO: Failed to detect whether we are running on Google Compute Engine.; 10:29:22.407 INFO Mutect2 - ------------------------------------------------------------; 10:29:22.408 INFO Mutect2 - The Genome Analysis Toolkit (GATK) v4.1.4.1; 10:29:22.408 INFO Mutect2 - For support and documentation go to https://software.broadinstitute.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7032:19036,Testability,log,log,19036,1:01:39.582 INFO ProgressMeter - 6:136884895 32.3 493710 15293.9; 11:01:49.601 INFO ProgressMeter - 6:137645024 32.4 496460 15299.9; 11:01:59.637 INFO ProgressMeter - 6:138403074 32.6 499180 15304.8; 11:02:09.707 INFO ProgressMeter - 6:139027372 32.8 501500 15297.3; 11:02:19.722 INFO ProgressMeter - 6:139763198 33.0 504200 15301.7; 11:02:29.730 INFO ProgressMeter - 6:140651241 33.1 507330 15319.2; 11:02:39.754 INFO ProgressMeter - 6:141519060 33.3 510390 15334.2; 11:02:49.770 INFO ProgressMeter - 6:142365895 33.5 513350 15346.2; 11:02:59.825 INFO ProgressMeter - 6:143095858 33.6 515950 15347.0; 11:03:09.839 INFO ProgressMeter - 6:143836224 33.8 518620 15350.2; 11:03:19.935 INFO ProgressMeter - 6:144523800 34.0 521100 15347.2; 11:03:29.954 INFO ProgressMeter - 6:145296272 34.1 523860 15353.0; 11:03:39.962 INFO ProgressMeter - 6:146107991 34.3 526730 15362.0; 11:03:49.985 INFO ProgressMeter - 6:146894128 34.5 529520 15368.5; 11:04:00.014 INFO ProgressMeter - 6:147667260 34.6 532290 15374.3; 11:04:10.038 INFO ProgressMeter - 6:148434247 34.8 535070 15380.4; 11:04:20.045 INFO ProgressMeter - 6:149146016 35.0 537680 15381.6; 11:04:30.067 INFO ProgressMeter - 6:149747499 35.1 539940 15372.8; 11:04:40.079 INFO ProgressMeter - 6:150367082 35.3 542250 15365.6; 11:04:50.105 INFO ProgressMeter - 6:151044177 35.5 544720 15362.9; 11:05:00.117 INFO ProgressMeter - 6:151680574 35.6 547110 15358.0; 11:05:10.177 INFO ProgressMeter - 6:152355153 35.8 549520 15353.4; 11:05:20.182 INFO ProgressMeter - 6:153064683 36.0 552080 15353.4; 11:05:30.185 INFO ProgressMeter - 6:153910522 36.1 555100 15366.1; 11:05:40.196 INFO ProgressMeter - 6:154615553 36.3 557700 15367.1; 11:05:50.234 INFO ProgressMeter - 6:155257622 36.5 560130 15363.2; 11:06:00.243 INFO ProgressMeter - 6:156087587 36.6 563090 15374.1; 11:06:10.286 INFO ProgressMeter - 6:156810430 36.8 565700 15375.1; free(): invalid size. Second log is the same but the issue at the end is the following one; `munmap_chunk(): invalid pointer`,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7032
https://github.com/broadinstitute/gatk/issues/7034:683,Availability,echo,echo,683,"Would it be possible to expose the [`READ_QUALITY_FILTER_THRESHOLD`](https://github.com/broadinstitute/gatk/blob/9d5727df8db3a475b1ba5f9bff6bc92a322f5633/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java#L729) on the command line for 4.9.0.1? I know on the latest branch we have [`--mapping-quality-threshold`](https://github.com/broadinstitute/gatk/blob/7e3d8a1e0c56206345128e3a6125ecc30427deda/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerArgumentCollection.java#L153). For data and regions where we get low mapping qualities (eg. PacBio), a hard-filter on mapq 20 is onerous. I'd also echo the comment in the latter TODO that the interplay between `----mapping-quality-threshold` (new) and ` --minimum-mapping-quality` (old) is confusing upon first inspection.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7034
https://github.com/broadinstitute/gatk/issues/7034:24,Security,expose,expose,24,"Would it be possible to expose the [`READ_QUALITY_FILTER_THRESHOLD`](https://github.com/broadinstitute/gatk/blob/9d5727df8db3a475b1ba5f9bff6bc92a322f5633/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerEngine.java#L729) on the command line for 4.9.0.1? I know on the latest branch we have [`--mapping-quality-threshold`](https://github.com/broadinstitute/gatk/blob/7e3d8a1e0c56206345128e3a6125ecc30427deda/src/main/java/org/broadinstitute/hellbender/tools/walkers/haplotypecaller/HaplotypeCallerArgumentCollection.java#L153). For data and regions where we get low mapping qualities (eg. PacBio), a hard-filter on mapq 20 is onerous. I'd also echo the comment in the latter TODO that the interplay between `----mapping-quality-threshold` (new) and ` --minimum-mapping-quality` (old) is confusing upon first inspection.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7034
https://github.com/broadinstitute/gatk/issues/7035:67,Availability,error,error,67,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:160,Availability,error,error,160,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:5756,Availability,down,down,5756,"0:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:46619 (size: 35.5 KB, free: 9.2 GB); 21/01/12 15:50:33 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96; 21/01/12 15:50:33 INFO FileInputFormat: Total input files to process : 1; 21/01/12 15:50:33 INFO SparkUI: Stopped Spark web UI at http://fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:4040; 21/01/12 15:50:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/01/12 15:50:33 INFO MemoryStore: MemoryStore cleared; 21/01/12 15:50:33 INFO BlockManager: BlockManager stopped; 21/01/12 15:50:33 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/01/12 15:50:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/01/12 15:50:33 INFO SparkContext: Successfully stopped SparkContext; 15:50:33.855 INFO MarkDuplicatesSpark - Shutting down engine; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:697,Deployability,release,release,697,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:904,Performance,load,load,904,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:297,Safety,unsafe,unsafe,297,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:511,Safety,unsafe,unsafe,511,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:211,Security,access,access,211,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:270,Security,access,access,270,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:551,Security,access,access,551,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:612,Security,access,access,612,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:652,Security,access,access,652,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:1101,Security,Secur,SecurityManager,1101,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:1170,Security,Secur,SecurityManager,1170,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:1241,Security,Secur,SecurityManager,1241,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:1313,Security,Secur,SecurityManager,1313,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:1387,Security,Secur,SecurityManager,1387,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:1404,Security,Secur,SecurityManager,1404,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:1421,Security,authenticat,authentication,1421,eline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up; 21/01/12 15:50:31 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-273b4c87-579e-4d57-81de-aa47a79634bb; 21/01/12 15:50:31 INFO MemoryStore: MemoryStore started with capacity 9.2 GB; 21/01/12 15:50:31 INFO SparkEnv: Registering OutputCommitCoordinator; 21/,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:6749,Security,Hash,HashMap,6749,"e; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$ap",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:6790,Security,Hash,HashMap,6790,:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureC,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:6839,Security,Hash,HashMap,6839,ms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collec,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:6880,Security,Hash,HashMap,6880,licatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.fore,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:6929,Security,Hash,HashTable,6929,totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCl,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:6958,Security,Hash,HashTable,6958,53216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$sp,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:7009,Security,Hash,HashMap,7009,ass file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306),MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:7030,Security,Hash,HashMap,7030, version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306); 	at org.apach,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:7078,Security,Hash,HashMap,7078,lassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306); 	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:16,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:7102,Security,Hash,HashMap,7102,166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:517); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$2.apply(ClosureCleaner.scala:500); 	at scala.collection.TraversableLike$WithFilter$$anonfun$foreach$1.apply(TraversableLike.scala:733); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashMap$$anon$1$$anonfun$foreach$2.apply(HashMap.scala:134); 	at scala.collection.mutable.HashTable$class.foreachEntry(HashTable.scala:236); 	at scala.collection.mutable.HashMap.foreachEntry(HashMap.scala:40); 	at scala.collection.mutable.HashMap$$anon$1.foreach(HashMap.scala:134); 	at scala.collection.TraversableLike$WithFilter.foreach(TraversableLike.scala:732); 	at org.apache.spark.util.FieldAccessFinder$$anon$3.visitMethodInsn(ClosureCleaner.scala:500); 	at org.apache.xbean.asm6.ClassReader.readCode(ClassReader.java:2175); 	at org.apache.xbean.asm6.ClassReader.readMethod(ClassReader.java:1238); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:631); 	at org.apache.xbean.asm6.ClassReader.accept(ClassReader.java:355); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:307); 	at org.apache.spark.util.ClosureCleaner$$anonfun$org$apache$spark$util$ClosureCleaner$$clean$14.apply(ClosureCleaner.scala:306); 	at scala.collection.immutable.List.foreach(List.scala:392); 	at org.apache.spark.util.ClosureCleaner$.org$apache$spark$util$ClosureCleaner$$clean(ClosureCleaner.scala:306); 	at org.apache.spark.util.ClosureCleaner$.clean(ClosureCleaner.scala:162); 	at org.apac,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:166,Testability,log,log,166,"## Bug Report; when I run the MarkDuplicatesSpark, it throws me an error: basically it shows the spark engine stopped when run this function. ; the part of the error log is here:; WARNING: An illegal reflective access operation has occurred; WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/rnaseq_pipeline_app/Apps/GATK/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar) to method java.nio.Bits.unaligned(); WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform; WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations; WARNING: All illegal access operations will be denied in a future release; Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties; 21/01/12 15:50:31 INFO SparkContext: Running Spark version 2.4.5; 21/01/12 15:50:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable; 21/01/12 15:50:31 INFO SparkContext: Submitted application: MarkDuplicatesSpark; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls to: root; 21/01/12 15:50:31 INFO SecurityManager: Changing view acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: Changing modify acls groups to: ; 21/01/12 15:50:31 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); groups with view permissions: Set(); users with modify permissions: Set(root); groups with modify permissions: Set(); 21/01/12 15:50:31 INFO Utils: Successfully started service 'sparkDriver' on port 36657.; 21/01/12 15:50:31 INFO SparkEnv: Registering MapOutputTracker; 21/01/12 15:50:31 INFO SparkEnv: Registering BlockManagerMaster; 21/01/12 15:50:31 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information; 21/01/12 15:50:31 INFO B",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7035:5382,Usability,clear,cleared,5382,"le at PathSplitSource.java:96; 21/01/12 15:50:33 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 172.9 KB, free 9.2 GB); 21/01/12 15:50:33 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 35.5 KB, free 9.2 GB); 21/01/12 15:50:33 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:46619 (size: 35.5 KB, free: 9.2 GB); 21/01/12 15:50:33 INFO SparkContext: Created broadcast 1 from newAPIHadoopFile at PathSplitSource.java:96; 21/01/12 15:50:33 INFO FileInputFormat: Total input files to process : 1; 21/01/12 15:50:33 INFO SparkUI: Stopped Spark web UI at http://fdbd4e9f571c4f8489ec11d570585d56000000.internal.cloudapp.net:4040; 21/01/12 15:50:33 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!; 21/01/12 15:50:33 INFO MemoryStore: MemoryStore cleared; 21/01/12 15:50:33 INFO BlockManager: BlockManager stopped; 21/01/12 15:50:33 INFO BlockManagerMaster: BlockManagerMaster stopped; 21/01/12 15:50:33 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!; 21/01/12 15:50:33 INFO SparkContext: Successfully stopped SparkContext; 15:50:33.855 INFO MarkDuplicatesSpark - Shutting down engine; [January 12, 2021 at 3:50:33 PM EST] org.broadinstitute.hellbender.tools.spark.transforms.markduplicates.MarkDuplicatesSpark done. Elapsed time: 0.06 minutes.; Runtime.totalMemory()=1065353216; java.lang.IllegalArgumentException: Unsupported class file major version 55; 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:166); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:148); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:136); 	at org.apache.xbean.asm6.ClassReader.<init>(ClassReader.java:237); 	at org.apache.spark.util.ClosureCleaner$.getClassReader(ClosureCleaner.scala:49); 	at org.apache.spark.util.FieldAccessFinder$$anon$3$$anonfun$visitMethodInsn$",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7035
https://github.com/broadinstitute/gatk/issues/7037:114,Availability,error,error,114,"## Bug Report; ### Version Information; GenomicsDBImport 4.1.9.0. ### Summary; A user posted on the forum with an error from GenomicsDBImport. @nalinigans @mlathara Can you determine what is causing this java.lang.IndexOutOfBoundsException?. This request was created from a contribution made by vivekruhela on January 12, 2021 19:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport). \--. Dear GATK Team,. I am using GATK version 4.1.9.0 for my WES data pipeline. In order to get accurate somatic call, I am trying to generate the Panel of Normal (PON) using GenomicsDBImport module of GATK. While using GenomicsDBImport for PON generation, I am not getting any output from my command. Here is the command I used to print the stack trace:. ```; gatk GenomicsDBImport \\ ; ; \-R /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.fasta \\ ; ; \--variant normal1.vcf \\ ; ; \--variant normal2.vcf \\ ; ; \--variant normal3.vcf \\ ; ; \--variant normal4.vcf \\ ; ; \--variant normal5.vcf \\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7037:1906,Availability,down,downloaded,1906,"k\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.fasta \\ ; ; \--variant normal1.vcf \\ ; ; \--variant normal2.vcf \\ ; ; \--variant normal3.vcf \\ ; ; \--variant normal4.vcf \\ ; ; \--variant normal5.vcf \\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format using UCSC liftover utility. GenomicsDBImport is not reporting any error related to command but also not reporting any results. Here are the details from GenomicsDBImport log file:. ```; 17:16:16.069 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/akansha/vivekruhela/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 12, 2021 5:16:16 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 17:16:16.329 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 17:16:16.329 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.9.0 ; ; 17:16:16.329 INFO GenomicsDBImport - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 17:16:16.330 INFO",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7037:2066,Availability,error,error,2066,"ant normal3.vcf \\ ; ; \--variant normal4.vcf \\ ; ; \--variant normal5.vcf \\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format using UCSC liftover utility. GenomicsDBImport is not reporting any error related to command but also not reporting any results. Here are the details from GenomicsDBImport log file:. ```; 17:16:16.069 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/akansha/vivekruhela/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 12, 2021 5:16:16 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 17:16:16.329 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 17:16:16.329 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.9.0 ; ; 17:16:16.329 INFO GenomicsDBImport - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 17:16:16.330 INFO GenomicsDBImport - Executing as akansha@sbilab on Linux v4.4.0-169-generic amd64 ; ; 17:16:16.330 INFO GenomicsDBImport - Jav",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7037:5582,Availability,down,down,5582,":16:21.553 INFO GenomicsDBLibLoader - GenomicsDB native library version : 1.3.2-e18fa63 ; ; 17:16:21.554 INFO GenomicsDBImport - Vid Map JSON file will be written to /home/akansha/vivekruhela/pon\_db/vidmap.json ; ; 17:16:21.554 INFO GenomicsDBImport - Callset Map JSON file will be written to /home/akansha/vivekruhela/pon\_db/callset.json ; ; 17:16:21.554 INFO GenomicsDBImport - Complete VCF Header will be written to /home/akansha/vivekruhela/pon\_db/vcfheader.vcf ; ; 17:16:21.554 INFO GenomicsDBImport - Importing to workspace - /home/akansha/vivekruhela/pon\_db ; ; 17:16:21.554 WARN GenomicsDBImport - GenomicsDBImport cannot use multiple VCF reader threads for initialization when the number of intervals is greater than 1. Falling back to serial VCF reader initialization. ; ; 17:16:21.554 INFO ProgressMeter - Starting traversal ; ; 17:16:21.554 INFO ProgressMeter - Current Locus Elapsed Minutes Batches Processed Batches/Minute ; ; 17:16:21.590 INFO GenomicsDBImport - Shutting down engine ; ; \[January 12, 2021 5:16:21 PM IST\] org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport done. Elapsed time: 0.09 minutes. ; ; Runtime.totalMemory()=2761949184 ; ; java.lang.IndexOutOfBoundsException: Index: 0 ; ; at java.util.Collections$EmptyList.get(Collections.java:4456) ; ; at org.genomicsdb.model.GenomicsDBImportConfiguration$ImportConfiguration.getColumnPartitions(GenomicsDBImportConfiguration.java:2083) ; ; at org.genomicsdb.importer.GenomicsDBImporter.<init>(GenomicsDBImporter.java:203) ; ; at org.broadinstitute.hellbender.tools.genomicsdb.GenomicsDBImport.traverse(GenomicsDBImport.java:745) ; ; at org.broadinstitute.hellbender.engine.GATKTool.doWork(GATKTool.java:1049) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.runTool(CommandLineProgram.java:140) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMainPostParseArgs(CommandLineProgram.java:192) ; ; at org.broadinstitute.hellbender.cmdline.CommandLineProgram.instanceMai",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7037:622,Deployability,pipeline,pipeline,622,"## Bug Report; ### Version Information; GenomicsDBImport 4.1.9.0. ### Summary; A user posted on the forum with an error from GenomicsDBImport. @nalinigans @mlathara Can you determine what is causing this java.lang.IndexOutOfBoundsException?. This request was created from a contribution made by vivekruhela on January 12, 2021 19:16 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076396392-No-Output-from-GenomicsDBImport). \--. Dear GATK Team,. I am using GATK version 4.1.9.0 for my WES data pipeline. In order to get accurate somatic call, I am trying to generate the Panel of Normal (PON) using GenomicsDBImport module of GATK. While using GenomicsDBImport for PON generation, I am not getting any output from my command. Here is the command I used to print the stack trace:. ```; gatk GenomicsDBImport \\ ; ; \-R /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.fasta \\ ; ; \--variant normal1.vcf \\ ; ; \--variant normal2.vcf \\ ; ; \--variant normal3.vcf \\ ; ; \--variant normal4.vcf \\ ; ; \--variant normal5.vcf \\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format us",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7037:2226,Performance,Load,Loading,2226,"riant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format using UCSC liftover utility. GenomicsDBImport is not reporting any error related to command but also not reporting any results. Here are the details from GenomicsDBImport log file:. ```; 17:16:16.069 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/akansha/vivekruhela/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 12, 2021 5:16:16 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 17:16:16.329 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 17:16:16.329 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.9.0 ; ; 17:16:16.329 INFO GenomicsDBImport - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 17:16:16.330 INFO GenomicsDBImport - Executing as akansha@sbilab on Linux v4.4.0-169-generic amd64 ; ; 17:16:16.330 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_265-8u265-b01-0ubuntu2~16.04-b01 ; ; 17:16:16.330 INFO GenomicsDBImport - Start Date/Time: January 12, 2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7037:2523,Safety,detect,detect,2523,"vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format using UCSC liftover utility. GenomicsDBImport is not reporting any error related to command but also not reporting any results. Here are the details from GenomicsDBImport log file:. ```; 17:16:16.069 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/akansha/vivekruhela/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 12, 2021 5:16:16 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 17:16:16.329 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 17:16:16.329 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.9.0 ; ; 17:16:16.329 INFO GenomicsDBImport - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 17:16:16.330 INFO GenomicsDBImport - Executing as akansha@sbilab on Linux v4.4.0-169-generic amd64 ; ; 17:16:16.330 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_265-8u265-b01-0ubuntu2~16.04-b01 ; ; 17:16:16.330 INFO GenomicsDBImport - Start Date/Time: January 12, 2021 5:16:16 PM IST ; ; 17:16:16.330 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 17:16:16.330 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 17:16:16.331 INFO GenomicsDBImport - HTSJDK Version: 2.23.0 ; ; 1",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7037:2170,Testability,log,log,2170,"\ ; ; \--variant normal6.vcf \\ ; ; \--variant normal7.vcf \\ ; ; \--variant normal8.vcf \\ ; ; \--variant normal9.vcf \\ ; ; \--variant normal10.vcf \\ ; ; \--variant normal11.vcf \\ ; ; \--variant normal12.vcf \\ ; ; \--variant normal13.vcf \\ ; ; \--variant normal14.vcf \\ ; ; \--variant normal15.vcf \\ ; ; \--variant normal16.vcf \\ ; ; \--variant normal17.vcf \\ ; ; .... ; ; \--variant normal80.vcf \\ ; ; \--genomicsdb-workspace-path pon\_db \\ ; ; \--tmp-dir /tmp1 \\ ; ; \-L /gatk\_bundle/hglft\_genome\_3bc14\_d6f440.bed \\ ; ; \--sequence-dictionary /gatk\_bundle/hg19\_v0\_Homo\_sapiens\_assembly19.dict \\ ; ; \--reader-threads 15 \\ ; ; \--java-options '-DGATK\_STACKTRACE\_ON\_USER\_EXCEPTION=true'; ```. Here For interval list, I have downloaded the hg38 target interval from GATK resource bundle and converted into hg19 format using UCSC liftover utility. GenomicsDBImport is not reporting any error related to command but also not reporting any results. Here are the details from GenomicsDBImport log file:. ```; 17:16:16.069 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/home/akansha/vivekruhela/gatk-4.1.9.0/gatk-package-4.1.9.0-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 12, 2021 5:16:16 PM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 17:16:16.329 INFO GenomicsDBImport - ------------------------------------------------------------ ; ; 17:16:16.329 INFO GenomicsDBImport - The Genome Analysis Toolkit (GATK) v4.1.9.0 ; ; 17:16:16.329 INFO GenomicsDBImport - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 17:16:16.330 INFO GenomicsDBImport - Executing as akansha@sbilab on Linux v4.4.0-169-generic amd64 ; ; 17:16:16.330 INFO GenomicsDBImport - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_265-8u265-b01-0ubuntu2~16.04-b01",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7037
https://github.com/broadinstitute/gatk/issues/7038:1023,Deployability,update,update,1023,"Hello,. There was at least one prior conversation about migrating or not migrating GATK3 CombineVariants to GATK4. My understanding is that there was a decision in GATK not to migrate CombineVariants, and instead push people to use Picard MergeVcfs. As you know, Picard MergeVcfs is somewhat similar; however, it doesnt merge genotypes. That is a pretty big difference in function. . CombineVariants is one of the few GATK3 tools my lab is still using. I'd like to move us off GATK3 in the coming months. Given GATK has already decided not to migrate it, I would first like to propose that we could port and take it over in my lab's DISCVRseq project (https://github.com/bimberlab/discvrseq). I'm happy to give attribution to GATK, etc. I would likely rename it MergeVcfsAndGenotypes (this is more intuitive to me), but I would otherwise not change functionality much. I'd prefer to do this instead of porting to GATK4 because porting to GATK is going to throw up a lot more obstacles and probably require that I modernize/update a good amount of that tool's code. I appreciate why this is required, but it takes a lot more work from us. If you did not like this, I'm open to considering porting to GATK4. In my initial review, it looked like CombineVariants was fairly self-contained and that most of the accessory code (merging genotypes is the most complex thing) was already migrated to GATK4. Some of you may have already done a more thorough review of it. . What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038
https://github.com/broadinstitute/gatk/issues/7038:1306,Security,access,accessory,1306,"Hello,. There was at least one prior conversation about migrating or not migrating GATK3 CombineVariants to GATK4. My understanding is that there was a decision in GATK not to migrate CombineVariants, and instead push people to use Picard MergeVcfs. As you know, Picard MergeVcfs is somewhat similar; however, it doesnt merge genotypes. That is a pretty big difference in function. . CombineVariants is one of the few GATK3 tools my lab is still using. I'd like to move us off GATK3 in the coming months. Given GATK has already decided not to migrate it, I would first like to propose that we could port and take it over in my lab's DISCVRseq project (https://github.com/bimberlab/discvrseq). I'm happy to give attribution to GATK, etc. I would likely rename it MergeVcfsAndGenotypes (this is more intuitive to me), but I would otherwise not change functionality much. I'd prefer to do this instead of porting to GATK4 because porting to GATK is going to throw up a lot more obstacles and probably require that I modernize/update a good amount of that tool's code. I appreciate why this is required, but it takes a lot more work from us. If you did not like this, I'm open to considering porting to GATK4. In my initial review, it looked like CombineVariants was fairly self-contained and that most of the accessory code (merging genotypes is the most complex thing) was already migrated to GATK4. Some of you may have already done a more thorough review of it. . What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038
https://github.com/broadinstitute/gatk/issues/7038:798,Usability,intuit,intuitive,798,"Hello,. There was at least one prior conversation about migrating or not migrating GATK3 CombineVariants to GATK4. My understanding is that there was a decision in GATK not to migrate CombineVariants, and instead push people to use Picard MergeVcfs. As you know, Picard MergeVcfs is somewhat similar; however, it doesnt merge genotypes. That is a pretty big difference in function. . CombineVariants is one of the few GATK3 tools my lab is still using. I'd like to move us off GATK3 in the coming months. Given GATK has already decided not to migrate it, I would first like to propose that we could port and take it over in my lab's DISCVRseq project (https://github.com/bimberlab/discvrseq). I'm happy to give attribution to GATK, etc. I would likely rename it MergeVcfsAndGenotypes (this is more intuitive to me), but I would otherwise not change functionality much. I'd prefer to do this instead of porting to GATK4 because porting to GATK is going to throw up a lot more obstacles and probably require that I modernize/update a good amount of that tool's code. I appreciate why this is required, but it takes a lot more work from us. If you did not like this, I'm open to considering porting to GATK4. In my initial review, it looked like CombineVariants was fairly self-contained and that most of the accessory code (merging genotypes is the most complex thing) was already migrated to GATK4. Some of you may have already done a more thorough review of it. . What do you think?",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7038
https://github.com/broadinstitute/gatk/issues/7040:250,Availability,ERROR,ERROR,250,"Hi, . I was wondering if it's possible to use funcotator to annotate a VCF with structural variants. I'm trying to use funcotator (GATK 4.1.9.0) to annotate a VCF from manta but it fails with the first variant (SVTYPE=DEL):. ```; [...]; 17:07:32.003 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000378191.5 for variant: chr1:4709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTri",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040
https://github.com/broadinstitute/gatk/issues/7040:1365,Availability,down,down,1365,"709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTrivialFieldsPopulated(GencodeFuncotationFactory.java:2214); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createDefaultFuncotationsOnProblemVariant(GencodeFuncotationFactory.java:923); [...]; ```. I've seen that FuncotateSegments works for segment files with CNVs, but I was wondering if there is (or there are plans to add) ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040
https://github.com/broadinstitute/gatk/issues/7040:1056,Performance,cache,cache,1056,"use funcotator to annotate a VCF with structural variants. I'm trying to use funcotator (GATK 4.1.9.0) to annotate a VCF from manta but it fails with the first variant (SVTYPE=DEL):. ```; [...]; 17:07:32.003 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000378191.5 for variant: chr1:4709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTrivialFieldsPopulated(GencodeFuncotationFact",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040
https://github.com/broadinstitute/gatk/issues/7040:1137,Performance,cache,cache,1137,"r (GATK 4.1.9.0) to annotate a VCF from manta but it fails with the first variant (SVTYPE=DEL):. ```; [...]; 17:07:32.003 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000378191.5 for variant: chr1:4709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTrivialFieldsPopulated(GencodeFuncotationFactory.java:2214); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040
https://github.com/broadinstitute/gatk/issues/7040:1219,Performance,cache,cache,1219,"]; 17:07:32.003 ERROR GencodeFuncotationFactory - Problem creating a GencodeFuncotation on transcript ENST00000378191.5 for variant: chr1:4709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTrivialFieldsPopulated(GencodeFuncotationFactory.java:2214); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createDefaultFuncotationsOnProblemVariant(GencodeFuncotationFactory.java:923); ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040
https://github.com/broadinstitute/gatk/issues/7040:1302,Performance,cache,cache,1302,"tion on transcript ENST00000378191.5 for variant: chr1:4709859-185537688(G* -> <DEL>): Variant overlaps transcript but is not completely contained ; within it. Funcotator cannot currently handle this case. Transcript: ENST00000378191.5 Variant: [VC Unknown @ chr1:4709859-185537688 Q. of type=SYMBOLIC alleles=[G*, <DEL>] attr={CIEND=[0, 4], CIPOS=[0, 4], END=185537688, HOML; EN=4, HOMSEQ=TCCT, SOMATIC=true, SOMATICSCORE=141, SVLEN=-180827829, SVTYPE=DEL} GT=PR:SR 68,0:94,0 38,23:94,24 filters=; 17:07:32.003 WARN GencodeFuncotationFactory - Creating default GencodeFuncotation on transcript ENST00000378191.5 for problem variant: chr1:4709859-185537688(G* -> <DEL>); 17:07:32.009 INFO VcfFuncotationFactory - ClinVar_VCF 20180429_hg38 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - dbSNP 9606_b151 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_exome 2.1 cache hits/total: 0/0; 17:07:32.010 INFO VcfFuncotationFactory - gnomAD_genome 2.1 cache hits/total: 0/0; 17:07:32.136 INFO Funcotator - Shutting down engine; [14 January 2021 17:07:32 GMT] org.broadinstitute.hellbender.tools.funcotator.Funcotator done. Elapsed time: 0.77 minutes.; Runtime.totalMemory()=1426182144; java.lang.ArrayIndexOutOfBoundsException: 0; at org.broadinstitute.hellbender.tools.funcotator.FuncotatorUtils.getNonOverlappingAltAlleleBaseString(FuncotatorUtils.java:294); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.getGenomeChangeString(GencodeFuncotationFactory.java:2346); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createGencodeFuncotationBuilderWithTrivialFieldsPopulated(GencodeFuncotationFactory.java:2214); at org.broadinstitute.hellbender.tools.funcotator.dataSources.gencode.GencodeFuncotationFactory.createDefaultFuncotationsOnProblemVariant(GencodeFuncotationFactory.java:923); [...]; ```. I've seen that FuncotateSegments works for segment files with CNVs, but",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7040
https://github.com/broadinstitute/gatk/pull/7041:191,Integrability,inject,inject,191,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:509,Integrability,interface,interfaces,509,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:1170,Integrability,interface,interface,1170,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:1565,Integrability,interface,interface,1565,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:598,Modifiability,extend,extending,598,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:747,Modifiability,extend,extended,747,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:825,Modifiability,extend,extend,825,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:963,Modifiability,extend,extend,963,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:1268,Modifiability,extend,extend,1268,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:1437,Modifiability,extend,extend,1437,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:1474,Modifiability,inherit,inherit,1474,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:151,Security,validat,validation,151,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:191,Security,inject,inject,191,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/pull/7041:1300,Usability,clear,clear,1300,"@jamesemery This is related to #6930 . The background is that PedigreeAnnotation is special-cased in GATK, which provides better command-line argument validation, and it will also be used to inject the PedigreeFile, create the SampleDB, etc. This is currently a subclass of InfoFieldAnnotation, and therefore cant be used for GenotypeFieldAnnotation. There shouldnt be this limitation, and this PR tried to address that. The way I propose to do this is to make InfoFieldAnnotation and GenotypeAnnotation into interfaces, with default methods where possible. The existing subclasses all switch from extending them to implementing them. This is generally a trivial difference, but it touches a lot of classes. . All existing classes that previously extended PedigreeAnnotation (formerly a subclass of InfoFieldAnnotation), now extend PedigreeAnnotation and implement InfoFieldAnnotation. This is a minimal difference, but it makes it possible for future classes to extend PedigreeAnnotation, and then implement GenotypeAnnotation. The only part this includes that I didnt like was the fact that the existing InfoFieldAnnotation overrides toString(), which I cant do in an interface. So I created AbstractInfoFieldAnnotation, and all existing InfoFieldAnnotation classes extend that. It's not currently clear to me how critical that override of toString() is. The weakness of this PR is that classes outside the GATK project that currently extend InfoFieldAnnotation would not inherit this. I could keep InfoFieldAnnotation a class as-is, and make a differently named interface behind it.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7041
https://github.com/broadinstitute/gatk/issues/7042:43,Availability,error,error,43,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:82,Availability,error,error,82,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:113,Availability,ERROR,ERROR,113,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:217,Availability,ERROR,ERROR,217,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:230,Availability,ERROR,ERROR,230,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:287,Availability,ERROR,ERROR,287,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:300,Availability,ERROR,ERROR,300,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:392,Availability,ERROR,ERROR,392,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:402,Availability,error,error,402,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:460,Availability,ERROR,ERROR,460,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:473,Availability,ERROR,ERROR,473,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:569,Availability,ERROR,ERROR,569,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:674,Availability,ERROR,ERROR,674,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:687,Availability,ERROR,ERROR,687,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:772,Availability,ERROR,ERROR,772,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:851,Availability,ERROR,ERROR,851,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:864,Availability,ERROR,ERROR,864,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:894,Availability,error,error,894,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:974,Availability,ERROR,ERROR,974,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:987,Availability,ERROR,ERROR,987,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:1143,Availability,ERROR,ERROR,1143,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:408,Integrability,message,message,408,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:995,Integrability,MESSAGE,MESSAGE,995,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/issues/7042:556,Usability,guid,guide,556,"I want to filter SNP, but encountered this error. Can anyone help me resolve this error. thanks .; zhang. `##### ERROR ------------------------------------------------------------------------------------------; ##### ERROR A USER ERROR has occurred (version 3.8-1-0-gf15c1c3ef): ; ##### ERROR; ##### ERROR This means that one or more arguments or inputs in your command are incorrect.; ##### ERROR The error message below tells you what is the problem.; ##### ERROR; ##### ERROR If the problem is an invalid argument, please check the online documentation guide; ##### ERROR (or rerun your command with --help) to view allowable command-line arguments for this tool.; ##### ERROR; ##### ERROR Visit our website and forum for extensive documentation and answers to ; ##### ERROR commonly asked questions https://software.broadinstitute.org/gatk; ##### ERROR; ##### ERROR Please do NOT post this error to the GATK forum unless you have really tried to fix it yourself.; ##### ERROR; ##### ERROR **MESSAGE: Bad input: The clustered SNPs filter does not work in the presence of non-variant records; see the** documentation for more details; ##### ERROR ------------------------------------------------------------------------------------------; `",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7042
https://github.com/broadinstitute/gatk/pull/7045:20,Modifiability,refactor,refactor,20,This is a suggested refactor of PrintSVEvidence to use a single output stream and parameterize the type of evidence.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7045
https://github.com/broadinstitute/gatk/pull/7045:82,Modifiability,parameteriz,parameterize,82,This is a suggested refactor of PrintSVEvidence to use a single output stream and parameterize the type of evidence.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7045
https://github.com/broadinstitute/gatk/pull/7046:995,Availability,Down,Downstream,995,"Fixes a bug that I inadvertently introduced long ago in #5408. A method there originally assumed that the intervals to be filtered coincide with the annotated intervals when filtering on annotations, but this assumption can be violated when e.g. using `-XL` to further exclude intervals. This breaks the annotation-based filtering and will result in incorrectly retained/dropped intervals. Unfortunately, the integration test cases were not quite complete enough to catch this. Fortunately, for typical data and parameters, the number of affected intervals is typically a very small percentage, especially in human (e.g., the default GC filters of [0.1, 0.9] affect <0.1% of 250bp bins); I only caught this when running on malaria data, since GC filtering has more impact there. I would also expect count-based filters to mitigate some of the effects (e.g., a bin with extreme GC that was erroneously retained when filtering on annotations might later be filtered because it has poor coverage). Downstream results are also all correct---they're just given for a slightly different set of intervals than would be expected. This bug would affect users that made use of the `blacklist_intervals_for_filter_intervals` option in the gCNV WDLs, but my feeling is this functionality is not used that frequently. @droazen I think this is a relatively minor bug, but it might be good to mention it in the release notes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046
https://github.com/broadinstitute/gatk/pull/7046:409,Deployability,integrat,integration,409,"Fixes a bug that I inadvertently introduced long ago in #5408. A method there originally assumed that the intervals to be filtered coincide with the annotated intervals when filtering on annotations, but this assumption can be violated when e.g. using `-XL` to further exclude intervals. This breaks the annotation-based filtering and will result in incorrectly retained/dropped intervals. Unfortunately, the integration test cases were not quite complete enough to catch this. Fortunately, for typical data and parameters, the number of affected intervals is typically a very small percentage, especially in human (e.g., the default GC filters of [0.1, 0.9] affect <0.1% of 250bp bins); I only caught this when running on malaria data, since GC filtering has more impact there. I would also expect count-based filters to mitigate some of the effects (e.g., a bin with extreme GC that was erroneously retained when filtering on annotations might later be filtered because it has poor coverage). Downstream results are also all correct---they're just given for a slightly different set of intervals than would be expected. This bug would affect users that made use of the `blacklist_intervals_for_filter_intervals` option in the gCNV WDLs, but my feeling is this functionality is not used that frequently. @droazen I think this is a relatively minor bug, but it might be good to mention it in the release notes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046
https://github.com/broadinstitute/gatk/pull/7046:1396,Deployability,release,release,1396,"Fixes a bug that I inadvertently introduced long ago in #5408. A method there originally assumed that the intervals to be filtered coincide with the annotated intervals when filtering on annotations, but this assumption can be violated when e.g. using `-XL` to further exclude intervals. This breaks the annotation-based filtering and will result in incorrectly retained/dropped intervals. Unfortunately, the integration test cases were not quite complete enough to catch this. Fortunately, for typical data and parameters, the number of affected intervals is typically a very small percentage, especially in human (e.g., the default GC filters of [0.1, 0.9] affect <0.1% of 250bp bins); I only caught this when running on malaria data, since GC filtering has more impact there. I would also expect count-based filters to mitigate some of the effects (e.g., a bin with extreme GC that was erroneously retained when filtering on annotations might later be filtered because it has poor coverage). Downstream results are also all correct---they're just given for a slightly different set of intervals than would be expected. This bug would affect users that made use of the `blacklist_intervals_for_filter_intervals` option in the gCNV WDLs, but my feeling is this functionality is not used that frequently. @droazen I think this is a relatively minor bug, but it might be good to mention it in the release notes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046
https://github.com/broadinstitute/gatk/pull/7046:409,Integrability,integrat,integration,409,"Fixes a bug that I inadvertently introduced long ago in #5408. A method there originally assumed that the intervals to be filtered coincide with the annotated intervals when filtering on annotations, but this assumption can be violated when e.g. using `-XL` to further exclude intervals. This breaks the annotation-based filtering and will result in incorrectly retained/dropped intervals. Unfortunately, the integration test cases were not quite complete enough to catch this. Fortunately, for typical data and parameters, the number of affected intervals is typically a very small percentage, especially in human (e.g., the default GC filters of [0.1, 0.9] affect <0.1% of 250bp bins); I only caught this when running on malaria data, since GC filtering has more impact there. I would also expect count-based filters to mitigate some of the effects (e.g., a bin with extreme GC that was erroneously retained when filtering on annotations might later be filtered because it has poor coverage). Downstream results are also all correct---they're just given for a slightly different set of intervals than would be expected. This bug would affect users that made use of the `blacklist_intervals_for_filter_intervals` option in the gCNV WDLs, but my feeling is this functionality is not used that frequently. @droazen I think this is a relatively minor bug, but it might be good to mention it in the release notes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046
https://github.com/broadinstitute/gatk/pull/7046:421,Testability,test,test,421,"Fixes a bug that I inadvertently introduced long ago in #5408. A method there originally assumed that the intervals to be filtered coincide with the annotated intervals when filtering on annotations, but this assumption can be violated when e.g. using `-XL` to further exclude intervals. This breaks the annotation-based filtering and will result in incorrectly retained/dropped intervals. Unfortunately, the integration test cases were not quite complete enough to catch this. Fortunately, for typical data and parameters, the number of affected intervals is typically a very small percentage, especially in human (e.g., the default GC filters of [0.1, 0.9] affect <0.1% of 250bp bins); I only caught this when running on malaria data, since GC filtering has more impact there. I would also expect count-based filters to mitigate some of the effects (e.g., a bin with extreme GC that was erroneously retained when filtering on annotations might later be filtered because it has poor coverage). Downstream results are also all correct---they're just given for a slightly different set of intervals than would be expected. This bug would affect users that made use of the `blacklist_intervals_for_filter_intervals` option in the gCNV WDLs, but my feeling is this functionality is not used that frequently. @droazen I think this is a relatively minor bug, but it might be good to mention it in the release notes.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7046
https://github.com/broadinstitute/gatk/issues/7047:0,Integrability,Depend,Depends,0,Depends on https://github.com/broadinstitute/cromwell/pull/6151,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7047
https://github.com/broadinstitute/gatk/pull/7050:27,Availability,error,error,27,I was getting a SQL syntax error before making this change.,MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7050
https://github.com/broadinstitute/gatk/issues/7051:8,Deployability,release,release,8,"The 1.7 release of the data sources has a lifted over hg19 version of Gencode. In this version contrary to other releases, the individual elements of each transcript seem to be represented in numerical order, rather than the order in which they appear in the transcript at transcription time. For `+` strand transcripts, this doesn't matter, but for `-` strand transcripts, the ordering of the exons/CDS regions in the gencode gtf file is reversed to what is expected. The result is that the coding sequence, protein prediction, and other annotations are incorrect. One user has already run into this issue: https://gatk.broadinstitute.org/hc/en-us/community/posts/360076207992--Repost-Wrong-annotation-with-Funcotator-1-7. One of two fixes is required:. 1. Update the code to always sort the transcript elements by how they appear in the transcribed sequence; 2. When generating the Gencode data, always sort the transcript elements by their transcribed order. We should do both and later roll back the sorting to optimize for speed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7051
https://github.com/broadinstitute/gatk/issues/7051:113,Deployability,release,releases,113,"The 1.7 release of the data sources has a lifted over hg19 version of Gencode. In this version contrary to other releases, the individual elements of each transcript seem to be represented in numerical order, rather than the order in which they appear in the transcript at transcription time. For `+` strand transcripts, this doesn't matter, but for `-` strand transcripts, the ordering of the exons/CDS regions in the gencode gtf file is reversed to what is expected. The result is that the coding sequence, protein prediction, and other annotations are incorrect. One user has already run into this issue: https://gatk.broadinstitute.org/hc/en-us/community/posts/360076207992--Repost-Wrong-annotation-with-Funcotator-1-7. One of two fixes is required:. 1. Update the code to always sort the transcript elements by how they appear in the transcribed sequence; 2. When generating the Gencode data, always sort the transcript elements by their transcribed order. We should do both and later roll back the sorting to optimize for speed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7051
https://github.com/broadinstitute/gatk/issues/7051:758,Deployability,Update,Update,758,"The 1.7 release of the data sources has a lifted over hg19 version of Gencode. In this version contrary to other releases, the individual elements of each transcript seem to be represented in numerical order, rather than the order in which they appear in the transcript at transcription time. For `+` strand transcripts, this doesn't matter, but for `-` strand transcripts, the ordering of the exons/CDS regions in the gencode gtf file is reversed to what is expected. The result is that the coding sequence, protein prediction, and other annotations are incorrect. One user has already run into this issue: https://gatk.broadinstitute.org/hc/en-us/community/posts/360076207992--Repost-Wrong-annotation-with-Funcotator-1-7. One of two fixes is required:. 1. Update the code to always sort the transcript elements by how they appear in the transcribed sequence; 2. When generating the Gencode data, always sort the transcript elements by their transcribed order. We should do both and later roll back the sorting to optimize for speed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7051
https://github.com/broadinstitute/gatk/issues/7051:1015,Performance,optimiz,optimize,1015,"The 1.7 release of the data sources has a lifted over hg19 version of Gencode. In this version contrary to other releases, the individual elements of each transcript seem to be represented in numerical order, rather than the order in which they appear in the transcript at transcription time. For `+` strand transcripts, this doesn't matter, but for `-` strand transcripts, the ordering of the exons/CDS regions in the gencode gtf file is reversed to what is expected. The result is that the coding sequence, protein prediction, and other annotations are incorrect. One user has already run into this issue: https://gatk.broadinstitute.org/hc/en-us/community/posts/360076207992--Repost-Wrong-annotation-with-Funcotator-1-7. One of two fixes is required:. 1. Update the code to always sort the transcript elements by how they appear in the transcribed sequence; 2. When generating the Gencode data, always sort the transcript elements by their transcribed order. We should do both and later roll back the sorting to optimize for speed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7051
https://github.com/broadinstitute/gatk/issues/7051:517,Safety,predict,prediction,517,"The 1.7 release of the data sources has a lifted over hg19 version of Gencode. In this version contrary to other releases, the individual elements of each transcript seem to be represented in numerical order, rather than the order in which they appear in the transcript at transcription time. For `+` strand transcripts, this doesn't matter, but for `-` strand transcripts, the ordering of the exons/CDS regions in the gencode gtf file is reversed to what is expected. The result is that the coding sequence, protein prediction, and other annotations are incorrect. One user has already run into this issue: https://gatk.broadinstitute.org/hc/en-us/community/posts/360076207992--Repost-Wrong-annotation-with-Funcotator-1-7. One of two fixes is required:. 1. Update the code to always sort the transcript elements by how they appear in the transcribed sequence; 2. When generating the Gencode data, always sort the transcript elements by their transcribed order. We should do both and later roll back the sorting to optimize for speed.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7051
https://github.com/broadinstitute/gatk/issues/7054:251,Availability,error,errors,251,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/issues/7054:516,Availability,Error,Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file,516,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/issues/7054:645,Availability,Error,Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file,645,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/issues/7054:710,Availability,Error,Error,710,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/issues/7054:3604,Availability,down,down,3604,"NC\_IO\_READ\_FOR\_SAMTOOLS : false ; ; 04:33:13.196 INFO IndexFeatureFile - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_SAMTOOLS : true ; ; 04:33:13.196 INFO IndexFeatureFile - HTSJDK Defaults.USE\_ASYNC\_IO\_WRITE\_FOR\_TRIBBLE : false ; ; 04:33:13.196 INFO IndexFeatureFile - Deflater: IntelDeflater ; ; 04:33:13.196 INFO IndexFeatureFile - Inflater: IntelInflater ; ; 04:33:13.196 INFO IndexFeatureFile - GCS max retries/reopens: 20 ; ; 04:33:13.196 INFO IndexFeatureFile - Requester pays: disabled ; ; 04:33:13.196 INFO IndexFeatureFile - Initializing engine ; ; 04:33:13.196 INFO IndexFeatureFile - Done initializing engine ; ; 04:33:13.396 INFO FeatureManager - Using codec EnsemblGtfCodec to read file file:///gatk/funcotator-scripts/gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.400 INFO ProgressMeter - Starting traversal ; ; 04:33:13.400 INFO ProgressMeter - Current Locus Elapsed Minutes Records Processed Records/Minute ; ; 04:33:21.040 INFO IndexFeatureFile - Shutting down engine ; ; \[January 25, 2021 4:33:21 AM GMT\] org.broadinstitute.hellbender.tools.IndexFeatureFile done. Elapsed time: 0.13 minutes. ; ; Runtime.totalMemory()=1835532288 ; ; java.lang.IllegalArgumentException: Unexpected value: IG\_D\_pseudogene ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$GeneTranscriptType.getEnum(GencodeGtfFeature.java:1060) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.<init>(GencodeGtfFeature.java:158) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.<init>(GencodeGtfGeneFeature.java:19) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfGeneFeature.create(GencodeGtfGeneFeature.java:23) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature$FeatureType$1.create(GencodeGtfFeature.java:760) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.GencodeGtfFeature.create(GencodeGtfFeature.java:327) ; ; at org.broadinstitute.hellbender.utils.codecs.gtf.AbstractGtfCo",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/issues/7054:1133,Performance,Load,Loading,1133," is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_242-8u242-b08-0ubuntu3~18.04-b08 ; ; 04:33:13.195 INFO IndexFeatureFile - Start Date/Time: January 25, 2021 4:33:13 AM ",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/issues/7054:1406,Safety,detect,detect,1406,"by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server VM v1.8.0\_242-8u242-b08-0ubuntu3~18.04-b08 ; ; 04:33:13.195 INFO IndexFeatureFile - Start Date/Time: January 25, 2021 4:33:13 AM GMT ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.196 INFO IndexFeatureFile - HTSJDK Version: 2.2",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/issues/7054:716,Testability,Log,Log,716,"## Description; A user wants to run Funcotator with a mouse sample but has an issue running IndexFeatureFile. The GencodeGTF parser is specific to human data. Funcotator could be useful for users with non-human data if there is a workaround for these errors. ### GATK Information; GATK 4.1.9.0; gatk IndexFeatureFile -I gencode.vM25.annotation.gtf; This request was created from a contribution made by T. Li on January 25, 2021 04:37 UTC. Link: [https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-](https://gatk.broadinstitute.org/hc/en-us/community/posts/360076815852-Error-Running-IndexFeatureFile-on-Ensembl-Mouse-GTF-file-). #### Error Log. ```; Using GATK jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar ; ; Running: ; ; java -Dsamjdk.use\_async\_io\_read\_samtools=false -Dsamjdk.use\_async\_io\_write\_samtools=true -Dsamjdk.use\_async\_io\_write\_tribble=false -Dsamjdk.compression\_level=2 -jar /gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar IndexFeatureFile -I gencode/mm10/gencode.vM25.annotation.gtf ; ; 04:33:13.081 INFO NativeLibraryLoader - Loading libgkl\_compression.so from jar:file:/gatk/gatk-package-4.1.9.0-SNAPSHOT-local.jar!/com/intel/gkl/native/libgkl\_compression.so ; ; Jan 25, 2021 4:33:13 AM shaded.cloud\_nio.com.google.auth.oauth2.ComputeEngineCredentials runningOnComputeEngine ; ; INFO: Failed to detect whether we are running on Google Compute Engine. ; ; 04:33:13.195 INFO IndexFeatureFile - ------------------------------------------------------------ ; ; 04:33:13.195 INFO IndexFeatureFile - The Genome Analysis Toolkit (GATK) v4.1.9.0-SNAPSHOT ; ; 04:33:13.195 INFO IndexFeatureFile - For support and documentation go to [https://software.broadinstitute.org/gatk/](https://software.broadinstitute.org/gatk/) ; ; 04:33:13.195 INFO IndexFeatureFile - Executing as root@b4c480938d0d on Linux v5.4.0-1029-aws amd64 ; ; 04:33:13.195 INFO IndexFeatureFile - Java runtime: OpenJDK 64-Bit Server",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/issues/7054
https://github.com/broadinstitute/gatk/pull/7056:423,Availability,down,down,423,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056
https://github.com/broadinstitute/gatk/pull/7056:705,Integrability,wrap,wrapping,705,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056
https://github.com/broadinstitute/gatk/pull/7056:611,Modifiability,refactor,refactor,611,"- I sneaked in another change where I pass in a single file containing a list of input_vcfs instead of an array of input_vcfs. I made this because Terra couldn't save my inputs when I passed in 700 samples.; - Most of the logic was moved into `CreateTables`, including the determination for what files to load. It would have been cleaner to move all of the file loading logic into `LoadTable` but the current approach cuts down the on the number of `gsutil ls` calls made and more importantly, only spins up a shard if there are files to load.; - I pushed the logic into a separate workflow because I wanted to refactor it as two tasks and I couldn't find a way to get a Task to call another Task without wrapping it in a workflow.",MatchSource.ISSUE,broadinstitute,gatk,4.6.0.0,https://software.broadinstitute.org/gatk,https://github.com/broadinstitute/gatk/pull/7056
