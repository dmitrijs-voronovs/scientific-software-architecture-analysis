id,quality_attribute,keyword,matched_word,match_idx,sentence,source,filename,author,repo,version,wiki,url
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:212,Modifiability,config,configured,212,"# The CI Service. ## Documentation Scope. This documentation is trying to achieve two goals:. - How the CI service is structured and operates as a general purpose, customizable component; - How the CI service is configured and deployed by the Hail team:; - From the `hail-is/hail:main` branch of the hail repository; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be ma",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:512,Modifiability,config,configured,512,"# The CI Service. ## Documentation Scope. This documentation is trying to achieve two goals:. - How the CI service is structured and operates as a general purpose, customizable component; - How the CI service is configured and deployed by the Hail team:; - From the `hail-is/hail:main` branch of the hail repository; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be ma",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:614,Modifiability,config,configuration,614,"# The CI Service. ## Documentation Scope. This documentation is trying to achieve two goals:. - How the CI service is structured and operates as a general purpose, customizable component; - How the CI service is configured and deployed by the Hail team:; - From the `hail-is/hail:main` branch of the hail repository; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be ma",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:724,Modifiability,config,configuration,724,"# The CI Service. ## Documentation Scope. This documentation is trying to achieve two goals:. - How the CI service is structured and operates as a general purpose, customizable component; - How the CI service is configured and deployed by the Hail team:; - From the `hail-is/hail:main` branch of the hail repository; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be ma",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:1271,Modifiability,config,configured,1271,"sitory; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be marked as stale using appropriate flags:; - The state of github branches, commits, and PRs (""`github_changed`""); - The state of batches CI is running to run tests or deploy to production (""`batch_changed`""); - Whether CI needs to act externally, to update Github or start new batches (""`state_changed`""). ### C",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:1597,Modifiability,config,configured,1597,"annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be marked as stale using appropriate flags:; - The state of github branches, commits, and PRs (""`github_changed`""); - The state of batches CI is running to run tests or deploy to production (""`batch_changed`""); - Whether CI needs to act externally, to update Github or start new batches (""`state_changed`""). ### CI Update Loop. The core CI update loop iterates over its set of ""watched branches"". If any of the state flags for any of the watched; branches are marked as dirty, then the CI service will re-evaluate the state of the watched branch and potentially take; action to u",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:2957,Modifiability,config,configurable,2957,"ags:; - The state of github branches, commits, and PRs (""`github_changed`""); - The state of batches CI is running to run tests or deploy to production (""`batch_changed`""); - Whether CI needs to act externally, to update Github or start new batches (""`state_changed`""). ### CI Update Loop. The core CI update loop iterates over its set of ""watched branches"". If any of the state flags for any of the watched; branches are marked as dirty, then the CI service will re-evaluate the state of the watched branch and potentially take; action to update either its own internal state or the state of github or the deployed system. A set of detailed flowcharts detailing the CI update loop is given in the [references](#references) section below, which; can be cross-referenced against the purposes and outcomes of the CI service as described in the following text sections. #### Detecting Stale State. ##### Regular Polling. At a configurable frequency, the CI service will mark **_all_** flags for **_all_** watched branches as dirty, which; will trigger a re-evaluation of the system state. ##### Github Webhooks. To make CI more responsive it also has endpoints to receive webhook event triggers from the github repository. This endpoint; is part of the CI API, listening on `/github_callback`. Depending on the type of webhook received, and the branch or PR which it is targeting, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched b",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:3613,Modifiability,config,configured,3613,"system. A set of detailed flowcharts detailing the CI update loop is given in the [references](#references) section below, which; can be cross-referenced against the purposes and outcomes of the CI service as described in the following text sections. #### Detecting Stale State. ##### Regular Polling. At a configurable frequency, the CI service will mark **_all_** flags for **_all_** watched branches as dirty, which; will trigger a re-evaluation of the system state. ##### Github Webhooks. To make CI more responsive it also has endpoints to receive webhook event triggers from the github repository. This endpoint; is part of the CI API, listening on `/github_callback`. Depending on the type of webhook received, and the branch or PR which it is targeting, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no fur",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:3852,Modifiability,config,configured,3852,"the following text sections. #### Detecting Stale State. ##### Regular Polling. At a configurable frequency, the CI service will mark **_all_** flags for **_all_** watched branches as dirty, which; will trigger a re-evaluation of the system state. ##### Github Webhooks. To make CI more responsive it also has endpoints to receive webhook event triggers from the github repository. This endpoint; is part of the CI API, listening on `/github_callback`. Depending on the type of webhook received, and the branch or PR which it is targeting, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:7157,Performance,load,load,7157," many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:10758,Performance,load,load,10758,"eploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>PB: Redeploy batch service; PVM->>CI: Redeploy CI service; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>PB: Submit test batches; PB->>PVM: Submit test batch jobs; activate PVM; PVM-->>PB: Validate results; deactivate PVM; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; ```. ## References. ### The update loop. The following reference diagrams show the action",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:8981,Safety,detect,detect,8981,"it test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required checks must be successful; - There must have been a CI-generated test batch; - The most recent test batch must have run against the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ; - CI will attempt to merge all PRs which are mergeable, in priority order; - Note: as soon as one PR merges, the remaining branches will no longer be mergeable because the target SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test case, the CI service uses targets in `build.yaml` to generate a set of jobs in a; batch run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are al",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:693,Security,validat,validated,693,"# The CI Service. ## Documentation Scope. This documentation is trying to achieve two goals:. - How the CI service is structured and operates as a general purpose, customizable component; - How the CI service is configured and deployed by the Hail team:; - From the `hail-is/hail:main` branch of the hail repository; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be ma",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:1290,Security,access,access,1290,"sitory; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be marked as stale using appropriate flags:; - The state of github branches, commits, and PRs (""`github_changed`""); - The state of batches CI is running to run tests or deploy to production (""`batch_changed`""); - Whether CI needs to act externally, to update Github or start new batches (""`state_changed`""). ### C",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:860,Testability,test,tests,860,"# The CI Service. ## Documentation Scope. This documentation is trying to achieve two goals:. - How the CI service is structured and operates as a general purpose, customizable component; - How the CI service is configured and deployed by the Hail team:; - From the `hail-is/hail:main` branch of the hail repository; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be ma",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:1656,Testability,test,tests,1656,"ration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be marked as stale using appropriate flags:; - The state of github branches, commits, and PRs (""`github_changed`""); - The state of batches CI is running to run tests or deploy to production (""`batch_changed`""); - Whether CI needs to act externally, to update Github or start new batches (""`state_changed`""). ### CI Update Loop. The core CI update loop iterates over its set of ""watched branches"". If any of the state flags for any of the watched; branches are marked as dirty, then the CI service will re-evaluate the state of the watched branch and potentially take; action to update either its own internal state or the state of github or the deployed system. A set of detailed flowcharts detailing the CI update loop is given in the",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:2156,Testability,test,tests,2156,"f is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be marked as stale using appropriate flags:; - The state of github branches, commits, and PRs (""`github_changed`""); - The state of batches CI is running to run tests or deploy to production (""`batch_changed`""); - Whether CI needs to act externally, to update Github or start new batches (""`state_changed`""). ### CI Update Loop. The core CI update loop iterates over its set of ""watched branches"". If any of the state flags for any of the watched; branches are marked as dirty, then the CI service will re-evaluate the state of the watched branch and potentially take; action to update either its own internal state or the state of github or the deployed system. A set of detailed flowcharts detailing the CI update loop is given in the [references](#references) section below, which; can be cross-referenced against the purposes and outcomes of the CI service as described in the following text sections. #### Detecting Stale State. ##### Regular Polling. At a configurable frequency, the CI service will mark **_all_** flags for **_all_** watched branches as dirty, which; will trigger a re-evaluation of the system state",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:3971,Testability,test,tests,3971,", the CI service will mark **_all_** flags for **_all_** watched branches as dirty, which; will trigger a re-evaluation of the system state. ##### Github Webhooks. To make CI more responsive it also has endpoints to receive webhook event triggers from the github repository. This endpoint; is part of the CI API, listening on `/github_callback`. Depending on the type of webhook received, and the branch or PR which it is targeting, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has alread",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:4183,Testability,test,tests,4183,"as endpoints to receive webhook event triggers from the github repository. This endpoint; is part of the CI API, listening on `/github_callback`. Depending on the type of webhook received, and the branch or PR which it is targeting, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch t",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:4363,Testability,test,tested,4363," of webhook received, and the branch or PR which it is targeting, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:4438,Testability,test,tested,4438,"ing, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pend",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:4622,Testability,test,tests,4622,"or `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pending Check against the PR in question; - CI will generate a new batch and submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:4762,Testability,test,tests,4762,"or `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pending Check against the PR in question; - CI will generate a new batch and submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:4795,Testability,test,tests,4795,"or `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pending Check against the PR in question; - CI will generate a new batch and submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:4985,Testability,test,tests,4985," Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against all PRs targetting a watched branch:. - Authorization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pending Check against the PR in question; - CI will generate a new batch and submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs which will:; - Clone the appropriate branch; - Squash and rebase onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:5178,Testability,test,tests,5178,"orization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pending Check against the PR in question; - CI will generate a new batch and submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs which will:; - Clone the appropriate branch; - Squash and rebase onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:5311,Testability,test,test,5311,"orization; - If the author is in the [`ci/ci/constants`](../../../ci/ci/constants.py) list of known developers, it can be tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pending Check against the PR in question; - CI will generate a new batch and submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs which will:; - Clone the appropriate branch; - Squash and rebase onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:5367,Testability,test,tests,5367,"tested.; - If the github SHA for the commit has been registered, it can be tested.; - Otherwise, it will be ignored.; - Check for validity; - The PR must be against a watched branch, or else it wouldn't be considered.; - If the current commit has already had tests run against it, no further action is taken `*`; - If the PR is marked with the ""do_not_test"" label, no further action is taken; - Run tests; - The CI service will run tests against the PR (see below) ; - Report results back to Github using the Checks interface. `*` Note: there is an important nuance to the statement ""If the current commit has already had tests run against it, no further action is taken"". - Every time CI loops through its update cycle, it will determine a ""merge candidate"" from all of the PRs which are approved.; - If the batch tests for the merge candidate PR were run against a different SHA than the current SHA of the watched branch,; then CI trigger a new test batch. . ### Running Tests. The process of running tests goes like:. - CI will create a pending Check against the PR in question; - CI will generate a new batch and submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs which will:; - Clone the appropriate branch; - Squash and rebase onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests agai",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:6354,Testability,test,tests,6354,"d submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs which will:; - Clone the appropriate branch; - Squash and rebase onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:6389,Testability,test,test,6389,"d submit it against the production Hail Batch service using its own service credentials; - Tasks in the batch are defined in `build.yaml` in the top repo directory. CI generates jobs in the batch from the steps defined in there.; - The batch contains jobs which will:; - Clone the appropriate branch; - Squash and rebase onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:6744,Testability,test,test,6744," onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:6808,Testability,log,log,6808," onto `main`; - This is done in a way that means the resulting SHA will match the SHA which would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:6889,Testability,test,test,6889,"h would be produced when the PR merges.; - Build new versions of all hail tools, packages and libraries; - Build a new set of docker images for hail query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:7076,Testability,log,logs,7076,"il query and the updated services; - Deploy the batch suite of k8s services into one of many CI-owned namespaces in the Hail Batch cluster; - These namespaces are named like `""pr-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:7219,Testability,test,testing,7219,"-<PR_NUMBER>-<CI-NAMESPACE>-<RANDOM>""`; - Where `CI-NAMESPACE` is the namespace where CI is running (usually `default`). ; - Run a series of tests against the services; - Each test:; - Submits a specially crafted batch to the newly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:7516,Testability,test,test-xyz,7516,"wly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required check",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:7568,Testability,test,test-xyz,7568,"wly deployed batch namespace; - Checks that the results of running the batch are what we would expect; - The CI service polls the batch which it submits for overall success or failure.; - Once the batch has either succeeded or failed, CI uses that result to report status back to GitHub. Examples of CI test runs can be seen by searching through the production batch log, as long as you are a member; of the `ci` billing project. . > [!NOTE]; > CI test runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Atest+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required check",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:7751,Testability,test,test,7751,"mber of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required checks must be successful; - There must have been a CI-generated test batch; - The most recent test batch must have run against the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:7993,Testability,test,test,7993,"mber of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required checks must be successful; - There must have been a CI-generated test batch; - The most recent test batch must have run against the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:8036,Testability,test,test,8036,"mber of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required checks must be successful; - There must have been a CI-generated test batch; - The most recent test batch must have run against the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:8069,Testability,test,test,8069,"mber of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Testing Timeline. The image below shows the CI testing timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end; box Kubernetes (CI: 'test-xyz' namespaces); participant CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required checks must be successful; - There must have been a CI-generated test batch; - The most recent test batch must have run against the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:8501,Testability,test,test,8501,"t CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required checks must be successful; - There must have been a CI-generated test batch; - The most recent test batch must have run against the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ; - CI will attempt to merge all PRs which are mergeable, in priority order; - Note: as soon as one PR merges, the remaining branches will no longer be mergeable because the target SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test ca",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:8531,Testability,test,test,8531,"t CIB as CI Batch (test-xyz namespaces); end; box GCE (CI VMs); participant CIVM as CI VMs; end. Github->>CI: Notify PR created/updated. CI->>Github: Register github check (pending); CI->>PB: Submit CI test batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>CIB: Deploy batch service; activate CIB; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>CIB: Submit test batches; CIB->>CIVM: Submit test batch jobs; activate CIVM; CIVM-->>CIB: Validate results; deactivate CIVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit cleanup jobs; activate PVM; PVM->>CIB: Clean up service; deactivate CIB; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; CI->>Github: Update github check; ```. ## Merging PRs. Mergability is determined by:. - All required checks must be successful; - There must have been a CI-generated test batch; - The most recent test batch must have run against the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ; - CI will attempt to merge all PRs which are mergeable, in priority order; - Note: as soon as one PR merges, the remaining branches will no longer be mergeable because the target SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test ca",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:9543,Testability,test,test,9543,"st the current SHA of the watched branch ; - The PR must be approved; - The PR must not have the ""DO_NOT_MERGE"" label. The control flow from final approval to CI merging a PRs looks like:. - The PR's state will change in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ; - CI will attempt to merge all PRs which are mergeable, in priority order; - Note: as soon as one PR merges, the remaining branches will no longer be mergeable because the target SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test case, the CI service uses targets in `build.yaml` to generate a set of jobs in a; batch run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=u",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:9797,Testability,test,tests,9797,"e in github (maybe a check changes to SUCCESS, or a review is approved); - The github webhook callback will cause the `github_changed` flag to be marked as dirty for the target `WatchedBranch`; - CI will detect that this PR is now considered mergeable ; - CI will attempt to merge all PRs which are mergeable, in priority order; - Note: as soon as one PR merges, the remaining branches will no longer be mergeable because the target SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test case, the CI service uses targets in `build.yaml` to generate a set of jobs in a; batch run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deplo",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:10158,Testability,test,test-ing,10158,"t SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test case, the CI service uses targets in `build.yaml` to generate a set of jobs in a; batch run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit buil",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:10204,Testability,test,test,10204,"t SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test case, the CI service uses targets in `build.yaml` to generate a set of jobs in a; batch run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit buil",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:10273,Testability,test,test,10273,"t SHA will have changed. ## Deploying services to the live infrastructure. When a PR is merged into the `main` branch, a webhook will trigger. The CI service will set its `github_changed` flag. During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test case, the CI service uses targets in `build.yaml` to generate a set of jobs in a; batch run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit buil",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:10417,Testability,test,tests,10417," During its update loop, the CI service will determine that the SHA of the `WatchedBranch` has changed and trigger; a deployment. Like in the test case, the CI service uses targets in `build.yaml` to generate a set of jobs in a; batch run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>PB: Redeploy batch service; PVM->>CI: Redeploy CI service; PVM-->>PB: Done; deactivate P",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:10677,Testability,log,logs,10677,"run: . - Create a new batch job to:; - Build various components and service images; - Deploy to the `default` (ie prod) namespace; - Run various post-deployment tests; - A handful of final actions; - eg rolling out artifact registry cleanup policies, amongst many other things. Note: It's not actually quite as waterfall-y as this. In fact the jobs are all running in a hail; batch, and each package being built and service being deployed has its own path through the DAG. So it's quite possible; that services are deploy/test-ing in parallel, and that the deploy and test jobs for one service might all complete before ; the deploy and test for another have even started. This should all be fine. Because we only merge in the first place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>PB: Redeploy batch service; PVM->>CI: Redeploy CI service; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>PB: Submit test batches; PB->>PVM: Submit test batch jobs; activate PVM; PVM-->>PB: Validate results; deactivate PVM; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; ```",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:11422,Testability,test,test,11422,"t place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>PB: Redeploy batch service; PVM->>CI: Redeploy CI service; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>PB: Submit test batches; PB->>PVM: Submit test batch jobs; activate PVM; PVM-->>PB: Validate results; deactivate PVM; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; ```. ## References. ### The update loop. The following reference diagrams show the actions taken during CI's main update loop. Note that these diagrams are code-up views of how CI works. They should be cross references against the; ""purpose down"" descriptions above, of how CI uses these flows to make the changes it wants to happen. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop --> UpdateGithub; subgraph UpdateGithub; GithubChanged{github_changed?} -->|yes| _update_github; end; ; UpdateGithub --> UpdateBatch; subgraph UpdateBatch; BatchChanged{batch_changed?} -->|yes| _update_batch; end. UpdateBatch --> UpdateState; subgraph UpdateState; StateChanged{state_changed?} -->|yes| _update_state; end. UpdateState -",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:11464,Testability,test,test,11464,"t place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>PB: Redeploy batch service; PVM->>CI: Redeploy CI service; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>PB: Submit test batches; PB->>PVM: Submit test batch jobs; activate PVM; PVM-->>PB: Validate results; deactivate PVM; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; ```. ## References. ### The update loop. The following reference diagrams show the actions taken during CI's main update loop. Note that these diagrams are code-up views of how CI works. They should be cross references against the; ""purpose down"" descriptions above, of how CI uses these flows to make the changes it wants to happen. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop --> UpdateGithub; subgraph UpdateGithub; GithubChanged{github_changed?} -->|yes| _update_github; end; ; UpdateGithub --> UpdateBatch; subgraph UpdateBatch; BatchChanged{batch_changed?} -->|yes| _update_batch; end. UpdateBatch --> UpdateState; subgraph UpdateState; StateChanged{state_changed?} -->|yes| _update_state; end. UpdateState -",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:11495,Testability,test,test,11495,"t place if the PR in question has already passed; tests against the current SHA of the watched branch. > [!NOTE]; > CI deploy runs in hail.is can be seen [here](https://batch.hail.is/batches?q=user+%3D+ci%0D%0Adeploy+%3D+1).; > Note:; > - You will need to be a member of the `ci` billing project to view these logs.; > - Due to the numbers of batches involved, this page may take a while to load . #### CI Deploy Timeline. The image below shows the CI deployment timeline:. ```mermaid; sequenceDiagram; participant Github; box Kubernetes (PROD: 'default' namespace); participant CI as PROD CI Service (default namespace); participant PB as PROD Batch (default namespace); end; box GCE (PROD VMs); participant PVM as PROD VMs; end. Github->>CI: Notify 'main' branch updated; CI->>PB: Submit CI deploy batch; activate PB; PB->>PVM: Submit build jobs; activate PVM; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit deploy jobs; activate PVM; PVM->>PB: Redeploy batch service; PVM->>CI: Redeploy CI service; PVM-->>PB: Done; deactivate PVM; PB->>PVM: Submit test jobs; activate PVM; PVM->>PB: Submit test batches; PB->>PVM: Submit test batch jobs; activate PVM; PVM-->>PB: Validate results; deactivate PVM; PVM-->>PB: Done; deactivate PVM; PB-->>CI: Detects completion; ```. ## References. ### The update loop. The following reference diagrams show the actions taken during CI's main update loop. Note that these diagrams are code-up views of how CI works. They should be cross references against the; ""purpose down"" descriptions above, of how CI uses these flows to make the changes it wants to happen. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop --> UpdateGithub; subgraph UpdateGithub; GithubChanged{github_changed?} -->|yes| _update_github; end; ; UpdateGithub --> UpdateBatch; subgraph UpdateBatch; BatchChanged{batch_changed?} -->|yes| _update_batch; end. UpdateBatch --> UpdateState; subgraph UpdateState; StateChanged{state_changed?} -->|yes| _update_state; end. UpdateState -",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:14274,Testability,test,test,14274,e_changed). end. UpdateGithub --> UpdatePRs; ```. #### Update Batch. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|batch_changed| UpdateBatch; UpdateBatch --> UpdateDeployable; UpdateBatch --> UpdatePRBatches ; subgraph UpdateDeployable; direction LR; Deployable{deployable?} --> UpdateDeployBatch(Update internal state of \ndeploy batch); end; subgraph UpdatePRBatches; direction LR; IterateOverPrs(Iterate over PRs) --> FindLatest(Find latest non-cancelled batch for SHA); FindLatest --> UpdateBatchState(Update local state of PR batch); UpdateBatchState --> BatchStateChanged{changed?}; BatchStateChanged -->|yes| SetStateChanged2(Set state_changed); end. ```. #### Update State. Updating the external state involves two steps: a 'heal' step and a 'try to merge' step. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|state_changed| Heal; Heal --> TryToMerge(Try to merge); ```. ##### Heal. ```mermaid; flowchart LR; subgraph HealDeploy; direction LR; NewDeploy{new deployable SHA?} -->|yes| CreateDeploy(Create deploy\nbatch); end; HealDeploy --> DetermineMergeCandidate(Determine merge candidate); DetermineMergeCandidate --> HealPRs; subgraph HealPRs; direction LR; IterateOverPrs2(Iterate over PRs) --> PostGithubStatus(Post github status); PostGithubStatus --> StartTestBatch; subgraph StartTestBatch; direction LR; NoTestsYet{no test batch yet?} -->|yes| CreateTestBatch(Create test batch); CurrentMergeCandidate{current merge\ncandidate} -->|yes| TestBatchStale(previous test batch\noutdated); TestBatchStale -->|yes| CreateTestBatch; end; end; HealPRs --> CancelOrphanBuilds ; ```. ##### Try to Merge. ```mermaid; flowchart LR; IterateOverMergeable(Iterate over\nmergeable PRs in\nmerge priority order); IterateOverMergeable --> IsMergeable{is_mergeable?\n\n-No DO_NOT_MERGE flag\n-Reviewed\n-Checks passed\n-Up to date test run}; ; IsMergeable -->|yes| Merge(Merge the PR). Merge -->|failure| IterateOverMergeable; Merge -->|success| Return; ```; ,MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:14323,Testability,test,test,14323,e_changed). end. UpdateGithub --> UpdatePRs; ```. #### Update Batch. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|batch_changed| UpdateBatch; UpdateBatch --> UpdateDeployable; UpdateBatch --> UpdatePRBatches ; subgraph UpdateDeployable; direction LR; Deployable{deployable?} --> UpdateDeployBatch(Update internal state of \ndeploy batch); end; subgraph UpdatePRBatches; direction LR; IterateOverPrs(Iterate over PRs) --> FindLatest(Find latest non-cancelled batch for SHA); FindLatest --> UpdateBatchState(Update local state of PR batch); UpdateBatchState --> BatchStateChanged{changed?}; BatchStateChanged -->|yes| SetStateChanged2(Set state_changed); end. ```. #### Update State. Updating the external state involves two steps: a 'heal' step and a 'try to merge' step. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|state_changed| Heal; Heal --> TryToMerge(Try to merge); ```. ##### Heal. ```mermaid; flowchart LR; subgraph HealDeploy; direction LR; NewDeploy{new deployable SHA?} -->|yes| CreateDeploy(Create deploy\nbatch); end; HealDeploy --> DetermineMergeCandidate(Determine merge candidate); DetermineMergeCandidate --> HealPRs; subgraph HealPRs; direction LR; IterateOverPrs2(Iterate over PRs) --> PostGithubStatus(Post github status); PostGithubStatus --> StartTestBatch; subgraph StartTestBatch; direction LR; NoTestsYet{no test batch yet?} -->|yes| CreateTestBatch(Create test batch); CurrentMergeCandidate{current merge\ncandidate} -->|yes| TestBatchStale(previous test batch\noutdated); TestBatchStale -->|yes| CreateTestBatch; end; end; HealPRs --> CancelOrphanBuilds ; ```. ##### Try to Merge. ```mermaid; flowchart LR; IterateOverMergeable(Iterate over\nmergeable PRs in\nmerge priority order); IterateOverMergeable --> IsMergeable{is_mergeable?\n\n-No DO_NOT_MERGE flag\n-Reviewed\n-Checks passed\n-Up to date test run}; ; IsMergeable -->|yes| Merge(Merge the PR). Merge -->|failure| IterateOverMergeable; Merge -->|success| Return; ```; ,MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:14417,Testability,test,test,14417,e_changed). end. UpdateGithub --> UpdatePRs; ```. #### Update Batch. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|batch_changed| UpdateBatch; UpdateBatch --> UpdateDeployable; UpdateBatch --> UpdatePRBatches ; subgraph UpdateDeployable; direction LR; Deployable{deployable?} --> UpdateDeployBatch(Update internal state of \ndeploy batch); end; subgraph UpdatePRBatches; direction LR; IterateOverPrs(Iterate over PRs) --> FindLatest(Find latest non-cancelled batch for SHA); FindLatest --> UpdateBatchState(Update local state of PR batch); UpdateBatchState --> BatchStateChanged{changed?}; BatchStateChanged -->|yes| SetStateChanged2(Set state_changed); end. ```. #### Update State. Updating the external state involves two steps: a 'heal' step and a 'try to merge' step. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|state_changed| Heal; Heal --> TryToMerge(Try to merge); ```. ##### Heal. ```mermaid; flowchart LR; subgraph HealDeploy; direction LR; NewDeploy{new deployable SHA?} -->|yes| CreateDeploy(Create deploy\nbatch); end; HealDeploy --> DetermineMergeCandidate(Determine merge candidate); DetermineMergeCandidate --> HealPRs; subgraph HealPRs; direction LR; IterateOverPrs2(Iterate over PRs) --> PostGithubStatus(Post github status); PostGithubStatus --> StartTestBatch; subgraph StartTestBatch; direction LR; NoTestsYet{no test batch yet?} -->|yes| CreateTestBatch(Create test batch); CurrentMergeCandidate{current merge\ncandidate} -->|yes| TestBatchStale(previous test batch\noutdated); TestBatchStale -->|yes| CreateTestBatch; end; end; HealPRs --> CancelOrphanBuilds ; ```. ##### Try to Merge. ```mermaid; flowchart LR; IterateOverMergeable(Iterate over\nmergeable PRs in\nmerge priority order); IterateOverMergeable --> IsMergeable{is_mergeable?\n\n-No DO_NOT_MERGE flag\n-Reviewed\n-Checks passed\n-Up to date test run}; ; IsMergeable -->|yes| Merge(Merge the PR). Merge -->|failure| IterateOverMergeable; Merge -->|success| Return; ```; ,MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:14767,Testability,test,test,14767,e_changed). end. UpdateGithub --> UpdatePRs; ```. #### Update Batch. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|batch_changed| UpdateBatch; UpdateBatch --> UpdateDeployable; UpdateBatch --> UpdatePRBatches ; subgraph UpdateDeployable; direction LR; Deployable{deployable?} --> UpdateDeployBatch(Update internal state of \ndeploy batch); end; subgraph UpdatePRBatches; direction LR; IterateOverPrs(Iterate over PRs) --> FindLatest(Find latest non-cancelled batch for SHA); FindLatest --> UpdateBatchState(Update local state of PR batch); UpdateBatchState --> BatchStateChanged{changed?}; BatchStateChanged -->|yes| SetStateChanged2(Set state_changed); end. ```. #### Update State. Updating the external state involves two steps: a 'heal' step and a 'try to merge' step. ```mermaid; flowchart LR; UpdateLoop[Update Loop]; ; UpdateLoop -->|state_changed| Heal; Heal --> TryToMerge(Try to merge); ```. ##### Heal. ```mermaid; flowchart LR; subgraph HealDeploy; direction LR; NewDeploy{new deployable SHA?} -->|yes| CreateDeploy(Create deploy\nbatch); end; HealDeploy --> DetermineMergeCandidate(Determine merge candidate); DetermineMergeCandidate --> HealPRs; subgraph HealPRs; direction LR; IterateOverPrs2(Iterate over PRs) --> PostGithubStatus(Post github status); PostGithubStatus --> StartTestBatch; subgraph StartTestBatch; direction LR; NoTestsYet{no test batch yet?} -->|yes| CreateTestBatch(Create test batch); CurrentMergeCandidate{current merge\ncandidate} -->|yes| TestBatchStale(previous test batch\noutdated); TestBatchStale -->|yes| CreateTestBatch; end; end; HealPRs --> CancelOrphanBuilds ; ```. ##### Try to Merge. ```mermaid; flowchart LR; IterateOverMergeable(Iterate over\nmergeable PRs in\nmerge priority order); IterateOverMergeable --> IsMergeable{is_mergeable?\n\n-No DO_NOT_MERGE flag\n-Reviewed\n-Checks passed\n-Up to date test run}; ; IsMergeable -->|yes| Merge(Merge the PR). Merge -->|failure| IterateOverMergeable; Merge -->|success| Return; ```; ,MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:567,Usability,clear,clearly,567,"# The CI Service. ## Documentation Scope. This documentation is trying to achieve two goals:. - How the CI service is structured and operates as a general purpose, customizable component; - How the CI service is configured and deployed by the Hail team:; - From the `hail-is/hail:main` branch of the hail repository; - To the `default` namespace of the Hail Batch cluster in GCP. The primary text of the document will focus on the first goal, documenting the general purpose component. When describing how CI is configured and deployed by the Hail team, this will be clearly annotated. ; Note that the Hail team's configuration is mostly stable, but should be treated with a grain of salt and validated ; against the actual configuration instead of being assumed to be true. ## Overview of the CI Service. The CI service has three functional purposes:. - Runs tests against pull requests which target designated 'watched branches'; - Merges PRs onto watched branches when they are ready; - Deploys services to the live infrastructure when the watched branch is updated. ## Structure and Operation. The CI service itself is deployed as a Kubernetes service in the Hail Batch cluster. See ; [architecture diagram](../Hail%20Batch%20Architectural%20Diagram.png). CI must be configured with an access token allowing it to operate on ; behalf of a github account . > [!NOTE] ; > This account is called `hail-ci-robot` in hail-is/hail. ### Watched Branches. One of the core concepts of the CI service is the ""watched branch"". A watched branch is a branch in a github repository; which the CI service is configured to monitor for changes. The CI service will run tests against PRs which target the; watched branch, will merge PRs against watched branches when they are ready, and will deploy services when the watched ; branch is updated. > [!NOTE] ; > In `hail-is/hail`, there is one watched branch: `hail-is/hail:main`. ### Tracked State. For each branch, CI will track three types of state which can be ma",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md:3159,Usability,responsiv,responsive,3159,"anged`""); - Whether CI needs to act externally, to update Github or start new batches (""`state_changed`""). ### CI Update Loop. The core CI update loop iterates over its set of ""watched branches"". If any of the state flags for any of the watched; branches are marked as dirty, then the CI service will re-evaluate the state of the watched branch and potentially take; action to update either its own internal state or the state of github or the deployed system. A set of detailed flowcharts detailing the CI update loop is given in the [references](#references) section below, which; can be cross-referenced against the purposes and outcomes of the CI service as described in the following text sections. #### Detecting Stale State. ##### Regular Polling. At a configurable frequency, the CI service will mark **_all_** flags for **_all_** watched branches as dirty, which; will trigger a re-evaluation of the system state. ##### Github Webhooks. To make CI more responsive it also has endpoints to receive webhook event triggers from the github repository. This endpoint; is part of the CI API, listening on `/github_callback`. Depending on the type of webhook received, and the branch or PR which it is targeting, the CI service will; potentially dirty one or more of its watched branches' state flags, meaning that CI will prioritize re-evaluating; the state of the branch in question. The webhooks themselves are configured manually within the github repository itself and not managed by terraform or deploy scripts. > [!NOTE] ; > - For `hail-is/hail`, the webhook target is: `ci.hail.is/github_callback`; > - For `hail-is/hail`, webhook callbacks are configured to happen on changes to the following:; > - Pull request reviews; > - Pull requests; > - Pushes. ## Running tests against pull requests. When a PR which targets a watched branch is created, updated or closed, the `github_changed` flag will be marked as dirty. . During its update loop, CI will potentially decide to run tests against a",MatchSource.DOCS,dev-docs/services/ci/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/ci/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:3301,Availability,error,error,3301,"le format version: 1.7.0. All library; versions before 0.2.119, for example 0.2.118, *cannot* read file format version 1.7.0. All library; versions after and including 0.2.119 *can* read file format version 1.7.0. Each version of the Hail Python library can only write files using the latest file format version it; supports. **The hl.experimental package and other methods marked experimental in the docs are exempt from this; policy. Their functionality or even existence may change without notice. Please contact us if you; critically depend on experimental functionality.**. ## Version 0.2.133. Released 2024-09-25. ### New Features. - (hail#14619) Teach `hailctl dataproc submit` to use the `--project` argument as an argument to `gcloud dataproc` rather than the submitted script. ### Bug Fixes. - (hail#14673) Fix typo in Interpret rule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:7638,Availability,error,error,7638,"ort these functions and use them directly.; - (hail#14405) `VariantDataset.validate` now checks that all ref blocks are no; longer than the ref_block_max_length field, if it exists. ### Bug Fixes. - (hail#14420) Fixes a serious, but likely rare, bug in the; Table/MatrixTable reader, which has been present since Sep 2020. It; manifests as many (around half or more) of the rows being dropped. This; could only happen when 1) reading a (matrix)table whose partitioning; metadata allows rows with the same key to be split across neighboring; partitions, and 2) reading it with a different partitioning than it was; written. 1) would likely only happen by reading data keyed by locus and; alleles, and rekeying it to only locus before writing. 2) would likely; only happen by using the `_intervals` or `_n_partitions` arguments to; `read_(matrix)_table`, or possibly `repartition`. Please reach out to us; if you're concerned you may have been affected by this.; - (hail#14330) Fixes erroneous error in `export_vcf` with unphased haploid Calls.; - (hail#14303) Fix missingness error when sampling entries from a MatrixTable.; - (hail#14288) Contigs may now be compared for inquality while filtering rows. ### Deprecations. - (hail#14386) `MatrixTable.make_table` is deprecated. Use `.localize_entries` instead. ## Version 0.2.128. Released 2024-02-16. In GCP, the Hail Annotation DB and Datasets API have moved from multi-regional US and EU buckets to; regional US-CENTRAL1 and EUROPE-WEST1 buckets. These buckets are requester pays which means unless; your cluster is in the US-CENTRAL1 or EUROPE-WEST1 region, you will pay a per-gigabyte rate to read; from the Annotation DB or Datasets API. We must make this change because [reading from a; multi-regional bucket into a regional VM is no longer; free](https://cloud.google.com/storage/pricing-announce#network). Unfortunately, cost constraints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### D",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:7721,Availability,error,error,7721,"e` now checks that all ref blocks are no; longer than the ref_block_max_length field, if it exists. ### Bug Fixes. - (hail#14420) Fixes a serious, but likely rare, bug in the; Table/MatrixTable reader, which has been present since Sep 2020. It; manifests as many (around half or more) of the rows being dropped. This; could only happen when 1) reading a (matrix)table whose partitioning; metadata allows rows with the same key to be split across neighboring; partitions, and 2) reading it with a different partitioning than it was; written. 1) would likely only happen by reading data keyed by locus and; alleles, and rekeying it to only locus before writing. 2) would likely; only happen by using the `_intervals` or `_n_partitions` arguments to; `read_(matrix)_table`, or possibly `repartition`. Please reach out to us; if you're concerned you may have been affected by this.; - (hail#14330) Fixes erroneous error in `export_vcf` with unphased haploid Calls.; - (hail#14303) Fix missingness error when sampling entries from a MatrixTable.; - (hail#14288) Contigs may now be compared for inquality while filtering rows. ### Deprecations. - (hail#14386) `MatrixTable.make_table` is deprecated. Use `.localize_entries` instead. ## Version 0.2.128. Released 2024-02-16. In GCP, the Hail Annotation DB and Datasets API have moved from multi-regional US and EU buckets to; regional US-CENTRAL1 and EUROPE-WEST1 buckets. These buckets are requester pays which means unless; your cluster is in the US-CENTRAL1 or EUROPE-WEST1 region, you will pay a per-gigabyte rate to read; from the Annotation DB or Datasets API. We must make this change because [reading from a; multi-regional bucket into a regional VM is no longer; free](https://cloud.google.com/storage/pricing-announce#network). Unfortunately, cost constraints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`,",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:9209,Availability,robust,robust,9209,"r pays which means unless; your cluster is in the US-CENTRAL1 or EUROPE-WEST1 region, you will pay a per-gigabyte rate to read; from the Annotation DB or Datasets API. We must make this change because [reading from a; multi-regional bucket into a regional VM is no longer; free](https://cloud.google.com/storage/pricing-announce#network). Unfortunately, cost constraints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`, `Table.annotate_globals`,; `Table.select_globals`, `Table.transmute_globals`, `Table.transmute`, `Table.annotate`, and; `Table.filter`.; - (hail#14242) Add examples to `Table.sample`, `Table.head`, and `Table.semi`_join. ### New Features. - (hail#14206) Introduce `hailctl config set http/timeout_in_seconds` which Batch and QoB users can; use to increase the timeout on their laptops. Laptops tend to have flaky internet connections and; a timeout of 300 seconds produces a more robust experience.; - (hail#14178) Reduce VDS Combiner runtime slightly by computing the maximum ref block length; without executing the combination pipeline twice.; - (hail#14207) VDS Combiner now verifies that every GVCF path and sample name is unique. ### Bug Fixes. - (hail#14300) Require orjson<3.9.12 to avoid a segfault introduced in orjson 3.9.12; - (hail#14071) Use indexed VEP cache files for GRCh38 on both dataproc and QoB.; - (hail#14232) Allow use of large numbers of fields on a table without triggering; `ClassTooLargeException: Class too large:`.; - (hail#14246)(hail#14245) Fix a bug, introduced in 0.2.114, in which `Table.multi_way_zip_join` and; `Table.aggregate_by_key` could throw ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially different from the desired; number of output partitions.; - (hail#14202) Support coercing `{}` (the empty dictionary) into any Stru",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:11092,Availability,down,downloads,11092,"coercing `{}` (the empty dictionary) into any Struct type (with all missing; fields).; - (hail#14239) Remove an erroneous statement from the MatrixTable tutorial.; - (hail#14176) `hailtop.fs.ls` can now list a bucket, e.g. `hailtop.fs.ls(""gs://my-bucket"")`.; - (hail#14258) Fix `import_avro` to not raise `NullPointerException` in certain rare cases; (e.g. when using `_key_by_assert_sorted`).; - (hail#14285) Fix a broken link in the MatrixTable tutorial. ### Deprecations. - (hail#14293) Support for the `hail-az://` scheme, deprecated in 0.2.116, is now gone. Please use; the standard `https://ACCOUNT.blob.core.windows.net/CONTAINER/PATH`. ## Version 0.2.127. Released 2024-01-12. If you have an Apple M1 laptop, verify that. ```; file $JAVA_HOME/bin/java; ```. returns a message including the phrase ""arm64"". If it instead includes the phrase ""x86_64"" then you; must upgrade to a new version of Java. You may find such a version of Java; [here](https://www.azul.com/downloads/?os=macos&architecture=arm-64-bit&package=jre#zulu). ### New Features. - (hail#14093) `hailctl dataproc` now creates clusters using Dataproc version 2.1.33. It previously used version 2.1.2.; - (hail#13617) Query-on-Batch now supports joining two tables keyed by intervals.; - (hail#13795)(hail#13567) Enable passing a requester pays configuration to `hailtop.fs.open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issu",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:12594,Availability,error,errors,12594,"118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now supports identity_by_descent on Apple M1 and M2 chips; however, your Java installation must be an arm64 installation. Using x86_64 Java with Hail on Apple M1 or M2 will cause SIGILL errors. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM.; - (hail#14022) Fix (hail#13937) caused by faulty library code in the Google Cloud Storage API Java client library.; - (hail#13812) Permit `hailctl batch submit` to accept relative paths. Fix (hail#13785).; - (hail#13885) Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary.; - (hail#14127) `hailctl dataproc start ... --dry-run` now uses shell escapes such that, after copied and pasted into a shell, the `gcloud` command works as expected.; - (hail#14062) Fix (hail#14052) which caused incorrect results for identity by descent in Query-on-Batch.; - (hail#14122) Ensure that stack traces are transmitted from workers to the driver to the client.; - (hail#14105) When a VCF contains missing values in array fie",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:12789,Availability,fault,faulty,12789,"github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now supports identity_by_descent on Apple M1 and M2 chips; however, your Java installation must be an arm64 installation. Using x86_64 Java with Hail on Apple M1 or M2 will cause SIGILL errors. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM.; - (hail#14022) Fix (hail#13937) caused by faulty library code in the Google Cloud Storage API Java client library.; - (hail#13812) Permit `hailctl batch submit` to accept relative paths. Fix (hail#13785).; - (hail#13885) Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary.; - (hail#14127) `hailctl dataproc start ... --dry-run` now uses shell escapes such that, after copied and pasted into a shell, the `gcloud` command works as expected.; - (hail#14062) Fix (hail#14052) which caused incorrect results for identity by descent in Query-on-Batch.; - (hail#14122) Ensure that stack traces are transmitted from workers to the driver to the client.; - (hail#14105) When a VCF contains missing values in array fields, Hail now suggests using `array_elements_required=False`. ### Deprecations. - (hail#13987) Deprecate `default_reference` parameter to `hl.init`, users should use `hl.default_reference` with an argument to set new default references us",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14030,Availability,error,errors,14030,"d Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary.; - (hail#14127) `hailctl dataproc start ... --dry-run` now uses shell escapes such that, after copied and pasted into a shell, the `gcloud` command works as expected.; - (hail#14062) Fix (hail#14052) which caused incorrect results for identity by descent in Query-on-Batch.; - (hail#14122) Ensure that stack traces are transmitted from workers to the driver to the client.; - (hail#14105) When a VCF contains missing values in array fields, Hail now suggests using `array_elements_required=False`. ### Deprecations. - (hail#13987) Deprecate `default_reference` parameter to `hl.init`, users should use `hl.default_reference` with an argument to set new default references usually shortly after `hl.init`. ## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14450,Availability,reliab,reliably,14450,"traces are transmitted from workers to the driver to the client.; - (hail#14105) When a VCF contains missing values in array fields, Hail now suggests using `array_elements_required=False`. ### Deprecations. - (hail#13987) Deprecate `default_reference` parameter to `hl.init`, users should use `hl.default_reference` with an argument to set new default references usually shortly after `hl.init`. ## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures conta",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14847,Availability,error,error,14847,"## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) F",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15589,Availability,error,errors,15589,"intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#1369",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15730,Availability,error,errors,15730,"d of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:16322,Availability,error,error,16322,"independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc submit` now expands `~` in the `--files` and `--pyfiles` arguments. - (hail#13797) Fix (hail#13756). Operations that collect large results such as `to_pandas` may require up to 3x less memory. - (hail#13826) Fix (hail#13793). Ensure `hailctl describe -u` overrides the `gcs_requester_pays/project` config variable. - (hail#13814) Fix (hail#13757). Pipelines that are memory-bound by copious use of `hl.literal`, such as `hl.vds.filter_intervals`, require substantially less memory. - (hail#13894) Fix (hail#13837) in which Hail",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:17689,Availability,avail,available,17689,"ail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc submit` now expands `~` in the `--files` and `--pyfiles` arguments. - (hail#13797) Fix (hail#13756). Operations that collect large results such as `to_pandas` may require up to 3x less memory. - (hail#13826) Fix (hail#13793). Ensure `hailctl describe -u` overrides the `gcs_requester_pays/project` config variable. - (hail#13814) Fix (hail#13757). Pipelines that are memory-bound by copious use of `hl.literal`, such as `hl.vds.filter_intervals`, require substantially less memory. - (hail#13894) Fix (hail#13837) in which Hail could break a Spark installation if the Hail JAR appears on the classpath before the Scala JARs. - (hail#13919) Fix (hail#13915) which prevented using a glob pattern in `hl.import_vcf`. ## Version 0.2.124. Released 2023-09-21. ### New Features. - (hail#13608) Change default behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.output_notebook and/or setting plotly.io.renderers.default = 'iframe' is no longer necessary). ### Bug Fixes; - (hail#13634) Fix a bug which caused Query-on-Batch pipelines with a large number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### N",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:18613,Availability,error,errors,18613," behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.output_notebook and/or setting plotly.io.renderers.default = 'iframe' is no longer necessary). ### Bug Fixes; - (hail#13634) Fix a bug which caused Query-on-Batch pipelines with a large number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom call fields via the `call_fields`; parameter.; - (hail#13224) `hailctl config get`, `set`, and `unset` now support shell auto-completion. Run; `hailctl --install-completion zsh` to install the auto-completion for",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:20876,Availability,degraded,degraded,20876,"il#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hailctl; option.; - (hail#13422) `hailtop.hail_frozenlist.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:23179,Availability,error,error,23179,"irst 1000. This could manifest in an `import_table` or `import_vcf` which used a glob; expression. In such a case, only the first 1000 files would have been included in the resulting; Table or MatrixTable.; - (hail#13550) `hl.utils.range_table(n)` now supports all valid 32-bit signed integer values of `n`.; - (hail#13500) In Query-on-Batch, the client-side Python code will not try to list every job when a; QoB batch fails. This could take hours for long-running pipelines or pipelines with many; partitions. ### Deprecations. - (hail#13275) Hail no longer officially supports Python 3.8.; - (hail#13508) The `n` parameter of `MatrixTable.tail` is deprecated in favor of a new `n_rows`; parameter. ## Version 0.2.120. Released 2023-07-27. ### New Features; - (hail#13206) The VDS Combiner now works in Query-on-Batch. ### Bug Fixes; - (hail#13313) Fix bug introduced in 0.2.119 which causes a serialization error when using; Query-on-Spark to read a VCF which is sorted by locus, with split multi-allelics, in which the; records sharing a single locus do not appear in the dictionary ordering of their alternate; alleles.; - (hail#13264) Fix bug which ignored the `partition_hint` of a Table group-by-and-aggregate.; - (hail#13239) Fix bug which ignored the `HAIL_BATCH_REGIONS` argument when determining in which; regions to schedule jobs when using Query-on-Batch.; - (hail#13253) Improve `hadoop_ls` and `hfs.ls` to quickly list globbed files in a directory. The; speed improvement is proportional to the number of files in the directory.; - (hail#13226) Fix the comparison of an `hl.Struct` to an `hl.struct` or field of type; `tstruct`. Resolves (hail#13045) and (Hail#13046).; - (hail#12995) Fixed bug causing poor performance and memory leaks for `MatrixTable.annotate_rows`; aggregations. ## Version 0.2.119. Released 2023-06-28. ### New Features; - (hail#12081) Hail now uses [Zstandard](https://facebook.github.io/zstd/) as; the default compression algorithm for table and matrix table st",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:25666,Availability,error,errors,25666,"method, for finding eigenvalues; of symmetric matrices (""h"" is for Hermitian, the complex analogue of; symmetric). ### Bug Fixes; - (hail#13184) The `vds.to_dense_mt` no longer densifies past the end of; contig boundaries. A logic bug in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference block of the contig.; - (hail#13173) Fix globbing in scala blob storage filesystem implementations. ### File Format. - The native file format version is now 1.7.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.118. Released 2023-06-13. ### New Features. - (hail#13140) Enable `hail-az` and Azure Blob Storage `https` URLs to contain SAS tokens to enable bearer-auth style file access to Azure storage.; - (hail#13129) Allow subnet to be passed through to gcloud in hailctl. ### Bug Fixes. - (hail#13126) Query-on-Batch pipelines with one partition are now retried when they encounter transient errors.; - (hail#13113) `hail.ggplot.geom_point` now displays a legend group for a column even when it has only one value in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:25844,Availability,error,error,25844,"g in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference block of the contig.; - (hail#13173) Fix globbing in scala blob storage filesystem implementations. ### File Format. - The native file format version is now 1.7.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.118. Released 2023-06-13. ### New Features. - (hail#13140) Enable `hail-az` and Azure Blob Storage `https` URLs to contain SAS tokens to enable bearer-auth style file access to Azure storage.; - (hail#13129) Allow subnet to be passed through to gcloud in hailctl. ### Bug Fixes. - (hail#13126) Query-on-Batch pipelines with one partition are now retried when they encounter transient errors.; - (hail#13113) `hail.ggplot.geom_point` now displays a legend group for a column even when it has only one value in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional t",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27459,Availability,error,error,27459," with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27553,Availability,error,error,27553," with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27726,Availability,error,errors,27726,"s and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.; - (hail#12917) The `hail-az` scheme for referencing blobs in ABS is now deprecated and will be removed in an upcoming release. ### Bug Fixes. - (hail",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27892,Availability,error,errors,27892,"sh in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.; - (hail#12917) The `hail-az` scheme for referencing blobs in ABS is now deprecated and will be removed in an upcoming release. ### Bug Fixes. - (hail#12913) Fixed bug in `hail.ggplot` where all legend entries would have the same text if one column had exactly one value for all rows and was mapped to either the `shape` or the `color` aesthetic for `geom_point`.; - (hail#12901) `hl.Struct` now has a correct ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:33023,Availability,error,errors,33023,"w supported.; - (hail#12643) In Query on Batch, `hl.liftover` is now supported.; - (hail#12629) In Query on Batch, `hl.ibd` is now supported.; - (hail#12722) Add `hl.simulate_random_mating` to generate a population from founders under the assumption of random mating.; - (hail#12701) Query on Spark now officially supports Spark 3.3.0 and Dataproc 2.1.x. ### Performance Improvements. - (hail#12679) In Query on Batch, `hl.balding_nichols_model` is slightly faster. Also added `hl.utils.genomic_range_table` to quickly create a table keyed by locus. ### Bug Fixes. - (hail#12711) In Query on Batch, fix null pointer exception (manifesting as `scala.MatchError: null`) when reading data from requester pays buckets.; - (hail#12739) Fix `hl.plot.cdf`, `hl.plot.pdf`, and `hl.plot.joint_plot` which were broken by changes in Hail and changes in bokeh.; - (hail#12735) Fix (hail#11738) by allowing user to override default types in `to_pandas`.; - (hail#12760) Mitigate some JVM bytecode generation errors, particularly those related to too many method parameters.; - (hail#12766) Fix (hail#12759) by loosening `parsimonious` dependency pin.; - (hail#12732) In Query on Batch, fix bug that sometimes prevented terminating a pipeline using Control-C.; - (hail#12771) Use a version of `jgscm` whose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field,",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:33687,Availability,checkpoint,checkpoint,33687," data from requester pays buckets.; - (hail#12739) Fix `hl.plot.cdf`, `hl.plot.pdf`, and `hl.plot.joint_plot` which were broken by changes in Hail and changes in bokeh.; - (hail#12735) Fix (hail#11738) by allowing user to override default types in `to_pandas`.; - (hail#12760) Mitigate some JVM bytecode generation errors, particularly those related to too many method parameters.; - (hail#12766) Fix (hail#12759) by loosening `parsimonious` dependency pin.; - (hail#12732) In Query on Batch, fix bug that sometimes prevented terminating a pipeline using Control-C.; - (hail#12771) Use a version of `jgscm` whose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time.; - (hail#12566) Improve error message when combining incompatibly indexed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:34278,Availability,error,error,34278,"ose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time.; - (hail#12566) Improve error message when combining incompatibly indexed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would be taller than the plot, the legend will now be scrollable. Legend entries for such plots can be clicked to show/hide traces on the plot, but this does not work and is a known issue that will only be addressed if `hail.ggplot` is migrated off of plotly.; - (hail#12584) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables wi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:35017,Availability,error,error,35017,"hen there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time.; - (hail#12566) Improve error message when combining incompatibly indexed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would be taller than the plot, the legend will now be scrollable. Legend entries for such plots can be clicked to show/hide traces on the plot, but this does not work and is a known issue that will only be addressed if `hail.ggplot` is migrated off of plotly.; - (hail#12584) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables with HTML unsafe column headers are rendered wrong in Jupyter.; - (hail#12574) Fixed a memory leak when processing tables. Could trigger unnecessarily high memory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to us",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:35501,Availability,error,errors,35501," support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would be taller than the plot, the legend will now be scrollable. Legend entries for such plots can be clicked to show/hide traces on the plot, but this does not work and is a known issue that will only be addressed if `hail.ggplot` is migrated off of plotly.; - (hail#12584) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables with HTML unsafe column headers are rendered wrong in Jupyter.; - (hail#12574) Fixed a memory leak when processing tables. Could trigger unnecessarily high memory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to use in batch scripts when not specified in code.; - (hail#12497) Added support for `scales`, `nrow`, and `ncol` arguments, as well as grouped legends, to `hail.ggplot.facet_wrap`.; - (hail#12471) Added `hailctl batch submit` command to run local scripts inside batch jobs.; - (hail#12525) Add support for passing arguments to `hailctl batch submit`.; - (hail#12465) Batch jobs' status now contains the region the job ran in. The job itself can access which region it is in through the `HAIL_REGION` en",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:35781,Availability,error,error,35781,"n be clicked to show/hide traces on the plot, but this does not work and is a known issue that will only be addressed if `hail.ggplot` is migrated off of plotly.; - (hail#12584) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables with HTML unsafe column headers are rendered wrong in Jupyter.; - (hail#12574) Fixed a memory leak when processing tables. Could trigger unnecessarily high memory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to use in batch scripts when not specified in code.; - (hail#12497) Added support for `scales`, `nrow`, and `ncol` arguments, as well as grouped legends, to `hail.ggplot.facet_wrap`.; - (hail#12471) Added `hailctl batch submit` command to run local scripts inside batch jobs.; - (hail#12525) Add support for passing arguments to `hailctl batch submit`.; - (hail#12465) Batch jobs' status now contains the region the job ran in. The job itself can access which region it is in through the `HAIL_REGION` environment variable.; - (hail#12464) When using Query-on-Batch, all jobs for a single hail session are inserted into the same batch instead of one batch per action.; - (hail#12457) `pca` and `hwe_normalized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function f",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:37531,Availability,failure,failures,37531,"riable.; - (hail#12464) When using Query-on-Batch, all jobs for a single hail session are inserted into the same batch instead of one batch per action.; - (hail#12457) `pca` and `hwe_normalized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter di",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:37607,Availability,error,error,37607,"he same batch instead of one batch per action.; - (hail#12457) `pca` and `hwe_normalized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-1",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:38235,Availability,error,errors,38235,"ut files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fixes. - (hail#12305): Fixed a rare crash reading tables/matrixtables with _intervals. ---. ## Version 0.2.102. Released 2022-10-06. ### New Features. - (hail#12218) Missing values are now supported in primitive columns in `Table.to_pandas`.; - (hail#12254) Cross-product-style legends for data groups have been replaced with factored ones (consistent with `ggplot2`'s implementation) for `hail.ggplot.geom_point`, and support has be",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:38334,Availability,error,error,38334,"u need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fixes. - (hail#12305): Fixed a rare crash reading tables/matrixtables with _intervals. ---. ## Version 0.2.102. Released 2022-10-06. ### New Features. - (hail#12218) Missing values are now supported in primitive columns in `Table.to_pandas`.; - (hail#12254) Cross-product-style legends for data groups have been replaced with factored ones (consistent with `ggplot2`'s implementation) for `hail.ggplot.geom_point`, and support has been added for custom legend group labels.; - (hail#12268) `VariantDataset` now implements `union_rows` for combining datasets with the sa",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:38452,Availability,error,error,38452,"etails. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fixes. - (hail#12305): Fixed a rare crash reading tables/matrixtables with _intervals. ---. ## Version 0.2.102. Released 2022-10-06. ### New Features. - (hail#12218) Missing values are now supported in primitive columns in `Table.to_pandas`.; - (hail#12254) Cross-product-style legends for data groups have been replaced with factored ones (consistent with `ggplot2`'s implementation) for `hail.ggplot.geom_point`, and support has been added for custom legend group labels.; - (hail#12268) `VariantDataset` now implements `union_rows` for combining datasets with the same samples but disjoint variants. ### Bug Fixes. - (hail#12278) Fixed bug made more lik",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:39476,Availability,error,errors,39476,"the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fixes. - (hail#12305): Fixed a rare crash reading tables/matrixtables with _intervals. ---. ## Version 0.2.102. Released 2022-10-06. ### New Features. - (hail#12218) Missing values are now supported in primitive columns in `Table.to_pandas`.; - (hail#12254) Cross-product-style legends for data groups have been replaced with factored ones (consistent with `ggplot2`'s implementation) for `hail.ggplot.geom_point`, and support has been added for custom legend group labels.; - (hail#12268) `VariantDataset` now implements `union_rows` for combining datasets with the same samples but disjoint variants. ### Bug Fixes. - (hail#12278) Fixed bug made more likely by 0.2.101 in which Hail errors when interacting with a NumPy integer or floating point type.; - (hail#12277) Fixed bug in reading tables/matrixtables with partition intervals that led to error or segfault. ---. ## Version 0.2.101. Released 2022-10-04. ### New Features. - (hail#12218) Support missing values in primitive columns in `Table.to_pandas`.; - (hail#12195) Add a `impute_sex_chr_ploidy_from_interval_coverage` to impute sex ploidy directly from a coverage MT.; - (hail#12222) Query-on-Batch pipelines now add worker jobs to the same batch as the driver; job instead of producing a new batch per stage.; - (hail#12244) Added support for custom labels for per-group legends to `hail.ggplot.geom_point` via the; `legend_format` keyword argument. ### Deprecations. - (hail#12230) The python-dill Batch images in `gcr.io/hail-vdc` are no longer supported.; Use `hailgenetics/python-dill` instead. ### Bug fixes. - (hail#12215) Fix search bar in the Hail Batch documentation. ---. ## Version 0.2.100. Released 2022-09-23. ### New Features. - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:39639,Availability,error,error,39639,"2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fixes. - (hail#12305): Fixed a rare crash reading tables/matrixtables with _intervals. ---. ## Version 0.2.102. Released 2022-10-06. ### New Features. - (hail#12218) Missing values are now supported in primitive columns in `Table.to_pandas`.; - (hail#12254) Cross-product-style legends for data groups have been replaced with factored ones (consistent with `ggplot2`'s implementation) for `hail.ggplot.geom_point`, and support has been added for custom legend group labels.; - (hail#12268) `VariantDataset` now implements `union_rows` for combining datasets with the same samples but disjoint variants. ### Bug Fixes. - (hail#12278) Fixed bug made more likely by 0.2.101 in which Hail errors when interacting with a NumPy integer or floating point type.; - (hail#12277) Fixed bug in reading tables/matrixtables with partition intervals that led to error or segfault. ---. ## Version 0.2.101. Released 2022-10-04. ### New Features. - (hail#12218) Support missing values in primitive columns in `Table.to_pandas`.; - (hail#12195) Add a `impute_sex_chr_ploidy_from_interval_coverage` to impute sex ploidy directly from a coverage MT.; - (hail#12222) Query-on-Batch pipelines now add worker jobs to the same batch as the driver; job instead of producing a new batch per stage.; - (hail#12244) Added support for custom labels for per-group legends to `hail.ggplot.geom_point` via the; `legend_format` keyword argument. ### Deprecations. - (hail#12230) The python-dill Batch images in `gcr.io/hail-vdc` are no longer supported.; Use `hailgenetics/python-dill` instead. ### Bug fixes. - (hail#12215) Fix search bar in the Hail Batch documentation. ---. ## Version 0.2.100. Released 2022-09-23. ### New Features. - (hail#12207) Add support for the `shape` aesthetic to `hail.ggplot.geom_point`. ### Deprecations. - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:42673,Availability,error,error,42673,"er, `phased`, to control the phasedness of the generated genotypes. ### Performance improvements. - (hail#12099) Make repeated VCF/PLINK queries much faster by caching compiler data structures.; - (hail#12038) Speed up `hl.import_matrix_table` by caching header line computation. ### Bug fixes. - (hail#12115) When using `use_new_shuffle=True`, fix a bug when there are more than 2^31 rows; - (hail#12074) Fix bug where `hl.init` could silently overwrite the global random seed.; - (hail#12079) Fix bug in handling of missing (aka NA) fields in grouped aggregation and distinct by key.; - (hail#12056) Fix `hl.export_vcf` to actually create tabix files when requested.; - (hail#12020) Fix bug in `hl.experimental.densify` which manifested as an `AssertionError` about dtypes. ---. ## Version 0.2.97. Released 2022-06-30. ### New Features. - (hail#11756) `hb.BatchPoolExecutor` and Python jobs both now also support async functions. ### Bug fixes. - (hail#11962) Fix error (logged as (hail#11891)) in VCF combiner when exactly 10 or 100 files are combined.; - (hail#11969) Fix `import_table` and `import_lines` to use multiple partitions when `force_bgz` is used.; - (hail#11964) Fix erroneous ""Bucket is a requester pays bucket but no user project provided."" errors in Google Dataproc by updating to the latest Dataproc image version. ---. ## Version 0.2.96. Released 2022-06-21. ### New Features. - (hail#11833) `hl.rand_unif` now has default arguments of 0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:42966,Availability,error,errors,42966,"- (hail#12115) When using `use_new_shuffle=True`, fix a bug when there are more than 2^31 rows; - (hail#12074) Fix bug where `hl.init` could silently overwrite the global random seed.; - (hail#12079) Fix bug in handling of missing (aka NA) fields in grouped aggregation and distinct by key.; - (hail#12056) Fix `hl.export_vcf` to actually create tabix files when requested.; - (hail#12020) Fix bug in `hl.experimental.densify` which manifested as an `AssertionError` about dtypes. ---. ## Version 0.2.97. Released 2022-06-30. ### New Features. - (hail#11756) `hb.BatchPoolExecutor` and Python jobs both now also support async functions. ### Bug fixes. - (hail#11962) Fix error (logged as (hail#11891)) in VCF combiner when exactly 10 or 100 files are combined.; - (hail#11969) Fix `import_table` and `import_lines` to use multiple partitions when `force_bgz` is used.; - (hail#11964) Fix erroneous ""Bucket is a requester pays bucket but no user project provided."" errors in Google Dataproc by updating to the latest Dataproc image version. ---. ## Version 0.2.96. Released 2022-06-21. ### New Features. - (hail#11833) `hl.rand_unif` now has default arguments of 0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the cur",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:43396,Availability,error,error,43396,"`hl.experimental.densify` which manifested as an `AssertionError` about dtypes. ---. ## Version 0.2.97. Released 2022-06-30. ### New Features. - (hail#11756) `hb.BatchPoolExecutor` and Python jobs both now also support async functions. ### Bug fixes. - (hail#11962) Fix error (logged as (hail#11891)) in VCF combiner when exactly 10 or 100 files are combined.; - (hail#11969) Fix `import_table` and `import_lines` to use multiple partitions when `force_bgz` is used.; - (hail#11964) Fix erroneous ""Bucket is a requester pays bucket but no user project provided."" errors in Google Dataproc by updating to the latest Dataproc image version. ---. ## Version 0.2.96. Released 2022-06-21. ### New Features. - (hail#11833) `hl.rand_unif` now has default arguments of 0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing e",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:43670,Availability,error,error,43670," (logged as (hail#11891)) in VCF combiner when exactly 10 or 100 files are combined.; - (hail#11969) Fix `import_table` and `import_lines` to use multiple partitions when `force_bgz` is used.; - (hail#11964) Fix erroneous ""Bucket is a requester pays bucket but no user project provided."" errors in Google Dataproc by updating to the latest Dataproc image version. ---. ## Version 0.2.96. Released 2022-06-21. ### New Features. - (hail#11833) `hl.rand_unif` now has default arguments of 0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (di",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:44199,Availability,toler,tolerance,44199,"0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container imag",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:44581,Availability,error,error,44581,"11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container images; - (hail#11725) `hl.ggplot` now supports `facet_wrap`; - (hail#11776) `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed. ### `hailctl dataproc`; - (hail#11710) support pass-through arguments to `connect`. ### Bug fixes. - (hail#11792) Resolved issue where corrupted tables could be created with whole-stage code generation enabled. ---. ## Version 0.2.93. Release 2022-03-27. ### Beta features",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:44687,Availability,error,error,44687,"in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container images; - (hail#11725) `hl.ggplot` now supports `facet_wrap`; - (hail#11776) `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed. ### `hailctl dataproc`; - (hail#11710) support pass-through arguments to `connect`. ### Bug fixes. - (hail#11792) Resolved issue where corrupted tables could be created with whole-stage code generation enabled. ---. ## Version 0.2.93. Release 2022-03-27. ### Beta features. - Several issues with the beta version of Hail Query on Hail Batch are addressed in this release",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:47605,Availability,error,error,47605,"l team is accessible at both; https://hail.zulipchat.com and https://discuss.hail.is . ---. ## Version 0.2.91. Release 2022-03-18. ### Bug fixes. - (hail#11614) Update `hail.utils.tutorial.get_movie_lens` to use `https` instead of `http`. Movie; Lens has stopped serving data over insecure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48016,Availability,error,error,48016,"ug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48367,Availability,error,error,48367,"breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48665,Availability,error,errors,48665,was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues about having too many open file handles. ### New features. - (hail#11300) `geom_histogram` infers min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; ,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48730,Availability,error,error,48730,ion 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues about having too many open file handles. ### New features. - (hail#11300) `geom_histogram` infers min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; - (hail#11276) Fixed `log` argument in `hail.plot.pdf`.; - (hail#11256) Fixed memory leak in L,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:49263,Availability,failure,failure,49263,".86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues about having too many open file handles. ### New features. - (hail#11300) `geom_histogram` infers min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; - (hail#11276) Fixed `log` argument in `hail.plot.pdf`.; - (hail#11256) Fixed memory leak in LD Prune. ### New features. - (hail#11274) Added `geom_col` to `hail.ggplot`. ### hailctl dataproc. - (hail#11280) Updated dataproc image version to one not affected by log4j vulnerabilities. ---. ## Version 0.2.82. Release 2022-01-24. ### Bug fixes. - (hail#11209) Significantly improved usefulness and speed of `Table.to_pandas`, resolved several bugs with output. ### New features. - (hail#11247) Introduces a new experimental plotting interface `hail.ggplot`, base",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:51842,Availability,error,error,51842,".2.81. Release 2021-12-20. ### hailctl dataproc. - (hail#11182) Updated Dataproc image version to mitigate yet more Log4j vulnerabilities. ---. ## Version 0.2.80. Release 2021-12-15. ### New features. - (hail#11077) `hl.experimental.write_matrix_tables` now returns the paths of the written matrix tables. ### hailctl dataproc. - (hail#11157) Updated Dataproc image version to mitigate the Log4j vulnerability.; - (hail#10900) Added `--region` parameter to `hailctl dataproc submit`.; - (hail#11090) Teach `hailctl dataproc describe` how to read URLs with the protocols `s3` (Amazon S3), `hail-az` (Azure Blob Storage), and `file` (local file system) in addition to `gs` (Google Cloud Storage). ---. ## Version 0.2.79. Release 2021-11-17. ### Bug fixes. - (hail#11023) Fixed bug in call decoding that was introduced in version 0.2.78. ### New features. - (hail#10993) New function `p_value_excess_het`. ---. ## Version 0.2.78. Release 2021-10-19. ### Bug fixes; - (hail#10766) Don't throw out of memory error when broadcasting more than 2^(31) - 1 bytes.; - (hail#10910) Filters on key field won't be slowed down by uses of `MatrixTable.localize_entries` or `Table.rename`.; - (hail#10959) Don't throw an error in certain situations where some key fields are optimized away. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash when calling `hl.liftover`.; - (hail#10883) Fix crash / long compilation times writing matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:51947,Availability,down,down,51947,"to mitigate yet more Log4j vulnerabilities. ---. ## Version 0.2.80. Release 2021-12-15. ### New features. - (hail#11077) `hl.experimental.write_matrix_tables` now returns the paths of the written matrix tables. ### hailctl dataproc. - (hail#11157) Updated Dataproc image version to mitigate the Log4j vulnerability.; - (hail#10900) Added `--region` parameter to `hailctl dataproc submit`.; - (hail#11090) Teach `hailctl dataproc describe` how to read URLs with the protocols `s3` (Amazon S3), `hail-az` (Azure Blob Storage), and `file` (local file system) in addition to `gs` (Google Cloud Storage). ---. ## Version 0.2.79. Release 2021-11-17. ### Bug fixes. - (hail#11023) Fixed bug in call decoding that was introduced in version 0.2.78. ### New features. - (hail#10993) New function `p_value_excess_het`. ---. ## Version 0.2.78. Release 2021-10-19. ### Bug fixes; - (hail#10766) Don't throw out of memory error when broadcasting more than 2^(31) - 1 bytes.; - (hail#10910) Filters on key field won't be slowed down by uses of `MatrixTable.localize_entries` or `Table.rename`.; - (hail#10959) Don't throw an error in certain situations where some key fields are optimized away. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash when calling `hl.liftover`.; - (hail#10883) Fix crash / long compilation times writing matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all seque",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:52044,Availability,error,error,52044,"erimental.write_matrix_tables` now returns the paths of the written matrix tables. ### hailctl dataproc. - (hail#11157) Updated Dataproc image version to mitigate the Log4j vulnerability.; - (hail#10900) Added `--region` parameter to `hailctl dataproc submit`.; - (hail#11090) Teach `hailctl dataproc describe` how to read URLs with the protocols `s3` (Amazon S3), `hail-az` (Azure Blob Storage), and `file` (local file system) in addition to `gs` (Google Cloud Storage). ---. ## Version 0.2.79. Release 2021-11-17. ### Bug fixes. - (hail#11023) Fixed bug in call decoding that was introduced in version 0.2.78. ### New features. - (hail#10993) New function `p_value_excess_het`. ---. ## Version 0.2.78. Release 2021-10-19. ### Bug fixes; - (hail#10766) Don't throw out of memory error when broadcasting more than 2^(31) - 1 bytes.; - (hail#10910) Filters on key field won't be slowed down by uses of `MatrixTable.localize_entries` or `Table.rename`.; - (hail#10959) Don't throw an error in certain situations where some key fields are optimized away. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash when calling `hl.liftover`.; - (hail#10883) Fix crash / long compilation times writing matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all sequences is large.; - (hail#10765) Fix rare bug where valid pipelines would fail to compile if intervals were created conditionally.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:52665,Availability,error,errors,52665,"993) New function `p_value_excess_het`. ---. ## Version 0.2.78. Release 2021-10-19. ### Bug fixes; - (hail#10766) Don't throw out of memory error when broadcasting more than 2^(31) - 1 bytes.; - (hail#10910) Filters on key field won't be slowed down by uses of `MatrixTable.localize_entries` or `Table.rename`.; - (hail#10959) Don't throw an error in certain situations where some key fields are optimized away. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash when calling `hl.liftover`.; - (hail#10883) Fix crash / long compilation times writing matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all sequences is large.; - (hail#10765) Fix rare bug where valid pipelines would fail to compile if intervals were created conditionally.; - (hail#10746) Various compiler improvements, decrease likelihood of `ClassTooLarge` errors.; - (hail#10829) Fix a bug where `hl.missing` and `CaseBuilder.or_error` failed if their type was a struct containing a field starting with a number. ### New features. - (hail#10768) Support multiplying `StringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:53150,Availability,error,errors,53150,"ay. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash when calling `hl.liftover`.; - (hail#10883) Fix crash / long compilation times writing matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all sequences is large.; - (hail#10765) Fix rare bug where valid pipelines would fail to compile if intervals were created conditionally.; - (hail#10746) Various compiler improvements, decrease likelihood of `ClassTooLarge` errors.; - (hail#10829) Fix a bug where `hl.missing` and `CaseBuilder.or_error` failed if their type was a struct containing a field starting with a number. ### New features. - (hail#10768) Support multiplying `StringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes. - (hail#10684) Fixed a rare bug reading arrays from disk where short arrays would have their first ele",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:54251,Availability,error,errors,54251,"eBuilder.or_error` failed if their type was a struct containing a field starting with a number. ### New features. - (hail#10768) Support multiplying `StringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes. - (hail#10684) Fixed a rare bug reading arrays from disk where short arrays would have their first elements corrupted and long arrays would cause segfaults.; - (hail#10523) Fixed bug where liftover would fail with ""Could not initialize class"" errors. ---. ## Version 0.2.72. Released 2021-07-19. ### New Features. - (hail#10655) Revamped many hail error messages to give useful python stack traces.; - (hail#10663) Added `DictExpression.items()` to mirror python's `dict.items()`.; - (hail#10657) `hl.map` now supports mapping over multiple lists like Python's built-in `map`. ### Bug fixes. - (hail#10662) Fixed partitioning logic in `hl.import_plink`.; - (hail#10669) `NDArrayNumericExpression.sum()` now works correctly on ndarrays of booleans. ---. ## Version 0.2.71. Released 2021-07-08. ### New Features. - (hail#10632) Added support for weighted linear regression to `hl.linear_regression_rows`.; - (hail#10635) Added `hl.nd.maximum` and `hl.nd.minimum`.; - (hail#10602) Added `hl.starmap`. ### Bug fixes. - (hail#10038) Fixed crashes when writing/reading matrix tables with 0 partitions.; - (hail#10624) Fixed out of bounds bug with `_quantile_from_cdf`. ### hailctl dataproc. - (hail#10633) Add",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:54356,Availability,error,error,54356,"ringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes. - (hail#10684) Fixed a rare bug reading arrays from disk where short arrays would have their first elements corrupted and long arrays would cause segfaults.; - (hail#10523) Fixed bug where liftover would fail with ""Could not initialize class"" errors. ---. ## Version 0.2.72. Released 2021-07-19. ### New Features. - (hail#10655) Revamped many hail error messages to give useful python stack traces.; - (hail#10663) Added `DictExpression.items()` to mirror python's `dict.items()`.; - (hail#10657) `hl.map` now supports mapping over multiple lists like Python's built-in `map`. ### Bug fixes. - (hail#10662) Fixed partitioning logic in `hl.import_plink`.; - (hail#10669) `NDArrayNumericExpression.sum()` now works correctly on ndarrays of booleans. ---. ## Version 0.2.71. Released 2021-07-08. ### New Features. - (hail#10632) Added support for weighted linear regression to `hl.linear_regression_rows`.; - (hail#10635) Added `hl.nd.maximum` and `hl.nd.minimum`.; - (hail#10602) Added `hl.starmap`. ### Bug fixes. - (hail#10038) Fixed crashes when writing/reading matrix tables with 0 partitions.; - (hail#10624) Fixed out of bounds bug with `_quantile_from_cdf`. ### hailctl dataproc. - (hail#10633) Added `--scopes` parameter to `hailctl dataproc start`. ---. ## Version 0.2.70. Released 2021-06-21. ---. ## Version 0.2.69. Released 2021-06-14. ### New Fe",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:57197,Availability,error,error,57197,"aploid GT calls to VCF combiner. ---. ## Version 0.2.65. Released 2021-04-14. ### Default Spark Version Change. - Starting from version 0.2.65, Hail uses Spark 3.1.1 by default. This will also allow the use of all python versions >= 3.6. By building hail from source, it is still possible to use older versions of Spark. ### New features. - (hail#10290) Added `hl.nd.solve`.; - (hail#10187) Added `NDArrayNumericExpression.sum`. ### Performance improvements. - (hail#10233) Loops created with `hl.experimental.loop` will now clean up unneeded memory between iterations. ### Bug fixes. - (hail#10227) `hl.nd.qr` now supports ndarrays that have 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ### New features; - (hail#10164) Add source_file_field parameter to hl.import_table to allow lines to be associated with their original source file. ### Bug fixes. - (hail#10182) Fixed serious memory leak in certain uses of `filter_intervals`.; - (hail#10133) Fix bug where some pipelines incorrectly infer missingness, leading to a type error.; - (hail#10134) Teach `hl.king` to treat filtered entries as missing values.; - (hail#10158) Fixes hail usage in latest versions of jupyter that rely on `asyncio`.; - (hail#10174) Fixed bad error message when incorrect return type specified with `hl.loop`. ---. ## Version 0.2.63. Released 2021-03-01. - (hail#10105) Hail will now return `frozenset` and `hail.utils.frozendict` instead of normal sets and dicts. ### Bug fixes. - (hail#10035) Fix mishandling of NaN values in `hl.agg.hist`, where they were unintentionally included in the first bin.; - (hail#10007) Improve error message from hadoop_ls when file does not exist. ### Performance Improvements. - (hail#10068) Make certain array copies faster.; - (hail#10061) Improve code generation of `hl.if_else` and `hl.coalesce`. ---. ## Version 0.2.62. Released 2021-02-03. ### New features. - (hail#9936) Deprecated `hl.null` in favor of `hl.missing` for naming consistency.; - (hail#9973) `hl.v",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:57394,Availability,error,error,57394,"m source, it is still possible to use older versions of Spark. ### New features. - (hail#10290) Added `hl.nd.solve`.; - (hail#10187) Added `NDArrayNumericExpression.sum`. ### Performance improvements. - (hail#10233) Loops created with `hl.experimental.loop` will now clean up unneeded memory between iterations. ### Bug fixes. - (hail#10227) `hl.nd.qr` now supports ndarrays that have 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ### New features; - (hail#10164) Add source_file_field parameter to hl.import_table to allow lines to be associated with their original source file. ### Bug fixes. - (hail#10182) Fixed serious memory leak in certain uses of `filter_intervals`.; - (hail#10133) Fix bug where some pipelines incorrectly infer missingness, leading to a type error.; - (hail#10134) Teach `hl.king` to treat filtered entries as missing values.; - (hail#10158) Fixes hail usage in latest versions of jupyter that rely on `asyncio`.; - (hail#10174) Fixed bad error message when incorrect return type specified with `hl.loop`. ---. ## Version 0.2.63. Released 2021-03-01. - (hail#10105) Hail will now return `frozenset` and `hail.utils.frozendict` instead of normal sets and dicts. ### Bug fixes. - (hail#10035) Fix mishandling of NaN values in `hl.agg.hist`, where they were unintentionally included in the first bin.; - (hail#10007) Improve error message from hadoop_ls when file does not exist. ### Performance Improvements. - (hail#10068) Make certain array copies faster.; - (hail#10061) Improve code generation of `hl.if_else` and `hl.coalesce`. ---. ## Version 0.2.62. Released 2021-02-03. ### New features. - (hail#9936) Deprecated `hl.null` in favor of `hl.missing` for naming consistency.; - (hail#9973) `hl.vep` now includes a `vep_proc_id` field to aid in debugging unexpected output.; - (hail#9839) Hail now eagerly deletes temporary files produced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:57777,Availability,error,error,57777,"ave 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ### New features; - (hail#10164) Add source_file_field parameter to hl.import_table to allow lines to be associated with their original source file. ### Bug fixes. - (hail#10182) Fixed serious memory leak in certain uses of `filter_intervals`.; - (hail#10133) Fix bug where some pipelines incorrectly infer missingness, leading to a type error.; - (hail#10134) Teach `hl.king` to treat filtered entries as missing values.; - (hail#10158) Fixes hail usage in latest versions of jupyter that rely on `asyncio`.; - (hail#10174) Fixed bad error message when incorrect return type specified with `hl.loop`. ---. ## Version 0.2.63. Released 2021-03-01. - (hail#10105) Hail will now return `frozenset` and `hail.utils.frozendict` instead of normal sets and dicts. ### Bug fixes. - (hail#10035) Fix mishandling of NaN values in `hl.agg.hist`, where they were unintentionally included in the first bin.; - (hail#10007) Improve error message from hadoop_ls when file does not exist. ### Performance Improvements. - (hail#10068) Make certain array copies faster.; - (hail#10061) Improve code generation of `hl.if_else` and `hl.coalesce`. ---. ## Version 0.2.62. Released 2021-02-03. ### New features. - (hail#9936) Deprecated `hl.null` in favor of `hl.missing` for naming consistency.; - (hail#9973) `hl.vep` now includes a `vep_proc_id` field to aid in debugging unexpected output.; - (hail#9839) Hail now eagerly deletes temporary files produced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument and a varargs of Boolean expressions.; - (hail#9816) `hl.pc_relate` now includes values on the diagonal of kinship, IBD-0, IBD-1, and IBD-2; - (hail#9736) Let NDArrayExpression.reshape take varargs instead of mandating a tuple.; - (hail#9766) `hl.export_vcf` now warns if INFO field names are invalid according to the VCF 4.3 spec. ### Bug fixes. - (hail#9976) Fixed `show()` repre",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:59254,Availability,error,error,59254,"pected output.; - (hail#9839) Hail now eagerly deletes temporary files produced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument and a varargs of Boolean expressions.; - (hail#9816) `hl.pc_relate` now includes values on the diagonal of kinship, IBD-0, IBD-1, and IBD-2; - (hail#9736) Let NDArrayExpression.reshape take varargs instead of mandating a tuple.; - (hail#9766) `hl.export_vcf` now warns if INFO field names are invalid according to the VCF 4.3 spec. ### Bug fixes. - (hail#9976) Fixed `show()` representation of Hail dictionaries. ### Performance improvements. - (hail#9909) Improved performance of `hl.experimental.densify` by approximately 35%. ---. ## Version 0.2.61. Released 2020-12-03. ### New features. - (hail#9749) Add or_error method to SwitchBuilder (`hl.switch`). ### Bug fixes. - (hail#9775) Fixed race condition leading to invalid intermediate files in VCF combiner.; - (hail#9751) Fix bug where constructing an array of empty structs causes type error.; - (hail#9731) Fix error and incorrect behavior when using `hl.import_matrix_table` with int64 data types. ---. ## Version 0.2.60. Released 2020-11-16. ### New features. - (hail#9696) `hl.experimental.export_elasticsearch` will now support Elasticsearch versions 6.8 - 7.x by default. ### Bug fixes. - (hail#9641) Showing hail ndarray data now always prints in correct order. ### hailctl dataproc. - (hail#9610) Support interval fields in `hailctl dataproc describe`. ---. ## Version 0.2.59. Released 2020-10-22. ### Datasets / Annotation DB. - (hail#9605) The Datasets API and the Annotation Database now support AWS, and users are required to specify what cloud platform they're using. ### hailctl dataproc. - (hail#9609) Fixed bug where `hailctl dataproc modify` did not correctly print corresponding `gcloud` command. ---. ## Version 0.2.58. Released 2020-10-08. ### New features. - (hail#9524) Hail should now be buildable using Spark 3.0.; - (hail#95",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:59280,Availability,error,error,59280,"ced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument and a varargs of Boolean expressions.; - (hail#9816) `hl.pc_relate` now includes values on the diagonal of kinship, IBD-0, IBD-1, and IBD-2; - (hail#9736) Let NDArrayExpression.reshape take varargs instead of mandating a tuple.; - (hail#9766) `hl.export_vcf` now warns if INFO field names are invalid according to the VCF 4.3 spec. ### Bug fixes. - (hail#9976) Fixed `show()` representation of Hail dictionaries. ### Performance improvements. - (hail#9909) Improved performance of `hl.experimental.densify` by approximately 35%. ---. ## Version 0.2.61. Released 2020-12-03. ### New features. - (hail#9749) Add or_error method to SwitchBuilder (`hl.switch`). ### Bug fixes. - (hail#9775) Fixed race condition leading to invalid intermediate files in VCF combiner.; - (hail#9751) Fix bug where constructing an array of empty structs causes type error.; - (hail#9731) Fix error and incorrect behavior when using `hl.import_matrix_table` with int64 data types. ---. ## Version 0.2.60. Released 2020-11-16. ### New features. - (hail#9696) `hl.experimental.export_elasticsearch` will now support Elasticsearch versions 6.8 - 7.x by default. ### Bug fixes. - (hail#9641) Showing hail ndarray data now always prints in correct order. ### hailctl dataproc. - (hail#9610) Support interval fields in `hailctl dataproc describe`. ---. ## Version 0.2.59. Released 2020-10-22. ### Datasets / Annotation DB. - (hail#9605) The Datasets API and the Annotation Database now support AWS, and users are required to specify what cloud platform they're using. ### hailctl dataproc. - (hail#9609) Fixed bug where `hailctl dataproc modify` did not correctly print corresponding `gcloud` command. ---. ## Version 0.2.58. Released 2020-10-08. ### New features. - (hail#9524) Hail should now be buildable using Spark 3.0.; - (hail#9549) Add `ignore_in_sample_frequency` flag to `hl.de_novo`.; - (hail#9501) C",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:61305,Availability,error,errors,61305," Configurable cache size for `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9474) Add `ArrayExpression.first` and `ArrayExpression.last`.; - (hail#9459) Add `StringExpression.join`, an analogue to Python's `str.join`.; - (hail#9398) Hail will now throw `HailUserError`s if the `or_error` branch of a `CaseBuilder` is hit. ### Bug fixes; - (hail#9503) NDArrays can now hold arbitrary data types, though only ndarrays of primitives can be collected to Python.; - (hail#9501) Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9424) `hl.experimental.writeBlockMatrices` didn't correctly support `overwrite` flag. ### Performance improvements; - (hail#9506) `hl.agg.ndarray_sum` will now do a tree aggregation. ### hailctl dataproc; - (hail#9502) Fix hailctl dataproc modify to install dependencies of the wheel file.; - (hail#9420) Add `--debug-mode` flag to `hailctl dataproc start`. This will enable heap dumps on OOM errors.; - (hail#9520) Add support for requester pays buckets to `hailctl dataproc describe`. ### Deprecations; - (hail#9482) `ArrayExpression.head` has been deprecated in favor of `ArrayExpression.first`. ---. ## Version 0.2.57. Released 2020-09-03. ### New features. - (hail#9343) Implement the KING method for relationship inference as `hl.methods.king`. ---. ## Version 0.2.56. Released 2020-08-31. ### New features. - (hail#9308) Add hl.enumerate in favor of hl.zip_with_index, which is now deprecated.; - (hail#9278) Add `ArrayExpression.grouped`, a function that groups hail arrays into fixed size subarrays. ### Performance. - (hail#9373)(hail#9374) Decrease amount of memory used when slicing or filtering along a single BlockMatrix dimension. ### Bug fixes. - (hail#9304) Fix crash in `run_combiner` caused by inputs where VCF lines and BGZ blocks align. ### hailctl dataproc. - (hail#9263) Add support for `--expiration-time` argument to `hailctl dataproc start`.; - (hail#92",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:62493,Availability,checkpoint,checkpoint,62493,"Version 0.2.57. Released 2020-09-03. ### New features. - (hail#9343) Implement the KING method for relationship inference as `hl.methods.king`. ---. ## Version 0.2.56. Released 2020-08-31. ### New features. - (hail#9308) Add hl.enumerate in favor of hl.zip_with_index, which is now deprecated.; - (hail#9278) Add `ArrayExpression.grouped`, a function that groups hail arrays into fixed size subarrays. ### Performance. - (hail#9373)(hail#9374) Decrease amount of memory used when slicing or filtering along a single BlockMatrix dimension. ### Bug fixes. - (hail#9304) Fix crash in `run_combiner` caused by inputs where VCF lines and BGZ blocks align. ### hailctl dataproc. - (hail#9263) Add support for `--expiration-time` argument to `hailctl dataproc start`.; - (hail#9263) Add support for `--no-max-idle`, `no-max-age`, `--max-age`, and `--expiration-time` to `hailctl dataproc --modify`. ---. ## Version 0.2.55. Released 2020-08-19. ### Performance. - (hail#9264) Table.checkpoint now uses a faster LZ4 compression scheme. ### Bug fixes. - (hail#9250) `hailctl dataproc` no longer uses deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved e",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:63518,Availability,error,error,63518,"mpression scheme. ### Bug fixes. - (hail#9250) `hailctl dataproc` no longer uses deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *row_id* in `hl.import_matrix_table`. ---. ## Version 0.2.50. Released 2020-07-23. ### Bug fixes. - (hail#9114) CHANGELOG: Fixed crash when using repeated calls ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:63595,Availability,error,error,63595,"es deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *row_id* in `hl.import_matrix_table`. ---. ## Version 0.2.50. Released 2020-07-23. ### Bug fixes. - (hail#9114) CHANGELOG: Fixed crash when using repeated calls to `hl.filter_intervals`. ### New features. - (hail#9101) Add `hl.nd.{concat, h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:64057,Availability,error,error,64057,"written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *row_id* in `hl.import_matrix_table`. ---. ## Version 0.2.50. Released 2020-07-23. ### Bug fixes. - (hail#9114) CHANGELOG: Fixed crash when using repeated calls to `hl.filter_intervals`. ### New features. - (hail#9101) Add `hl.nd.{concat, hstack, vstack}` to concatenate ndarrays.; - (hail#9105) Add `hl.nd.{eye, identity}` to create identity matrix ndarrays.; - (hail#9093) Add `hl.nd.inv` to invert ndarrays.; - (hail#9063) Add `BlockMatrix.tree_matmul` to improve matrix multiply performance with a large inner dimension. ---. ## Version 0.2.49. Released 2020-07-08. ### Bug fixes. - (hail#9058) Fixed memory leak affecting `Table.aggregate`, `MatrixTable.annotate_cols` aggregations, an",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:65779,Availability,error,error,65779," (hail#9063) Add `BlockMatrix.tree_matmul` to improve matrix multiply performance with a large inner dimension. ---. ## Version 0.2.49. Released 2020-07-08. ### Bug fixes. - (hail#9058) Fixed memory leak affecting `Table.aggregate`, `MatrixTable.annotate_cols` aggregations, and `hl.sample_qc`. ---. ## Version 0.2.48. Released 2020-07-07. ### Bug fixes. - (hail#9029) Fix crash when using `hl.agg.linreg` with no aggregated data records.; - (hail#9028) Fixed memory leak affecting `Table.annotate` with scans, `hl.experimental.densify`, and `Table.group_by` / `aggregate`.; - (hail#8978) Fixed aggregation behavior of `MatrixTable.{group_rows_by, group_cols_by}` to skip filtered entries. ---. ## Version 0.2.47. Released 2020-06-23. ### Bug fixes. - (hail#9009) Fix memory leak when counting per-partition. This caused excessive memory use in `BlockMatrix.write_from_entry_expr`, and likely in many other places.; - (hail#9006) Fix memory leak in `hl.export_bgen`.; - (hail#9001) Fix double close error that showed up on Azure Cloud. ## Version 0.2.46. Released 2020-06-17. ### Site; - (hail#8955) Natural language documentation search. ### Bug fixes; - (hail#8981) Fix BlockMatrix OOM triggered by the MatrixWriteBlockMatrix WriteBlocksRDD method. ---. ## Version 0.2.45. Release 2020-06-15. ### Bug fixes. - (hail#8948) Fix integer overflow error when reading files >2G with; `hl.import_plink`.; - (hail#8903) Fix Python type annotations for empty collection constructors and; `hl.shuffle`.; - (hail#8942) Refactored VCF combiner to support other GVCF schemas.; - (hail#8941) Fixed `hl.import_plink` with multiple data partitions. ### hailctl dataproc. - (hail#8946) Fix bug when a user specifies packages in `hailctl dataproc start`; that are also dependencies of the Hail package.; - (hail#8939) Support tuples in `hailctl dataproc describe`. ---. ## Version 0.2.44. Release 2020-06-06. ### New Features. - (hail#8914) `hl.export_vcf` can now export tables as sites-only VCFs.; - (hail#8894) Add",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:66125,Availability,error,error,66125,"g fixes. - (hail#9029) Fix crash when using `hl.agg.linreg` with no aggregated data records.; - (hail#9028) Fixed memory leak affecting `Table.annotate` with scans, `hl.experimental.densify`, and `Table.group_by` / `aggregate`.; - (hail#8978) Fixed aggregation behavior of `MatrixTable.{group_rows_by, group_cols_by}` to skip filtered entries. ---. ## Version 0.2.47. Released 2020-06-23. ### Bug fixes. - (hail#9009) Fix memory leak when counting per-partition. This caused excessive memory use in `BlockMatrix.write_from_entry_expr`, and likely in many other places.; - (hail#9006) Fix memory leak in `hl.export_bgen`.; - (hail#9001) Fix double close error that showed up on Azure Cloud. ## Version 0.2.46. Released 2020-06-17. ### Site; - (hail#8955) Natural language documentation search. ### Bug fixes; - (hail#8981) Fix BlockMatrix OOM triggered by the MatrixWriteBlockMatrix WriteBlocksRDD method. ---. ## Version 0.2.45. Release 2020-06-15. ### Bug fixes. - (hail#8948) Fix integer overflow error when reading files >2G with; `hl.import_plink`.; - (hail#8903) Fix Python type annotations for empty collection constructors and; `hl.shuffle`.; - (hail#8942) Refactored VCF combiner to support other GVCF schemas.; - (hail#8941) Fixed `hl.import_plink` with multiple data partitions. ### hailctl dataproc. - (hail#8946) Fix bug when a user specifies packages in `hailctl dataproc start`; that are also dependencies of the Hail package.; - (hail#8939) Support tuples in `hailctl dataproc describe`. ---. ## Version 0.2.44. Release 2020-06-06. ### New Features. - (hail#8914) `hl.export_vcf` can now export tables as sites-only VCFs.; - (hail#8894) Added `hl.shuffle` function to randomly permute arrays.; - (hail#8854) Add `composable` option to parallel text export for use with `gsutil compose`. ### Bug fixes. - (hail#8883) Fix an issue related to failures in pipelines with `force_bgz=True`. ### Performance. - (hail#8887) Substantially improve the performance of `hl.experimental.import_gtf`.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:66981,Availability,failure,failures,66981,"e MatrixWriteBlockMatrix WriteBlocksRDD method. ---. ## Version 0.2.45. Release 2020-06-15. ### Bug fixes. - (hail#8948) Fix integer overflow error when reading files >2G with; `hl.import_plink`.; - (hail#8903) Fix Python type annotations for empty collection constructors and; `hl.shuffle`.; - (hail#8942) Refactored VCF combiner to support other GVCF schemas.; - (hail#8941) Fixed `hl.import_plink` with multiple data partitions. ### hailctl dataproc. - (hail#8946) Fix bug when a user specifies packages in `hailctl dataproc start`; that are also dependencies of the Hail package.; - (hail#8939) Support tuples in `hailctl dataproc describe`. ---. ## Version 0.2.44. Release 2020-06-06. ### New Features. - (hail#8914) `hl.export_vcf` can now export tables as sites-only VCFs.; - (hail#8894) Added `hl.shuffle` function to randomly permute arrays.; - (hail#8854) Add `composable` option to parallel text export for use with `gsutil compose`. ### Bug fixes. - (hail#8883) Fix an issue related to failures in pipelines with `force_bgz=True`. ### Performance. - (hail#8887) Substantially improve the performance of `hl.experimental.import_gtf`. ---. ## Version 0.2.43. Released 2020-05-28. ### Bug fixes. - (hail#8867) Fix a major correctness bug ocurring when calling BlockMatrix.transpose on sparse, non-symmetric BlockMatrices.; - (hail#8876) Fixed ""ChannelClosedException: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutO",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68364,Availability,error,error,68364,"n: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unn",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68439,Availability,error,error,68439,"ures. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containin",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68814,Availability,error,errors,68814,"rray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and perform",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68885,Availability,error,errors,68885,"ntervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69764,Availability,reliab,reliability,69764,"; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:70548,Availability,fault,fault,70548,"ed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:70554,Availability,toler,tolerant,70554,"ed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:70835,Availability,error,error,70835,"prove installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bund",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:70937,Availability,error,error,70937,"larify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""up",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:71087,Availability,error,error,71087,"ocument describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#83",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:71356,Availability,error,error,71356,"ible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#8322) Fixed bug where `aggregate_rows` did not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_e",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:71418,Availability,error,error,71418,"ible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#8322) Fixed bug where `aggregate_rows` did not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_e",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:72036,Availability,error,error,72036,"ting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#8322) Fixed bug where `aggregate_rows` did not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_entries_by_col`.; - (hail#8326) Codegen infrastructure improvement resulting in ~3% overall speedup. ### hailctl dataproc. - (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New features. - (hail#8233) `StringExpression.matches` can now take a hail `StringExpression`, as opposed to only regular python strings.; - (hail#8198) Improved matrix multiplication interoperation between hail `NDArrayExpression` and numpy. ### Bug fixes. - (hail#8279) Fix a bug wher",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:73089,Availability,error,error,73089,"id not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_entries_by_col`.; - (hail#8326) Codegen infrastructure improvement resulting in ~3% overall speedup. ### hailctl dataproc. - (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New features. - (hail#8233) `StringExpression.matches` can now take a hail `StringExpression`, as opposed to only regular python strings.; - (hail#8198) Improved matrix multiplication interoperation between hail `NDArrayExpression` and numpy. ### Bug fixes. - (hail#8279) Fix a bug where `hl.agg.approx_cdf` failed inside of a `group_cols_by`.; - (hail#8275) Fix bad error message coming from `mt.make_table()` when keys are missing.; - (hail#8274) Fix memory leak in `hl.export_bgen`.; - (hail#8273) Fix segfault caused by `hl.agg.downsample` inside of an `array_agg` or `group_by`. ### hailctl dataproc. - (hail#8253) `hailctl dataproc` now supports new flags `--requester-pays-allow-all` and `--requester-pays-allow-buckets`. This will configure your hail installation to be able to read from requester pays buckets. The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:73254,Availability,down,downsample,73254,"antly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_entries_by_col`.; - (hail#8326) Codegen infrastructure improvement resulting in ~3% overall speedup. ### hailctl dataproc. - (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New features. - (hail#8233) `StringExpression.matches` can now take a hail `StringExpression`, as opposed to only regular python strings.; - (hail#8198) Improved matrix multiplication interoperation between hail `NDArrayExpression` and numpy. ### Bug fixes. - (hail#8279) Fix a bug where `hl.agg.approx_cdf` failed inside of a `group_cols_by`.; - (hail#8275) Fix bad error message coming from `mt.make_table()` when keys are missing.; - (hail#8274) Fix memory leak in `hl.export_bgen`.; - (hail#8273) Fix segfault caused by `hl.agg.downsample` inside of an `array_agg` or `group_by`. ### hailctl dataproc. - (hail#8253) `hailctl dataproc` now supports new flags `--requester-pays-allow-all` and `--requester-pays-allow-buckets`. This will configure your hail installation to be able to read from requester pays buckets. The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#817",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:74550,Availability,failure,failures,74550,"The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:74579,Availability,error,error,74579,"The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75496,Availability,error,error,75496,"luster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888)",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75587,Availability,error,error,75587,"- (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression p",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75800,Availability,error,error,75800,"hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans o",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:76229,Availability,error,errors,76229,"of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by re",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:77137,Availability,error,error,77137,"information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:77197,Availability,error,error,77197," array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:78116,Availability,error,errors,78116,"il#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ignored.; - (hail#7688) Added experimental support for `NDArrayExpression`s in new `hl.nd` module.; - (hail#7608) `hl.grep` now has a `show` argument that allows users to either print the results (default) or return a dictionary of the results. ### `hailctl dataproc`; - (hail#7717) Throw error when mispelling arguments instead of silently quitting. ---. ## Version 0.2.28. Released 2019-11-22. ### Critical correctness bug fix; - (hail#7588) Fixes a bug where filtering old matrix tables in newer versions of hail did not wo",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:78426,Availability,down,down,78426,"Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ignored.; - (hail#7688) Added experimental support for `NDArrayExpression`s in new `hl.nd` module.; - (hail#7608) `hl.grep` now has a `show` argument that allows users to either print the results (default) or return a dictionary of the results. ### `hailctl dataproc`; - (hail#7717) Throw error when mispelling arguments instead of silently quitting. ---. ## Version 0.2.28. Released 2019-11-22. ### Critical correctness bug fix; - (hail#7588) Fixes a bug where filtering old matrix tables in newer versions of hail did not work as expected. Please update from 0.2.27. ### Bug fixes; - (hail#7571) Don't set GQ to missing if PL is missing in `split_multi_hts`.; - (hail#7577) Fixed an optimizer bug. ### New Features; - (hail#7561) Added `hl.plot.visualize_missingness()` to plot missingness patterns for MatrixTables.; - (hail#7575) A",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:78847,Availability,error,error,78847,"`hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ignored.; - (hail#7688) Added experimental support for `NDArrayExpression`s in new `hl.nd` module.; - (hail#7608) `hl.grep` now has a `show` argument that allows users to either print the results (default) or return a dictionary of the results. ### `hailctl dataproc`; - (hail#7717) Throw error when mispelling arguments instead of silently quitting. ---. ## Version 0.2.28. Released 2019-11-22. ### Critical correctness bug fix; - (hail#7588) Fixes a bug where filtering old matrix tables in newer versions of hail did not work as expected. Please update from 0.2.27. ### Bug fixes; - (hail#7571) Don't set GQ to missing if PL is missing in `split_multi_hts`.; - (hail#7577) Fixed an optimizer bug. ### New Features; - (hail#7561) Added `hl.plot.visualize_missingness()` to plot missingness patterns for MatrixTables.; - (hail#7575) Added `hl.version()` to quickly check hail version. ### `hailctl dataproc`; - (hail#7586) `hailctl dataproc` now supports `--gcloud_configuration` option. ### Documentation; - (hail#7570) Hail has a cheatsheet for Tables now. ---. ## Version 0.2.27. Released 2019-11-15. ### New Features. - (hail#7379) Add `delimiter` argument to `hl.import_matrix_table`; - (hail#7389) Add `force` and `force_bgz` arguments to `hl.experimental.import_gtf`; - (hail#7386)(hail#73",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:80104,Availability,failure,failure,80104," hail did not work as expected. Please update from 0.2.27. ### Bug fixes; - (hail#7571) Don't set GQ to missing if PL is missing in `split_multi_hts`.; - (hail#7577) Fixed an optimizer bug. ### New Features; - (hail#7561) Added `hl.plot.visualize_missingness()` to plot missingness patterns for MatrixTables.; - (hail#7575) Added `hl.version()` to quickly check hail version. ### `hailctl dataproc`; - (hail#7586) `hailctl dataproc` now supports `--gcloud_configuration` option. ### Documentation; - (hail#7570) Hail has a cheatsheet for Tables now. ---. ## Version 0.2.27. Released 2019-11-15. ### New Features. - (hail#7379) Add `delimiter` argument to `hl.import_matrix_table`; - (hail#7389) Add `force` and `force_bgz` arguments to `hl.experimental.import_gtf`; - (hail#7386)(hail#7394) Add `{Table, MatrixTable}.tail`.; - (hail#7467) Added `hl.if_else` as an alias for `hl.cond`; deprecated `hl.cond`.; - (hail#7453) Add `hl.parse_int{32, 64}` and `hl.parse_float{32, 64}`, which can parse strings to numbers and return missing on failure.; - (hail#7475) Add `row_join_type` argument to `MatrixTable.union_cols` to support outer joins on rows. ### Bug fixes. - (hail#7479)(hail#7368)(hail#7402) Fix optimizer bugs.; - (hail#7506) Updated to latest htsjdk to resolve VCF parsing problems. ### `hailctl dataproc`. - (hail#7460) The Spark monitor widget now automatically collapses after a job completes. ---. ## Version 0.2.26. Released 2019-10-24. ### New Features; - (hail#7325) Add `string.reverse` function.; - (hail#7328) Add `string.translate` function.; - (hail#7344) Add `hl.reverse_complement` function.; - (hail#7306) Teach the VCF combiner to handle allele specific (`AS_*`) fields.; - (hail#7346) Add `hl.agg.approx_median` function. ### Bug Fixes; - (hail#7361) Fix `AD` calculation in `sparse_split_multi`. ### Performance Improvements; - (hail#7355) Improve performance of IR copying. ### File Format. - The native file format version is now 1.3.0. Older versions of Hail will not; b",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82036,Availability,checkpoint,checkpoints,82036,". - The native file format version is now 1.3.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.25. Released 2019-10-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable, Table}.describe`. Use this by passing the argument `widget=True`.; - (hail#7250) `{Table, MatrixTable, Expression}.summarize()` now summarizes elements of collections (arrays, sets, dicts).; - (hail#7271) Improve `hl.plot.qq` by increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance improvements; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:83040,Availability,error,error,83040,"tiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log state",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:83109,Availability,down,downstream,83109," of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once abou",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:83559,Availability,error,error,83559,"ter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improv",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:85410,Availability,error,errors,85410,"erformance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (hail#6903) Teach `BlockMatrix` how to `checkpoint`. ### Performance; - (hail#6895) Improved performance of `hl.import_bgen(...).count()`.; - (hail#6948) Fixed performance bug in `BlockMatrix` filtering functions.; - (hail#6943) Improved scaling of `Table.union`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ### `hailctl dataproc`; - (hail#6904) Added `--dry-run` option to `submit`.; - (hail#6951) Fixed `--max-idle` and `--max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed no",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:85663,Availability,checkpoint,checkpoint,85663,"s involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (hail#6903) Teach `BlockMatrix` how to `checkpoint`. ### Performance; - (hail#6895) Improved performance of `hl.import_bgen(...).count()`.; - (hail#6948) Fixed performance bug in `BlockMatrix` filtering functions.; - (hail#6943) Improved scaling of `Table.union`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ### `hailctl dataproc`; - (hail#6904) Added `--dry-run` option to `submit`.; - (hail#6951) Fixed `--max-idle` and `--max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.n",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:87277,Availability,error,error,87277,"emory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:90872,Availability,failure,failures,90872,"ization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not the full list of overlapping sample IDs.; - (hail#6583) Fixed `hl.plot.manhattan` for non-default reference genomes. ### Experimental. - (hail#6488) Exposed `table.multi_way_zip_join`. This takes a list of tables of; identical types, and zips them together into one table. ### File Format. - The native file format version is now 1.1.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. -----. ## Version 0.2.16. Released 2019-06-19. ### `hailctl`. - (hail#6357) Accommodated Google Dataproc bug causing cluster creation failures. ### Bug fixes. - (hail#6378) Fixed problem in how `entry_float_type` was being handled in `import_vcf`. -----. ## Version 0.2.15. Released 2019-06-14. After some infrastructural changes to our development process, we should be; getting back to frequent releases. ### `hailctl`. Starting in 0.2.15, `pip` installations of Hail come bundled with a command-; line tool, `hailctl`. This tool subsumes the functionality of `cloudtools`,; which is now deprecated. See the; [release thread on the forum](https://discuss.hail.is/t/new-command-line-utility-hailctl/981); for more information. ### New features. - (hail#5932)(hail#6115) `hl.import_bed` abd `hl.import_locus_intervals` now; accept keyword arguments to pass through to `hl.import_table`, which is used; internally. This permits parameters like `min_partitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `Mat",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:94022,Availability,down,downgrade,94022,"(hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `arr",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:95409,Availability,failure,failure,95409," version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will now produce a much more detailed; error message.; - (hail#5723) `hl.import_matrix_table` can now import a matrix table with no; columns.; - (hail#5724) `hl.rand_norm2d` samples from a two dimensional random normal. ### Bug fixes. - (hail#5885) Fix `Table.to_spark` in the presence of fields of tuples.; - (hail#5882)(hail#5886) Fix `BlockMatrix` conversion methods to correctly; handle filtered entries.; - (hail#5884)(hail#4874) Fix longstanding crash when reading Hail data files; under certain conditions.; - (hail#5855)(hail#5786) Fix `hl.mendel_errors` incorrectly reporting children counts in; the presence of entry filtering.; - (hail#5830)(hail#5835) Fix Nirvana support; - (hail#5773) Fix `hl.sample_qc` to use correct number of total rows when; calculating call rate.; - (hail#5763)(hail#5764) Fix `hl.agg.array_agg` to work inside; `mt.annotate_rows` and similar functions.; - (hail#5770) Hail now uses the correct unicode string encoding which resolves a; number of issues when a Table o",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:95477,Availability,error,error,95477," version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will now produce a much more detailed; error message.; - (hail#5723) `hl.import_matrix_table` can now import a matrix table with no; columns.; - (hail#5724) `hl.rand_norm2d` samples from a two dimensional random normal. ### Bug fixes. - (hail#5885) Fix `Table.to_spark` in the presence of fields of tuples.; - (hail#5882)(hail#5886) Fix `BlockMatrix` conversion methods to correctly; handle filtered entries.; - (hail#5884)(hail#4874) Fix longstanding crash when reading Hail data files; under certain conditions.; - (hail#5855)(hail#5786) Fix `hl.mendel_errors` incorrectly reporting children counts in; the presence of entry filtering.; - (hail#5830)(hail#5835) Fix Nirvana support; - (hail#5773) Fix `hl.sample_qc` to use correct number of total rows when; calculating call rate.; - (hail#5763)(hail#5764) Fix `hl.agg.array_agg` to work inside; `mt.annotate_rows` and similar functions.; - (hail#5770) Hail now uses the correct unicode string encoding which resolves a; number of issues when a Table o",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:98416,Availability,checkpoint,checkpoint,98416," MatrixTable, and Expression.; - (hail#5570) Add `hl.agg.approx_cdf` aggregator for approximate density calculation.; - (hail#5571) Add `log` parameter to `hl.plot.histogram`.; - (hail#5601) Add `hl.plot.joint_plot`, extend functionality of `hl.plot.scatter`.; - (hail#5608) Add LD score simulation framework.; - (hail#5628) Add `hl.experimental.full_outer_join_mt` for full outer joins on `MatrixTable`s. -----. ## Version 0.2.11. Released 2019-03-06. ### New features. - (hail#5374) Add default arguments to `hl.add_sequence` for running on GCP.; - (hail#5481) Added `sample_cols` method to `MatrixTable`.; - (hail#5501) Exposed `MatrixTable.unfilter_entries`. See `filter_entries` documentation for more information.; - (hail#5480) Added `n_cols` argument to `MatrixTable.head`.; - (hail#5529) Added `Table.{semi_join, anti_join}` and `MatrixTable.{semi_join_rows, semi_join_cols, anti_join_rows, anti_join_cols}`.; - (hail#5528) Added `{MatrixTable, Table}.checkpoint` methods as wrappers around `write` / `read_{matrix_table, table}`. ### Bug fixes. - (hail#5416) Resolved issue wherein VEP and certain regressions were recomputed on each use, rather than once.; - (hail#5419) Resolved issue with `import_vcf` `force_bgz` and file size checks.; - (hail#5427) Resolved issue with `Table.show` and dictionary field types.; - (hail#5468) Resolved ordering problem with `Expression.show` on key fields that are not the first key.; - (hail#5492) Fixed `hl.agg.collect` crashing when collecting `float32` values.; - (hail#5525) Fixed `hl.trio_matrix` crashing when `complete_trios` is `False`. -----. ## Version 0.2.10. Released 2019-02-15. ### New features. - (hail#5272) Added a new 'delimiter' option to Table.export.; - (hail#5251) Add utility aliases to `hl.plot` for `output_notebook` and `show`.; - (hail#5249) Add `histogram2d` function to `hl.plot` module.; - (hail#5247) Expose `MatrixTable.localize_entries` method for converting to a Table with an entries array.; - (hail#5300) Add new `fi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:101246,Availability,error,error,101246," (hail#5295) Fix crash in `Table.index` related to key field incompatibilities. -----. ## Version 0.2.9. Released 2019-01-30. ### New features. - (hail#5149) Added bitwise transformation functions: `hl.bit_{and, or, xor, not, lshift, rshift}`.; - (hail#5154) Added `hl.rbind` function, which is similar to `hl.bind` but expects a function as the last argument instead of the first. ### Performance improvements. - (hail#5107) Hail's Python interface generates tighter intermediate code, which should result in moderate performance improvements in many pipelines.; - (hail#5172) Fix unintentional performance deoptimization related to `Table.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `float32` as well as `float64`. ### Performance improvements. - (hail#5068) Improved optimization of `MatrixTable.count_cols`.; - (hail#5131) Fixed performance bug related to `hl.literal` on large values with missingness. ### Bug fixes. - (hail#5088) Fixed name separator in `MatrixTable.make_table`.; - (hail#5104) Fixed optimizer bug related to experimental functionality.; - (hail#5122) Fixed error constructing `Table` or `MatrixTable` objects with fields with certain character patterns like `$`. -----. ## Versi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:102136,Availability,error,error,102136,"eyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `float32` as well as `float64`. ### Performance improvements. - (hail#5068) Improved optimization of `MatrixTable.count_cols`.; - (hail#5131) Fixed performance bug related to `hl.literal` on large values with missingness. ### Bug fixes. - (hail#5088) Fixed name separator in `MatrixTable.make_table`.; - (hail#5104) Fixed optimizer bug related to experimental functionality.; - (hail#5122) Fixed error constructing `Table` or `MatrixTable` objects with fields with certain character patterns like `$`. -----. ## Version 0.2.7. Released 2019-01-03. ### New features. - (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_ind",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103110,Availability,error,error,103110,"ionality.; - (hail#5122) Fixed error constructing `Table` or `MatrixTable` objects with fields with certain character patterns like `$`. -----. ## Version 0.2.7. Released 2019-01-03. ### New features. - (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_stra",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103287,Availability,error,error,103287," (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of ba",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103322,Availability,toler,tolerance,103322," (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of ba",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103350,Availability,failure,failure,103350," (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of ba",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103384,Availability,error,error,103384,"export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103744,Availability,error,errors,103744,"`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed ass",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103905,Availability,error,error,103905,"ons, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104602,Availability,error,errors,104602,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104703,Availability,error,error,104703,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104759,Availability,error,error,104759,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104944,Availability,error,error,104944,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:105171,Availability,avail,available,105171,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:289,Deployability,release,released,289,"# Change Log And Version Policy. ## Python Version Compatibility Policy. Hail complies with [NumPy's compatibility policy](https://numpy.org/neps/nep-0029-deprecation_policy.html#implementation) on Python; versions. In particular, Hail officially supports:. - All minor versions of Python released 42 months prior to the project, and at minimum the two; latest minor versions. - All minor versions of numpy released in the 24 months prior to the project, and at minimum the; last three minor versions. ## Frequently Asked Questions. ### With a version like 0.x, is Hail ready for use in publications?. Yes. The [semantic versioning standard](https://semver.org) uses 0.x (development) versions to; refer to software that is either ""buggy"" or ""partial"". While we don't view; Hail as particularly buggy (especially compared to one-off untested; scripts pervasive in bioinformatics!), Hail 0.2 is a partial realization; of a larger vision. ### What is the difference between the Hail Python library version and the native file format version?. The Hail Python library version, the version you see on [PyPI](https://pypi.org/project/hail/), in; `pip`, or in `hl.version()` changes every time we release the Python library. The Hail native file; format version only changes when we change the format of Hail Table and MatrixTable files. If a; version of the Python library introduces a new native file format version, we note that in the; change log. All subsequent versions of the Python library can read the new file format version. The native file format changes much slower than the Python library version. It is not currently; possible to view the file format version of a Hail Table or MatrixTable. ### What stability is guaranteed?. The Hail file formats and Python API are backwards compatible. This means that a script developed to; run on Hail 0.2.5 should continue to work in every subsequent release within the 0.2 major version.; This also means any file written by python library versions 0.2",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:407,Deployability,release,released,407,"# Change Log And Version Policy. ## Python Version Compatibility Policy. Hail complies with [NumPy's compatibility policy](https://numpy.org/neps/nep-0029-deprecation_policy.html#implementation) on Python; versions. In particular, Hail officially supports:. - All minor versions of Python released 42 months prior to the project, and at minimum the two; latest minor versions. - All minor versions of numpy released in the 24 months prior to the project, and at minimum the; last three minor versions. ## Frequently Asked Questions. ### With a version like 0.x, is Hail ready for use in publications?. Yes. The [semantic versioning standard](https://semver.org) uses 0.x (development) versions to; refer to software that is either ""buggy"" or ""partial"". While we don't view; Hail as particularly buggy (especially compared to one-off untested; scripts pervasive in bioinformatics!), Hail 0.2 is a partial realization; of a larger vision. ### What is the difference between the Hail Python library version and the native file format version?. The Hail Python library version, the version you see on [PyPI](https://pypi.org/project/hail/), in; `pip`, or in `hl.version()` changes every time we release the Python library. The Hail native file; format version only changes when we change the format of Hail Table and MatrixTable files. If a; version of the Python library introduces a new native file format version, we note that in the; change log. All subsequent versions of the Python library can read the new file format version. The native file format changes much slower than the Python library version. It is not currently; possible to view the file format version of a Hail Table or MatrixTable. ### What stability is guaranteed?. The Hail file formats and Python API are backwards compatible. This means that a script developed to; run on Hail 0.2.5 should continue to work in every subsequent release within the 0.2 major version.; This also means any file written by python library versions 0.2",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:1191,Deployability,release,release,1191,"ation) on Python; versions. In particular, Hail officially supports:. - All minor versions of Python released 42 months prior to the project, and at minimum the two; latest minor versions. - All minor versions of numpy released in the 24 months prior to the project, and at minimum the; last three minor versions. ## Frequently Asked Questions. ### With a version like 0.x, is Hail ready for use in publications?. Yes. The [semantic versioning standard](https://semver.org) uses 0.x (development) versions to; refer to software that is either ""buggy"" or ""partial"". While we don't view; Hail as particularly buggy (especially compared to one-off untested; scripts pervasive in bioinformatics!), Hail 0.2 is a partial realization; of a larger vision. ### What is the difference between the Hail Python library version and the native file format version?. The Hail Python library version, the version you see on [PyPI](https://pypi.org/project/hail/), in; `pip`, or in `hl.version()` changes every time we release the Python library. The Hail native file; format version only changes when we change the format of Hail Table and MatrixTable files. If a; version of the Python library introduces a new native file format version, we note that in the; change log. All subsequent versions of the Python library can read the new file format version. The native file format changes much slower than the Python library version. It is not currently; possible to view the file format version of a Hail Table or MatrixTable. ### What stability is guaranteed?. The Hail file formats and Python API are backwards compatible. This means that a script developed to; run on Hail 0.2.5 should continue to work in every subsequent release within the 0.2 major version.; This also means any file written by python library versions 0.2.1 through 0.2.5 can be read by; 0.2.5. Forward compatibility of file formats and the Python API is not guaranteed. In particular, a new; file format version is only readable by library v",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:1899,Deployability,release,release,1899," 0.2 is a partial realization; of a larger vision. ### What is the difference between the Hail Python library version and the native file format version?. The Hail Python library version, the version you see on [PyPI](https://pypi.org/project/hail/), in; `pip`, or in `hl.version()` changes every time we release the Python library. The Hail native file; format version only changes when we change the format of Hail Table and MatrixTable files. If a; version of the Python library introduces a new native file format version, we note that in the; change log. All subsequent versions of the Python library can read the new file format version. The native file format changes much slower than the Python library version. It is not currently; possible to view the file format version of a Hail Table or MatrixTable. ### What stability is guaranteed?. The Hail file formats and Python API are backwards compatible. This means that a script developed to; run on Hail 0.2.5 should continue to work in every subsequent release within the 0.2 major version.; This also means any file written by python library versions 0.2.1 through 0.2.5 can be read by; 0.2.5. Forward compatibility of file formats and the Python API is not guaranteed. In particular, a new; file format version is only readable by library versions released after the file format. For; example, Python library version 0.2.119 introduces a new file format version: 1.7.0. All library; versions before 0.2.119, for example 0.2.118, *cannot* read file format version 1.7.0. All library; versions after and including 0.2.119 *can* read file format version 1.7.0. Each version of the Hail Python library can only write files using the latest file format version it; supports. **The hl.experimental package and other methods marked experimental in the docs are exempt from this; policy. Their functionality or even existence may change without notice. Please contact us if you; critically depend on experimental functionality.**. ## Version 0.2.1",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:2196,Deployability,release,released,2196,"anges every time we release the Python library. The Hail native file; format version only changes when we change the format of Hail Table and MatrixTable files. If a; version of the Python library introduces a new native file format version, we note that in the; change log. All subsequent versions of the Python library can read the new file format version. The native file format changes much slower than the Python library version. It is not currently; possible to view the file format version of a Hail Table or MatrixTable. ### What stability is guaranteed?. The Hail file formats and Python API are backwards compatible. This means that a script developed to; run on Hail 0.2.5 should continue to work in every subsequent release within the 0.2 major version.; This also means any file written by python library versions 0.2.1 through 0.2.5 can be read by; 0.2.5. Forward compatibility of file formats and the Python API is not guaranteed. In particular, a new; file format version is only readable by library versions released after the file format. For; example, Python library version 0.2.119 introduces a new file format version: 1.7.0. All library; versions before 0.2.119, for example 0.2.118, *cannot* read file format version 1.7.0. All library; versions after and including 0.2.119 *can* read file format version 1.7.0. Each version of the Hail Python library can only write files using the latest file format version it; supports. **The hl.experimental package and other methods marked experimental in the docs are exempt from this; policy. Their functionality or even existence may change without notice. Please contact us if you; critically depend on experimental functionality.**. ## Version 0.2.133. Released 2024-09-25. ### New Features. - (hail#14619) Teach `hailctl dataproc submit` to use the `--project` argument as an argument to `gcloud dataproc` rather than the submitted script. ### Bug Fixes. - (hail#14673) Fix typo in Interpret rule for `TableAggregate`.; - (hail#14697",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:3889,Deployability,pipeline,pipelines,3889," 2024-09-25. ### New Features. - (hail#14619) Teach `hailctl dataproc submit` to use the `--project` argument as an argument to `gcloud dataproc` rather than the submitted script. ### Bug Fixes. - (hail#14673) Fix typo in Interpret rule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. W",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4035,Deployability,pipeline,pipelines,4035,"ent to `gcloud dataproc` rather than the submitted script. ### Bug Fixes. - (hail#14673) Fix typo in Interpret rule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4104,Deployability,configurat,configuration,4104,"ule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4149,Deployability,pipeline,pipelines,4149,"ule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4524,Deployability,install,installed,4524,"oc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4570,Deployability,upgrade,upgraded,4570,"oc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4974,Deployability,update,update,4974,"ug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5007,Deployability,install,installing,5007,"ug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5049,Deployability,install,install-gcs-connector,5049,"xpressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5097,Deployability,update,update,5097,"nfiguration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haensz",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5112,Deployability,install,installing,5112,"nfiguration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haensz",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5201,Deployability,configurat,configuration,5201," Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5302,Deployability,upgrade,upgrade,5302,"r now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (hail#14393) `hail` depends on `protobuf` no longer; users may choose",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:9358,Deployability,pipeline,pipeline,9358,"om the Annotation DB or Datasets API. We must make this change because [reading from a; multi-regional bucket into a regional VM is no longer; free](https://cloud.google.com/storage/pricing-announce#network). Unfortunately, cost constraints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`, `Table.annotate_globals`,; `Table.select_globals`, `Table.transmute_globals`, `Table.transmute`, `Table.annotate`, and; `Table.filter`.; - (hail#14242) Add examples to `Table.sample`, `Table.head`, and `Table.semi`_join. ### New Features. - (hail#14206) Introduce `hailctl config set http/timeout_in_seconds` which Batch and QoB users can; use to increase the timeout on their laptops. Laptops tend to have flaky internet connections and; a timeout of 300 seconds produces a more robust experience.; - (hail#14178) Reduce VDS Combiner runtime slightly by computing the maximum ref block length; without executing the combination pipeline twice.; - (hail#14207) VDS Combiner now verifies that every GVCF path and sample name is unique. ### Bug Fixes. - (hail#14300) Require orjson<3.9.12 to avoid a segfault introduced in orjson 3.9.12; - (hail#14071) Use indexed VEP cache files for GRCh38 on both dataproc and QoB.; - (hail#14232) Allow use of large numbers of fields on a table without triggering; `ClassTooLargeException: Class too large:`.; - (hail#14246)(hail#14245) Fix a bug, introduced in 0.2.114, in which `Table.multi_way_zip_join` and; `Table.aggregate_by_key` could throw ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially different from the desired; number of output partitions.; - (hail#14202) Support coercing `{}` (the empty dictionary) into any Struct type (with all missing; fields).; - (hail#14239) Remove an erroneous statement from the MatrixTable tutorial.; - (hail#14176) ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:10993,Deployability,upgrade,upgrade,10993,"more of the tables had a number of partitions substantially different from the desired; number of output partitions.; - (hail#14202) Support coercing `{}` (the empty dictionary) into any Struct type (with all missing; fields).; - (hail#14239) Remove an erroneous statement from the MatrixTable tutorial.; - (hail#14176) `hailtop.fs.ls` can now list a bucket, e.g. `hailtop.fs.ls(""gs://my-bucket"")`.; - (hail#14258) Fix `import_avro` to not raise `NullPointerException` in certain rare cases; (e.g. when using `_key_by_assert_sorted`).; - (hail#14285) Fix a broken link in the MatrixTable tutorial. ### Deprecations. - (hail#14293) Support for the `hail-az://` scheme, deprecated in 0.2.116, is now gone. Please use; the standard `https://ACCOUNT.blob.core.windows.net/CONTAINER/PATH`. ## Version 0.2.127. Released 2024-01-12. If you have an Apple M1 laptop, verify that. ```; file $JAVA_HOME/bin/java; ```. returns a message including the phrase ""arm64"". If it instead includes the phrase ""x86_64"" then you; must upgrade to a new version of Java. You may find such a version of Java; [here](https://www.azul.com/downloads/?os=macos&architecture=arm-64-bit&package=jre#zulu). ### New Features. - (hail#14093) `hailctl dataproc` now creates clusters using Dataproc version 2.1.33. It previously used version 2.1.2.; - (hail#13617) Query-on-Batch now supports joining two tables keyed by intervals.; - (hail#13795)(hail#13567) Enable passing a requester pays configuration to `hailtop.fs.open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:11436,Deployability,configurat,configuration,11436,"t raise `NullPointerException` in certain rare cases; (e.g. when using `_key_by_assert_sorted`).; - (hail#14285) Fix a broken link in the MatrixTable tutorial. ### Deprecations. - (hail#14293) Support for the `hail-az://` scheme, deprecated in 0.2.116, is now gone. Please use; the standard `https://ACCOUNT.blob.core.windows.net/CONTAINER/PATH`. ## Version 0.2.127. Released 2024-01-12. If you have an Apple M1 laptop, verify that. ```; file $JAVA_HOME/bin/java; ```. returns a message including the phrase ""arm64"". If it instead includes the phrase ""x86_64"" then you; must upgrade to a new version of Java. You may find such a version of Java; [here](https://www.azul.com/downloads/?os=macos&architecture=arm-64-bit&package=jre#zulu). ### New Features. - (hail#14093) `hailctl dataproc` now creates clusters using Dataproc version 2.1.33. It previously used version 2.1.2.; - (hail#13617) Query-on-Batch now supports joining two tables keyed by intervals.; - (hail#13795)(hail#13567) Enable passing a requester pays configuration to `hailtop.fs.open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now support",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:12318,Deployability,pipeline,pipelines,12318,"2.1.2.; - (hail#13617) Query-on-Batch now supports joining two tables keyed by intervals.; - (hail#13795)(hail#13567) Enable passing a requester pays configuration to `hailtop.fs.open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now supports identity_by_descent on Apple M1 and M2 chips; however, your Java installation must be an arm64 installation. Using x86_64 Java with Hail on Apple M1 or M2 will cause SIGILL errors. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM.; - (hail#14022) Fix (hail#13937) caused by faulty library code in the Google Cloud Storage API Java client library.; - (hail#13812) Permit `hailctl batch submit` to accept relative paths. Fix (hail#13785).; - (hail#13885) Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary.; - (hail#14127) `hailctl dataproc start ... --dry-run` now uses shell escapes such that, after copied and pasted into a shell, the `gcloud` command works as ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:12486,Deployability,install,installation,12486,"open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now supports identity_by_descent on Apple M1 and M2 chips; however, your Java installation must be an arm64 installation. Using x86_64 Java with Hail on Apple M1 or M2 will cause SIGILL errors. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM.; - (hail#14022) Fix (hail#13937) caused by faulty library code in the Google Cloud Storage API Java client library.; - (hail#13812) Permit `hailctl batch submit` to accept relative paths. Fix (hail#13785).; - (hail#13885) Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary.; - (hail#14127) `hailctl dataproc start ... --dry-run` now uses shell escapes such that, after copied and pasted into a shell, the `gcloud` command works as expected.; - (hail#14062) Fix (hail#14052) which caused incorrect results for identity by descent in Query-on-Batch.; - (hail#14122) Ensure that stack traces are transmitted from w",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:12516,Deployability,install,installation,12516,"open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now supports identity_by_descent on Apple M1 and M2 chips; however, your Java installation must be an arm64 installation. Using x86_64 Java with Hail on Apple M1 or M2 will cause SIGILL errors. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM.; - (hail#14022) Fix (hail#13937) caused by faulty library code in the Google Cloud Storage API Java client library.; - (hail#13812) Permit `hailctl batch submit` to accept relative paths. Fix (hail#13785).; - (hail#13885) Hail Query-on-Batch previously used Class A Operations for all interaction with blobs. This change ensures that QoB only uses Class A Operations when necessary.; - (hail#14127) `hailctl dataproc start ... --dry-run` now uses shell escapes such that, after copied and pasted into a shell, the `gcloud` command works as expected.; - (hail#14062) Fix (hail#14052) which caused incorrect results for identity by descent in Query-on-Batch.; - (hail#14122) Ensure that stack traces are transmitted from w",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14749,Deployability,pipeline,pipelines,14749," to set new default references usually shortly after `hl.init`. ## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by i",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15148,Deployability,pipeline,pipelines,15148,"h zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc N",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15654,Deployability,pipeline,pipelines,15654,"d of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:16010,Deployability,update,update,16010,"rgument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc submit` now expands `~` in the `--files` and `--pyfiles` arguments. - (hail#13797) Fix (hail#13756). Operations that collect large results such as `to_pandas` may require up to 3x less memory. - (hail#13826) Fix (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:17354,Deployability,install,installation,17354,"h manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc submit` now expands `~` in the `--files` and `--pyfiles` arguments. - (hail#13797) Fix (hail#13756). Operations that collect large results such as `to_pandas` may require up to 3x less memory. - (hail#13826) Fix (hail#13793). Ensure `hailctl describe -u` overrides the `gcs_requester_pays/project` config variable. - (hail#13814) Fix (hail#13757). Pipelines that are memory-bound by copious use of `hl.literal`, such as `hl.vds.filter_intervals`, require substantially less memory. - (hail#13894) Fix (hail#13837) in which Hail could break a Spark installation if the Hail JAR appears on the classpath before the Scala JARs. - (hail#13919) Fix (hail#13915) which prevented using a glob pattern in `hl.import_vcf`. ## Version 0.2.124. Released 2023-09-21. ### New Features. - (hail#13608) Change default behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.output_notebook and/or setting plotly.io.renderers.default = 'iframe' is no longer necessary). ### Bug Fixes; - (hail#13634) Fix a bug which caused Query-on-Batch pipelines with a large number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:18234,Deployability,pipeline,pipelines,18234,"substantially less memory. - (hail#13894) Fix (hail#13837) in which Hail could break a Spark installation if the Hail JAR appears on the classpath before the Scala JARs. - (hail#13919) Fix (hail#13915) which prevented using a glob pattern in `hl.import_vcf`. ## Version 0.2.124. Released 2023-09-21. ### New Features. - (hail#13608) Change default behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.output_notebook and/or setting plotly.io.renderers.default = 'iframe' is no longer necessary). ### Bug Fixes; - (hail#13634) Fix a bug which caused Query-on-Batch pipelines with a large number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain confi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:18412,Deployability,pipeline,pipelines,18412,"classpath before the Scala JARs. - (hail#13919) Fix (hail#13915) which prevented using a glob pattern in `hl.import_vcf`. ## Version 0.2.124. Released 2023-09-21. ### New Features. - (hail#13608) Change default behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.output_notebook and/or setting plotly.io.renderers.default = 'iframe' is no longer necessary). ### Bug Fixes; - (hail#13634) Fix a bug which caused Query-on-Batch pipelines with a large number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom ca",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:19256,Deployability,configurat,configuration,19256,"e number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom call fields via the `call_fields`; parameter.; - (hail#13224) `hailctl config get`, `set`, and `unset` now support shell auto-completion. Run; `hailctl --install-completion zsh` to install the auto-completion for `zsh`. You must already have; completion enabled for `zsh`.; - (hail#13279) Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.impor",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:19551,Deployability,install,install-completion,19551,"olor_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom call fields via the `call_fields`; parameter.; - (hail#13224) `hailctl config get`, `set`, and `unset` now support shell auto-completion. Run; `hailctl --install-completion zsh` to install the auto-completion for `zsh`. You must already have; completion enabled for `zsh`.; - (hail#13279) Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) I",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:19578,Deployability,install,install,19578,"olor_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom call fields via the `call_fields`; parameter.; - (hail#13224) `hailctl config get`, `set`, and `unset` now support shell auto-completion. Run; `hailctl --install-completion zsh` to install the auto-completion for `zsh`. You must already have; completion enabled for `zsh`.; - (hail#13279) Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) I",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:20657,Deployability,pipeline,pipelines,20657," Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hail",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:21266,Deployability,pipeline,pipelines,21266,"rt_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hailctl; option.; - (hail#13422) `hailtop.hail_frozenlist.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickle-able.; - (hail#13505) Fix bug introduced in 0.2.117 by commit `c9de81108` which prevented the passing of; keyword arguments to Python jobs. This manifested as ""ValueError: too many values to unpack"".; - (hail#13536) Fixed (hail#13535) which prevented the use of Python jobs when the client (e.g. your; laptop) Python version is 3.11 or later.; - (hail#13434) In QoB, Hail's file systems now correctly list all files in a directory, n",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:22735,Deployability,pipeline,pipelines,22735,"t.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickle-able.; - (hail#13505) Fix bug introduced in 0.2.117 by commit `c9de81108` which prevented the passing of; keyword arguments to Python jobs. This manifested as ""ValueError: too many values to unpack"".; - (hail#13536) Fixed (hail#13535) which prevented the use of Python jobs when the client (e.g. your; laptop) Python version is 3.11 or later.; - (hail#13434) In QoB, Hail's file systems now correctly list all files in a directory, not just the; first 1000. This could manifest in an `import_table` or `import_vcf` which used a glob; expression. In such a case, only the first 1000 files would have been included in the resulting; Table or MatrixTable.; - (hail#13550) `hl.utils.range_table(n)` now supports all valid 32-bit signed integer values of `n`.; - (hail#13500) In Query-on-Batch, the client-side Python code will not try to list every job when a; QoB batch fails. This could take hours for long-running pipelines or pipelines with many; partitions. ### Deprecations. - (hail#13275) Hail no longer officially supports Python 3.8.; - (hail#13508) The `n` parameter of `MatrixTable.tail` is deprecated in favor of a new `n_rows`; parameter. ## Version 0.2.120. Released 2023-07-27. ### New Features; - (hail#13206) The VDS Combiner now works in Query-on-Batch. ### Bug Fixes; - (hail#13313) Fix bug introduced in 0.2.119 which causes a serialization error when using; Query-on-Spark to read a VCF which is sorted by locus, with split multi-allelics, in which the; records sharing a single locus do not appear in the dictionary ordering of their alternate; alleles.; - (hail#13264) Fix bug which ignored the `partition_hint` of a Table group-by-and-aggregate.; - (hail#13239) Fix bug which ignored the `HAIL_BATCH_REGIONS` argument when determining in which; regions to schedule jobs when using Query-on-Batch.; - (hail#13253) Improve `hadoop_ls` and `hfs.ls` to quickly list globbed files in a directory. The;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:22748,Deployability,pipeline,pipelines,22748,"t.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickle-able.; - (hail#13505) Fix bug introduced in 0.2.117 by commit `c9de81108` which prevented the passing of; keyword arguments to Python jobs. This manifested as ""ValueError: too many values to unpack"".; - (hail#13536) Fixed (hail#13535) which prevented the use of Python jobs when the client (e.g. your; laptop) Python version is 3.11 or later.; - (hail#13434) In QoB, Hail's file systems now correctly list all files in a directory, not just the; first 1000. This could manifest in an `import_table` or `import_vcf` which used a glob; expression. In such a case, only the first 1000 files would have been included in the resulting; Table or MatrixTable.; - (hail#13550) `hl.utils.range_table(n)` now supports all valid 32-bit signed integer values of `n`.; - (hail#13500) In Query-on-Batch, the client-side Python code will not try to list every job when a; QoB batch fails. This could take hours for long-running pipelines or pipelines with many; partitions. ### Deprecations. - (hail#13275) Hail no longer officially supports Python 3.8.; - (hail#13508) The `n` parameter of `MatrixTable.tail` is deprecated in favor of a new `n_rows`; parameter. ## Version 0.2.120. Released 2023-07-27. ### New Features; - (hail#13206) The VDS Combiner now works in Query-on-Batch. ### Bug Fixes; - (hail#13313) Fix bug introduced in 0.2.119 which causes a serialization error when using; Query-on-Spark to read a VCF which is sorted by locus, with split multi-allelics, in which the; records sharing a single locus do not appear in the dictionary ordering of their alternate; alleles.; - (hail#13264) Fix bug which ignored the `partition_hint` of a Table group-by-and-aggregate.; - (hail#13239) Fix bug which ignored the `HAIL_BATCH_REGIONS` argument when determining in which; regions to schedule jobs when using Query-on-Batch.; - (hail#13253) Improve `hadoop_ls` and `hfs.ls` to quickly list globbed files in a directory. The;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:25591,Deployability,pipeline,pipelines,25591,"method, for finding eigenvalues; of symmetric matrices (""h"" is for Hermitian, the complex analogue of; symmetric). ### Bug Fixes; - (hail#13184) The `vds.to_dense_mt` no longer densifies past the end of; contig boundaries. A logic bug in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference block of the contig.; - (hail#13173) Fix globbing in scala blob storage filesystem implementations. ### File Format. - The native file format version is now 1.7.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.118. Released 2023-06-13. ### New Features. - (hail#13140) Enable `hail-az` and Azure Blob Storage `https` URLs to contain SAS tokens to enable bearer-auth style file access to Azure storage.; - (hail#13129) Allow subnet to be passed through to gcloud in hailctl. ### Bug Fixes. - (hail#13126) Query-on-Batch pipelines with one partition are now retried when they encounter transient errors.; - (hail#13113) `hail.ggplot.geom_point` now displays a legend group for a column even when it has only one value in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:25859,Deployability,pipeline,pipelines,25859,"g in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference block of the contig.; - (hail#13173) Fix globbing in scala blob storage filesystem implementations. ### File Format. - The native file format version is now 1.7.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.118. Released 2023-06-13. ### New Features. - (hail#13140) Enable `hail-az` and Azure Blob Storage `https` URLs to contain SAS tokens to enable bearer-auth style file access to Azure storage.; - (hail#13129) Allow subnet to be passed through to gcloud in hailctl. ### Bug Fixes. - (hail#13126) Query-on-Batch pipelines with one partition are now retried when they encounter transient errors.; - (hail#13113) `hail.ggplot.geom_point` now displays a legend group for a column even when it has only one value in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional t",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:26617,Deployability,pipeline,pipelines,26617,"rtition are now retried when they encounter transient errors.; - (hail#13113) `hail.ggplot.geom_point` now displays a legend group for a column even when it has only one value in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail no",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:28615,Deployability,release,release,28615,"; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.; - (hail#12917) The `hail-az` scheme for referencing blobs in ABS is now deprecated and will be removed in an upcoming release. ### Bug Fixes. - (hail#12913) Fixed bug in `hail.ggplot` where all legend entries would have the same text if one column had exactly one value for all rows and was mapped to either the `shape` or the `color` aesthetic for `geom_point`.; - (hail#12901) `hl.Struct` now has a correct and useful implementation of `pprint`. ---. ## Version 0.2.115. Released 2023-04-25. ### New Features. - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works; for local fs, gs, s3 and abs. This can be used by `import hailtop.fs as hfs` but has also; replaced the underlying implementation of the `hl.hadoop_*` methods. This means that the; `hl.hadoop_*` methods now support these additional blob storage providers.; - (hail#12917) ABS blob URIs in the form of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported when running in Azure. ### Deprecations; - (hail#12917) The `hail-az` s",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:29677,Deployability,release,release,29677,"ed in an upcoming release. ### Bug Fixes. - (hail#12913) Fixed bug in `hail.ggplot` where all legend entries would have the same text if one column had exactly one value for all rows and was mapped to either the `shape` or the `color` aesthetic for `geom_point`.; - (hail#12901) `hl.Struct` now has a correct and useful implementation of `pprint`. ---. ## Version 0.2.115. Released 2023-04-25. ### New Features. - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works; for local fs, gs, s3 and abs. This can be used by `import hailtop.fs as hfs` but has also; replaced the underlying implementation of the `hl.hadoop_*` methods. This means that the; `hl.hadoop_*` methods now support these additional blob storage providers.; - (hail#12917) ABS blob URIs in the form of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported when running in Azure. ### Deprecations; - (hail#12917) The `hail-az` scheme for referencing ABS blobs in Azure is deprecated in favor of the `https` scheme and will be removed in a future release. ### Bug Fixes. - (hail#12919) An interactive hail session is no longer unusable after hitting CTRL-C during a batch execution in Query-on-Batch; - (hail#12913) Fixed bug in `hail.ggplot` where all legend entries would have the same text if one column had exactly one value for all rows and was mapped to either the `shape` or the `color` aesthetic for `geom_point`. ---. ## Version 0.2.114. Released 2023-04-19. ### New Features. - (hail#12880) Added `hl.vds.store_ref_block_max_len` to patch old VDSes to make interval filtering faster. ### Bug Fixes. - (hail#12860) Fixed memory leak in shuffles in Query-on-Batch. ---. ## Version 0.2.113. Released 2023-04-07. ### New Features. - (hail#12798) Query-on-Batch now supports `BlockMatrix.write(..., stage_locally=True)`.; - (hail#12793) Query-on-Batch now supports `hl.poisson_regression_rows`.; - (hail#12801) Hitting CTRL-C while interactively using Query-on-Ba",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:30173,Deployability,patch,patch,30173,"lso; replaced the underlying implementation of the `hl.hadoop_*` methods. This means that the; `hl.hadoop_*` methods now support these additional blob storage providers.; - (hail#12917) ABS blob URIs in the form of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported when running in Azure. ### Deprecations; - (hail#12917) The `hail-az` scheme for referencing ABS blobs in Azure is deprecated in favor of the `https` scheme and will be removed in a future release. ### Bug Fixes. - (hail#12919) An interactive hail session is no longer unusable after hitting CTRL-C during a batch execution in Query-on-Batch; - (hail#12913) Fixed bug in `hail.ggplot` where all legend entries would have the same text if one column had exactly one value for all rows and was mapped to either the `shape` or the `color` aesthetic for `geom_point`. ---. ## Version 0.2.114. Released 2023-04-19. ### New Features. - (hail#12880) Added `hl.vds.store_ref_block_max_len` to patch old VDSes to make interval filtering faster. ### Bug Fixes. - (hail#12860) Fixed memory leak in shuffles in Query-on-Batch. ---. ## Version 0.2.113. Released 2023-04-07. ### New Features. - (hail#12798) Query-on-Batch now supports `BlockMatrix.write(..., stage_locally=True)`.; - (hail#12793) Query-on-Batch now supports `hl.poisson_regression_rows`.; - (hail#12801) Hitting CTRL-C while interactively using Query-on-Batch cancels the underlying batch.; - (hail#12810) `hl.array` can now convert 1-d ndarrays into the equivalent list.; - (hail#12851) `hl.variant_qc` no longer requires a locus field.; - (hail#12816) In Query-on-Batch, `hl.logistic_regression('firth', ...)` is now supported.; - (hail#12854) In Query-on-Batch, simple pipelines with large numbers of partitions should be substantially faster. ### Bug Fixes. - (hail#12783) Fixed bug where logs were not properly transmitted to Python.; - (hail#12812) Fixed bug where `Table/MT._calculate_new_partitions` returned unbalanced intervals with",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:30914,Deployability,pipeline,pipelines,30914," column had exactly one value for all rows and was mapped to either the `shape` or the `color` aesthetic for `geom_point`. ---. ## Version 0.2.114. Released 2023-04-19. ### New Features. - (hail#12880) Added `hl.vds.store_ref_block_max_len` to patch old VDSes to make interval filtering faster. ### Bug Fixes. - (hail#12860) Fixed memory leak in shuffles in Query-on-Batch. ---. ## Version 0.2.113. Released 2023-04-07. ### New Features. - (hail#12798) Query-on-Batch now supports `BlockMatrix.write(..., stage_locally=True)`.; - (hail#12793) Query-on-Batch now supports `hl.poisson_regression_rows`.; - (hail#12801) Hitting CTRL-C while interactively using Query-on-Batch cancels the underlying batch.; - (hail#12810) `hl.array` can now convert 1-d ndarrays into the equivalent list.; - (hail#12851) `hl.variant_qc` no longer requires a locus field.; - (hail#12816) In Query-on-Batch, `hl.logistic_regression('firth', ...)` is now supported.; - (hail#12854) In Query-on-Batch, simple pipelines with large numbers of partitions should be substantially faster. ### Bug Fixes. - (hail#12783) Fixed bug where logs were not properly transmitted to Python.; - (hail#12812) Fixed bug where `Table/MT._calculate_new_partitions` returned unbalanced intervals with whole-stage code generation runtime.; - (hail#12839) Fixed `hailctl dataproc` jupyter notebooks to be compatible with Spark 3.3, which have been broken since 0.2.110.; - (hail#12855) In Query-on-Batch, allow writing to requester pays buckets, which was broken before this release. ---. ## Version 0.2.112. Released 2023-03-15. ### Bug Fixes. - (hail#12784) Removed an internal caching mechanism in Query on Batch that caused stalls in pipelines with large intermediates. ---. ## Version 0.2.111. Released 2023-03-13. ### New Features. - (hail#12581) In Query on Batch, users can specify which regions to have jobs run in. ### Bug Fixes. - (hail#12772) Fix `hailctl hdinsight submit` to pass args to the files. ---. ## Version 0.2.110. Released 2",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:31457,Deployability,release,release,31457,"s `BlockMatrix.write(..., stage_locally=True)`.; - (hail#12793) Query-on-Batch now supports `hl.poisson_regression_rows`.; - (hail#12801) Hitting CTRL-C while interactively using Query-on-Batch cancels the underlying batch.; - (hail#12810) `hl.array` can now convert 1-d ndarrays into the equivalent list.; - (hail#12851) `hl.variant_qc` no longer requires a locus field.; - (hail#12816) In Query-on-Batch, `hl.logistic_regression('firth', ...)` is now supported.; - (hail#12854) In Query-on-Batch, simple pipelines with large numbers of partitions should be substantially faster. ### Bug Fixes. - (hail#12783) Fixed bug where logs were not properly transmitted to Python.; - (hail#12812) Fixed bug where `Table/MT._calculate_new_partitions` returned unbalanced intervals with whole-stage code generation runtime.; - (hail#12839) Fixed `hailctl dataproc` jupyter notebooks to be compatible with Spark 3.3, which have been broken since 0.2.110.; - (hail#12855) In Query-on-Batch, allow writing to requester pays buckets, which was broken before this release. ---. ## Version 0.2.112. Released 2023-03-15. ### Bug Fixes. - (hail#12784) Removed an internal caching mechanism in Query on Batch that caused stalls in pipelines with large intermediates. ---. ## Version 0.2.111. Released 2023-03-13. ### New Features. - (hail#12581) In Query on Batch, users can specify which regions to have jobs run in. ### Bug Fixes. - (hail#12772) Fix `hailctl hdinsight submit` to pass args to the files. ---. ## Version 0.2.110. Released 2023-03-08. ### New Features. - (hail#12643) In Query on Batch, `hl.skat(..., logistic=True)` is now supported.; - (hail#12643) In Query on Batch, `hl.liftover` is now supported.; - (hail#12629) In Query on Batch, `hl.ibd` is now supported.; - (hail#12722) Add `hl.simulate_random_mating` to generate a population from founders under the assumption of random mating.; - (hail#12701) Query on Spark now officially supports Spark 3.3.0 and Dataproc 2.1.x. ### Performance Improveme",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:31620,Deployability,pipeline,pipelines,31620,"ry-on-Batch cancels the underlying batch.; - (hail#12810) `hl.array` can now convert 1-d ndarrays into the equivalent list.; - (hail#12851) `hl.variant_qc` no longer requires a locus field.; - (hail#12816) In Query-on-Batch, `hl.logistic_regression('firth', ...)` is now supported.; - (hail#12854) In Query-on-Batch, simple pipelines with large numbers of partitions should be substantially faster. ### Bug Fixes. - (hail#12783) Fixed bug where logs were not properly transmitted to Python.; - (hail#12812) Fixed bug where `Table/MT._calculate_new_partitions` returned unbalanced intervals with whole-stage code generation runtime.; - (hail#12839) Fixed `hailctl dataproc` jupyter notebooks to be compatible with Spark 3.3, which have been broken since 0.2.110.; - (hail#12855) In Query-on-Batch, allow writing to requester pays buckets, which was broken before this release. ---. ## Version 0.2.112. Released 2023-03-15. ### Bug Fixes. - (hail#12784) Removed an internal caching mechanism in Query on Batch that caused stalls in pipelines with large intermediates. ---. ## Version 0.2.111. Released 2023-03-13. ### New Features. - (hail#12581) In Query on Batch, users can specify which regions to have jobs run in. ### Bug Fixes. - (hail#12772) Fix `hailctl hdinsight submit` to pass args to the files. ---. ## Version 0.2.110. Released 2023-03-08. ### New Features. - (hail#12643) In Query on Batch, `hl.skat(..., logistic=True)` is now supported.; - (hail#12643) In Query on Batch, `hl.liftover` is now supported.; - (hail#12629) In Query on Batch, `hl.ibd` is now supported.; - (hail#12722) Add `hl.simulate_random_mating` to generate a population from founders under the assumption of random mating.; - (hail#12701) Query on Spark now officially supports Spark 3.3.0 and Dataproc 2.1.x. ### Performance Improvements. - (hail#12679) In Query on Batch, `hl.balding_nichols_model` is slightly faster. Also added `hl.utils.genomic_range_table` to quickly create a table keyed by locus. ### Bug Fixes",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:33248,Deployability,pipeline,pipeline,33248,"o generate a population from founders under the assumption of random mating.; - (hail#12701) Query on Spark now officially supports Spark 3.3.0 and Dataproc 2.1.x. ### Performance Improvements. - (hail#12679) In Query on Batch, `hl.balding_nichols_model` is slightly faster. Also added `hl.utils.genomic_range_table` to quickly create a table keyed by locus. ### Bug Fixes. - (hail#12711) In Query on Batch, fix null pointer exception (manifesting as `scala.MatchError: null`) when reading data from requester pays buckets.; - (hail#12739) Fix `hl.plot.cdf`, `hl.plot.pdf`, and `hl.plot.joint_plot` which were broken by changes in Hail and changes in bokeh.; - (hail#12735) Fix (hail#11738) by allowing user to override default types in `to_pandas`.; - (hail#12760) Mitigate some JVM bytecode generation errors, particularly those related to too many method parameters.; - (hail#12766) Fix (hail#12759) by loosening `parsimonious` dependency pin.; - (hail#12732) In Query on Batch, fix bug that sometimes prevented terminating a pipeline using Control-C.; - (hail#12771) Use a version of `jgscm` whose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly suppo",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:36896,Deployability,update,updated,36896,"ew Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to use in batch scripts when not specified in code.; - (hail#12497) Added support for `scales`, `nrow`, and `ncol` arguments, as well as grouped legends, to `hail.ggplot.facet_wrap`.; - (hail#12471) Added `hailctl batch submit` command to run local scripts inside batch jobs.; - (hail#12525) Add support for passing arguments to `hailctl batch submit`.; - (hail#12465) Batch jobs' status now contains the region the job ran in. The job itself can access which region it is in through the `HAIL_REGION` environment variable.; - (hail#12464) When using Query-on-Batch, all jobs for a single hail session are inserted into the same batch instead of one batch per action.; - (hail#12457) `pca` and `hwe_normalized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regressio",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:37698,Deployability,configurat,configuration,37698,"malized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which inclu",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:39953,Deployability,pipeline,pipelines,39953," primitive columns in `Table.to_pandas`.; - (hail#12254) Cross-product-style legends for data groups have been replaced with factored ones (consistent with `ggplot2`'s implementation) for `hail.ggplot.geom_point`, and support has been added for custom legend group labels.; - (hail#12268) `VariantDataset` now implements `union_rows` for combining datasets with the same samples but disjoint variants. ### Bug Fixes. - (hail#12278) Fixed bug made more likely by 0.2.101 in which Hail errors when interacting with a NumPy integer or floating point type.; - (hail#12277) Fixed bug in reading tables/matrixtables with partition intervals that led to error or segfault. ---. ## Version 0.2.101. Released 2022-10-04. ### New Features. - (hail#12218) Support missing values in primitive columns in `Table.to_pandas`.; - (hail#12195) Add a `impute_sex_chr_ploidy_from_interval_coverage` to impute sex ploidy directly from a coverage MT.; - (hail#12222) Query-on-Batch pipelines now add worker jobs to the same batch as the driver; job instead of producing a new batch per stage.; - (hail#12244) Added support for custom labels for per-group legends to `hail.ggplot.geom_point` via the; `legend_format` keyword argument. ### Deprecations. - (hail#12230) The python-dill Batch images in `gcr.io/hail-vdc` are no longer supported.; Use `hailgenetics/python-dill` instead. ### Bug fixes. - (hail#12215) Fix search bar in the Hail Batch documentation. ---. ## Version 0.2.100. Released 2022-09-23. ### New Features. - (hail#12207) Add support for the `shape` aesthetic to `hail.ggplot.geom_point`. ### Deprecations. - (hail#12213) The `batch_size` parameter of `vds.new_combiner` is deprecated in favor of `gvcf_batch_size`. ### Bug fixes. - (hail#12216) Fix bug that caused `make install-on-cluster` to fail with a message about `sys_platform`.; - (hail#12164) Fix bug that caused Query on Batch pipelines to fail on datasets with indexes greater than 2GiB. ---. ## Version 0.2.99. Released 2022-09-13. ### New ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:40761,Deployability,install,install-on-cluster,40761," columns in `Table.to_pandas`.; - (hail#12195) Add a `impute_sex_chr_ploidy_from_interval_coverage` to impute sex ploidy directly from a coverage MT.; - (hail#12222) Query-on-Batch pipelines now add worker jobs to the same batch as the driver; job instead of producing a new batch per stage.; - (hail#12244) Added support for custom labels for per-group legends to `hail.ggplot.geom_point` via the; `legend_format` keyword argument. ### Deprecations. - (hail#12230) The python-dill Batch images in `gcr.io/hail-vdc` are no longer supported.; Use `hailgenetics/python-dill` instead. ### Bug fixes. - (hail#12215) Fix search bar in the Hail Batch documentation. ---. ## Version 0.2.100. Released 2022-09-23. ### New Features. - (hail#12207) Add support for the `shape` aesthetic to `hail.ggplot.geom_point`. ### Deprecations. - (hail#12213) The `batch_size` parameter of `vds.new_combiner` is deprecated in favor of `gvcf_batch_size`. ### Bug fixes. - (hail#12216) Fix bug that caused `make install-on-cluster` to fail with a message about `sys_platform`.; - (hail#12164) Fix bug that caused Query on Batch pipelines to fail on datasets with indexes greater than 2GiB. ---. ## Version 0.2.99. Released 2022-09-13. ### New Features. - (hail#12091) Teach `Table` to `write_many`, which writes one table per provided field.; - (hail#12067) Add `rand_int32` and `rand_int64` for generating random 32-bit and 64-bit integers, respectively. ### Performance Improvements. - (hail#12159) Improve performance of MatrixTable reads when using `_intervals` argument. ### Bug fixes. - (hail#12179) Fix incorrect composition of interval filters with unordered interval lists that could lead to over- or under-filtering.; - (hail#12162) Fixed crash in `collect_cols_by_key` with preceding random functions. ---. ## Version 0.2.98. Released 2022-08-22. ### New Features. - (hail#12062) `hl.balding_nichols_model` now supports an optional boolean parameter, `phased`, to control the phasedness of the generated genotype",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:40877,Deployability,pipeline,pipelines,40877," sex ploidy directly from a coverage MT.; - (hail#12222) Query-on-Batch pipelines now add worker jobs to the same batch as the driver; job instead of producing a new batch per stage.; - (hail#12244) Added support for custom labels for per-group legends to `hail.ggplot.geom_point` via the; `legend_format` keyword argument. ### Deprecations. - (hail#12230) The python-dill Batch images in `gcr.io/hail-vdc` are no longer supported.; Use `hailgenetics/python-dill` instead. ### Bug fixes. - (hail#12215) Fix search bar in the Hail Batch documentation. ---. ## Version 0.2.100. Released 2022-09-23. ### New Features. - (hail#12207) Add support for the `shape` aesthetic to `hail.ggplot.geom_point`. ### Deprecations. - (hail#12213) The `batch_size` parameter of `vds.new_combiner` is deprecated in favor of `gvcf_batch_size`. ### Bug fixes. - (hail#12216) Fix bug that caused `make install-on-cluster` to fail with a message about `sys_platform`.; - (hail#12164) Fix bug that caused Query on Batch pipelines to fail on datasets with indexes greater than 2GiB. ---. ## Version 0.2.99. Released 2022-09-13. ### New Features. - (hail#12091) Teach `Table` to `write_many`, which writes one table per provided field.; - (hail#12067) Add `rand_int32` and `rand_int64` for generating random 32-bit and 64-bit integers, respectively. ### Performance Improvements. - (hail#12159) Improve performance of MatrixTable reads when using `_intervals` argument. ### Bug fixes. - (hail#12179) Fix incorrect composition of interval filters with unordered interval lists that could lead to over- or under-filtering.; - (hail#12162) Fixed crash in `collect_cols_by_key` with preceding random functions. ---. ## Version 0.2.98. Released 2022-08-22. ### New Features. - (hail#12062) `hl.balding_nichols_model` now supports an optional boolean parameter, `phased`, to control the phasedness of the generated genotypes. ### Performance improvements. - (hail#12099) Make repeated VCF/PLINK queries much faster by caching compile",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:44141,Deployability,configurat,configuration,44141,"0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container imag",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:45087,Deployability,toggle,toggle,45087,"_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container images; - (hail#11725) `hl.ggplot` now supports `facet_wrap`; - (hail#11776) `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed. ### `hailctl dataproc`; - (hail#11710) support pass-through arguments to `connect`. ### Bug fixes. - (hail#11792) Resolved issue where corrupted tables could be created with whole-stage code generation enabled. ---. ## Version 0.2.93. Release 2022-03-27. ### Beta features. - Several issues with the beta version of Hail Query on Hail Batch are addressed in this release. ---. ## Version 0.2.92. Release 2022-03-25. ### New features. - (hail#11613) Add `hl.ggplot` support for `scale_fill_hue`, `scale_color_hue`, and `scale_fill_manual`,; `scale_color_manual`. This allows for an infinite number of discrete colors.; - (hail#11608) Add all remaining and all versions of extant public gnomAD datasets to the Hail; Annotation Database and Datasets API. Current as of March 23rd 2022.;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:45684,Deployability,release,release,45684," to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container images; - (hail#11725) `hl.ggplot` now supports `facet_wrap`; - (hail#11776) `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed. ### `hailctl dataproc`; - (hail#11710) support pass-through arguments to `connect`. ### Bug fixes. - (hail#11792) Resolved issue where corrupted tables could be created with whole-stage code generation enabled. ---. ## Version 0.2.93. Release 2022-03-27. ### Beta features. - Several issues with the beta version of Hail Query on Hail Batch are addressed in this release. ---. ## Version 0.2.92. Release 2022-03-25. ### New features. - (hail#11613) Add `hl.ggplot` support for `scale_fill_hue`, `scale_color_hue`, and `scale_fill_manual`,; `scale_color_manual`. This allows for an infinite number of discrete colors.; - (hail#11608) Add all remaining and all versions of extant public gnomAD datasets to the Hail; Annotation Database and Datasets API. Current as of March 23rd 2022.; - (hail#11662) Add the `weight` aesthetic `geom_bar`. ### Beta features. - This version of Hail includes all the necessary client-side infrastructure to execute Hail Query; pipelines on a Hail Batch cluster. This effectively enables a ""serverless"" version of Hail Query; which is independent of Apache Spark. Broad affiliated users should contact the Hail team for help; using Hail Query on Hail Batch. Unaffiliated users should also contact the Hail team to discuss; the feasibility of running your own Hail Batch cluster. The Hail team ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:46278,Deployability,pipeline,pipelines,46278,"p.aiotools.copy` will always show a progress bar when `--verbose` is passed. ### `hailctl dataproc`; - (hail#11710) support pass-through arguments to `connect`. ### Bug fixes. - (hail#11792) Resolved issue where corrupted tables could be created with whole-stage code generation enabled. ---. ## Version 0.2.93. Release 2022-03-27. ### Beta features. - Several issues with the beta version of Hail Query on Hail Batch are addressed in this release. ---. ## Version 0.2.92. Release 2022-03-25. ### New features. - (hail#11613) Add `hl.ggplot` support for `scale_fill_hue`, `scale_color_hue`, and `scale_fill_manual`,; `scale_color_manual`. This allows for an infinite number of discrete colors.; - (hail#11608) Add all remaining and all versions of extant public gnomAD datasets to the Hail; Annotation Database and Datasets API. Current as of March 23rd 2022.; - (hail#11662) Add the `weight` aesthetic `geom_bar`. ### Beta features. - This version of Hail includes all the necessary client-side infrastructure to execute Hail Query; pipelines on a Hail Batch cluster. This effectively enables a ""serverless"" version of Hail Query; which is independent of Apache Spark. Broad affiliated users should contact the Hail team for help; using Hail Query on Hail Batch. Unaffiliated users should also contact the Hail team to discuss; the feasibility of running your own Hail Batch cluster. The Hail team is accessible at both; https://hail.zulipchat.com and https://discuss.hail.is . ---. ## Version 0.2.91. Release 2022-03-18. ### Bug fixes. - (hail#11614) Update `hail.utils.tutorial.get_movie_lens` to use `https` instead of `http`. Movie; Lens has stopped serving data over insecure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:47902,Deployability,release,release,47902,"cure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:47924,Deployability,deploy,deploy,47924,"cure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:47952,Deployability,release,release,47952,"[hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48029,Deployability,deploy,deploy,48029,"ug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48069,Deployability,release,release,48069,"ug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48112,Deployability,release,release,48112," and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48311,Deployability,pipeline,pipelines,48311,"breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:52991,Deployability,pipeline,pipelines,52991,"name`.; - (hail#10959) Don't throw an error in certain situations where some key fields are optimized away. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash when calling `hl.liftover`.; - (hail#10883) Fix crash / long compilation times writing matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all sequences is large.; - (hail#10765) Fix rare bug where valid pipelines would fail to compile if intervals were created conditionally.; - (hail#10746) Various compiler improvements, decrease likelihood of `ClassTooLarge` errors.; - (hail#10829) Fix a bug where `hl.missing` and `CaseBuilder.or_error` failed if their type was a struct containing a field starting with a number. ### New features. - (hail#10768) Support multiplying `StringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:53509,Deployability,pipeline,pipelines,53509,"iting matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all sequences is large.; - (hail#10765) Fix rare bug where valid pipelines would fail to compile if intervals were created conditionally.; - (hail#10746) Various compiler improvements, decrease likelihood of `ClassTooLarge` errors.; - (hail#10829) Fix a bug where `hl.missing` and `CaseBuilder.or_error` failed if their type was a struct containing a field starting with a number. ### New features. - (hail#10768) Support multiplying `StringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes. - (hail#10684) Fixed a rare bug reading arrays from disk where short arrays would have their first elements corrupted and long arrays would cause segfaults.; - (hail#10523) Fixed bug where liftover would fail with ""Could not initialize class"" errors. ---. ## Version 0.2.72. Released 2021-07-19. ### New Features. - (hail#10655) Revamped many hail error messages to give useful python stack traces.; - (hail#10663) Added `DictExpression.items()` to mirror python's `dict.items()`.; - (hail#10657) `hl.ma",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:57138,Deployability,pipeline,pipelines,57138,"aploid GT calls to VCF combiner. ---. ## Version 0.2.65. Released 2021-04-14. ### Default Spark Version Change. - Starting from version 0.2.65, Hail uses Spark 3.1.1 by default. This will also allow the use of all python versions >= 3.6. By building hail from source, it is still possible to use older versions of Spark. ### New features. - (hail#10290) Added `hl.nd.solve`.; - (hail#10187) Added `NDArrayNumericExpression.sum`. ### Performance improvements. - (hail#10233) Loops created with `hl.experimental.loop` will now clean up unneeded memory between iterations. ### Bug fixes. - (hail#10227) `hl.nd.qr` now supports ndarrays that have 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ### New features; - (hail#10164) Add source_file_field parameter to hl.import_table to allow lines to be associated with their original source file. ### Bug fixes. - (hail#10182) Fixed serious memory leak in certain uses of `filter_intervals`.; - (hail#10133) Fix bug where some pipelines incorrectly infer missingness, leading to a type error.; - (hail#10134) Teach `hl.king` to treat filtered entries as missing values.; - (hail#10158) Fixes hail usage in latest versions of jupyter that rely on `asyncio`.; - (hail#10174) Fixed bad error message when incorrect return type specified with `hl.loop`. ---. ## Version 0.2.63. Released 2021-03-01. - (hail#10105) Hail will now return `frozenset` and `hail.utils.frozendict` instead of normal sets and dicts. ### Bug fixes. - (hail#10035) Fix mishandling of NaN values in `hl.agg.hist`, where they were unintentionally included in the first bin.; - (hail#10007) Improve error message from hadoop_ls when file does not exist. ### Performance Improvements. - (hail#10068) Make certain array copies faster.; - (hail#10061) Improve code generation of `hl.if_else` and `hl.coalesce`. ---. ## Version 0.2.62. Released 2021-02-03. ### New features. - (hail#9936) Deprecated `hl.null` in favor of `hl.missing` for naming consistency.; - (hail#9973) `hl.v",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:61162,Deployability,install,install,61162," (hail#9524) Hail should now be buildable using Spark 3.0.; - (hail#9549) Add `ignore_in_sample_frequency` flag to `hl.de_novo`.; - (hail#9501) Configurable cache size for `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9474) Add `ArrayExpression.first` and `ArrayExpression.last`.; - (hail#9459) Add `StringExpression.join`, an analogue to Python's `str.join`.; - (hail#9398) Hail will now throw `HailUserError`s if the `or_error` branch of a `CaseBuilder` is hit. ### Bug fixes; - (hail#9503) NDArrays can now hold arbitrary data types, though only ndarrays of primitives can be collected to Python.; - (hail#9501) Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9424) `hl.experimental.writeBlockMatrices` didn't correctly support `overwrite` flag. ### Performance improvements; - (hail#9506) `hl.agg.ndarray_sum` will now do a tree aggregation. ### hailctl dataproc; - (hail#9502) Fix hailctl dataproc modify to install dependencies of the wheel file.; - (hail#9420) Add `--debug-mode` flag to `hailctl dataproc start`. This will enable heap dumps on OOM errors.; - (hail#9520) Add support for requester pays buckets to `hailctl dataproc describe`. ### Deprecations; - (hail#9482) `ArrayExpression.head` has been deprecated in favor of `ArrayExpression.first`. ---. ## Version 0.2.57. Released 2020-09-03. ### New features. - (hail#9343) Implement the KING method for relationship inference as `hl.methods.king`. ---. ## Version 0.2.56. Released 2020-08-31. ### New features. - (hail#9308) Add hl.enumerate in favor of hl.zip_with_index, which is now deprecated.; - (hail#9278) Add `ArrayExpression.grouped`, a function that groups hail arrays into fixed size subarrays. ### Performance. - (hail#9373)(hail#9374) Decrease amount of memory used when slicing or filtering along a single BlockMatrix dimension. ### Bug fixes. - (hail#9304) Fix crash in `run_combiner` caused by inputs where VCF lines ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:62662,Deployability,update,update,62662,"## Version 0.2.56. Released 2020-08-31. ### New features. - (hail#9308) Add hl.enumerate in favor of hl.zip_with_index, which is now deprecated.; - (hail#9278) Add `ArrayExpression.grouped`, a function that groups hail arrays into fixed size subarrays. ### Performance. - (hail#9373)(hail#9374) Decrease amount of memory used when slicing or filtering along a single BlockMatrix dimension. ### Bug fixes. - (hail#9304) Fix crash in `run_combiner` caused by inputs where VCF lines and BGZ blocks align. ### hailctl dataproc. - (hail#9263) Add support for `--expiration-time` argument to `hailctl dataproc start`.; - (hail#9263) Add support for `--no-max-idle`, `no-max-age`, `--max-age`, and `--expiration-time` to `hailctl dataproc --modify`. ---. ## Version 0.2.55. Released 2020-08-19. ### Performance. - (hail#9264) Table.checkpoint now uses a faster LZ4 compression scheme. ### Bug fixes. - (hail#9250) `hailctl dataproc` no longer uses deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Rele",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:66993,Deployability,pipeline,pipelines,66993,"e MatrixWriteBlockMatrix WriteBlocksRDD method. ---. ## Version 0.2.45. Release 2020-06-15. ### Bug fixes. - (hail#8948) Fix integer overflow error when reading files >2G with; `hl.import_plink`.; - (hail#8903) Fix Python type annotations for empty collection constructors and; `hl.shuffle`.; - (hail#8942) Refactored VCF combiner to support other GVCF schemas.; - (hail#8941) Fixed `hl.import_plink` with multiple data partitions. ### hailctl dataproc. - (hail#8946) Fix bug when a user specifies packages in `hailctl dataproc start`; that are also dependencies of the Hail package.; - (hail#8939) Support tuples in `hailctl dataproc describe`. ---. ## Version 0.2.44. Release 2020-06-06. ### New Features. - (hail#8914) `hl.export_vcf` can now export tables as sites-only VCFs.; - (hail#8894) Added `hl.shuffle` function to randomly permute arrays.; - (hail#8854) Add `composable` option to parallel text export for use with `gsutil compose`. ### Bug fixes. - (hail#8883) Fix an issue related to failures in pipelines with `force_bgz=True`. ### Performance. - (hail#8887) Substantially improve the performance of `hl.experimental.import_gtf`. ---. ## Version 0.2.43. Released 2020-05-28. ### Bug fixes. - (hail#8867) Fix a major correctness bug ocurring when calling BlockMatrix.transpose on sparse, non-symmetric BlockMatrices.; - (hail#8876) Fixed ""ChannelClosedException: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutO",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68009,Deployability,pipeline,pipelines,68009," pipelines with `force_bgz=True`. ### Performance. - (hail#8887) Substantially improve the performance of `hl.experimental.import_gtf`. ---. ## Version 0.2.43. Released 2020-05-28. ### Bug fixes. - (hail#8867) Fix a major correctness bug ocurring when calling BlockMatrix.transpose on sparse, non-symmetric BlockMatrices.; - (hail#8876) Fixed ""ChannelClosedException: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69203,Deployability,configurat,configuration,69203,"Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Li",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69834,Deployability,install,installation,69834,"y strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.mult",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:70011,Deployability,install,installation,70011,"d.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. #",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:71060,Deployability,pipeline,pipeline,71060,"ocument describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#83",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:71670,Deployability,pipeline,pipelines,71670,"handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#8322) Fixed bug where `aggregate_rows` did not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_entries_by_col`.; - (hail#8326) Codegen infrastructure improvement resulting in ~3% overall speedup. ### hailctl dataproc. - (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potentia",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:71722,Deployability,update,update,71722,"handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#8322) Fixed bug where `aggregate_rows` did not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_entries_by_col`.; - (hail#8326) Codegen infrastructure improvement resulting in ~3% overall speedup. ### hailctl dataproc. - (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:73481,Deployability,install,installation,73481,"- (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New features. - (hail#8233) `StringExpression.matches` can now take a hail `StringExpression`, as opposed to only regular python strings.; - (hail#8198) Improved matrix multiplication interoperation between hail `NDArrayExpression` and numpy. ### Bug fixes. - (hail#8279) Fix a bug where `hl.agg.approx_cdf` failed inside of a `group_cols_by`.; - (hail#8275) Fix bad error message coming from `mt.make_table()` when keys are missing.; - (hail#8274) Fix memory leak in `hl.export_bgen`.; - (hail#8273) Fix segfault caused by `hl.agg.downsample` inside of an `array_agg` or `group_by`. ### hailctl dataproc. - (hail#8253) `hailctl dataproc` now supports new flags `--requester-pays-allow-all` and `--requester-pays-allow-buckets`. This will configure your hail installation to be able to read from requester pays buckets. The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75276,Deployability,pipeline,pipelines,75276,atures. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hai,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:76244,Deployability,pipeline,pipelines,76244,"of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by re",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:76321,Deployability,configurat,configuration,76321,"ely.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in inges",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:79107,Deployability,update,update,79107,"throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ignored.; - (hail#7688) Added experimental support for `NDArrayExpression`s in new `hl.nd` module.; - (hail#7608) `hl.grep` now has a `show` argument that allows users to either print the results (default) or return a dictionary of the results. ### `hailctl dataproc`; - (hail#7717) Throw error when mispelling arguments instead of silently quitting. ---. ## Version 0.2.28. Released 2019-11-22. ### Critical correctness bug fix; - (hail#7588) Fixes a bug where filtering old matrix tables in newer versions of hail did not work as expected. Please update from 0.2.27. ### Bug fixes; - (hail#7571) Don't set GQ to missing if PL is missing in `split_multi_hts`.; - (hail#7577) Fixed an optimizer bug. ### New Features; - (hail#7561) Added `hl.plot.visualize_missingness()` to plot missingness patterns for MatrixTables.; - (hail#7575) Added `hl.version()` to quickly check hail version. ### `hailctl dataproc`; - (hail#7586) `hailctl dataproc` now supports `--gcloud_configuration` option. ### Documentation; - (hail#7570) Hail has a cheatsheet for Tables now. ---. ## Version 0.2.27. Released 2019-11-15. ### New Features. - (hail#7379) Add `delimiter` argument to `hl.import_matrix_table`; - (hail#7389) Add `force` and `force_bgz` arguments to `hl.experimental.import_gtf`; - (hail#7386)(hail#7394) Add `{Table, MatrixTable}.tail`.; - (hail#7467) Added `hl.if_else` as an alias for `hl.cond`; deprecated `hl.cond`.; - (hail#7453) Add `hl.parse_int{32, 64}` and `hl.parse_float{32, 64}`, which can parse strings to numbers and return missing on failur",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82202,Deployability,pipeline,pipelines,82202,"-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable, Table}.describe`. Use this by passing the argument `widget=True`.; - (hail#7250) `{Table, MatrixTable, Expression}.summarize()` now summarizes elements of collections (arrays, sets, dicts).; - (hail#7271) Improve `hl.plot.qq` by increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance improvements; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of ed",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82518,Deployability,update,update,82518," increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance improvements; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82920,Deployability,install,installed,82920,"ments; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82956,Deployability,configurat,configuration,82956,"ments; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84639,Deployability,pipeline,pipelines,84639,"methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:86136,Deployability,update,update-hail-version,86136,"arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (hail#6903) Teach `BlockMatrix` how to `checkpoint`. ### Performance; - (hail#6895) Improved performance of `hl.import_bgen(...).count()`.; - (hail#6948) Fixed performance bug in `BlockMatrix` filtering functions.; - (hail#6943) Improved scaling of `Table.union`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ### `hailctl dataproc`; - (hail#6904) Added `--dry-run` option to `submit`.; - (hail#6951) Fixed `--max-idle` and `--max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88173,Deployability,pipeline,pipelines,88173,"er_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by a",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88247,Deployability,pipeline,pipeline,88247,"70) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88362,Deployability,update,update,88362,"and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annota",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:89295,Deployability,pipeline,pipelines,89295,".2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:91135,Deployability,release,releases,91135,"ators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not the full list of overlapping sample IDs.; - (hail#6583) Fixed `hl.plot.manhattan` for non-default reference genomes. ### Experimental. - (hail#6488) Exposed `table.multi_way_zip_join`. This takes a list of tables of; identical types, and zips them together into one table. ### File Format. - The native file format version is now 1.1.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. -----. ## Version 0.2.16. Released 2019-06-19. ### `hailctl`. - (hail#6357) Accommodated Google Dataproc bug causing cluster creation failures. ### Bug fixes. - (hail#6378) Fixed problem in how `entry_float_type` was being handled in `import_vcf`. -----. ## Version 0.2.15. Released 2019-06-14. After some infrastructural changes to our development process, we should be; getting back to frequent releases. ### `hailctl`. Starting in 0.2.15, `pip` installations of Hail come bundled with a command-; line tool, `hailctl`. This tool subsumes the functionality of `cloudtools`,; which is now deprecated. See the; [release thread on the forum](https://discuss.hail.is/t/new-command-line-utility-hailctl/981); for more information. ### New features. - (hail#5932)(hail#6115) `hl.import_bed` abd `hl.import_locus_intervals` now; accept keyword arguments to pass through to `hl.import_table`, which is used; internally. This permits parameters like `min_partitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that m",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:91186,Deployability,install,installations,91186," printed in `hl.concordance` to print the number of overlapping; samples, not the full list of overlapping sample IDs.; - (hail#6583) Fixed `hl.plot.manhattan` for non-default reference genomes. ### Experimental. - (hail#6488) Exposed `table.multi_way_zip_join`. This takes a list of tables of; identical types, and zips them together into one table. ### File Format. - The native file format version is now 1.1.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. -----. ## Version 0.2.16. Released 2019-06-19. ### `hailctl`. - (hail#6357) Accommodated Google Dataproc bug causing cluster creation failures. ### Bug fixes. - (hail#6378) Fixed problem in how `entry_float_type` was being handled in `import_vcf`. -----. ## Version 0.2.15. Released 2019-06-14. After some infrastructural changes to our development process, we should be; getting back to frequent releases. ### `hailctl`. Starting in 0.2.15, `pip` installations of Hail come bundled with a command-; line tool, `hailctl`. This tool subsumes the functionality of `cloudtools`,; which is now deprecated. See the; [release thread on the forum](https://discuss.hail.is/t/new-command-line-utility-hailctl/981); for more information. ### New features. - (hail#5932)(hail#6115) `hl.import_bed` abd `hl.import_locus_intervals` now; accept keyword arguments to pass through to `hl.import_table`, which is used; internally. This permits parameters like `min_partitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:91350,Deployability,release,release,91350,"anhattan` for non-default reference genomes. ### Experimental. - (hail#6488) Exposed `table.multi_way_zip_join`. This takes a list of tables of; identical types, and zips them together into one table. ### File Format. - The native file format version is now 1.1.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. -----. ## Version 0.2.16. Released 2019-06-19. ### `hailctl`. - (hail#6357) Accommodated Google Dataproc bug causing cluster creation failures. ### Bug fixes. - (hail#6378) Fixed problem in how `entry_float_type` was being handled in `import_vcf`. -----. ## Version 0.2.15. Released 2019-06-14. After some infrastructural changes to our development process, we should be; getting back to frequent releases. ### `hailctl`. Starting in 0.2.15, `pip` installations of Hail come bundled with a command-; line tool, `hailctl`. This tool subsumes the functionality of `cloudtools`,; which is now deprecated. See the; [release thread on the forum](https://discuss.hail.is/t/new-command-line-utility-hailctl/981); for more information. ### New features. - (hail#5932)(hail#6115) `hl.import_bed` abd `hl.import_locus_intervals` now; accept keyword arguments to pass through to `hl.import_table`, which is used; internally. This permits parameters like `min_partitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted n",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:92536,Deployability,pipeline,pipelines,92536,"accept keyword arguments to pass through to `hl.import_table`, which is used; internally. This permits parameters like `min_partitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted numeric arrays.; - (hail#6224) Moved implementation of `hl.concordance` from backend to Python.; Performance directly from `read()` is slightly worse, but inside larger; pipelines this function will be optimized much better than before, and it; will benefit improvements to general infrastructure.; - (hail#6214) Updated Hail Python dependencies.; - (hail#5979) Added optimizer pass to rewrite filter expressions on keys as; interval filters where possible, leading to massive speedups for point queries.; See the [blog post](https://discuss.hail.is/t/new-optimizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:93922,Deployability,patch,patch,93922,"imizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:93928,Deployability,update,update,93928,"imizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:93976,Deployability,install,installs,93976,"rval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also s",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:94054,Deployability,upgrade,upgrade,94054,"ng-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `ar",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:94464,Deployability,update,update,94464," Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will n",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:94689,Deployability,pipeline,pipelines,94689,"Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will now produce a much more detailed; error message.; - (hail#5723) `hl.import_matrix_table` can now import a matrix table with no; columns.; - (hail#5724) `hl.rand_norm2d` samples from a two dimensional random normal. ### B",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:100808,Deployability,pipeline,pipelines,100808,"Fix `ReferenceGenome.add_sequence` causing a crash.; - (hail#5268) Fix `Table.export` writing a file called 'None' in the current directory.; - (hail#5265) Fix `hl.get_reference` raising an exception when called before `hl.init()`.; - (hail#5250) Fix crash in `pc_relate` when called on a MatrixTable field other than 'GT'.; - (hail#5278) Fix crash in `Table.order_by` when sorting by fields whose names are not valid Python identifiers.; - (hail#5294) Fix crash in `hl.trio_matrix` when sample IDs are missing.; - (hail#5295) Fix crash in `Table.index` related to key field incompatibilities. -----. ## Version 0.2.9. Released 2019-01-30. ### New features. - (hail#5149) Added bitwise transformation functions: `hl.bit_{and, or, xor, not, lshift, rshift}`.; - (hail#5154) Added `hl.rbind` function, which is similar to `hl.bind` but expects a function as the last argument instead of the first. ### Performance improvements. - (hail#5107) Hail's Python interface generates tighter intermediate code, which should result in moderate performance improvements in many pipelines.; - (hail#5172) Fix unintentional performance deoptimization related to `Table.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `fl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104637,Deployability,pipeline,pipelines,104637,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:20641,Energy Efficiency,reduce,reduce,20641," Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hail",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:20817,Energy Efficiency,reduce,reduce,20817,"il#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hailctl; option.; - (hail#13422) `hailtop.hail_frozenlist.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:23598,Energy Efficiency,schedul,schedule,23598,"values of `n`.; - (hail#13500) In Query-on-Batch, the client-side Python code will not try to list every job when a; QoB batch fails. This could take hours for long-running pipelines or pipelines with many; partitions. ### Deprecations. - (hail#13275) Hail no longer officially supports Python 3.8.; - (hail#13508) The `n` parameter of `MatrixTable.tail` is deprecated in favor of a new `n_rows`; parameter. ## Version 0.2.120. Released 2023-07-27. ### New Features; - (hail#13206) The VDS Combiner now works in Query-on-Batch. ### Bug Fixes; - (hail#13313) Fix bug introduced in 0.2.119 which causes a serialization error when using; Query-on-Spark to read a VCF which is sorted by locus, with split multi-allelics, in which the; records sharing a single locus do not appear in the dictionary ordering of their alternate; alleles.; - (hail#13264) Fix bug which ignored the `partition_hint` of a Table group-by-and-aggregate.; - (hail#13239) Fix bug which ignored the `HAIL_BATCH_REGIONS` argument when determining in which; regions to schedule jobs when using Query-on-Batch.; - (hail#13253) Improve `hadoop_ls` and `hfs.ls` to quickly list globbed files in a directory. The; speed improvement is proportional to the number of files in the directory.; - (hail#13226) Fix the comparison of an `hl.Struct` to an `hl.struct` or field of type; `tstruct`. Resolves (hail#13045) and (Hail#13046).; - (hail#12995) Fixed bug causing poor performance and memory leaks for `MatrixTable.annotate_rows`; aggregations. ## Version 0.2.119. Released 2023-06-28. ### New Features; - (hail#12081) Hail now uses [Zstandard](https://facebook.github.io/zstd/) as; the default compression algorithm for table and matrix table storage. Reducing; file size around 20% in most cases.; - (hail#12988) Arbitrary aggregations can now be used on arrays via; `ArrayExpression.aggregate`. This method is useful for accessing; functionality that exists in the aggregator library but not the; basic expression library, for instance,",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27675,Energy Efficiency,reduce,reduce,27675,"s and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.; - (hail#12917) The `hail-az` scheme for referencing blobs in ABS is now deprecated and will be removed in an upcoming release. ### Bug Fixes. - (hail",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:62823,Energy Efficiency,monitor,monitoring,62823,"x, which is now deprecated.; - (hail#9278) Add `ArrayExpression.grouped`, a function that groups hail arrays into fixed size subarrays. ### Performance. - (hail#9373)(hail#9374) Decrease amount of memory used when slicing or filtering along a single BlockMatrix dimension. ### Bug fixes. - (hail#9304) Fix crash in `run_combiner` caused by inputs where VCF lines and BGZ blocks align. ### hailctl dataproc. - (hail#9263) Add support for `--expiration-time` argument to `hailctl dataproc start`.; - (hail#9263) Add support for `--no-max-idle`, `no-max-age`, `--max-age`, and `--expiration-time` to `hailctl dataproc --modify`. ---. ## Version 0.2.55. Released 2020-08-19. ### Performance. - (hail#9264) Table.checkpoint now uses a faster LZ4 compression scheme. ### Bug fixes. - (hail#9250) `hailctl dataproc` no longer uses deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:73546,Energy Efficiency,charge,charges,73546,"ep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New features. - (hail#8233) `StringExpression.matches` can now take a hail `StringExpression`, as opposed to only regular python strings.; - (hail#8198) Improved matrix multiplication interoperation between hail `NDArrayExpression` and numpy. ### Bug fixes. - (hail#8279) Fix a bug where `hl.agg.approx_cdf` failed inside of a `group_cols_by`.; - (hail#8275) Fix bad error message coming from `mt.make_table()` when keys are missing.; - (hail#8274) Fix memory leak in `hl.export_bgen`.; - (hail#8273) Fix segfault caused by `hl.agg.downsample` inside of an `array_agg` or `group_by`. ### hailctl dataproc. - (hail#8253) `hailctl dataproc` now supports new flags `--requester-pays-allow-all` and `--requester-pays-allow-buckets`. This will configure your hail installation to be able to read from requester pays buckets. The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:78322,Energy Efficiency,efficient,efficient,78322,".; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ignored.; - (hail#7688) Added experimental support for `NDArrayExpression`s in new `hl.nd` module.; - (hail#7608) `hl.grep` now has a `show` argument that allows users to either print the results (default) or return a dictionary of the results. ### `hailctl dataproc`; - (hail#7717) Throw error when mispelling arguments instead of silently quitting. ---. ## Version 0.2.28. Released 2019-11-22. ### Critical correctness bug fix; - (hail#7588) Fixes a bug where filtering old matrix tables in newer versions of hail did not work as expected. Please update from 0.2.27. ### Bug fixes; - (hail#7571) Don't set GQ to missing if PL is missing in `split_multi_hts`.; - (hail#7577) Fixed an optimizer bug. ### New Features; - (hail#7561) Added `hl.plot.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:80409,Energy Efficiency,monitor,monitor,80409," hail version. ### `hailctl dataproc`; - (hail#7586) `hailctl dataproc` now supports `--gcloud_configuration` option. ### Documentation; - (hail#7570) Hail has a cheatsheet for Tables now. ---. ## Version 0.2.27. Released 2019-11-15. ### New Features. - (hail#7379) Add `delimiter` argument to `hl.import_matrix_table`; - (hail#7389) Add `force` and `force_bgz` arguments to `hl.experimental.import_gtf`; - (hail#7386)(hail#7394) Add `{Table, MatrixTable}.tail`.; - (hail#7467) Added `hl.if_else` as an alias for `hl.cond`; deprecated `hl.cond`.; - (hail#7453) Add `hl.parse_int{32, 64}` and `hl.parse_float{32, 64}`, which can parse strings to numbers and return missing on failure.; - (hail#7475) Add `row_join_type` argument to `MatrixTable.union_cols` to support outer joins on rows. ### Bug fixes. - (hail#7479)(hail#7368)(hail#7402) Fix optimizer bugs.; - (hail#7506) Updated to latest htsjdk to resolve VCF parsing problems. ### `hailctl dataproc`. - (hail#7460) The Spark monitor widget now automatically collapses after a job completes. ---. ## Version 0.2.26. Released 2019-10-24. ### New Features; - (hail#7325) Add `string.reverse` function.; - (hail#7328) Add `string.translate` function.; - (hail#7344) Add `hl.reverse_complement` function.; - (hail#7306) Teach the VCF combiner to handle allele specific (`AS_*`) fields.; - (hail#7346) Add `hl.agg.approx_median` function. ### Bug Fixes; - (hail#7361) Fix `AD` calculation in `sparse_split_multi`. ### Performance Improvements; - (hail#7355) Improve performance of IR copying. ### File Format. - The native file format version is now 1.3.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.25. Released 2019-10-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable, Table}.describe`. Use this by passing the argument `widget=True`.; - (hail#7250) `{Table, MatrixTable, Expression}.summarize()` now summarizes elements of collections (",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84032,Energy Efficiency,allocate,allocated,84032,"7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88998,Energy Efficiency,reduce,reduces,88998,"## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:2830,Integrability,depend,depend,2830,"ped to; run on Hail 0.2.5 should continue to work in every subsequent release within the 0.2 major version.; This also means any file written by python library versions 0.2.1 through 0.2.5 can be read by; 0.2.5. Forward compatibility of file formats and the Python API is not guaranteed. In particular, a new; file format version is only readable by library versions released after the file format. For; example, Python library version 0.2.119 introduces a new file format version: 1.7.0. All library; versions before 0.2.119, for example 0.2.118, *cannot* read file format version 1.7.0. All library; versions after and including 0.2.119 *can* read file format version 1.7.0. Each version of the Hail Python library can only write files using the latest file format version it; supports. **The hl.experimental package and other methods marked experimental in the docs are exempt from this; policy. Their functionality or even existence may change without notice. Please contact us if you; critically depend on experimental functionality.**. ## Version 0.2.133. Released 2024-09-25. ### New Features. - (hail#14619) Teach `hailctl dataproc submit` to use the `--project` argument as an argument to `gcloud dataproc` rather than the submitted script. ### Bug Fixes. - (hail#14673) Fix typo in Interpret rule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:6256,Integrability,depend,depends,6256,"hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (hail#14393) `hail` depends on `protobuf` no longer; users may choose their own version of `protobuf`.; - (hail#14360) Exposed previously internal `_num_allele_type` as `numeric_allele_type`; and deprecated it. Add new `AlleleType` enumeration for users to be able to easily; use the values returned by `numeric_allele_type`.; - (hail#14297) `vds.sample_gc` now uses independent aggregators.; Users may now import these functions and use them directly.; - (hail#14405) `VariantDataset.validate` now checks that all ref blocks are no; longer than the ref_block_max_length field, if it exists. ### Bug Fixes. - (hail#14420) Fixes a serious, but likely rare, bug in the; Table/MatrixTable reader, which has been present since Sep 2020. It; manifests as many (around half or more) of the rows being dropped. This; could only happen when 1) reading a (matrix)table whose partitioning; metadata allows rows with the same key to be split across neighboring; partitions, and 2) reading it with a different partitioning than it was; written. 1) would likely ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:10897,Integrability,message,message,10897,"ow ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially different from the desired; number of output partitions.; - (hail#14202) Support coercing `{}` (the empty dictionary) into any Struct type (with all missing; fields).; - (hail#14239) Remove an erroneous statement from the MatrixTable tutorial.; - (hail#14176) `hailtop.fs.ls` can now list a bucket, e.g. `hailtop.fs.ls(""gs://my-bucket"")`.; - (hail#14258) Fix `import_avro` to not raise `NullPointerException` in certain rare cases; (e.g. when using `_key_by_assert_sorted`).; - (hail#14285) Fix a broken link in the MatrixTable tutorial. ### Deprecations. - (hail#14293) Support for the `hail-az://` scheme, deprecated in 0.2.116, is now gone. Please use; the standard `https://ACCOUNT.blob.core.windows.net/CONTAINER/PATH`. ## Version 0.2.127. Released 2024-01-12. If you have an Apple M1 laptop, verify that. ```; file $JAVA_HOME/bin/java; ```. returns a message including the phrase ""arm64"". If it instead includes the phrase ""x86_64"" then you; must upgrade to a new version of Java. You may find such a version of Java; [here](https://www.azul.com/downloads/?os=macos&architecture=arm-64-bit&package=jre#zulu). ### New Features. - (hail#14093) `hailctl dataproc` now creates clusters using Dataproc version 2.1.33. It previously used version 2.1.2.; - (hail#13617) Query-on-Batch now supports joining two tables keyed by intervals.; - (hail#13795)(hail#13567) Enable passing a requester pays configuration to `hailtop.fs.open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl datapro",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14853,Integrability,message,message,14853,"## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) F",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14941,Integrability,depend,dependent,14941,"introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in respo",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15877,Integrability,message,message,15877,".logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc submit` now expands `~` in the `--files` and `--pyfiles` argume",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:26770,Integrability,message,messages,26770,"e in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will u",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:26872,Integrability,message,messages,26872,"e in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will u",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27465,Integrability,message,message,27465," with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:33150,Integrability,depend,dependency,33150," Query on Batch, `hl.ibd` is now supported.; - (hail#12722) Add `hl.simulate_random_mating` to generate a population from founders under the assumption of random mating.; - (hail#12701) Query on Spark now officially supports Spark 3.3.0 and Dataproc 2.1.x. ### Performance Improvements. - (hail#12679) In Query on Batch, `hl.balding_nichols_model` is slightly faster. Also added `hl.utils.genomic_range_table` to quickly create a table keyed by locus. ### Bug Fixes. - (hail#12711) In Query on Batch, fix null pointer exception (manifesting as `scala.MatchError: null`) when reading data from requester pays buckets.; - (hail#12739) Fix `hl.plot.cdf`, `hl.plot.pdf`, and `hl.plot.joint_plot` which were broken by changes in Hail and changes in bokeh.; - (hail#12735) Fix (hail#11738) by allowing user to override default types in `to_pandas`.; - (hail#12760) Mitigate some JVM bytecode generation errors, particularly those related to too many method parameters.; - (hail#12766) Fix (hail#12759) by loosening `parsimonious` dependency pin.; - (hail#12732) In Query on Batch, fix bug that sometimes prevented terminating a pipeline using Control-C.; - (hail#12771) Use a version of `jgscm` whose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:34284,Integrability,message,message,34284,"ose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time.; - (hail#12566) Improve error message when combining incompatibly indexed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would be taller than the plot, the legend will now be scrollable. Legend entries for such plots can be clicked to show/hide traces on the plot, but this does not work and is a known issue that will only be addressed if `hail.ggplot` is migrated off of plotly.; - (hail#12584) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables wi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:40796,Integrability,message,message,40796," columns in `Table.to_pandas`.; - (hail#12195) Add a `impute_sex_chr_ploidy_from_interval_coverage` to impute sex ploidy directly from a coverage MT.; - (hail#12222) Query-on-Batch pipelines now add worker jobs to the same batch as the driver; job instead of producing a new batch per stage.; - (hail#12244) Added support for custom labels for per-group legends to `hail.ggplot.geom_point` via the; `legend_format` keyword argument. ### Deprecations. - (hail#12230) The python-dill Batch images in `gcr.io/hail-vdc` are no longer supported.; Use `hailgenetics/python-dill` instead. ### Bug fixes. - (hail#12215) Fix search bar in the Hail Batch documentation. ---. ## Version 0.2.100. Released 2022-09-23. ### New Features. - (hail#12207) Add support for the `shape` aesthetic to `hail.ggplot.geom_point`. ### Deprecations. - (hail#12213) The `batch_size` parameter of `vds.new_combiner` is deprecated in favor of `gvcf_batch_size`. ### Bug fixes. - (hail#12216) Fix bug that caused `make install-on-cluster` to fail with a message about `sys_platform`.; - (hail#12164) Fix bug that caused Query on Batch pipelines to fail on datasets with indexes greater than 2GiB. ---. ## Version 0.2.99. Released 2022-09-13. ### New Features. - (hail#12091) Teach `Table` to `write_many`, which writes one table per provided field.; - (hail#12067) Add `rand_int32` and `rand_int64` for generating random 32-bit and 64-bit integers, respectively. ### Performance Improvements. - (hail#12159) Improve performance of MatrixTable reads when using `_intervals` argument. ### Bug fixes. - (hail#12179) Fix incorrect composition of interval filters with unordered interval lists that could lead to over- or under-filtering.; - (hail#12162) Fixed crash in `collect_cols_by_key` with preceding random functions. ---. ## Version 0.2.98. Released 2022-08-22. ### New Features. - (hail#12062) `hl.balding_nichols_model` now supports an optional boolean parameter, `phased`, to control the phasedness of the generated genotype",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:47332,Integrability,depend,dependency,47332,"Broad affiliated users should contact the Hail team for help; using Hail Query on Hail Batch. Unaffiliated users should also contact the Hail team to discuss; the feasibility of running your own Hail Batch cluster. The Hail team is accessible at both; https://hail.zulipchat.com and https://discuss.hail.is . ---. ## Version 0.2.91. Release 2022-03-18. ### Bug fixes. - (hail#11614) Update `hail.utils.tutorial.get_movie_lens` to use `https` instead of `http`. Movie; Lens has stopped serving data over insecure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pan",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:47375,Integrability,depend,depends,47375,"Broad affiliated users should contact the Hail team for help; using Hail Query on Hail Batch. Unaffiliated users should also contact the Hail team to discuss; the feasibility of running your own Hail Batch cluster. The Hail team is accessible at both; https://hail.zulipchat.com and https://discuss.hail.is . ---. ## Version 0.2.91. Release 2022-03-18. ### Bug fixes. - (hail#11614) Update `hail.utils.tutorial.get_movie_lens` to use `https` instead of `http`. Movie; Lens has stopped serving data over insecure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pan",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:50203,Integrability,interface,interface,50203," - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues about having too many open file handles. ### New features. - (hail#11300) `geom_histogram` infers min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; - (hail#11276) Fixed `log` argument in `hail.plot.pdf`.; - (hail#11256) Fixed memory leak in LD Prune. ### New features. - (hail#11274) Added `geom_col` to `hail.ggplot`. ### hailctl dataproc. - (hail#11280) Updated dataproc image version to one not affected by log4j vulnerabilities. ---. ## Version 0.2.82. Release 2022-01-24. ### Bug fixes. - (hail#11209) Significantly improved usefulness and speed of `Table.to_pandas`, resolved several bugs with output. ### New features. - (hail#11247) Introduces a new experimental plotting interface `hail.ggplot`, based on R's ggplot library.; - (hail#11173) Many math functions like `hail.sqrt` now automatically broadcast over ndarrays. ### Performance Improvements. - (hail#11216) Significantly improve performance of `parse_locus_interval`. ### Python and Java Support. - (hail#11219) We no longer officially support Python 3.6, though it may continue to work in the short term.; - (hail#11220) We support building hail with Java 11. ### File Format. - The native file format version is now 1.6.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.81. Release 2021-12-20. ### hailctl dataproc. - (hail#11182) Updated Dataproc image version to mitigate yet more Log4j vulnerabilities. ---. ## Version 0.2.80. Release 2021-12-15. ### New features. - (hail#11077) `hl.experimental.write_matrix_tables` now returns the paths of the written matrix tables. ### hailctl dataproc. - (hail#11157) Up",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:51399,Integrability,protocol,protocols,51399,"ance of `parse_locus_interval`. ### Python and Java Support. - (hail#11219) We no longer officially support Python 3.6, though it may continue to work in the short term.; - (hail#11220) We support building hail with Java 11. ### File Format. - The native file format version is now 1.6.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.81. Release 2021-12-20. ### hailctl dataproc. - (hail#11182) Updated Dataproc image version to mitigate yet more Log4j vulnerabilities. ---. ## Version 0.2.80. Release 2021-12-15. ### New features. - (hail#11077) `hl.experimental.write_matrix_tables` now returns the paths of the written matrix tables. ### hailctl dataproc. - (hail#11157) Updated Dataproc image version to mitigate the Log4j vulnerability.; - (hail#10900) Added `--region` parameter to `hailctl dataproc submit`.; - (hail#11090) Teach `hailctl dataproc describe` how to read URLs with the protocols `s3` (Amazon S3), `hail-az` (Azure Blob Storage), and `file` (local file system) in addition to `gs` (Google Cloud Storage). ---. ## Version 0.2.79. Release 2021-11-17. ### Bug fixes. - (hail#11023) Fixed bug in call decoding that was introduced in version 0.2.78. ### New features. - (hail#10993) New function `p_value_excess_het`. ---. ## Version 0.2.78. Release 2021-10-19. ### Bug fixes; - (hail#10766) Don't throw out of memory error when broadcasting more than 2^(31) - 1 bytes.; - (hail#10910) Filters on key field won't be slowed down by uses of `MatrixTable.localize_entries` or `Table.rename`.; - (hail#10959) Don't throw an error in certain situations where some key fields are optimized away. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:54362,Integrability,message,messages,54362,"ringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes. - (hail#10684) Fixed a rare bug reading arrays from disk where short arrays would have their first elements corrupted and long arrays would cause segfaults.; - (hail#10523) Fixed bug where liftover would fail with ""Could not initialize class"" errors. ---. ## Version 0.2.72. Released 2021-07-19. ### New Features. - (hail#10655) Revamped many hail error messages to give useful python stack traces.; - (hail#10663) Added `DictExpression.items()` to mirror python's `dict.items()`.; - (hail#10657) `hl.map` now supports mapping over multiple lists like Python's built-in `map`. ### Bug fixes. - (hail#10662) Fixed partitioning logic in `hl.import_plink`.; - (hail#10669) `NDArrayNumericExpression.sum()` now works correctly on ndarrays of booleans. ---. ## Version 0.2.71. Released 2021-07-08. ### New Features. - (hail#10632) Added support for weighted linear regression to `hl.linear_regression_rows`.; - (hail#10635) Added `hl.nd.maximum` and `hl.nd.minimum`.; - (hail#10602) Added `hl.starmap`. ### Bug fixes. - (hail#10038) Fixed crashes when writing/reading matrix tables with 0 partitions.; - (hail#10624) Fixed out of bounds bug with `_quantile_from_cdf`. ### hailctl dataproc. - (hail#10633) Added `--scopes` parameter to `hailctl dataproc start`. ---. ## Version 0.2.70. Released 2021-06-21. ---. ## Version 0.2.69. Released 2021-06-14. ### New Fe",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:57400,Integrability,message,message,57400,"m source, it is still possible to use older versions of Spark. ### New features. - (hail#10290) Added `hl.nd.solve`.; - (hail#10187) Added `NDArrayNumericExpression.sum`. ### Performance improvements. - (hail#10233) Loops created with `hl.experimental.loop` will now clean up unneeded memory between iterations. ### Bug fixes. - (hail#10227) `hl.nd.qr` now supports ndarrays that have 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ### New features; - (hail#10164) Add source_file_field parameter to hl.import_table to allow lines to be associated with their original source file. ### Bug fixes. - (hail#10182) Fixed serious memory leak in certain uses of `filter_intervals`.; - (hail#10133) Fix bug where some pipelines incorrectly infer missingness, leading to a type error.; - (hail#10134) Teach `hl.king` to treat filtered entries as missing values.; - (hail#10158) Fixes hail usage in latest versions of jupyter that rely on `asyncio`.; - (hail#10174) Fixed bad error message when incorrect return type specified with `hl.loop`. ---. ## Version 0.2.63. Released 2021-03-01. - (hail#10105) Hail will now return `frozenset` and `hail.utils.frozendict` instead of normal sets and dicts. ### Bug fixes. - (hail#10035) Fix mishandling of NaN values in `hl.agg.hist`, where they were unintentionally included in the first bin.; - (hail#10007) Improve error message from hadoop_ls when file does not exist. ### Performance Improvements. - (hail#10068) Make certain array copies faster.; - (hail#10061) Improve code generation of `hl.if_else` and `hl.coalesce`. ---. ## Version 0.2.62. Released 2021-02-03. ### New features. - (hail#9936) Deprecated `hl.null` in favor of `hl.missing` for naming consistency.; - (hail#9973) `hl.vep` now includes a `vep_proc_id` field to aid in debugging unexpected output.; - (hail#9839) Hail now eagerly deletes temporary files produced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:57783,Integrability,message,message,57783,"ave 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ### New features; - (hail#10164) Add source_file_field parameter to hl.import_table to allow lines to be associated with their original source file. ### Bug fixes. - (hail#10182) Fixed serious memory leak in certain uses of `filter_intervals`.; - (hail#10133) Fix bug where some pipelines incorrectly infer missingness, leading to a type error.; - (hail#10134) Teach `hl.king` to treat filtered entries as missing values.; - (hail#10158) Fixes hail usage in latest versions of jupyter that rely on `asyncio`.; - (hail#10174) Fixed bad error message when incorrect return type specified with `hl.loop`. ---. ## Version 0.2.63. Released 2021-03-01. - (hail#10105) Hail will now return `frozenset` and `hail.utils.frozendict` instead of normal sets and dicts. ### Bug fixes. - (hail#10035) Fix mishandling of NaN values in `hl.agg.hist`, where they were unintentionally included in the first bin.; - (hail#10007) Improve error message from hadoop_ls when file does not exist. ### Performance Improvements. - (hail#10068) Make certain array copies faster.; - (hail#10061) Improve code generation of `hl.if_else` and `hl.coalesce`. ---. ## Version 0.2.62. Released 2021-02-03. ### New features. - (hail#9936) Deprecated `hl.null` in favor of `hl.missing` for naming consistency.; - (hail#9973) `hl.vep` now includes a `vep_proc_id` field to aid in debugging unexpected output.; - (hail#9839) Hail now eagerly deletes temporary files produced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument and a varargs of Boolean expressions.; - (hail#9816) `hl.pc_relate` now includes values on the diagonal of kinship, IBD-0, IBD-1, and IBD-2; - (hail#9736) Let NDArrayExpression.reshape take varargs instead of mandating a tuple.; - (hail#9766) `hl.export_vcf` now warns if INFO field names are invalid according to the VCF 4.3 spec. ### Bug fixes. - (hail#9976) Fixed `show()` repre",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:61170,Integrability,depend,dependencies,61170," (hail#9524) Hail should now be buildable using Spark 3.0.; - (hail#9549) Add `ignore_in_sample_frequency` flag to `hl.de_novo`.; - (hail#9501) Configurable cache size for `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9474) Add `ArrayExpression.first` and `ArrayExpression.last`.; - (hail#9459) Add `StringExpression.join`, an analogue to Python's `str.join`.; - (hail#9398) Hail will now throw `HailUserError`s if the `or_error` branch of a `CaseBuilder` is hit. ### Bug fixes; - (hail#9503) NDArrays can now hold arbitrary data types, though only ndarrays of primitives can be collected to Python.; - (hail#9501) Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9424) `hl.experimental.writeBlockMatrices` didn't correctly support `overwrite` flag. ### Performance improvements; - (hail#9506) `hl.agg.ndarray_sum` will now do a tree aggregation. ### hailctl dataproc; - (hail#9502) Fix hailctl dataproc modify to install dependencies of the wheel file.; - (hail#9420) Add `--debug-mode` flag to `hailctl dataproc start`. This will enable heap dumps on OOM errors.; - (hail#9520) Add support for requester pays buckets to `hailctl dataproc describe`. ### Deprecations; - (hail#9482) `ArrayExpression.head` has been deprecated in favor of `ArrayExpression.first`. ---. ## Version 0.2.57. Released 2020-09-03. ### New features. - (hail#9343) Implement the KING method for relationship inference as `hl.methods.king`. ---. ## Version 0.2.56. Released 2020-08-31. ### New features. - (hail#9308) Add hl.enumerate in favor of hl.zip_with_index, which is now deprecated.; - (hail#9278) Add `ArrayExpression.grouped`, a function that groups hail arrays into fixed size subarrays. ### Performance. - (hail#9373)(hail#9374) Decrease amount of memory used when slicing or filtering along a single BlockMatrix dimension. ### Bug fixes. - (hail#9304) Fix crash in `run_combiner` caused by inputs where VCF lines ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:63273,Integrability,interface,interface,63273,"ration-time` argument to `hailctl dataproc start`.; - (hail#9263) Add support for `--no-max-idle`, `no-max-age`, `--max-age`, and `--expiration-time` to `hailctl dataproc --modify`. ---. ## Version 0.2.55. Released 2020-08-19. ### Performance. - (hail#9264) Table.checkpoint now uses a faster LZ4 compression scheme. ### Bug fixes. - (hail#9250) `hailctl dataproc` no longer uses deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that preven",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:63524,Integrability,message,messages,63524,"mpression scheme. ### Bug fixes. - (hail#9250) `hailctl dataproc` no longer uses deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *row_id* in `hl.import_matrix_table`. ---. ## Version 0.2.50. Released 2020-07-23. ### Bug fixes. - (hail#9114) CHANGELOG: Fixed crash when using repeated calls ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:63802,Integrability,depend,dependency,63802,"res the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *row_id* in `hl.import_matrix_table`. ---. ## Version 0.2.50. Released 2020-07-23. ### Bug fixes. - (hail#9114) CHANGELOG: Fixed crash when using repeated calls to `hl.filter_intervals`. ### New features. - (hail#9101) Add `hl.nd.{concat, hstack, vstack}` to concatenate ndarrays.; - (hail#9105) Add `hl.nd.{eye, identity}` to create identity matrix ndarrays.; - (hail#9093) Add `hl.nd.inv` to invert ndarrays.; - (hail#9063) Add `BlockM",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:66533,Integrability,depend,dependencies,66533,"d 2020-06-23. ### Bug fixes. - (hail#9009) Fix memory leak when counting per-partition. This caused excessive memory use in `BlockMatrix.write_from_entry_expr`, and likely in many other places.; - (hail#9006) Fix memory leak in `hl.export_bgen`.; - (hail#9001) Fix double close error that showed up on Azure Cloud. ## Version 0.2.46. Released 2020-06-17. ### Site; - (hail#8955) Natural language documentation search. ### Bug fixes; - (hail#8981) Fix BlockMatrix OOM triggered by the MatrixWriteBlockMatrix WriteBlocksRDD method. ---. ## Version 0.2.45. Release 2020-06-15. ### Bug fixes. - (hail#8948) Fix integer overflow error when reading files >2G with; `hl.import_plink`.; - (hail#8903) Fix Python type annotations for empty collection constructors and; `hl.shuffle`.; - (hail#8942) Refactored VCF combiner to support other GVCF schemas.; - (hail#8941) Fixed `hl.import_plink` with multiple data partitions. ### hailctl dataproc. - (hail#8946) Fix bug when a user specifies packages in `hailctl dataproc start`; that are also dependencies of the Hail package.; - (hail#8939) Support tuples in `hailctl dataproc describe`. ---. ## Version 0.2.44. Release 2020-06-06. ### New Features. - (hail#8914) `hl.export_vcf` can now export tables as sites-only VCFs.; - (hail#8894) Added `hl.shuffle` function to randomly permute arrays.; - (hail#8854) Add `composable` option to parallel text export for use with `gsutil compose`. ### Bug fixes. - (hail#8883) Fix an issue related to failures in pipelines with `force_bgz=True`. ### Performance. - (hail#8887) Substantially improve the performance of `hl.experimental.import_gtf`. ---. ## Version 0.2.43. Released 2020-05-28. ### Bug fixes. - (hail#8867) Fix a major correctness bug ocurring when calling BlockMatrix.transpose on sparse, non-symmetric BlockMatrices.; - (hail#8876) Fixed ""ChannelClosedException: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrali",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:71424,Integrability,message,message,71424,"ible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.multi_way_zip_join`.; - (hail#8488) Fix `hl.agg.call_stats` to appropriately throw an error for badly-formatted calls. ### New features. - (hail#8327) Attempting to write to the same file being read from in a pipeline will now throw an error instead of corrupting data. ---. ## Version 0.2.36. Released 2020-04-06. ### Critical Memory Management Bug Fix. - (hail#8463) Reverted a change (separate to the bug in 0.2.34) that led to a memory leak in version 0.2.35. ### Bug fixes; - (hail#8371) Fix runtime error in joins leading to ""Cannot set required field missing"" error message.; - (hail#8436) Fix compiler bug leading to possibly-invalid generated code. ---. ## Version 0.2.35. Released 2020-04-02. ### Critical Memory Management Bug Fix. - (hail#8412) Fixed a serious per-partition memory leak that causes certain pipelines to run out of memory unexpectedly. Please update from 0.2.34. ### New features. - (hail#8404) Added ""CanFam3"" (a reference genome for dogs) as a bundled reference genome. ### Bug fixes. - (hail#8420) Fixed a bug where `hl.binom_test`'s `""lower""` and `""upper""` alternative options were reversed.; - (hail#8377) Fixed ""inconsistent agg or scan environments"" error.; - (hail#8322) Fixed bug where `aggregate_rows` did not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_e",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:73095,Integrability,message,message,73095,"id not interact with `hl.agg.array_agg` correctly. ### Performance Improvements. - (hail#8413) Improves internal region memory management, decreasing JVM overhead.; - (hail#8383) Significantly improve GVCF import speed.; - (hail#8358) Fixed memory leak in `hl.experimental.export_entries_by_col`.; - (hail#8326) Codegen infrastructure improvement resulting in ~3% overall speedup. ### hailctl dataproc. - (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New features. - (hail#8233) `StringExpression.matches` can now take a hail `StringExpression`, as opposed to only regular python strings.; - (hail#8198) Improved matrix multiplication interoperation between hail `NDArrayExpression` and numpy. ### Bug fixes. - (hail#8279) Fix a bug where `hl.agg.approx_cdf` failed inside of a `group_cols_by`.; - (hail#8275) Fix bad error message coming from `mt.make_table()` when keys are missing.; - (hail#8274) Fix memory leak in `hl.export_bgen`.; - (hail#8273) Fix segfault caused by `hl.agg.downsample` inside of an `array_agg` or `group_by`. ### hailctl dataproc. - (hail#8253) `hailctl dataproc` now supports new flags `--requester-pays-allow-all` and `--requester-pays-allow-buckets`. This will configure your hail installation to be able to read from requester pays buckets. The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:74585,Integrability,message,message,74585,"The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:78378,Integrability,wrap,wrapping,78378,"Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ignored.; - (hail#7688) Added experimental support for `NDArrayExpression`s in new `hl.nd` module.; - (hail#7608) `hl.grep` now has a `show` argument that allows users to either print the results (default) or return a dictionary of the results. ### `hailctl dataproc`; - (hail#7717) Throw error when mispelling arguments instead of silently quitting. ---. ## Version 0.2.28. Released 2019-11-22. ### Critical correctness bug fix; - (hail#7588) Fixes a bug where filtering old matrix tables in newer versions of hail did not work as expected. Please update from 0.2.27. ### Bug fixes; - (hail#7571) Don't set GQ to missing if PL is missing in `split_multi_hts`.; - (hail#7577) Fixed an optimizer bug. ### New Features; - (hail#7561) Added `hl.plot.visualize_missingness()` to plot missingness patterns for MatrixTables.; - (hail#7575) A",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82483,Integrability,depend,dependencies,82483," increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance improvements; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:90210,Integrability,message,message,90210," genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not the full list of overlapping sample IDs.; - (hail#6583) Fixed `hl.plot.manhattan` for non-default reference genomes. ### Experimental. - (hail#6488) Exposed `table.multi_way_zip_join`. This takes a list of tables of; identical types, and zips them together into one table. ### File Format. - The native file format version is now 1.1.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. -----. ## Version 0.2.16. Released 2019-06-19. ### `hailctl`. - (hail#6357) Accommodated Google Dataproc bug causing cluster creation failures. ### Bug fixes. - (hail#6378) Fixed problem in how `entry_float_type` was being handled in `import_vcf`. -----. ## Version 0.2.15. Released 2019-06-14. After some infrastructural changes to our development process, we should be; getting back to frequent releases. ### `hailctl`. Starting in 0.2.15, `pip` installations of Hail c",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:92699,Integrability,depend,dependencies,92699,"artitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted numeric arrays.; - (hail#6224) Moved implementation of `hl.concordance` from backend to Python.; Performance directly from `read()` is slightly worse, but inside larger; pipelines this function will be optimized much better than before, and it; will benefit improvements to general infrastructure.; - (hail#6214) Updated Hail Python dependencies.; - (hail#5979) Added optimizer pass to rewrite filter expressions on keys as; interval filters where possible, leading to massive speedups for point queries.; See the [blog post](https://discuss.hail.is/t/new-optimizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior wh",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:94547,Integrability,depend,dependency,94547,"Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will now produce a much more detailed; error message.; - (hail#5723) `hl.import_matrix_table` can now import a matrix table with no; colum",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:95483,Integrability,message,message,95483," version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will now produce a much more detailed; error message.; - (hail#5723) `hl.import_matrix_table` can now import a matrix table with no; columns.; - (hail#5724) `hl.rand_norm2d` samples from a two dimensional random normal. ### Bug fixes. - (hail#5885) Fix `Table.to_spark` in the presence of fields of tuples.; - (hail#5882)(hail#5886) Fix `BlockMatrix` conversion methods to correctly; handle filtered entries.; - (hail#5884)(hail#4874) Fix longstanding crash when reading Hail data files; under certain conditions.; - (hail#5855)(hail#5786) Fix `hl.mendel_errors` incorrectly reporting children counts in; the presence of entry filtering.; - (hail#5830)(hail#5835) Fix Nirvana support; - (hail#5773) Fix `hl.sample_qc` to use correct number of total rows when; calculating call rate.; - (hail#5763)(hail#5764) Fix `hl.agg.array_agg` to work inside; `mt.annotate_rows` and similar functions.; - (hail#5770) Hail now uses the correct unicode string encoding which resolves a; number of issues when a Table o",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:98439,Integrability,wrap,wrappers,98439," MatrixTable, and Expression.; - (hail#5570) Add `hl.agg.approx_cdf` aggregator for approximate density calculation.; - (hail#5571) Add `log` parameter to `hl.plot.histogram`.; - (hail#5601) Add `hl.plot.joint_plot`, extend functionality of `hl.plot.scatter`.; - (hail#5608) Add LD score simulation framework.; - (hail#5628) Add `hl.experimental.full_outer_join_mt` for full outer joins on `MatrixTable`s. -----. ## Version 0.2.11. Released 2019-03-06. ### New features. - (hail#5374) Add default arguments to `hl.add_sequence` for running on GCP.; - (hail#5481) Added `sample_cols` method to `MatrixTable`.; - (hail#5501) Exposed `MatrixTable.unfilter_entries`. See `filter_entries` documentation for more information.; - (hail#5480) Added `n_cols` argument to `MatrixTable.head`.; - (hail#5529) Added `Table.{semi_join, anti_join}` and `MatrixTable.{semi_join_rows, semi_join_cols, anti_join_rows, anti_join_cols}`.; - (hail#5528) Added `{MatrixTable, Table}.checkpoint` methods as wrappers around `write` / `read_{matrix_table, table}`. ### Bug fixes. - (hail#5416) Resolved issue wherein VEP and certain regressions were recomputed on each use, rather than once.; - (hail#5419) Resolved issue with `import_vcf` `force_bgz` and file size checks.; - (hail#5427) Resolved issue with `Table.show` and dictionary field types.; - (hail#5468) Resolved ordering problem with `Expression.show` on key fields that are not the first key.; - (hail#5492) Fixed `hl.agg.collect` crashing when collecting `float32` values.; - (hail#5525) Fixed `hl.trio_matrix` crashing when `complete_trios` is `False`. -----. ## Version 0.2.10. Released 2019-02-15. ### New features. - (hail#5272) Added a new 'delimiter' option to Table.export.; - (hail#5251) Add utility aliases to `hl.plot` for `output_notebook` and `show`.; - (hail#5249) Add `histogram2d` function to `hl.plot` module.; - (hail#5247) Expose `MatrixTable.localize_entries` method for converting to a Table with an entries array.; - (hail#5300) Add new `fi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:100696,Integrability,interface,interface,100696,"Fix `ReferenceGenome.add_sequence` causing a crash.; - (hail#5268) Fix `Table.export` writing a file called 'None' in the current directory.; - (hail#5265) Fix `hl.get_reference` raising an exception when called before `hl.init()`.; - (hail#5250) Fix crash in `pc_relate` when called on a MatrixTable field other than 'GT'.; - (hail#5278) Fix crash in `Table.order_by` when sorting by fields whose names are not valid Python identifiers.; - (hail#5294) Fix crash in `hl.trio_matrix` when sample IDs are missing.; - (hail#5295) Fix crash in `Table.index` related to key field incompatibilities. -----. ## Version 0.2.9. Released 2019-01-30. ### New features. - (hail#5149) Added bitwise transformation functions: `hl.bit_{and, or, xor, not, lshift, rshift}`.; - (hail#5154) Added `hl.rbind` function, which is similar to `hl.bind` but expects a function as the last argument instead of the first. ### Performance improvements. - (hail#5107) Hail's Python interface generates tighter intermediate code, which should result in moderate performance improvements in many pipelines.; - (hail#5172) Fix unintentional performance deoptimization related to `Table.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `fl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103390,Integrability,message,message,103390,"export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103731,Integrability,message,messages,103731,"`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed ass",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103911,Integrability,message,message,103911,"ons, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4104,Modifiability,config,configuration,4104,"ule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5201,Modifiability,config,configuration,5201," Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:9002,Modifiability,config,config,9002,"API have moved from multi-regional US and EU buckets to; regional US-CENTRAL1 and EUROPE-WEST1 buckets. These buckets are requester pays which means unless; your cluster is in the US-CENTRAL1 or EUROPE-WEST1 region, you will pay a per-gigabyte rate to read; from the Annotation DB or Datasets API. We must make this change because [reading from a; multi-regional bucket into a regional VM is no longer; free](https://cloud.google.com/storage/pricing-announce#network). Unfortunately, cost constraints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`, `Table.annotate_globals`,; `Table.select_globals`, `Table.transmute_globals`, `Table.transmute`, `Table.annotate`, and; `Table.filter`.; - (hail#14242) Add examples to `Table.sample`, `Table.head`, and `Table.semi`_join. ### New Features. - (hail#14206) Introduce `hailctl config set http/timeout_in_seconds` which Batch and QoB users can; use to increase the timeout on their laptops. Laptops tend to have flaky internet connections and; a timeout of 300 seconds produces a more robust experience.; - (hail#14178) Reduce VDS Combiner runtime slightly by computing the maximum ref block length; without executing the combination pipeline twice.; - (hail#14207) VDS Combiner now verifies that every GVCF path and sample name is unique. ### Bug Fixes. - (hail#14300) Require orjson<3.9.12 to avoid a segfault introduced in orjson 3.9.12; - (hail#14071) Use indexed VEP cache files for GRCh38 on both dataproc and QoB.; - (hail#14232) Allow use of large numbers of fields on a table without triggering; `ClassTooLargeException: Class too large:`.; - (hail#14246)(hail#14245) Fix a bug, introduced in 0.2.114, in which `Table.multi_way_zip_join` and; `Table.aggregate_by_key` could throw ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially d",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:11436,Modifiability,config,configuration,11436,"t raise `NullPointerException` in certain rare cases; (e.g. when using `_key_by_assert_sorted`).; - (hail#14285) Fix a broken link in the MatrixTable tutorial. ### Deprecations. - (hail#14293) Support for the `hail-az://` scheme, deprecated in 0.2.116, is now gone. Please use; the standard `https://ACCOUNT.blob.core.windows.net/CONTAINER/PATH`. ## Version 0.2.127. Released 2024-01-12. If you have an Apple M1 laptop, verify that. ```; file $JAVA_HOME/bin/java; ```. returns a message including the phrase ""arm64"". If it instead includes the phrase ""x86_64"" then you; must upgrade to a new version of Java. You may find such a version of Java; [here](https://www.azul.com/downloads/?os=macos&architecture=arm-64-bit&package=jre#zulu). ### New Features. - (hail#14093) `hailctl dataproc` now creates clusters using Dataproc version 2.1.33. It previously used version 2.1.2.; - (hail#13617) Query-on-Batch now supports joining two tables keyed by intervals.; - (hail#13795)(hail#13567) Enable passing a requester pays configuration to `hailtop.fs.open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now support",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14459,Modifiability,rewrite,rewrite,14459,"traces are transmitted from workers to the driver to the client.; - (hail#14105) When a VCF contains missing values in array fields, Hail now suggests using `array_elements_required=False`. ### Deprecations. - (hail#13987) Deprecate `default_reference` parameter to `hl.init`, users should use `hl.default_reference` with an argument to set new default references usually shortly after `hl.init`. ## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures conta",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14951,Modifiability,variab,variable,14951,"introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in respo",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:17104,Modifiability,config,config,17104,"K was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc submit` now expands `~` in the `--files` and `--pyfiles` arguments. - (hail#13797) Fix (hail#13756). Operations that collect large results such as `to_pandas` may require up to 3x less memory. - (hail#13826) Fix (hail#13793). Ensure `hailctl describe -u` overrides the `gcs_requester_pays/project` config variable. - (hail#13814) Fix (hail#13757). Pipelines that are memory-bound by copious use of `hl.literal`, such as `hl.vds.filter_intervals`, require substantially less memory. - (hail#13894) Fix (hail#13837) in which Hail could break a Spark installation if the Hail JAR appears on the classpath before the Scala JARs. - (hail#13919) Fix (hail#13915) which prevented using a glob pattern in `hl.import_vcf`. ## Version 0.2.124. Released 2023-09-21. ### New Features. - (hail#13608) Change default behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.outpu",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:17111,Modifiability,variab,variable,17111,"K was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc submit` now expands `~` in the `--files` and `--pyfiles` arguments. - (hail#13797) Fix (hail#13756). Operations that collect large results such as `to_pandas` may require up to 3x less memory. - (hail#13826) Fix (hail#13793). Ensure `hailctl describe -u` overrides the `gcs_requester_pays/project` config variable. - (hail#13814) Fix (hail#13757). Pipelines that are memory-bound by copious use of `hl.literal`, such as `hl.vds.filter_intervals`, require substantially less memory. - (hail#13894) Fix (hail#13837) in which Hail could break a Spark installation if the Hail JAR appears on the classpath before the Scala JARs. - (hail#13919) Fix (hail#13915) which prevented using a glob pattern in `hl.import_vcf`. ## Version 0.2.124. Released 2023-09-21. ### New Features. - (hail#13608) Change default behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.outpu",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:19256,Modifiability,config,configuration,19256,"e number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom call fields via the `call_fields`; parameter.; - (hail#13224) `hailctl config get`, `set`, and `unset` now support shell auto-completion. Run; `hailctl --install-completion zsh` to install the auto-completion for `zsh`. You must already have; completion enabled for `zsh`.; - (hail#13279) Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.impor",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:19468,Modifiability,config,config,19468,"sentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom call fields via the `call_fields`; parameter.; - (hail#13224) `hailctl config get`, `set`, and `unset` now support shell auto-completion. Run; `hailctl --install-completion zsh` to install the auto-completion for `zsh`. You must already have; completion enabled for `zsh`.; - (hail#13279) Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, the",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:35935,Modifiability,config,config,35935,"4) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables with HTML unsafe column headers are rendered wrong in Jupyter.; - (hail#12574) Fixed a memory leak when processing tables. Could trigger unnecessarily high memory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to use in batch scripts when not specified in code.; - (hail#12497) Added support for `scales`, `nrow`, and `ncol` arguments, as well as grouped legends, to `hail.ggplot.facet_wrap`.; - (hail#12471) Added `hailctl batch submit` command to run local scripts inside batch jobs.; - (hail#12525) Add support for passing arguments to `hailctl batch submit`.; - (hail#12465) Batch jobs' status now contains the region the job ran in. The job itself can access which region it is in through the `HAIL_REGION` environment variable.; - (hail#12464) When using Query-on-Batch, all jobs for a single hail session are inserted into the same batch instead of one batch per action.; - (hail#12457) `pca` and `hwe_normalized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:36513,Modifiability,variab,variable,36513,"mory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to use in batch scripts when not specified in code.; - (hail#12497) Added support for `scales`, `nrow`, and `ncol` arguments, as well as grouped legends, to `hail.ggplot.facet_wrap`.; - (hail#12471) Added `hailctl batch submit` command to run local scripts inside batch jobs.; - (hail#12525) Add support for passing arguments to `hailctl batch submit`.; - (hail#12465) Batch jobs' status now contains the region the job ran in. The job itself can access which region it is in through the `HAIL_REGION` environment variable.; - (hail#12464) When using Query-on-Batch, all jobs for a single hail session are inserted into the same batch instead of one batch per action.; - (hail#12457) `pca` and `hwe_normalized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:37698,Modifiability,config,configuration,37698,"malized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which inclu",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:44141,Modifiability,config,configuration,44141,"0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container imag",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68085,Modifiability,config,configured,68085,"tf`. ---. ## Version 0.2.43. Released 2020-05-28. ### Bug fixes. - (hail#8867) Fix a major correctness bug ocurring when calling BlockMatrix.transpose on sparse, non-symmetric BlockMatrices.; - (hail#8876) Fixed ""ChannelClosedException: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### Ne",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69203,Modifiability,config,configuration,69203,"Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Li",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69250,Modifiability,config,configure,69250,"#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correct",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:73461,Modifiability,config,configure,73461,"- (hail#8399) Enable spark speculation by default.; - (hail#8340) Add new Australia region to `--vep`.; - (hail#8347) Support all GCP machine types as potential master machines. ---. ## Version 0.2.34. Released 2020-03-12. ### New features. - (hail#8233) `StringExpression.matches` can now take a hail `StringExpression`, as opposed to only regular python strings.; - (hail#8198) Improved matrix multiplication interoperation between hail `NDArrayExpression` and numpy. ### Bug fixes. - (hail#8279) Fix a bug where `hl.agg.approx_cdf` failed inside of a `group_cols_by`.; - (hail#8275) Fix bad error message coming from `mt.make_table()` when keys are missing.; - (hail#8274) Fix memory leak in `hl.export_bgen`.; - (hail#8273) Fix segfault caused by `hl.agg.downsample` inside of an `array_agg` or `group_by`. ### hailctl dataproc. - (hail#8253) `hailctl dataproc` now supports new flags `--requester-pays-allow-all` and `--requester-pays-allow-buckets`. This will configure your hail installation to be able to read from requester pays buckets. The charges for reading from these buckets will be billed to the project that the cluster is created in.; - (hail#8268) The data sources for VEP have been moved to `gs://hail-us-vep`, `gs://hail-eu-vep`, and `gs://hail-uk-vep`, which are requester-pays buckets in Google Cloud. `hailctl dataproc` will automatically infer which of these buckets you should pull data from based on the region your cluster is spun up in. If you are in none of those regions, please contact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:76321,Modifiability,config,configuration,76321,"ely.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in inges",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82956,Modifiability,config,configuration,82956,"ments; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:92752,Modifiability,rewrite,rewrite,92752,"all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted numeric arrays.; - (hail#6224) Moved implementation of `hl.concordance` from backend to Python.; Performance directly from `read()` is slightly worse, but inside larger; pipelines this function will be optimized much better than before, and it; will benefit improvements to general infrastructure.; - (hail#6214) Updated Hail Python dependencies.; - (hail#5979) Added optimizer pass to rewrite filter expressions on keys as; interval filters where possible, leading to massive speedups for point queries.; See the [blog post](https://discuss.hail.is/t/new-optimizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.spl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:97672,Modifiability,extend,extend,97672,"l#5730)(hail#5782) Taught `import_bgen` to optimize its `variants` argument. ### Experimental. - (hail#5732) The `hl.agg.approx_quantiles` aggregate computes an approximation; of the quantiles of an expression.; - (hail#5693)(hail#5396) `Table._multi_way_zip_join` now correctly handles keys; that have been truncated. -----. ## Version 0.2.12. Released 2019-03-28. ### New features. - (hail#5614) Add support for multiple missing values in `hl.import_table`.; - (hail#5666) Produce HTML table output for `Table.show()` when running in Jupyter notebook. ### Bug fixes. - (hail#5603)(hail#5697) Fixed issue where `min_partitions` on `hl.import_table` was non-functional.; - (hail#5611) Fix `hl.nirvana` crash. ### Experimental. - (hail#5524) Add `summarize` functions to Table, MatrixTable, and Expression.; - (hail#5570) Add `hl.agg.approx_cdf` aggregator for approximate density calculation.; - (hail#5571) Add `log` parameter to `hl.plot.histogram`.; - (hail#5601) Add `hl.plot.joint_plot`, extend functionality of `hl.plot.scatter`.; - (hail#5608) Add LD score simulation framework.; - (hail#5628) Add `hl.experimental.full_outer_join_mt` for full outer joins on `MatrixTable`s. -----. ## Version 0.2.11. Released 2019-03-06. ### New features. - (hail#5374) Add default arguments to `hl.add_sequence` for running on GCP.; - (hail#5481) Added `sample_cols` method to `MatrixTable`.; - (hail#5501) Exposed `MatrixTable.unfilter_entries`. See `filter_entries` documentation for more information.; - (hail#5480) Added `n_cols` argument to `MatrixTable.head`.; - (hail#5529) Added `Table.{semi_join, anti_join}` and `MatrixTable.{semi_join_rows, semi_join_cols, anti_join_rows, anti_join_cols}`.; - (hail#5528) Added `{MatrixTable, Table}.checkpoint` methods as wrappers around `write` / `read_{matrix_table, table}`. ### Bug fixes. - (hail#5416) Resolved issue wherein VEP and certain regressions were recomputed on each use, rather than once.; - (hail#5419) Resolved issue with `import_vcf` `force_bgz",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103093,Modifiability,variab,variable,103093,"ionality.; - (hail#5122) Fixed error constructing `Table` or `MatrixTable` objects with fields with certain character patterns like `$`. -----. ## Version 0.2.7. Released 2019-01-03. ### New features. - (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_stra",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:9596,Performance,cache,cache,9596,"ve chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`, `Table.annotate_globals`,; `Table.select_globals`, `Table.transmute_globals`, `Table.transmute`, `Table.annotate`, and; `Table.filter`.; - (hail#14242) Add examples to `Table.sample`, `Table.head`, and `Table.semi`_join. ### New Features. - (hail#14206) Introduce `hailctl config set http/timeout_in_seconds` which Batch and QoB users can; use to increase the timeout on their laptops. Laptops tend to have flaky internet connections and; a timeout of 300 seconds produces a more robust experience.; - (hail#14178) Reduce VDS Combiner runtime slightly by computing the maximum ref block length; without executing the combination pipeline twice.; - (hail#14207) VDS Combiner now verifies that every GVCF path and sample name is unique. ### Bug Fixes. - (hail#14300) Require orjson<3.9.12 to avoid a segfault introduced in orjson 3.9.12; - (hail#14071) Use indexed VEP cache files for GRCh38 on both dataproc and QoB.; - (hail#14232) Allow use of large numbers of fields on a table without triggering; `ClassTooLargeException: Class too large:`.; - (hail#14246)(hail#14245) Fix a bug, introduced in 0.2.114, in which `Table.multi_way_zip_join` and; `Table.aggregate_by_key` could throw ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially different from the desired; number of output partitions.; - (hail#14202) Support coercing `{}` (the empty dictionary) into any Struct type (with all missing; fields).; - (hail#14239) Remove an erroneous statement from the MatrixTable tutorial.; - (hail#14176) `hailtop.fs.ls` can now list a bucket, e.g. `hailtop.fs.ls(""gs://my-bucket"")`.; - (hail#14258) Fix `import_avro` to not raise `NullPointerException` in certain rare cases; (e.g. when using `_key_by_assert_sorted`).; - (hail#14285) Fix a broken link in the MatrixTable tutorial. ### Deprecations. - (hail",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14791,Performance,latency,latency,14791," to set new default references usually shortly after `hl.init`. ## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by i",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:18381,Performance,optimiz,optimization,18381,"classpath before the Scala JARs. - (hail#13919) Fix (hail#13915) which prevented using a glob pattern in `hl.import_vcf`. ## Version 0.2.124. Released 2023-09-21. ### New Features. - (hail#13608) Change default behavior of hl.ggplot.geom_density to use a new method. The old method is still available using the flag smoothed=True. The new method is typically a much more accurate representation, and works well for any distribution, not just smooth ones. ## Version 0.2.123. Released 2023-09-19. ### New Features. - (hail#13610) Additional setup is no longer required when using hail.plot or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.output_notebook and/or setting plotly.io.renderers.default = 'iframe' is no longer necessary). ### Bug Fixes; - (hail#13634) Fix a bug which caused Query-on-Batch pipelines with a large number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom ca",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:20885,Performance,perform,performance,20885,"il#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#13479) in which `hl.vds.local_to_global` could produce invalid values when; the LA field is too short. There were and are no issues when the LA field has the correct length.; - (hail#13340) Fix `copy_log` to correctly copy relative file paths.; - (hail#13364) `hl.import_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hailctl; option.; - (hail#13422) `hailtop.hail_frozenlist.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:21212,Performance,optimiz,optimization,21212,"rt_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hailctl; option.; - (hail#13422) `hailtop.hail_frozenlist.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickle-able.; - (hail#13505) Fix bug introduced in 0.2.117 by commit `c9de81108` which prevented the passing of; keyword arguments to Python jobs. This manifested as ""ValueError: too many values to unpack"".; - (hail#13536) Fixed (hail#13535) which prevented the use of Python jobs when the client (e.g. your; laptop) Python version is 3.11 or later.; - (hail#13434) In QoB, Hail's file systems now correctly list all files in a directory, n",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:23993,Performance,perform,performance,23993,"ed 2023-07-27. ### New Features; - (hail#13206) The VDS Combiner now works in Query-on-Batch. ### Bug Fixes; - (hail#13313) Fix bug introduced in 0.2.119 which causes a serialization error when using; Query-on-Spark to read a VCF which is sorted by locus, with split multi-allelics, in which the; records sharing a single locus do not appear in the dictionary ordering of their alternate; alleles.; - (hail#13264) Fix bug which ignored the `partition_hint` of a Table group-by-and-aggregate.; - (hail#13239) Fix bug which ignored the `HAIL_BATCH_REGIONS` argument when determining in which; regions to schedule jobs when using Query-on-Batch.; - (hail#13253) Improve `hadoop_ls` and `hfs.ls` to quickly list globbed files in a directory. The; speed improvement is proportional to the number of files in the directory.; - (hail#13226) Fix the comparison of an `hl.Struct` to an `hl.struct` or field of type; `tstruct`. Resolves (hail#13045) and (Hail#13046).; - (hail#12995) Fixed bug causing poor performance and memory leaks for `MatrixTable.annotate_rows`; aggregations. ## Version 0.2.119. Released 2023-06-28. ### New Features; - (hail#12081) Hail now uses [Zstandard](https://facebook.github.io/zstd/) as; the default compression algorithm for table and matrix table storage. Reducing; file size around 20% in most cases.; - (hail#12988) Arbitrary aggregations can now be used on arrays via; `ArrayExpression.aggregate`. This method is useful for accessing; functionality that exists in the aggregator library but not the; basic expression library, for instance, `call_stats`.; - (hail#13166) Add an `eigh` ndarray method, for finding eigenvalues; of symmetric matrices (""h"" is for Hermitian, the complex analogue of; symmetric). ### Bug Fixes; - (hail#13184) The `vds.to_dense_mt` no longer densifies past the end of; contig boundaries. A logic bug in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27301,Performance,perform,performs,27301,"uccessfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This i",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:33766,Performance,perform,performance,33766," data from requester pays buckets.; - (hail#12739) Fix `hl.plot.cdf`, `hl.plot.pdf`, and `hl.plot.joint_plot` which were broken by changes in Hail and changes in bokeh.; - (hail#12735) Fix (hail#11738) by allowing user to override default types in `to_pandas`.; - (hail#12760) Mitigate some JVM bytecode generation errors, particularly those related to too many method parameters.; - (hail#12766) Fix (hail#12759) by loosening `parsimonious` dependency pin.; - (hail#12732) In Query on Batch, fix bug that sometimes prevented terminating a pipeline using Control-C.; - (hail#12771) Use a version of `jgscm` whose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time.; - (hail#12566) Improve error message when combining incompatibly indexed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:37870,Performance,perform,performance,37870,"on has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fixes. - (hail#12305): Fixed a rare crash reading tables/matrixtables with _intervals. ---. #",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:41258,Performance,perform,performance,41258,"ail-vdc` are no longer supported.; Use `hailgenetics/python-dill` instead. ### Bug fixes. - (hail#12215) Fix search bar in the Hail Batch documentation. ---. ## Version 0.2.100. Released 2022-09-23. ### New Features. - (hail#12207) Add support for the `shape` aesthetic to `hail.ggplot.geom_point`. ### Deprecations. - (hail#12213) The `batch_size` parameter of `vds.new_combiner` is deprecated in favor of `gvcf_batch_size`. ### Bug fixes. - (hail#12216) Fix bug that caused `make install-on-cluster` to fail with a message about `sys_platform`.; - (hail#12164) Fix bug that caused Query on Batch pipelines to fail on datasets with indexes greater than 2GiB. ---. ## Version 0.2.99. Released 2022-09-13. ### New Features. - (hail#12091) Teach `Table` to `write_many`, which writes one table per provided field.; - (hail#12067) Add `rand_int32` and `rand_int64` for generating random 32-bit and 64-bit integers, respectively. ### Performance Improvements. - (hail#12159) Improve performance of MatrixTable reads when using `_intervals` argument. ### Bug fixes. - (hail#12179) Fix incorrect composition of interval filters with unordered interval lists that could lead to over- or under-filtering.; - (hail#12162) Fixed crash in `collect_cols_by_key` with preceding random functions. ---. ## Version 0.2.98. Released 2022-08-22. ### New Features. - (hail#12062) `hl.balding_nichols_model` now supports an optional boolean parameter, `phased`, to control the phasedness of the generated genotypes. ### Performance improvements. - (hail#12099) Make repeated VCF/PLINK queries much faster by caching compiler data structures.; - (hail#12038) Speed up `hl.import_matrix_table` by caching header line computation. ### Bug fixes. - (hail#12115) When using `use_new_shuffle=True`, fix a bug when there are more than 2^31 rows; - (hail#12074) Fix bug where `hl.init` could silently overwrite the global random seed.; - (hail#12079) Fix bug in handling of missing (aka NA) fields in grouped aggregation and dis",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:50420,Performance,perform,performance,50420,"min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; - (hail#11276) Fixed `log` argument in `hail.plot.pdf`.; - (hail#11256) Fixed memory leak in LD Prune. ### New features. - (hail#11274) Added `geom_col` to `hail.ggplot`. ### hailctl dataproc. - (hail#11280) Updated dataproc image version to one not affected by log4j vulnerabilities. ---. ## Version 0.2.82. Release 2022-01-24. ### Bug fixes. - (hail#11209) Significantly improved usefulness and speed of `Table.to_pandas`, resolved several bugs with output. ### New features. - (hail#11247) Introduces a new experimental plotting interface `hail.ggplot`, based on R's ggplot library.; - (hail#11173) Many math functions like `hail.sqrt` now automatically broadcast over ndarrays. ### Performance Improvements. - (hail#11216) Significantly improve performance of `parse_locus_interval`. ### Python and Java Support. - (hail#11219) We no longer officially support Python 3.6, though it may continue to work in the short term.; - (hail#11220) We support building hail with Java 11. ### File Format. - The native file format version is now 1.6.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.81. Release 2021-12-20. ### hailctl dataproc. - (hail#11182) Updated Dataproc image version to mitigate yet more Log4j vulnerabilities. ---. ## Version 0.2.80. Release 2021-12-15. ### New features. - (hail#11077) `hl.experimental.write_matrix_tables` now returns the paths of the written matrix tables. ### hailctl dataproc. - (hail#11157) Updated Dataproc image version to mitigate the Log4j vulnerability.; - (hail#10900) Added `--region` parameter to `hailctl dataproc submit`.; - (hail#11090) Teach `hailctl dataproc describe` how to read URLs with the protocols `s3` (Amazo",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:52098,Performance,optimiz,optimized,52098,"erimental.write_matrix_tables` now returns the paths of the written matrix tables. ### hailctl dataproc. - (hail#11157) Updated Dataproc image version to mitigate the Log4j vulnerability.; - (hail#10900) Added `--region` parameter to `hailctl dataproc submit`.; - (hail#11090) Teach `hailctl dataproc describe` how to read URLs with the protocols `s3` (Amazon S3), `hail-az` (Azure Blob Storage), and `file` (local file system) in addition to `gs` (Google Cloud Storage). ---. ## Version 0.2.79. Release 2021-11-17. ### Bug fixes. - (hail#11023) Fixed bug in call decoding that was introduced in version 0.2.78. ### New features. - (hail#10993) New function `p_value_excess_het`. ---. ## Version 0.2.78. Release 2021-10-19. ### Bug fixes; - (hail#10766) Don't throw out of memory error when broadcasting more than 2^(31) - 1 bytes.; - (hail#10910) Filters on key field won't be slowed down by uses of `MatrixTable.localize_entries` or `Table.rename`.; - (hail#10959) Don't throw an error in certain situations where some key fields are optimized away. ### New features; - (hail#10855) Arbitrary aggregations can be implemented using `hl.agg.fold`. ### Performance Improvements; - (hail#10971) Substantially improve the speed of `Table.collect` when collecting large amounts of data. ---. ## Version 0.2.77. Release 2021-09-21. ### Bug fixes. - (hail#10888) Fix crash when calling `hl.liftover`.; - (hail#10883) Fix crash / long compilation times writing matrix tables with many partitions. ---. ## Version 0.2.76. Released 2021-09-15. ### Bug fixes. - (hail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all sequences is large.; - (hail#10765) Fix rare bug where valid pipelines would fail to compile if intervals were created conditionally.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:53591,Performance,perform,performance,53591,"ail#10872) Fix long compile times or method size errors when writing tables with many partitions; - (hail#10878) Fix crash importing or sorting tables with empty data partitions. ---. ## Version 0.2.75. Released 2021-09-10. ### Bug fixes. - (hail#10733) Fix a bug in tabix parsing when the size of the list of all sequences is large.; - (hail#10765) Fix rare bug where valid pipelines would fail to compile if intervals were created conditionally.; - (hail#10746) Various compiler improvements, decrease likelihood of `ClassTooLarge` errors.; - (hail#10829) Fix a bug where `hl.missing` and `CaseBuilder.or_error` failed if their type was a struct containing a field starting with a number. ### New features. - (hail#10768) Support multiplying `StringExpression`s to repeat them, as with normal python strings. ### Performance improvements. - (hail#10625) Reduced need to copy strings around, pipelines with many string operations should get faster.; - (hail#10775) Improved performance of `to_matrix_table_row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes. - (hail#10684) Fixed a rare bug reading arrays from disk where short arrays would have their first elements corrupted and long arrays would cause segfaults.; - (hail#10523) Fixed bug where liftover would fail with ""Could not initialize class"" errors. ---. ## Version 0.2.72. Released 2021-07-19. ### New Features. - (hail#10655) Revamped many hail error messages to give useful python stack traces.; - (hail#10663) Added `DictExpression.items()` to mirror python's `dict.items()`.; - (hail#10657) `hl.map` now supports mapping over multiple lists like Python's built-in `map`. ### Bug fixes. - (hail#10662) Fi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:55860,Performance,perform,performance,55860,"linear regression to `hl.linear_regression_rows`.; - (hail#10635) Added `hl.nd.maximum` and `hl.nd.minimum`.; - (hail#10602) Added `hl.starmap`. ### Bug fixes. - (hail#10038) Fixed crashes when writing/reading matrix tables with 0 partitions.; - (hail#10624) Fixed out of bounds bug with `_quantile_from_cdf`. ### hailctl dataproc. - (hail#10633) Added `--scopes` parameter to `hailctl dataproc start`. ---. ## Version 0.2.70. Released 2021-06-21. ---. ## Version 0.2.69. Released 2021-06-14. ### New Features. - (hail#10592) Added `hl.get_hgdp` function.; - (hail#10555) Added `hl.hadoop_scheme_supported` function.; - (hail#10551) Indexing ndarrays now supports ellipses. ### Bug fixes. - (hail#10553) Dividing two integers now returns a `float64`, not a `float32`.; - (hail#10595) Don't include nans in `lambda_gc_agg`. ### hailctl dataproc. - (hail#10574) Hail logs will now be stored in `/home/hail` by default. ---. ## Version 0.2.68. Released 2021-05-27. ---. ## Version 0.2.67. ### Critical performance fix. Released 2021-05-06. - (hail#10451) Fixed a memory leak / performance bug triggered by `hl.literal(...).contains(...)`. ---. ## Version 0.2.66. Released 2021-05-03. ### New features. - (hail#10398) Added new method `BlockMatrix.to_ndarray`.; - (hail#10251) Added suport for haploid GT calls to VCF combiner. ---. ## Version 0.2.65. Released 2021-04-14. ### Default Spark Version Change. - Starting from version 0.2.65, Hail uses Spark 3.1.1 by default. This will also allow the use of all python versions >= 3.6. By building hail from source, it is still possible to use older versions of Spark. ### New features. - (hail#10290) Added `hl.nd.solve`.; - (hail#10187) Added `NDArrayNumericExpression.sum`. ### Performance improvements. - (hail#10233) Loops created with `hl.experimental.loop` will now clean up unneeded memory between iterations. ### Bug fixes. - (hail#10227) `hl.nd.qr` now supports ndarrays that have 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ##",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:55935,Performance,perform,performance,55935," `hl.nd.maximum` and `hl.nd.minimum`.; - (hail#10602) Added `hl.starmap`. ### Bug fixes. - (hail#10038) Fixed crashes when writing/reading matrix tables with 0 partitions.; - (hail#10624) Fixed out of bounds bug with `_quantile_from_cdf`. ### hailctl dataproc. - (hail#10633) Added `--scopes` parameter to `hailctl dataproc start`. ---. ## Version 0.2.70. Released 2021-06-21. ---. ## Version 0.2.69. Released 2021-06-14. ### New Features. - (hail#10592) Added `hl.get_hgdp` function.; - (hail#10555) Added `hl.hadoop_scheme_supported` function.; - (hail#10551) Indexing ndarrays now supports ellipses. ### Bug fixes. - (hail#10553) Dividing two integers now returns a `float64`, not a `float32`.; - (hail#10595) Don't include nans in `lambda_gc_agg`. ### hailctl dataproc. - (hail#10574) Hail logs will now be stored in `/home/hail` by default. ---. ## Version 0.2.68. Released 2021-05-27. ---. ## Version 0.2.67. ### Critical performance fix. Released 2021-05-06. - (hail#10451) Fixed a memory leak / performance bug triggered by `hl.literal(...).contains(...)`. ---. ## Version 0.2.66. Released 2021-05-03. ### New features. - (hail#10398) Added new method `BlockMatrix.to_ndarray`.; - (hail#10251) Added suport for haploid GT calls to VCF combiner. ---. ## Version 0.2.65. Released 2021-04-14. ### Default Spark Version Change. - Starting from version 0.2.65, Hail uses Spark 3.1.1 by default. This will also allow the use of all python versions >= 3.6. By building hail from source, it is still possible to use older versions of Spark. ### New features. - (hail#10290) Added `hl.nd.solve`.; - (hail#10187) Added `NDArrayNumericExpression.sum`. ### Performance improvements. - (hail#10233) Loops created with `hl.experimental.loop` will now clean up unneeded memory between iterations. ### Bug fixes. - (hail#10227) `hl.nd.qr` now supports ndarrays that have 0 rows or columns. ---. ## Version 0.2.64. Released 2021-03-11. ### New features; - (hail#10164) Add source_file_field parameter to hl.imp",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:58877,Performance,perform,performance,58877,"8) Make certain array copies faster.; - (hail#10061) Improve code generation of `hl.if_else` and `hl.coalesce`. ---. ## Version 0.2.62. Released 2021-02-03. ### New features. - (hail#9936) Deprecated `hl.null` in favor of `hl.missing` for naming consistency.; - (hail#9973) `hl.vep` now includes a `vep_proc_id` field to aid in debugging unexpected output.; - (hail#9839) Hail now eagerly deletes temporary files produced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument and a varargs of Boolean expressions.; - (hail#9816) `hl.pc_relate` now includes values on the diagonal of kinship, IBD-0, IBD-1, and IBD-2; - (hail#9736) Let NDArrayExpression.reshape take varargs instead of mandating a tuple.; - (hail#9766) `hl.export_vcf` now warns if INFO field names are invalid according to the VCF 4.3 spec. ### Bug fixes. - (hail#9976) Fixed `show()` representation of Hail dictionaries. ### Performance improvements. - (hail#9909) Improved performance of `hl.experimental.densify` by approximately 35%. ---. ## Version 0.2.61. Released 2020-12-03. ### New features. - (hail#9749) Add or_error method to SwitchBuilder (`hl.switch`). ### Bug fixes. - (hail#9775) Fixed race condition leading to invalid intermediate files in VCF combiner.; - (hail#9751) Fix bug where constructing an array of empty structs causes type error.; - (hail#9731) Fix error and incorrect behavior when using `hl.import_matrix_table` with int64 data types. ---. ## Version 0.2.60. Released 2020-11-16. ### New features. - (hail#9696) `hl.experimental.export_elasticsearch` will now support Elasticsearch versions 6.8 - 7.x by default. ### Bug fixes. - (hail#9641) Showing hail ndarray data now always prints in correct order. ### hailctl dataproc. - (hail#9610) Support interval fields in `hailctl dataproc describe`. ---. ## Version 0.2.59. Released 2020-10-22. ### Datasets / Annotation DB. - (hail#9605) The Datasets API and the Annotation Database now support ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:59104,Performance,race condition,race condition,59104,"ncy.; - (hail#9973) `hl.vep` now includes a `vep_proc_id` field to aid in debugging unexpected output.; - (hail#9839) Hail now eagerly deletes temporary files produced by some BlockMatrix operations.; - (hail#9835) `hl.any` and `hl.all` now also support a single collection argument and a varargs of Boolean expressions.; - (hail#9816) `hl.pc_relate` now includes values on the diagonal of kinship, IBD-0, IBD-1, and IBD-2; - (hail#9736) Let NDArrayExpression.reshape take varargs instead of mandating a tuple.; - (hail#9766) `hl.export_vcf` now warns if INFO field names are invalid according to the VCF 4.3 spec. ### Bug fixes. - (hail#9976) Fixed `show()` representation of Hail dictionaries. ### Performance improvements. - (hail#9909) Improved performance of `hl.experimental.densify` by approximately 35%. ---. ## Version 0.2.61. Released 2020-12-03. ### New features. - (hail#9749) Add or_error method to SwitchBuilder (`hl.switch`). ### Bug fixes. - (hail#9775) Fixed race condition leading to invalid intermediate files in VCF combiner.; - (hail#9751) Fix bug where constructing an array of empty structs causes type error.; - (hail#9731) Fix error and incorrect behavior when using `hl.import_matrix_table` with int64 data types. ---. ## Version 0.2.60. Released 2020-11-16. ### New features. - (hail#9696) `hl.experimental.export_elasticsearch` will now support Elasticsearch versions 6.8 - 7.x by default. ### Bug fixes. - (hail#9641) Showing hail ndarray data now always prints in correct order. ### hailctl dataproc. - (hail#9610) Support interval fields in `hailctl dataproc describe`. ---. ## Version 0.2.59. Released 2020-10-22. ### Datasets / Annotation DB. - (hail#9605) The Datasets API and the Annotation Database now support AWS, and users are required to specify what cloud platform they're using. ### hailctl dataproc. - (hail#9609) Fixed bug where `hailctl dataproc modify` did not correctly print corresponding `gcloud` command. ---. ## Version 0.2.58. Released 2020-10-08. ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:60304,Performance,cache,cache,60304,"avior when using `hl.import_matrix_table` with int64 data types. ---. ## Version 0.2.60. Released 2020-11-16. ### New features. - (hail#9696) `hl.experimental.export_elasticsearch` will now support Elasticsearch versions 6.8 - 7.x by default. ### Bug fixes. - (hail#9641) Showing hail ndarray data now always prints in correct order. ### hailctl dataproc. - (hail#9610) Support interval fields in `hailctl dataproc describe`. ---. ## Version 0.2.59. Released 2020-10-22. ### Datasets / Annotation DB. - (hail#9605) The Datasets API and the Annotation Database now support AWS, and users are required to specify what cloud platform they're using. ### hailctl dataproc. - (hail#9609) Fixed bug where `hailctl dataproc modify` did not correctly print corresponding `gcloud` command. ---. ## Version 0.2.58. Released 2020-10-08. ### New features. - (hail#9524) Hail should now be buildable using Spark 3.0.; - (hail#9549) Add `ignore_in_sample_frequency` flag to `hl.de_novo`.; - (hail#9501) Configurable cache size for `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9474) Add `ArrayExpression.first` and `ArrayExpression.last`.; - (hail#9459) Add `StringExpression.join`, an analogue to Python's `str.join`.; - (hail#9398) Hail will now throw `HailUserError`s if the `or_error` branch of a `CaseBuilder` is hit. ### Bug fixes; - (hail#9503) NDArrays can now hold arbitrary data types, though only ndarrays of primitives can be collected to Python.; - (hail#9501) Remove memory leak in `BlockMatrix.to_matrix_table_row_major` and `BlockMatrix.to_table_row_major`.; - (hail#9424) `hl.experimental.writeBlockMatrices` didn't correctly support `overwrite` flag. ### Performance improvements; - (hail#9506) `hl.agg.ndarray_sum` will now do a tree aggregation. ### hailctl dataproc; - (hail#9502) Fix hailctl dataproc modify to install dependencies of the wheel file.; - (hail#9420) Add `--debug-mode` flag to `hailctl dataproc start`. This will enable heap dumps on OOM",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:63364,Performance,perform,performance,63364,"ion-time` to `hailctl dataproc --modify`. ---. ## Version 0.2.55. Released 2020-08-19. ### Performance. - (hail#9264) Table.checkpoint now uses a faster LZ4 compression scheme. ### Bug fixes. - (hail#9250) `hailctl dataproc` no longer uses deprecated `gcloud`; flags. Consequently, users must update to a recent version of `gcloud`.; - (hail#9294) The ""Python 3"" kernel in notebooks in clusters started by `hailctl; dataproc` now features the same Spark monitoring widget found in the ""Hail""; kernel. There is now no reason to use the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *r",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:64850,Performance,perform,performance,64850,"il#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *row_id* in `hl.import_matrix_table`. ---. ## Version 0.2.50. Released 2020-07-23. ### Bug fixes. - (hail#9114) CHANGELOG: Fixed crash when using repeated calls to `hl.filter_intervals`. ### New features. - (hail#9101) Add `hl.nd.{concat, hstack, vstack}` to concatenate ndarrays.; - (hail#9105) Add `hl.nd.{eye, identity}` to create identity matrix ndarrays.; - (hail#9093) Add `hl.nd.inv` to invert ndarrays.; - (hail#9063) Add `BlockMatrix.tree_matmul` to improve matrix multiply performance with a large inner dimension. ---. ## Version 0.2.49. Released 2020-07-08. ### Bug fixes. - (hail#9058) Fixed memory leak affecting `Table.aggregate`, `MatrixTable.annotate_cols` aggregations, and `hl.sample_qc`. ---. ## Version 0.2.48. Released 2020-07-07. ### Bug fixes. - (hail#9029) Fix crash when using `hl.agg.linreg` with no aggregated data records.; - (hail#9028) Fixed memory leak affecting `Table.annotate` with scans, `hl.experimental.densify`, and `Table.group_by` / `aggregate`.; - (hail#8978) Fixed aggregation behavior of `MatrixTable.{group_rows_by, group_cols_by}` to skip filtered entries. ---. ## Version 0.2.47. Released 2020-06-23. ### Bug fixes. - (hail#9009) Fix memory leak when counting per-partition. This caused excessive memory use in `BlockMatrix.write_from_entry_expr`, and likely in many other places.; - (hail#9006) Fix memory leak in `hl.export_bgen`.; - (hail#9001) Fix double close error that showed up on Azure Cloud. ## Version 0.2.46. Released 2020-06",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:67083,Performance,perform,performance,67083,"5. ### Bug fixes. - (hail#8948) Fix integer overflow error when reading files >2G with; `hl.import_plink`.; - (hail#8903) Fix Python type annotations for empty collection constructors and; `hl.shuffle`.; - (hail#8942) Refactored VCF combiner to support other GVCF schemas.; - (hail#8941) Fixed `hl.import_plink` with multiple data partitions. ### hailctl dataproc. - (hail#8946) Fix bug when a user specifies packages in `hailctl dataproc start`; that are also dependencies of the Hail package.; - (hail#8939) Support tuples in `hailctl dataproc describe`. ---. ## Version 0.2.44. Release 2020-06-06. ### New Features. - (hail#8914) `hl.export_vcf` can now export tables as sites-only VCFs.; - (hail#8894) Added `hl.shuffle` function to randomly permute arrays.; - (hail#8854) Add `composable` option to parallel text export for use with `gsutil compose`. ### Bug fixes. - (hail#8883) Fix an issue related to failures in pipelines with `force_bgz=True`. ### Performance. - (hail#8887) Substantially improve the performance of `hl.experimental.import_gtf`. ---. ## Version 0.2.43. Released 2020-05-28. ### Bug fixes. - (hail#8867) Fix a major correctness bug ocurring when calling BlockMatrix.transpose on sparse, non-symmetric BlockMatrices.; - (hail#8876) Fixed ""ChannelClosedException: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69780,Performance,perform,performance,69780,"; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69879,Performance,perform,performing,69879,"y strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correctness bug in the linear regression aggregator. This was introduced in version 0.2.29.; See https://discuss.hail.is/t/possible-incorrect-linreg-aggregator-results-in-0-2-29-0-2-37/1375 for more details. ### Performance improvements; - (hail#8558) Make `hl.experimental.export_entries_by_col` more fault tolerant. ----. ## Version 0.2.37. Released 2020-04-14. ### Bug fixes. - (hail#8487) Fix incorrect handling of badly formatted data for `hl.gp_dosage`.; - (hail#8497) Fix handling of missingness for `hl.hamming`.; - (hail#8537) Fix compile-time errror.; - (hail#8539) Fix compiler error in `Table.mult",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75002,Performance,perform,performance,75002,tact us on discuss.hail.is. ### File Format. - The native file format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet s,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75050,Performance,perform,performance,75050,e format version is now 1.4.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New fe,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75195,Performance,perform,performance,75195,sion of Hail. ---. ## Version 0.2.33. Released 2020-02-27. ### New features. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75261,Performance,perform,performance,75261,atures. - (hail#8173) Added new method `hl.zeros`. ### Bug fixes. - (hail#8153) Fixed complier bug causing `MatchError` in `import_bgen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hai,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75365,Performance,perform,performance,75365,"gen`.; - (hail#8123) Fixed an issue with multiple Python HailContexts running on the same cluster.; - (hail#8150) Fixed an issue where output from VEP about failures was not reported in error message.; - (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:75577,Performance,optimiz,optimizer,75577,"- (hail#8152) Fixed an issue where the row count of a MatrixTable coming from `import_matrix_table` was incorrect.; - (hail#8175) Fixed a bug where `persist` did not actually do anything. ### `hailctl dataproc`. - (hail#8079) Using `connect` to open the jupyter notebook browser will no longer crash if your project contains requester-pays buckets. ---. ## Version 0.2.32. Released 2020-02-07. ### Critical performance regression fix. - (hail#7989) Fixed performance regression leading to a large slowdown when `hl.variant_qc` was run after filtering columns. ### Performance. - (hail#7962) Improved performance of `hl.pc_relate`.; - (hail#8032) Drastically improve performance of pipelines calling `hl.variant_qc` and `hl.sample_qc` iteratively.; - (hail#8037) Improve performance of NDArray matrix multiply by using native linear algebra libraries. ### Bug fixes. - (hail#7976) Fixed divide-by-zero error in `hl.concordance` with no overlapping rows or cols.; - (hail#7965) Fixed optimizer error leading to crashes caused by `MatrixTable.union_rows`.; - (hail#8035) Fix compiler bug in `Table.multi_way_zip_join`.; - (hail#8021) Fix bug in computing shape after `BlockMatrix.filter`.; - (hail#7986) Fix error in NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression p",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:76763,Performance,perform,performance,76763,"n NDArray matrix/vector multiply. ### New features. - (hail#8007) Add `hl.nd.diagonal` function. ### Cheat sheets. - (hail#7940) Added cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:76890,Performance,perform,performance,76890,"ded cheat sheet for MatrixTables.; - (hail#7963) Improved Table sheet sheet. ---. ## Version 0.2.31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompa",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:77031,Performance,perform,performance,77031,"31. Released 2020-01-22. ### New features. - (hail#7787) Added transition/transversion information to `hl.summarize_variants`.; - (hail#7792) Add Python stack trace to array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matr",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:77187,Performance,optimiz,optimizer,77187," array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:77475,Performance,perform,performance,77475,`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Adde,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:77551,Performance,perform,performance,77551,"e. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hail#7653) Fixed crash in `ld_prune` by unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ig",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:79243,Performance,optimiz,optimizer,79243,"y unfiltering missing GTs. ### Performance improvements; - (hail#7719) Generate more efficient IR for `Table.flatten`.; - (hail#7740) Method wrapping large let bindings to keep method size down. ### New features; - (hail#7686) Added `comment` argument to `import_matrix_table`, allowing lines with certain prefixes to be ignored.; - (hail#7688) Added experimental support for `NDArrayExpression`s in new `hl.nd` module.; - (hail#7608) `hl.grep` now has a `show` argument that allows users to either print the results (default) or return a dictionary of the results. ### `hailctl dataproc`; - (hail#7717) Throw error when mispelling arguments instead of silently quitting. ---. ## Version 0.2.28. Released 2019-11-22. ### Critical correctness bug fix; - (hail#7588) Fixes a bug where filtering old matrix tables in newer versions of hail did not work as expected. Please update from 0.2.27. ### Bug fixes; - (hail#7571) Don't set GQ to missing if PL is missing in `split_multi_hts`.; - (hail#7577) Fixed an optimizer bug. ### New Features; - (hail#7561) Added `hl.plot.visualize_missingness()` to plot missingness patterns for MatrixTables.; - (hail#7575) Added `hl.version()` to quickly check hail version. ### `hailctl dataproc`; - (hail#7586) `hailctl dataproc` now supports `--gcloud_configuration` option. ### Documentation; - (hail#7570) Hail has a cheatsheet for Tables now. ---. ## Version 0.2.27. Released 2019-11-15. ### New Features. - (hail#7379) Add `delimiter` argument to `hl.import_matrix_table`; - (hail#7389) Add `force` and `force_bgz` arguments to `hl.experimental.import_gtf`; - (hail#7386)(hail#7394) Add `{Table, MatrixTable}.tail`.; - (hail#7467) Added `hl.if_else` as an alias for `hl.cond`; deprecated `hl.cond`.; - (hail#7453) Add `hl.parse_int{32, 64}` and `hl.parse_float{32, 64}`, which can parse strings to numbers and return missing on failure.; - (hail#7475) Add `row_join_type` argument to `MatrixTable.union_cols` to support outer joins on rows. ### Bug fixes. - (hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:80272,Performance,optimiz,optimizer,80272,"## New Features; - (hail#7561) Added `hl.plot.visualize_missingness()` to plot missingness patterns for MatrixTables.; - (hail#7575) Added `hl.version()` to quickly check hail version. ### `hailctl dataproc`; - (hail#7586) `hailctl dataproc` now supports `--gcloud_configuration` option. ### Documentation; - (hail#7570) Hail has a cheatsheet for Tables now. ---. ## Version 0.2.27. Released 2019-11-15. ### New Features. - (hail#7379) Add `delimiter` argument to `hl.import_matrix_table`; - (hail#7389) Add `force` and `force_bgz` arguments to `hl.experimental.import_gtf`; - (hail#7386)(hail#7394) Add `{Table, MatrixTable}.tail`.; - (hail#7467) Added `hl.if_else` as an alias for `hl.cond`; deprecated `hl.cond`.; - (hail#7453) Add `hl.parse_int{32, 64}` and `hl.parse_float{32, 64}`, which can parse strings to numbers and return missing on failure.; - (hail#7475) Add `row_join_type` argument to `MatrixTable.union_cols` to support outer joins on rows. ### Bug fixes. - (hail#7479)(hail#7368)(hail#7402) Fix optimizer bugs.; - (hail#7506) Updated to latest htsjdk to resolve VCF parsing problems. ### `hailctl dataproc`. - (hail#7460) The Spark monitor widget now automatically collapses after a job completes. ---. ## Version 0.2.26. Released 2019-10-24. ### New Features; - (hail#7325) Add `string.reverse` function.; - (hail#7328) Add `string.translate` function.; - (hail#7344) Add `hl.reverse_complement` function.; - (hail#7306) Teach the VCF combiner to handle allele specific (`AS_*`) fields.; - (hail#7346) Add `hl.agg.approx_median` function. ### Bug Fixes; - (hail#7361) Fix `AD` calculation in `sparse_split_multi`. ### Performance Improvements; - (hail#7355) Improve performance of IR copying. ### File Format. - The native file format version is now 1.3.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.25. Released 2019-10-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:80944,Performance,perform,performance,80944,"n alias for `hl.cond`; deprecated `hl.cond`.; - (hail#7453) Add `hl.parse_int{32, 64}` and `hl.parse_float{32, 64}`, which can parse strings to numbers and return missing on failure.; - (hail#7475) Add `row_join_type` argument to `MatrixTable.union_cols` to support outer joins on rows. ### Bug fixes. - (hail#7479)(hail#7368)(hail#7402) Fix optimizer bugs.; - (hail#7506) Updated to latest htsjdk to resolve VCF parsing problems. ### `hailctl dataproc`. - (hail#7460) The Spark monitor widget now automatically collapses after a job completes. ---. ## Version 0.2.26. Released 2019-10-24. ### New Features; - (hail#7325) Add `string.reverse` function.; - (hail#7328) Add `string.translate` function.; - (hail#7344) Add `hl.reverse_complement` function.; - (hail#7306) Teach the VCF combiner to handle allele specific (`AS_*`) fields.; - (hail#7346) Add `hl.agg.approx_median` function. ### Bug Fixes; - (hail#7361) Fix `AD` calculation in `sparse_split_multi`. ### Performance Improvements; - (hail#7355) Improve performance of IR copying. ### File Format. - The native file format version is now 1.3.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.25. Released 2019-10-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable, Table}.describe`. Use this by passing the argument `widget=True`.; - (hail#7250) `{Table, MatrixTable, Expression}.summarize()` now summarizes elements of collections (arrays, sets, dicts).; - (hail#7271) Improve `hl.plot.qq` by increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:81899,Performance,optimiz,optimizer,81899,"lti`. ### Performance Improvements; - (hail#7355) Improve performance of IR copying. ### File Format. - The native file format version is now 1.3.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.25. Released 2019-10-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable, Table}.describe`. Use this by passing the argument `widget=True`.; - (hail#7250) `{Table, MatrixTable, Expression}.summarize()` now summarizes elements of collections (arrays, sets, dicts).; - (hail#7271) Improve `hl.plot.qq` by increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance improvements; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172)",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:81980,Performance,perform,performance,81980,". - The native file format version is now 1.3.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.25. Released 2019-10-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable, Table}.describe`. Use this by passing the argument `widget=True`.; - (hail#7250) `{Table, MatrixTable, Expression}.summarize()` now summarizes elements of collections (arrays, sets, dicts).; - (hail#7271) Improve `hl.plot.qq` by increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance improvements; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:82094,Performance,perform,performance,82094," tables written by this version of Hail. ## Version 0.2.25. Released 2019-10-14. ### New features; - (hail#7240) Add interactive schema widget to `{MatrixTable, Table}.describe`. Use this by passing the argument `widget=True`.; - (hail#7250) `{Table, MatrixTable, Expression}.summarize()` now summarizes elements of collections (arrays, sets, dicts).; - (hail#7271) Improve `hl.plot.qq` by increasing point size, adding the unscaled p-value to hover data, and printing lambda-GC on the plot.; - (hail#7280) Add HTML output for `{Table, MatrixTable, Expression}.summarize()`.; - (hail#7294) Add HTML output for `hl.summarize_variants()`. ### Bug fixes; - (hail#7200) Fix VCF parsing with missingness inside arrays of floating-point values in the FORMAT field.; - (hail#7219) Fix crash due to invalid optimizer rule. ### Performance improvements; - (hail#7187) Dramatically improve performance of chained `BlockMatrix` multiplies without checkpoints in between.; - (hail#7195)(hail#7194) Improve performance of `group[_rows]_by` / `aggregate`.; - (hail#7201) Permit code generation of larger aggregation pipelines. ### File Format. - The native file format version is now 1.2.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:83914,Performance,perform,perform,83914,"ermit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84412,Performance,perform,performance,84412,"to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack over",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84464,Performance,perform,performance,84464," Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New fea",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84517,Performance,perform,performance,84517,"y collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value di",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84618,Performance,perform,performance,84618,"methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84869,Performance,perform,performance,84869,"; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (hail#6903) Teach `BlockMatrix` how to `checkpoint`. ### Performance; - (hail#6895) Improved performance of `hl.import_bgen(...).count()`.; - (hail#6948) Fixed performance bug in `BlockMatrix` filtering functions.; - (hail#6943) Improv",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84958,Performance,perform,performance,84958,"y management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (hail#6903) Teach `BlockMatrix` how to `checkpoint`. ### Performance; - (hail#6895) Improved performance of `hl.import_bgen(...).count()`.; - (hail#6948) Fixed performance bug in `BlockMatrix` filtering functions.; - (hail#6943) Improved scaling of `Table.union`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:85716,Performance,perform,performance,85716," Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (hail#6903) Teach `BlockMatrix` how to `checkpoint`. ### Performance; - (hail#6895) Improved performance of `hl.import_bgen(...).count()`.; - (hail#6948) Fixed performance bug in `BlockMatrix` filtering functions.; - (hail#6943) Improved scaling of `Table.union`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ### `hailctl dataproc`; - (hail#6904) Added `--dry-run` option to `submit`.; - (hail#6951) Fixed `--max-idle` and `--max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; -",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:85783,Performance,perform,performance,85783," and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (hail#7033)(hail#7049) Various improvements leading to overall 10-15%; improvement. ### `hailctl dataproc`; - (hail#7003) Pass through extra arguments for `hailctl dataproc list` and; `hailctl dataproc stop`. ---. ## Version 0.2.21. Released 2019-09-03. ### Bug fixes; - (hail#6945) Fixed `expand_types` to preserve ordering by key, also affects; `to_pandas` and `to_spark`.; - (hail#6958) Fixed stack overflow errors when counting the result of a `Table.union`. ### New features; - (hail#6856) Teach `hl.agg.counter` to weigh each value differently.; - (hail#6903) Teach `hl.range` to treat a single argument as `0..N`.; - (hail#6903) Teach `BlockMatrix` how to `checkpoint`. ### Performance; - (hail#6895) Improved performance of `hl.import_bgen(...).count()`.; - (hail#6948) Fixed performance bug in `BlockMatrix` filtering functions.; - (hail#6943) Improved scaling of `Table.union`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ### `hailctl dataproc`; - (hail#6904) Added `--dry-run` option to `submit`.; - (hail#6951) Fixed `--max-idle` and `--max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:86823,Performance,perform,performance,86823,"functions.; - (hail#6943) Improved scaling of `Table.union`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ### `hailctl dataproc`; - (hail#6904) Added `--dry-run` option to `submit`.; - (hail#6951) Fixed `--max-idle` and `--max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:86875,Performance,perform,performance,86875,"nion`.; - (hail#6980) Reduced compute time for `split_multi_hts` by as much as 40%. ### `hailctl dataproc`; - (hail#6904) Added `--dry-run` option to `submit`.; - (hail#6951) Fixed `--max-idle` and `--max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:87083,Performance,optimiz,optimizations,87083,"max-age` arguments to `start`.; - (hail#6919) Added `--update-hail-version` to `modify`. ---. ## Version 0.2.20. Released 2019-08-19. ### Critical memory management fix. - (hail#6824) Fixed memory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:87437,Performance,perform,performance,87437,".lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed cod",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:87514,Performance,perform,performance,87514,"nd `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:87659,Performance,perform,performance,87659,"gate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:87714,Performance,perform,performance,87714,"l.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349)",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88038,Performance,perform,performance,88038,"s; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88114,Performance,perform,performance,88114,"er_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by a",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88489,Performance,perform,performance,88489,"ized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:88533,Performance,perform,performance,88533,"- (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expressi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:89018,Performance,load,load,89018,"## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:89101,Performance,perform,performance,89101,"issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue has exists in versions 0.2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:89280,Performance,perform,performance,89280,".2.15, 0.2.16, and 0.2.17, and; any users on those versions should update as soon as possible.**. ### Bug fixes. - (hail#6598) Fixed code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:89417,Performance,perform,performance,89417," code generated by `MatrixTable.unfilter_entries` to; improve performance. This will slightly improve the performance of; `hwe_normalized_pca` and relatedness computation methods, which use; `unfilter_entries` internally. -----. ## Version 0.2.17. Released 2019-07-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not the full list of overlapping sample IDs.; - (hail#6583) Fixed `hl.plot.manhattan` for non-default reference genomes. ### Experimenta",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:89698,Performance,optimiz,optimization,89698,"7-10. ### New features. - (hail#6349) Added `compression` parameter to `export_block_matrices`, which can; be `'gz'` or `'bgz'`.; - (hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not the full list of overlapping sample IDs.; - (hail#6583) Fixed `hl.plot.manhattan` for non-default reference genomes. ### Experimental. - (hail#6488) Exposed `table.multi_way_zip_join`. This takes a list of tables of; identical types, and zips them together into one table. ### File Format. - The native file format version is now 1.1.0. Older versions of Hail will not; be able to read tables or ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:89835,Performance,optimiz,optimization,89835,"hail#6405) When a matrix table has string column-keys, `matrixtable.show` uses; the column key as the column name.; - (hail#6345) Added an improved scan implementation, which reduces the memory; load on master.; - (hail#6462) Added `export_bgen` method.; - (hail#6473) Improved performance of `hl.agg.array_sum` by about 50%.; - (hail#6498) Added method `hl.lambda_gc` to calculate the genomic control inflation factor.; - (hail#6456) Dramatically improved performance of pipelines containing long chains of calls to; `Table.annotate`, or `MatrixTable` equivalents.; - (hail#6506) Improved the performance of the generated code for the `Table.annotate(**thing)`; pattern. ### Bug fixes. - (hail#6404) Added `n_rows` and `n_cols` parameters to `Expression.show` for; consistency with other `show` methods.; - (hail#6408)(hail#6419) Fixed an issue where the `filter_intervals` optimization; could make scans return incorrect results.; - (hail#6459)(hail#6458) Fixed rare correctness bug in the `filter_intervals`; optimization which could result too many rows being kept.; - (hail#6496) Fixed html output of `show` methods to truncate long field; contents.; - (hail#6478) Fixed the broken documentation for the experimental `approx_cdf`; and `approx_quantiles` aggregators.; - (hail#6504) Fix `Table.show` collecting data twice while running in Jupyter notebooks.; - (hail#6571) Fixed the message printed in `hl.concordance` to print the number of overlapping; samples, not the full list of overlapping sample IDs.; - (hail#6583) Fixed `hl.plot.manhattan` for non-default reference genomes. ### Experimental. - (hail#6488) Exposed `table.multi_way_zip_join`. This takes a list of tables of; identical types, and zips them together into one table. ### File Format. - The native file format version is now 1.1.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. -----. ## Version 0.2.16. Released 2019-06-19. ### `hailctl`. - (hail#6357) Accommoda",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:92568,Performance,optimiz,optimized,92568,"accept keyword arguments to pass through to `hl.import_table`, which is used; internally. This permits parameters like `min_partitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted numeric arrays.; - (hail#6224) Moved implementation of `hl.concordance` from backend to Python.; Performance directly from `read()` is slightly worse, but inside larger; pipelines this function will be optimized much better than before, and it; will benefit improvements to general infrastructure.; - (hail#6214) Updated Hail Python dependencies.; - (hail#5979) Added optimizer pass to rewrite filter expressions on keys as; interval filters where possible, leading to massive speedups for point queries.; See the [blog post](https://discuss.hail.is/t/new-optimizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:92734,Performance,optimiz,optimizer,92734,"all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted numeric arrays.; - (hail#6224) Moved implementation of `hl.concordance` from backend to Python.; Performance directly from `read()` is slightly worse, but inside larger; pipelines this function will be optimized much better than before, and it; will benefit improvements to general infrastructure.; - (hail#6214) Updated Hail Python dependencies.; - (hail#5979) Added optimizer pass to rewrite filter expressions on keys as; interval filters where possible, leading to massive speedups for point queries.; See the [blog post](https://discuss.hail.is/t/new-optimizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.spl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:92922,Performance,optimiz,optimizer-pass-that-extracts-point-queries-and-interval-filters,92922,"y. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted numeric arrays.; - (hail#6224) Moved implementation of `hl.concordance` from backend to Python.; Performance directly from `read()` is slightly worse, but inside larger; pipelines this function will be optimized much better than before, and it; will benefit improvements to general infrastructure.; - (hail#6214) Updated Hail Python dependencies.; - (hail#5979) Added optimizer pass to rewrite filter expressions on keys as; interval filters where possible, leading to massive speedups for point queries.; See the [blog post](https://discuss.hail.is/t/new-optimizer-pass-that-extracts-point-queries-and-interval-filters/979); for examples. ### Bug fixes. - (hail#5895) Fixed crash caused by `-0.0` floating-point values in `hl.agg.hist`.; - (hail#6013) Turned off feature in HTSJDK that caused crashes in `hl.import_vcf`; due to header fields being overwritten with different types, if the field had; a different type than the type in the VCF 4.2 spec.; - (hail#6117) Fixed problem causing `Table.flatten()` to be quadratic in the size; of the schema.; - (hail#6228)(hail#5993) Fixed `MatrixTable.union_rows()` to join distinct keys; on the right, preventing an unintentional cartesian product.; - (hail#6235) Fixed an issue related to aggregation inside `MatrixTable.filter_cols`.; - (hail#6226) Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has b",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:94651,Performance,perform,performance,94651,"Restored lost behavior where `Table.show(x < 0)` shows the entire table.; - (hail#6267) Fixed cryptic crashes related to `hl.split_multi` and `MatrixTable.entries()`; with duplicate row keys. -----. ## Version 0.2.14. Released 2019-04-24. A back-incompatible patch update to PySpark, 2.4.2, has broken fresh pip; installs of Hail 0.2.13. To fix this, either *downgrade* PySpark to 2.4.1 or; upgrade to the latest version of Hail. ### New features. - (hail#5915) Added `hl.cite_hail` and `hl.cite_hail_bibtex` functions to; generate appropriate citations.; - (hail#5872) Fixed `hl.init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will now produce a much more detailed; error message.; - (hail#5723) `hl.import_matrix_table` can now import a matrix table with no; columns.; - (hail#5724) `hl.rand_norm2d` samples from a two dimensional random normal. ### B",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:95242,Performance,perform,performance,95242,"init` when the `idempotent` parameter is `True`. -----. ## Version 0.2.13. Released 2019-04-18. Hail is now using Spark 2.4.x by default. If you build hail from source, you; will need to acquire this version of Spark and update your build invocations; accordingly. ### New features. - (hail#5828) Remove dependency on htsjdk for VCF INFO parsing, enabling; faster import of some VCFs.; - (hail#5860) Improve performance of some column annotation pipelines.; - (hail#5858) Add `unify` option to `Table.union` which allows unification of; tables with different fields or field orderings.; - (hail#5799) `mt.entries()` is four times faster.; - (hail#5756) Hail now uses Spark 2.4.x by default.; - (hail#5677) `MatrixTable` now also supports `show`.; - (hail#5793)(hail#5701) Add `array.index(x)` which find the first index of; `array` whose value is equal to `x`.; - (hail#5790) Add `array.head()` which returns the first element of the array,; or missing if the array is empty.; - (hail#5690) Improve performance of `ld_matrix`.; - (hail#5743) `mt.compute_entry_filter_stats` computes statistics about the number; of filtered entries in a matrix table.; - (hail#5758) failure to parse an interval will now produce a much more detailed; error message.; - (hail#5723) `hl.import_matrix_table` can now import a matrix table with no; columns.; - (hail#5724) `hl.rand_norm2d` samples from a two dimensional random normal. ### Bug fixes. - (hail#5885) Fix `Table.to_spark` in the presence of fields of tuples.; - (hail#5882)(hail#5886) Fix `BlockMatrix` conversion methods to correctly; handle filtered entries.; - (hail#5884)(hail#4874) Fix longstanding crash when reading Hail data files; under certain conditions.; - (hail#5855)(hail#5786) Fix `hl.mendel_errors` incorrectly reporting children counts in; the presence of entry filtering.; - (hail#5830)(hail#5835) Fix Nirvana support; - (hail#5773) Fix `hl.sample_qc` to use correct number of total rows when; calculating call rate.; - (hail#5763)(hail#576",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:96722,Performance,optimiz,optimize,96722,"e presence of fields of tuples.; - (hail#5882)(hail#5886) Fix `BlockMatrix` conversion methods to correctly; handle filtered entries.; - (hail#5884)(hail#4874) Fix longstanding crash when reading Hail data files; under certain conditions.; - (hail#5855)(hail#5786) Fix `hl.mendel_errors` incorrectly reporting children counts in; the presence of entry filtering.; - (hail#5830)(hail#5835) Fix Nirvana support; - (hail#5773) Fix `hl.sample_qc` to use correct number of total rows when; calculating call rate.; - (hail#5763)(hail#5764) Fix `hl.agg.array_agg` to work inside; `mt.annotate_rows` and similar functions.; - (hail#5770) Hail now uses the correct unicode string encoding which resolves a; number of issues when a Table or MatrixTable has a key field containing; unicode characters.; - (hail#5692) When `keyed` is `True`, `hl.maximal_independent_set` now does not; produce duplicates.; - (hail#5725) Docs now consistently refer to `hl.agg` not `agg`.; - (hail#5730)(hail#5782) Taught `import_bgen` to optimize its `variants` argument. ### Experimental. - (hail#5732) The `hl.agg.approx_quantiles` aggregate computes an approximation; of the quantiles of an expression.; - (hail#5693)(hail#5396) `Table._multi_way_zip_join` now correctly handles keys; that have been truncated. -----. ## Version 0.2.12. Released 2019-03-28. ### New features. - (hail#5614) Add support for multiple missing values in `hl.import_table`.; - (hail#5666) Produce HTML table output for `Table.show()` when running in Jupyter notebook. ### Bug fixes. - (hail#5603)(hail#5697) Fixed issue where `min_partitions` on `hl.import_table` was non-functional.; - (hail#5611) Fix `hl.nirvana` crash. ### Experimental. - (hail#5524) Add `summarize` functions to Table, MatrixTable, and Expression.; - (hail#5570) Add `hl.agg.approx_cdf` aggregator for approximate density calculation.; - (hail#5571) Add `log` parameter to `hl.plot.histogram`.; - (hail#5601) Add `hl.plot.joint_plot`, extend functionality of `hl.plot.scatter`",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:100775,Performance,perform,performance,100775,"Fix `ReferenceGenome.add_sequence` causing a crash.; - (hail#5268) Fix `Table.export` writing a file called 'None' in the current directory.; - (hail#5265) Fix `hl.get_reference` raising an exception when called before `hl.init()`.; - (hail#5250) Fix crash in `pc_relate` when called on a MatrixTable field other than 'GT'.; - (hail#5278) Fix crash in `Table.order_by` when sorting by fields whose names are not valid Python identifiers.; - (hail#5294) Fix crash in `hl.trio_matrix` when sample IDs are missing.; - (hail#5295) Fix crash in `Table.index` related to key field incompatibilities. -----. ## Version 0.2.9. Released 2019-01-30. ### New features. - (hail#5149) Added bitwise transformation functions: `hl.bit_{and, or, xor, not, lshift, rshift}`.; - (hail#5154) Added `hl.rbind` function, which is similar to `hl.bind` but expects a function as the last argument instead of the first. ### Performance improvements. - (hail#5107) Hail's Python interface generates tighter intermediate code, which should result in moderate performance improvements in many pipelines.; - (hail#5172) Fix unintentional performance deoptimization related to `Table.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `fl",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:100852,Performance,perform,performance,100852,"in the current directory.; - (hail#5265) Fix `hl.get_reference` raising an exception when called before `hl.init()`.; - (hail#5250) Fix crash in `pc_relate` when called on a MatrixTable field other than 'GT'.; - (hail#5278) Fix crash in `Table.order_by` when sorting by fields whose names are not valid Python identifiers.; - (hail#5294) Fix crash in `hl.trio_matrix` when sample IDs are missing.; - (hail#5295) Fix crash in `Table.index` related to key field incompatibilities. -----. ## Version 0.2.9. Released 2019-01-30. ### New features. - (hail#5149) Added bitwise transformation functions: `hl.bit_{and, or, xor, not, lshift, rshift}`.; - (hail#5154) Added `hl.rbind` function, which is similar to `hl.bind` but expects a function as the last argument instead of the first. ### Performance improvements. - (hail#5107) Hail's Python interface generates tighter intermediate code, which should result in moderate performance improvements in many pipelines.; - (hail#5172) Fix unintentional performance deoptimization related to `Table.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `float32` as well as `float64`. ### Performance improvements. - (hail#5068) Improved optimization of `MatrixTable.coun",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:100947,Performance,perform,performance,100947,"en called before `hl.init()`.; - (hail#5250) Fix crash in `pc_relate` when called on a MatrixTable field other than 'GT'.; - (hail#5278) Fix crash in `Table.order_by` when sorting by fields whose names are not valid Python identifiers.; - (hail#5294) Fix crash in `hl.trio_matrix` when sample IDs are missing.; - (hail#5295) Fix crash in `Table.index` related to key field incompatibilities. -----. ## Version 0.2.9. Released 2019-01-30. ### New features. - (hail#5149) Added bitwise transformation functions: `hl.bit_{and, or, xor, not, lshift, rshift}`.; - (hail#5154) Added `hl.rbind` function, which is similar to `hl.bind` but expects a function as the last argument instead of the first. ### Performance improvements. - (hail#5107) Hail's Python interface generates tighter intermediate code, which should result in moderate performance improvements in many pipelines.; - (hail#5172) Fix unintentional performance deoptimization related to `Table.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `float32` as well as `float64`. ### Performance improvements. - (hail#5068) Improved optimization of `MatrixTable.count_cols`.; - (hail#5131) Fixed performance bug related to `hl.literal` on large values w",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:101825,Performance,optimiz,optimization,101825,"#5172) Fix unintentional performance deoptimization related to `Table.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `float32` as well as `float64`. ### Performance improvements. - (hail#5068) Improved optimization of `MatrixTable.count_cols`.; - (hail#5131) Fixed performance bug related to `hl.literal` on large values with missingness. ### Bug fixes. - (hail#5088) Fixed name separator in `MatrixTable.make_table`.; - (hail#5104) Fixed optimizer bug related to experimental functionality.; - (hail#5122) Fixed error constructing `Table` or `MatrixTable` objects with fields with certain character patterns like `$`. -----. ## Version 0.2.7. Released 2019-01-03. ### New features. - (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:101888,Performance,perform,performance,101888,"able.show` introduced in 0.2.8.; - (hail#5078) Improve performance of `hl.ld_prune` by up to 30x. ### Bug fixes. - (hail#5144) Fix crash caused by `hl.index_bgen` (since 0.2.7); - (hail#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `float32` as well as `float64`. ### Performance improvements. - (hail#5068) Improved optimization of `MatrixTable.count_cols`.; - (hail#5131) Fixed performance bug related to `hl.literal` on large values with missingness. ### Bug fixes. - (hail#5088) Fixed name separator in `MatrixTable.make_table`.; - (hail#5104) Fixed optimizer bug related to experimental functionality.; - (hail#5122) Fixed error constructing `Table` or `MatrixTable` objects with fields with certain character patterns like `$`. -----. ## Version 0.2.7. Released 2019-01-03. ### New features. - (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#492",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:102062,Performance,optimiz,optimizer,102062,"#5177) Fix bug causing `Table.repartition(n, shuffle=True)` to fail to increase partitioning for unkeyed tables.; - (hail#5173) Fix bug causing `Table.show` to throw an error when the table is empty (since 0.2.8).; - (hail#5210) Fix bug causing `Table.show` to always print types, regardless of `types` argument (since 0.2.8).; - (hail#5211) Fix bug causing `MatrixTable.make_table` to unintentionally discard non-key row fields (since 0.2.8). -----. ## Version 0.2.8. Released 2019-01-15. ### New features. - (hail#5072) Added multi-phenotype option to `hl.logistic_regression_rows`; - (hail#5077) Added support for importing VCF floating-point FORMAT fields as `float32` as well as `float64`. ### Performance improvements. - (hail#5068) Improved optimization of `MatrixTable.count_cols`.; - (hail#5131) Fixed performance bug related to `hl.literal` on large values with missingness. ### Bug fixes. - (hail#5088) Fixed name separator in `MatrixTable.make_table`.; - (hail#5104) Fixed optimizer bug related to experimental functionality.; - (hail#5122) Fixed error constructing `Table` or `MatrixTable` objects with fields with certain character patterns like `$`. -----. ## Version 0.2.7. Released 2019-01-03. ### New features. - (hail#5046)(experimental) Added option to BlockMatrix.export_rectangles to export as NumPy-compatible binary. ### Performance improvements. - (hail#5050) Short-circuit iteration in `logistic_regression_rows` and `poisson_regression_rows` if NaNs appear. -----. ## Version 0.2.6. Released 2018-12-17. ### New features. - (hail#4962) Expanded comparison operators (`==`, `!=`, `<`, `<=`, `>`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104582,Performance,optimiz,optimizer,104582,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104924,Performance,optimiz,optimizer,104924,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:9089,Safety,timeout,timeout,9089,"API have moved from multi-regional US and EU buckets to; regional US-CENTRAL1 and EUROPE-WEST1 buckets. These buckets are requester pays which means unless; your cluster is in the US-CENTRAL1 or EUROPE-WEST1 region, you will pay a per-gigabyte rate to read; from the Annotation DB or Datasets API. We must make this change because [reading from a; multi-regional bucket into a regional VM is no longer; free](https://cloud.google.com/storage/pricing-announce#network). Unfortunately, cost constraints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`, `Table.annotate_globals`,; `Table.select_globals`, `Table.transmute_globals`, `Table.transmute`, `Table.annotate`, and; `Table.filter`.; - (hail#14242) Add examples to `Table.sample`, `Table.head`, and `Table.semi`_join. ### New Features. - (hail#14206) Introduce `hailctl config set http/timeout_in_seconds` which Batch and QoB users can; use to increase the timeout on their laptops. Laptops tend to have flaky internet connections and; a timeout of 300 seconds produces a more robust experience.; - (hail#14178) Reduce VDS Combiner runtime slightly by computing the maximum ref block length; without executing the combination pipeline twice.; - (hail#14207) VDS Combiner now verifies that every GVCF path and sample name is unique. ### Bug Fixes. - (hail#14300) Require orjson<3.9.12 to avoid a segfault introduced in orjson 3.9.12; - (hail#14071) Use indexed VEP cache files for GRCh38 on both dataproc and QoB.; - (hail#14232) Allow use of large numbers of fields on a table without triggering; `ClassTooLargeException: Class too large:`.; - (hail#14246)(hail#14245) Fix a bug, introduced in 0.2.114, in which `Table.multi_way_zip_join` and; `Table.aggregate_by_key` could throw ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially d",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:9170,Safety,timeout,timeout,9170,"r pays which means unless; your cluster is in the US-CENTRAL1 or EUROPE-WEST1 region, you will pay a per-gigabyte rate to read; from the Annotation DB or Datasets API. We must make this change because [reading from a; multi-regional bucket into a regional VM is no longer; free](https://cloud.google.com/storage/pricing-announce#network). Unfortunately, cost constraints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`, `Table.annotate_globals`,; `Table.select_globals`, `Table.transmute_globals`, `Table.transmute`, `Table.annotate`, and; `Table.filter`.; - (hail#14242) Add examples to `Table.sample`, `Table.head`, and `Table.semi`_join. ### New Features. - (hail#14206) Introduce `hailctl config set http/timeout_in_seconds` which Batch and QoB users can; use to increase the timeout on their laptops. Laptops tend to have flaky internet connections and; a timeout of 300 seconds produces a more robust experience.; - (hail#14178) Reduce VDS Combiner runtime slightly by computing the maximum ref block length; without executing the combination pipeline twice.; - (hail#14207) VDS Combiner now verifies that every GVCF path and sample name is unique. ### Bug Fixes. - (hail#14300) Require orjson<3.9.12 to avoid a segfault introduced in orjson 3.9.12; - (hail#14071) Use indexed VEP cache files for GRCh38 on both dataproc and QoB.; - (hail#14232) Allow use of large numbers of fields on a table without triggering; `ClassTooLargeException: Class too large:`.; - (hail#14246)(hail#14245) Fix a bug, introduced in 0.2.114, in which `Table.multi_way_zip_join` and; `Table.aggregate_by_key` could throw ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially different from the desired; number of output partitions.; - (hail#14202) Support coercing `{}` (the empty dictionary) into any Stru",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:9519,Safety,avoid,avoid,9519,"ints; require us to choose only one region per continent and we have chosen US-CENTRAL1 and EUROPE-WEST1. ### Documentation. - (hail#14113) Add examples to `Table.parallelize`, `Table.key_by`, `Table.annotate_globals`,; `Table.select_globals`, `Table.transmute_globals`, `Table.transmute`, `Table.annotate`, and; `Table.filter`.; - (hail#14242) Add examples to `Table.sample`, `Table.head`, and `Table.semi`_join. ### New Features. - (hail#14206) Introduce `hailctl config set http/timeout_in_seconds` which Batch and QoB users can; use to increase the timeout on their laptops. Laptops tend to have flaky internet connections and; a timeout of 300 seconds produces a more robust experience.; - (hail#14178) Reduce VDS Combiner runtime slightly by computing the maximum ref block length; without executing the combination pipeline twice.; - (hail#14207) VDS Combiner now verifies that every GVCF path and sample name is unique. ### Bug Fixes. - (hail#14300) Require orjson<3.9.12 to avoid a segfault introduced in orjson 3.9.12; - (hail#14071) Use indexed VEP cache files for GRCh38 on both dataproc and QoB.; - (hail#14232) Allow use of large numbers of fields on a table without triggering; `ClassTooLargeException: Class too large:`.; - (hail#14246)(hail#14245) Fix a bug, introduced in 0.2.114, in which `Table.multi_way_zip_join` and; `Table.aggregate_by_key` could throw ""NoSuchElementException: Ref with name `__iruid_...`"" when; one or more of the tables had a number of partitions substantially different from the desired; number of output partitions.; - (hail#14202) Support coercing `{}` (the empty dictionary) into any Struct type (with all missing; fields).; - (hail#14239) Remove an erroneous statement from the MatrixTable tutorial.; - (hail#14176) `hailtop.fs.ls` can now list a bucket, e.g. `hailtop.fs.ls(""gs://my-bucket"")`.; - (hail#14258) Fix `import_avro` to not raise `NullPointerException` in certain rare cases; (e.g. when using `_key_by_assert_sorted`).; - (hail#14285) Fix a",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:11852,Safety,detect,detected,11852,"ify that. ```; file $JAVA_HOME/bin/java; ```. returns a message including the phrase ""arm64"". If it instead includes the phrase ""x86_64"" then you; must upgrade to a new version of Java. You may find such a version of Java; [here](https://www.azul.com/downloads/?os=macos&architecture=arm-64-bit&package=jre#zulu). ### New Features. - (hail#14093) `hailctl dataproc` now creates clusters using Dataproc version 2.1.33. It previously used version 2.1.2.; - (hail#13617) Query-on-Batch now supports joining two tables keyed by intervals.; - (hail#13795)(hail#13567) Enable passing a requester pays configuration to `hailtop.fs.open`. ### Bug Fixes. - (hail#14110) Fix `hailctl hdinsight start`, which has been broken since 0.2.118.; - (hail#14098)(hail#14090)(hail#14118) Fix (hail#14089), which makes `hailctl dataproc connect` work in Windows Subsystem for Linux.; - (hail#14048) Fix (hail#13979), affecting Query-on-Batch and manifesting most frequently as ""com.github.luben.zstd.ZstdException: Corrupted block detected"".; - (hail#14066) Since 0.2.110, `hailctl dataproc` set the heap size of the driver JVM dangerously high. It is now set to an appropriate level. This issue manifests in a variety of inscrutable ways including RemoteDisconnectedError and socket closed. See issue (hail#13960) for details.; - (hail#14057) Fix (hail#13998) which appeared in 0.2.58 and prevented reading from a networked filesystem mounted within the filesystem of the worker node for certain pipelines (those that did not trigger ""lowering"").; - (hail#14006) Fix (hail#14000). Hail now supports identity_by_descent on Apple M1 and M2 chips; however, your Java installation must be an arm64 installation. Using x86_64 Java with Hail on Apple M1 or M2 will cause SIGILL errors. If you have an Apple M1 or Apple M2 and `/usr/libexec/java_home -V` does not include `(arm64)`, you must switch to an arm64 version of the JVM.; - (hail#14022) Fix (hail#13937) caused by faulty library code in the Google Cloud Storage API J",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15720,Safety,detect,detected,15720,"d of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:21230,Safety,avoid,avoids,21230,"rt_gvcf_interval` now treats `PGT` as a call field.; - (hail#13333) Fix interval filtering regression: `filter_rows` or `filter` mentioning the same; field twice or using two fields incorrectly read the entire dataset. In 0.2.121, these filters; will correctly read only the relevant subset of the data.; - (hail#13368) In Azure, Hail now uses fewer ""list blobs"" operations. This should reduce cost on; pipelines that import many files, export many of files, or use file glob expressions.; - (hail#13414) Resolves (hail#13407) in which uses of `union_rows` could reduce parallelism to one; partition resulting in severely degraded performance.; - (hail#13405) `MatrixTable.aggregate_cols` no longer forces a distributed computation. This should; be what you want in the majority of cases. In case you know the aggregation is very slow and; should be parallelized, use `mt.cols().aggregate` instead.; - (hail#13460) In Query-on-Spark, restore `hl.read_table` optimization that avoids reading; unnecessary data in pipelines that do not reference row fields.; - (hail#13447) Fix (hail#13446). In all three submit commands (`batch`, `dataproc`, and; `hdinsight`), Hail now allows and encourages the use of -- to separate arguments meant for the; user script from those meant for hailctl. In hailctl batch submit, option-like arguments, for; example ""--foo"", are now supported before ""--"" if and only if they do not conflict with a hailctl; option.; - (hail#13422) `hailtop.hail_frozenlist.frozenlist` now has an eval-able `repr`.; - (hail#13523) `hl.Struct` is now pickle-able.; - (hail#13505) Fix bug introduced in 0.2.117 by commit `c9de81108` which prevented the passing of; keyword arguments to Python jobs. This manifested as ""ValueError: too many values to unpack"".; - (hail#13536) Fixed (hail#13535) which prevented the use of Python jobs when the client (e.g. your; laptop) Python version is 3.11 or later.; - (hail#13434) In QoB, Hail's file systems now correctly list all files in a directory, n",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:35326,Safety,unsafe,unsafe,35326,"exed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would be taller than the plot, the legend will now be scrollable. Legend entries for such plots can be clicked to show/hide traces on the plot, but this does not work and is a known issue that will only be addressed if `hail.ggplot` is migrated off of plotly.; - (hail#12584) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables with HTML unsafe column headers are rendered wrong in Jupyter.; - (hail#12574) Fixed a memory leak when processing tables. Could trigger unnecessarily high memory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to use in batch scripts when not specified in code.; - (hail#12497) Added support for `scales`, `nrow`, and `ncol` arguments, as well as grouped legends, to `hail.ggplot.facet_wrap`.; - (hail#12471) Added `hailctl batch submit` command to run local scripts inside batch jobs.; - (hail#12525) Add support for passing arguments",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:44599,Safety,timeout,timeout,44599,"11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `hl.split_multi`. ---. ## Version 0.2.95. Released 2022-05-13. ### New features. - (hail#11809) Export `dtypes_from_pandas` in `expr.types`; - (hail#11807) Teach smoothed_pdf to add a plot to an existing figure.; - (hail#11746) The ServiceBackend, in interactive mode, will print a link to the currently executing driver batch.; - (hail#11759) `hl.logistic_regression_rows`, `hl.poisson_regression_rows`, and `hl.skat` all now support configuration of the maximum number of iterations and the tolerance.; - (hail#11835) Add `hl.ggplot.geom_density` which renders a plot of an approximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container images; - (hail#11725) `hl.ggplot` now supports `facet_wrap`; - (hail#11776) `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed. ### `hailctl dataproc`; - (hail#11710) support pass-through arguments to `connect`. ### Bug fixes. - (hail#11792) Resolved issue where corrupted tables could be created with whole-stage code generation enabled. ---. ## Version 0.2.93. Release 2022-03-27. ### Beta features",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:3334,Security,access,access,3334,"le format version: 1.7.0. All library; versions before 0.2.119, for example 0.2.118, *cannot* read file format version 1.7.0. All library; versions after and including 0.2.119 *can* read file format version 1.7.0. Each version of the Hail Python library can only write files using the latest file format version it; supports. **The hl.experimental package and other methods marked experimental in the docs are exempt from this; policy. Their functionality or even existence may change without notice. Please contact us if you; critically depend on experimental functionality.**. ## Version 0.2.133. Released 2024-09-25. ### New Features. - (hail#14619) Teach `hailctl dataproc submit` to use the `--project` argument as an argument to `gcloud dataproc` rather than the submitted script. ### Bug Fixes. - (hail#14673) Fix typo in Interpret rule for `TableAggregate`.; - (hail#14697) Set `QUAL="".""` to missing rather than htsjdk's sentinel value.; - (hail#14292) Prevent GCS cold storage check from throwing an error when reading from a public access bucket.; - (hail#14651) Remove jackson string length restriction for all backends.; - (hail#14653) Add `--public-ip-address` argument to `gcloud dataproc start` command built by `hailctl dataproc start`, fixing creation of dataproc 2.2 clusters. ## Version 0.2.132. Released 2024-07-08. ### New Features. - (hail#14572) Added `StringExpression.find` for finding substrings in a Hail str. ### Bug Fixes. - (hail#14574) Fixed `TypeError` bug when initializing Hail Query with `backend='batch'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:6721,Security,validat,validate,6721,"cs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (hail#14393) `hail` depends on `protobuf` no longer; users may choose their own version of `protobuf`.; - (hail#14360) Exposed previously internal `_num_allele_type` as `numeric_allele_type`; and deprecated it. Add new `AlleleType` enumeration for users to be able to easily; use the values returned by `numeric_allele_type`.; - (hail#14297) `vds.sample_gc` now uses independent aggregators.; Users may now import these functions and use them directly.; - (hail#14405) `VariantDataset.validate` now checks that all ref blocks are no; longer than the ref_block_max_length field, if it exists. ### Bug Fixes. - (hail#14420) Fixes a serious, but likely rare, bug in the; Table/MatrixTable reader, which has been present since Sep 2020. It; manifests as many (around half or more) of the rows being dropped. This; could only happen when 1) reading a (matrix)table whose partitioning; metadata allows rows with the same key to be split across neighboring; partitions, and 2) reading it with a different partitioning than it was; written. 1) would likely only happen by reading data keyed by locus and; alleles, and rekeying it to only locus before writing. 2) would likely; only happen by using the `_intervals` or `_n_partitions` arguments to; `read_(matrix)_table`, or possibly `repartition`. Please reach out to us; if you're concerned you may have been affected by this.; - (hail#14330) Fixes erroneous error in `export_vcf` with unphased haploid Calls.; - (hail#14303) Fix missingness error when sampling entries from a MatrixTable.; - (h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:18970,Security,access,access,18970,"t or hail.ggplot in a Jupyter notebook (calling bokeh.io.output_notebook or hail.plot.output_notebook and/or setting plotly.io.renderers.default = 'iframe' is no longer necessary). ### Bug Fixes; - (hail#13634) Fix a bug which caused Query-on-Batch pipelines with a large number of partitions (close to 100k) to run out of memory on the driver after all partitions finish.; - (hail#13619) Fix an optimization bug that, on some pipelines, since at least 0.2.58 (commit 23813af), resulted in Hail using essentially unbounded amounts of memory.; - (hail#13609) Fix a bug in hail.ggplot.scale_color_continuous that sometimes caused errors by generating invalid colors. ## Version 0.2.122. Released 2023-09-07. ### New Features. - (hail#13508) The n parameter of MatrixTable.tail is deprecated in favor of a new n_rows parameter. ### Bug Fixes; - (hail#13498) Fix a bug where field names can shadow methods on the StructExpression class, e.g. ""items"", ""keys"", ""values"". Now the only way to access such fields is through the getitem syntax, e.g. ""some_struct['items']"". It's possible this could break existing code that uses such field names.; - (hail#13585) Fix bug introduced in 0.2.121 where Query-on-Batch; users could not make requests to `batch.hail.is` without a domain configuration; set. ## Version 0.2.121. Released 2023-09-06. ### New Features. - (hail#13385) The VDS combiner now supports arbitrary custom call fields via the `call_fields`; parameter.; - (hail#13224) `hailctl config get`, `set`, and `unset` now support shell auto-completion. Run; `hailctl --install-completion zsh` to install the auto-completion for `zsh`. You must already have; completion enabled for `zsh`.; - (hail#13279) Add `hailctl batch init` which helps new users interactively set up `hailctl` for; Query-on-Batch and Batch use. ### Bug Fixes; - (hail#13573) Fix (hail#12936) in which VEP frequently failed (due to Docker not starting up) on; clusters with a non-trivial number of workers.; - (hail#13485) Fix (hail#",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:24448,Security,access,accessing,24448,"239) Fix bug which ignored the `HAIL_BATCH_REGIONS` argument when determining in which; regions to schedule jobs when using Query-on-Batch.; - (hail#13253) Improve `hadoop_ls` and `hfs.ls` to quickly list globbed files in a directory. The; speed improvement is proportional to the number of files in the directory.; - (hail#13226) Fix the comparison of an `hl.Struct` to an `hl.struct` or field of type; `tstruct`. Resolves (hail#13045) and (Hail#13046).; - (hail#12995) Fixed bug causing poor performance and memory leaks for `MatrixTable.annotate_rows`; aggregations. ## Version 0.2.119. Released 2023-06-28. ### New Features; - (hail#12081) Hail now uses [Zstandard](https://facebook.github.io/zstd/) as; the default compression algorithm for table and matrix table storage. Reducing; file size around 20% in most cases.; - (hail#12988) Arbitrary aggregations can now be used on arrays via; `ArrayExpression.aggregate`. This method is useful for accessing; functionality that exists in the aggregator library but not the; basic expression library, for instance, `call_stats`.; - (hail#13166) Add an `eigh` ndarray method, for finding eigenvalues; of symmetric matrices (""h"" is for Hermitian, the complex analogue of; symmetric). ### Bug Fixes; - (hail#13184) The `vds.to_dense_mt` no longer densifies past the end of; contig boundaries. A logic bug in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference block of the contig.; - (hail#13173) Fix globbing in scala blob storage filesystem implementations. ### File Format. - The native file format version is now 1.7.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.118. Released 2023-06-13. ### New Features. - (hail#13140) Enable `hail-az` and Azure Blob Storage `https` URLs to contain SAS tokens to enable bearer-auth style file access to Azure storage.; - (hail#13129) Allow sub",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:25449,Security,access,access,25449,"Expression.aggregate`. This method is useful for accessing; functionality that exists in the aggregator library but not the; basic expression library, for instance, `call_stats`.; - (hail#13166) Add an `eigh` ndarray method, for finding eigenvalues; of symmetric matrices (""h"" is for Hermitian, the complex analogue of; symmetric). ### Bug Fixes; - (hail#13184) The `vds.to_dense_mt` no longer densifies past the end of; contig boundaries. A logic bug in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference block of the contig.; - (hail#13173) Fix globbing in scala blob storage filesystem implementations. ### File Format. - The native file format version is now 1.7.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.118. Released 2023-06-13. ### New Features. - (hail#13140) Enable `hail-az` and Azure Blob Storage `https` URLs to contain SAS tokens to enable bearer-auth style file access to Azure storage.; - (hail#13129) Allow subnet to be passed through to gcloud in hailctl. ### Bug Fixes. - (hail#13126) Query-on-Batch pipelines with one partition are now retried when they encounter transient errors.; - (hail#13113) `hail.ggplot.geom_point` now displays a legend group for a column even when it has only one value in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:36446,Security,access,access,36446,"mory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to use in batch scripts when not specified in code.; - (hail#12497) Added support for `scales`, `nrow`, and `ncol` arguments, as well as grouped legends, to `hail.ggplot.facet_wrap`.; - (hail#12471) Added `hailctl batch submit` command to run local scripts inside batch jobs.; - (hail#12525) Add support for passing arguments to `hailctl batch submit`.; - (hail#12465) Batch jobs' status now contains the region the job ran in. The job itself can access which region it is in through the `HAIL_REGION` environment variable.; - (hail#12464) When using Query-on-Batch, all jobs for a single hail session are inserted into the same batch instead of one batch per action.; - (hail#12457) `pca` and `hwe_normalized_pca` are now supported in Query-on-Batch.; - (hail#12376) Added `hail.query_table` function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:46646,Security,access,accessible,46646,"il Batch are addressed in this release. ---. ## Version 0.2.92. Release 2022-03-25. ### New features. - (hail#11613) Add `hl.ggplot` support for `scale_fill_hue`, `scale_color_hue`, and `scale_fill_manual`,; `scale_color_manual`. This allows for an infinite number of discrete colors.; - (hail#11608) Add all remaining and all versions of extant public gnomAD datasets to the Hail; Annotation Database and Datasets API. Current as of March 23rd 2022.; - (hail#11662) Add the `weight` aesthetic `geom_bar`. ### Beta features. - This version of Hail includes all the necessary client-side infrastructure to execute Hail Query; pipelines on a Hail Batch cluster. This effectively enables a ""serverless"" version of Hail Query; which is independent of Apache Spark. Broad affiliated users should contact the Hail team for help; using Hail Query on Hail Batch. Unaffiliated users should also contact the Hail team to discuss; the feasibility of running your own Hail Batch cluster. The Hail team is accessible at both; https://hail.zulipchat.com and https://discuss.hail.is . ---. ## Version 0.2.91. Release 2022-03-18. ### Bug fixes. - (hail#11614) Update `hail.utils.tutorial.get_movie_lens` to use `https` instead of `http`. Movie; Lens has stopped serving data over insecure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins wh",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:67757,Security,access,accessing,67757,"hail#8894) Added `hl.shuffle` function to randomly permute arrays.; - (hail#8854) Add `composable` option to parallel text export for use with `gsutil compose`. ### Bug fixes. - (hail#8883) Fix an issue related to failures in pipelines with `force_bgz=True`. ### Performance. - (hail#8887) Substantially improve the performance of `hl.experimental.import_gtf`. ---. ## Version 0.2.43. Released 2020-05-28. ### Bug fixes. - (hail#8867) Fix a major correctness bug ocurring when calling BlockMatrix.transpose on sparse, non-symmetric BlockMatrices.; - (hail#8876) Fixed ""ChannelClosedException: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:1441,Testability,log,log,1441," versions of numpy released in the 24 months prior to the project, and at minimum the; last three minor versions. ## Frequently Asked Questions. ### With a version like 0.x, is Hail ready for use in publications?. Yes. The [semantic versioning standard](https://semver.org) uses 0.x (development) versions to; refer to software that is either ""buggy"" or ""partial"". While we don't view; Hail as particularly buggy (especially compared to one-off untested; scripts pervasive in bioinformatics!), Hail 0.2 is a partial realization; of a larger vision. ### What is the difference between the Hail Python library version and the native file format version?. The Hail Python library version, the version you see on [PyPI](https://pypi.org/project/hail/), in; `pip`, or in `hl.version()` changes every time we release the Python library. The Hail native file; format version only changes when we change the format of Hail Table and MatrixTable files. If a; version of the Python library introduces a new native file format version, we note that in the; change log. All subsequent versions of the Python library can read the new file format version. The native file format changes much slower than the Python library version. It is not currently; possible to view the file format version of a Hail Table or MatrixTable. ### What stability is guaranteed?. The Hail file formats and Python API are backwards compatible. This means that a script developed to; run on Hail 0.2.5 should continue to work in every subsequent release within the 0.2 major version.; This also means any file written by python library versions 0.2.1 through 0.2.5 can be read by; 0.2.5. Forward compatibility of file formats and the Python API is not guaranteed. In particular, a new; file format version is only readable by library versions released after the file format. For; example, Python library version 0.2.119 introduces a new file format version: 1.7.0. All library; versions before 0.2.119, for example 0.2.118, *cannot* re",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:4841,Testability,test,tests,4841,"h'`.; - (hail#14571) Fixed a deficiency that caused certain pipelines that construct Hail `NDArray`s; from streams to run out of memory.; - (hail#14579) Fix serialization bug that broke some Query-on-Batch pipelines with many complex expressions.; - (hail#14567) Fix Jackson configuration that broke some Query-on-Batch pipelines with many complex expressions. ## Version 0.2.131. Released 2024-05-30. ### New Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5196,Testability,test,test,5196," Features. - (hail#14560) The gvcf import stage of the VDS combiner now preserves the GT; of reference blocks. Some datasets have haploid calls on sex chromosomes,; and the fact that the reference was haploid should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:5468,Testability,log,log,5468,"should be preserved. ### Bug Fixes. - (hail#14563) The version of `notebook` installed in Hail Dataproc clusters has; been upgraded from 6.5.4 to 6.5.6 in order to fix a bug where Jupyter; Notebooks wouldn't start on clusters. The workaround involving creating; a cluster with `--packages='ipython<8.22'` is no longer necessary. ### Deprecations. - (hail#14158) Hail now supports and primarily tests against Dataproc 2.2.5,; Spark 3.5.0, and Java 11. We strongly recommend updating to Spark 3.5.0 and; Java 11. You should also update your GCS connector *after installing Hail*:; `curl https://broad.io/install-gcs-connector | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (hail#14393) `hail` depends on `protobuf` no longer; users may choose their own version of `protobuf`.; - (hail#14360) Exposed previously internal `_num_allele_type` as `numeric_allele_type`; and deprecated it. A",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:6109,Testability,test,test,6109,"or | python3`. Do not try to update; before installing Hail 0.2.131. ## Version 0.2.130. Released 2024-10-02. 0.2.129 contained test configuration artifacts that prevented users from; starting dataproc clusters with `hailctl`. Please upgrade to 0.2.130 if you use; dataproc. ### New Features. - (hail##14447) Added `copy_spark_log_on_error` initialization flag that when set,; copies the hail driver log to the remote `tmpdir` if query execution raises an; exception. ### Bug Fixes. - (hail#14452) Fixes a bug that prevents users from starting dataproc clusters with; hailctl. ## Version 0.2.129. Released 2024-04-02. ### Documentation. - (hail#14321) Removed `GOOGLE_APPLICATION_CREDENTIALS` from batch docs.; Metadata server introduction means users no longer need to explicitly activate; service accounts with the `gcloud` command line tool.; - (hail#14339) Added citations since 2021. ### New Features. - (hail#14406) Performance improvements for reading structured data from (Matrix)Tables; - (hail#14255) Added Cochran-Hantel-Haenszel test for association (`cochran_mantel_haenszel_test`).; Our thanks to @Will-Tyler for generously contributing this feature.; - (hail#14393) `hail` depends on `protobuf` no longer; users may choose their own version of `protobuf`.; - (hail#14360) Exposed previously internal `_num_allele_type` as `numeric_allele_type`; and deprecated it. Add new `AlleleType` enumeration for users to be able to easily; use the values returned by `numeric_allele_type`.; - (hail#14297) `vds.sample_gc` now uses independent aggregators.; Users may now import these functions and use them directly.; - (hail#14405) `VariantDataset.validate` now checks that all ref blocks are no; longer than the ref_block_max_length field, if it exists. ### Bug Fixes. - (hail#14420) Fixes a serious, but likely rare, bug in the; Table/MatrixTable reader, which has been present since Sep 2020. It; manifests as many (around half or more) of the rows being dropped. This; could only happen when ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15785,Testability,log,logic,15785,"much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:15797,Testability,log,logic,15797,"ail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` now accepts strings as the names of individuals. It has always accepted structures containing a single string field. - (hail#13713) Fix (hail#13704), in which Hail could encounter an IllegalArgumentException if there are too many transient errors. - (hail#13730) Fix (hail#13356) and (hail#13409). In QoB pipelines with 10K or more partitions, transient ""Corrupted block detected"" errors were common. This was caused by incorrect retry logic. That logic has been fixed. - (hail#13732) Fix (hail#13721) which manifested with the message ""Missing Range header in response"". The root cause was a bug in the Google Cloud Storage SDK on which we rely. The fix is to update to a version without this bug. The buggy version of GCS SDK was introduced in 0.2.123. - (hail#13759) Since Hail 0.2.123, Hail would hang in Dataproc Notebooks due to (hail#13690). - (hail#13755) Ndarray concatenation now works with arrays with size zero dimensions. - (hail#13817) Mitigate new transient error from Google Cloud Storage which manifests as `aiohttp.client_exceptions.ClientOSError: [Errno 1] [SSL: SSLV3_ALERT_BAD_RECORD_MAC] sslv3 alert bad record mac (_ssl.c:2548)`. - (hail#13715) Fix (hail#13697), a long standing issue with QoB. When a QoB driver or worker fails, the corresponding Batch Job will also appear as failed. - (hail#13829) Fix (hail#13828). The Hail combiner now properly imports `PGT` fields from GVCFs. - (hail#13805) Fix (hail#13767). `hailctl dataproc",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:24841,Testability,log,logic,24841,"l#13045) and (Hail#13046).; - (hail#12995) Fixed bug causing poor performance and memory leaks for `MatrixTable.annotate_rows`; aggregations. ## Version 0.2.119. Released 2023-06-28. ### New Features; - (hail#12081) Hail now uses [Zstandard](https://facebook.github.io/zstd/) as; the default compression algorithm for table and matrix table storage. Reducing; file size around 20% in most cases.; - (hail#12988) Arbitrary aggregations can now be used on arrays via; `ArrayExpression.aggregate`. This method is useful for accessing; functionality that exists in the aggregator library but not the; basic expression library, for instance, `call_stats`.; - (hail#13166) Add an `eigh` ndarray method, for finding eigenvalues; of symmetric matrices (""h"" is for Hermitian, the complex analogue of; symmetric). ### Bug Fixes; - (hail#13184) The `vds.to_dense_mt` no longer densifies past the end of; contig boundaries. A logic bug in `to_dense_mt` could lead to reference data; toward's the end of one contig being applied to the following contig up until; the first reference block of the contig.; - (hail#13173) Fix globbing in scala blob storage filesystem implementations. ### File Format. - The native file format version is now 1.7.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ## Version 0.2.118. Released 2023-06-13. ### New Features. - (hail#13140) Enable `hail-az` and Azure Blob Storage `https` URLs to contain SAS tokens to enable bearer-auth style file access to Azure storage.; - (hail#13129) Allow subnet to be passed through to gcloud in hailctl. ### Bug Fixes. - (hail#13126) Query-on-Batch pipelines with one partition are now retried when they encounter transient errors.; - (hail#13113) `hail.ggplot.geom_point` now displays a legend group for a column even when it has only one value in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutExcepti",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:26745,Testability,log,logs,26745,"e in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will u",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:26868,Testability,log,log,26868,"e in it.; - (hail#13075) (hail#13074) Add a new transient error plaguing pipelines in Query-on-Batch in Google: `java.net.SocketTimeoutException: connect timed out`.; - (hail#12569) The documentation for `hail.ggplot.facets` is now correctly included in the API reference. ---. ## Version 0.2.117. Released 2023-05-22. ### New Features. - (hail#12875) Parallel export modes now write a manifest file. These manifest files are text files with one filename per line, containing name of each shard written successfully to the directory. These filenames are relative to the export directory.; - (hail#13007) In Query-on-Batch and `hailtop.batch`, memory and storage request strings may now be optionally terminated with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will u",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:27543,Testability,assert,assertion,27543," with a `B` for bytes. ### Bug Fixes. - (hail#13065) In Azure Query-on-Batch, fix a resource leak that prevented running pipelines with >500 partitions and created flakiness with >250 partitions.; - (hail#13067) In Query-on-Batch, driver and worker logs no longer buffer so messages should arrive in the UI after a fixed delay rather than proportional to the frequency of log messages.; - (hail#13028) Fix crash in `hl.vds.filter_intervals` when using a table to filter a VDS that stores the max ref block length.; - (hail#13060) Prevent 500 Internal Server Error in Jupyter Notebooks of Dataproc clusters started by `hailctl dataproc`.; - (hail#13051) In Query-on-Batch and `hailtop.batch`, Azure Blob Storage `https` URLs are now supported.; - (hail#13042) In Query-on-Batch, `naive_coalesce` no longer performs a full write/read of the dataset. It now operates identically to the Query-on-Spark implementation.; - (hail#13031) In `hl.ld_prune`, an informative error message is raised when a dataset does not contain diploid calls instead of an assertion error.; - (hail#13032) In Query-on-Batch, in Azure, Hail now users a newer version of the Azure blob storage libraries to reduce the frequency of ""Stream is already closed"" errors.; - (hail#13011) In Query-on-Batch, the driver will use ~1/2 as much memory to read results as it did in 0.2.115.; - (hail#13013) In Query-on-Batch, transient errors while streaming from Google Storage are now automatically retried. ---. ## Version 0.2.116. Released 2023-05-08. ### New Features. - (hail#12917) ABS blob URIs in the format of `https://<ACCOUNT_NAME>.blob.core.windows.net/<CONTAINER_NAME>/<PATH>` are now supported.; - (hail#12731) Introduced `hailtop.fs` that makes public a filesystem module that works for local fs, gs, s3 and abs. This is now used as the `Backend.fs` for hail query but can be used standalone for Hail Batch users by `import hailtop.fs as hfs`. ### Deprecations. - (hail#12929) Hail no longer officially supports Python 3.7.;",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:31035,Testability,log,logs,31035,"om_point`. ---. ## Version 0.2.114. Released 2023-04-19. ### New Features. - (hail#12880) Added `hl.vds.store_ref_block_max_len` to patch old VDSes to make interval filtering faster. ### Bug Fixes. - (hail#12860) Fixed memory leak in shuffles in Query-on-Batch. ---. ## Version 0.2.113. Released 2023-04-07. ### New Features. - (hail#12798) Query-on-Batch now supports `BlockMatrix.write(..., stage_locally=True)`.; - (hail#12793) Query-on-Batch now supports `hl.poisson_regression_rows`.; - (hail#12801) Hitting CTRL-C while interactively using Query-on-Batch cancels the underlying batch.; - (hail#12810) `hl.array` can now convert 1-d ndarrays into the equivalent list.; - (hail#12851) `hl.variant_qc` no longer requires a locus field.; - (hail#12816) In Query-on-Batch, `hl.logistic_regression('firth', ...)` is now supported.; - (hail#12854) In Query-on-Batch, simple pipelines with large numbers of partitions should be substantially faster. ### Bug Fixes. - (hail#12783) Fixed bug where logs were not properly transmitted to Python.; - (hail#12812) Fixed bug where `Table/MT._calculate_new_partitions` returned unbalanced intervals with whole-stage code generation runtime.; - (hail#12839) Fixed `hailctl dataproc` jupyter notebooks to be compatible with Spark 3.3, which have been broken since 0.2.110.; - (hail#12855) In Query-on-Batch, allow writing to requester pays buckets, which was broken before this release. ---. ## Version 0.2.112. Released 2023-03-15. ### Bug Fixes. - (hail#12784) Removed an internal caching mechanism in Query on Batch that caused stalls in pipelines with large intermediates. ---. ## Version 0.2.111. Released 2023-03-13. ### New Features. - (hail#12581) In Query on Batch, users can specify which regions to have jobs run in. ### Bug Fixes. - (hail#12772) Fix `hailctl hdinsight submit` to pass args to the files. ---. ## Version 0.2.110. Released 2023-03-08. ### New Features. - (hail#12643) In Query on Batch, `hl.skat(..., logistic=True)` is now supported.; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:32007,Testability,log,logistic,32007,"ed bug where logs were not properly transmitted to Python.; - (hail#12812) Fixed bug where `Table/MT._calculate_new_partitions` returned unbalanced intervals with whole-stage code generation runtime.; - (hail#12839) Fixed `hailctl dataproc` jupyter notebooks to be compatible with Spark 3.3, which have been broken since 0.2.110.; - (hail#12855) In Query-on-Batch, allow writing to requester pays buckets, which was broken before this release. ---. ## Version 0.2.112. Released 2023-03-15. ### Bug Fixes. - (hail#12784) Removed an internal caching mechanism in Query on Batch that caused stalls in pipelines with large intermediates. ---. ## Version 0.2.111. Released 2023-03-13. ### New Features. - (hail#12581) In Query on Batch, users can specify which regions to have jobs run in. ### Bug Fixes. - (hail#12772) Fix `hailctl hdinsight submit` to pass args to the files. ---. ## Version 0.2.110. Released 2023-03-08. ### New Features. - (hail#12643) In Query on Batch, `hl.skat(..., logistic=True)` is now supported.; - (hail#12643) In Query on Batch, `hl.liftover` is now supported.; - (hail#12629) In Query on Batch, `hl.ibd` is now supported.; - (hail#12722) Add `hl.simulate_random_mating` to generate a population from founders under the assumption of random mating.; - (hail#12701) Query on Spark now officially supports Spark 3.3.0 and Dataproc 2.1.x. ### Performance Improvements. - (hail#12679) In Query on Batch, `hl.balding_nichols_model` is slightly faster. Also added `hl.utils.genomic_range_table` to quickly create a table keyed by locus. ### Bug Fixes. - (hail#12711) In Query on Batch, fix null pointer exception (manifesting as `scala.MatchError: null`) when reading data from requester pays buckets.; - (hail#12739) Fix `hl.plot.cdf`, `hl.plot.pdf`, and `hl.plot.joint_plot` which were broken by changes in Hail and changes in bokeh.; - (hail#12735) Fix (hail#11738) by allowing user to override default types in `to_pandas`.; - (hail#12760) Mitigate some JVM bytecode generation ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:33590,Testability,log,logistic,33590,"ail#12711) In Query on Batch, fix null pointer exception (manifesting as `scala.MatchError: null`) when reading data from requester pays buckets.; - (hail#12739) Fix `hl.plot.cdf`, `hl.plot.pdf`, and `hl.plot.joint_plot` which were broken by changes in Hail and changes in bokeh.; - (hail#12735) Fix (hail#11738) by allowing user to override default types in `to_pandas`.; - (hail#12760) Mitigate some JVM bytecode generation errors, particularly those related to too many method parameters.; - (hail#12766) Fix (hail#12759) by loosening `parsimonious` dependency pin.; - (hail#12732) In Query on Batch, fix bug that sometimes prevented terminating a pipeline using Control-C.; - (hail#12771) Use a version of `jgscm` whose version complies with PEP 440. ---. ## Version 0.2.109. Released 2023-02-08. ### New Features. - (hail#12605) Add `hl.pgenchisq` the cumulative distribution function of the generalized chi-squared distribution.; - (hail#12637) Query-on-Batch now supports `hl.skat(..., logistic=False)`.; - (hail#12645) Added `hl.vds.truncate_reference_blocks` to transform a VDS to checkpoint reference blocks in order to drastically improve interval filtering performance. Also added `hl.vds.merge_reference_blocks` to merge adjacent reference blocks according to user criteria to better compress reference data. ### Bug Fixes. - (hail#12650) Hail will now throw an exception on `hl.export_bgen` when there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time.; - (hail#12566) Improve error message when combining incompatibly indexed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:35007,Testability,assert,assertion,35007,"hen there is no GP field, instead of exporting null records.; - (hail#12635) Fix bug where `hl.skat` did not work on Apple M1 machines.; - (hail#12571) When using Query-on-Batch, hl.hadoop* methods now properly support creation and modification time.; - (hail#12566) Improve error message when combining incompatibly indexed fields in certain operations including array indexing. ---. ## Version 0.2.108. Released 2023-1-12. ### New Features. - (hail#12576) `hl.import_bgen` and `hl.export_bgen` now support compression with Zstd. ### Bug fixes. - (hail#12585) `hail.ggplot`s that have more than one legend group or facet are now interactive. If such a plot has enough legend entries that the legend would be taller than the plot, the legend will now be scrollable. Legend entries for such plots can be clicked to show/hide traces on the plot, but this does not work and is a known issue that will only be addressed if `hail.ggplot` is migrated off of plotly.; - (hail#12584) Fixed bug which arose as an assertion error about type mismatches. This was usually triggered when working with tuples.; - (hail#12583) Fixed bug which showed an empty table for `ht.col_key.show()`.; - (hail#12582) Fixed bug where matrix tables with duplicate col keys do not show properly. Also fixed bug where tables and matrix tables with HTML unsafe column headers are rendered wrong in Jupyter.; - (hail#12574) Fixed a memory leak when processing tables. Could trigger unnecessarily high memory use and out of memory errors when there are many rows per partition or large key fields.; - (hail#12565) Fixed a bug that prevented exploding on a field of a Table whose value is a random value. ---. ## Version 0.2.107. Released 2022-12-14. ### Bug fixes. - (hail#12543) Fixed `hl.vds.local_to_global` error when LA array contains non-ascending allele indices. ---. ## Version 0.2.106. Released 2022-12-13. ### New Features. - (hail#12522) Added `hailctl` config setting `'batch/backend'` to specify the default backend to us",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:42680,Testability,log,logged,42680,"er, `phased`, to control the phasedness of the generated genotypes. ### Performance improvements. - (hail#12099) Make repeated VCF/PLINK queries much faster by caching compiler data structures.; - (hail#12038) Speed up `hl.import_matrix_table` by caching header line computation. ### Bug fixes. - (hail#12115) When using `use_new_shuffle=True`, fix a bug when there are more than 2^31 rows; - (hail#12074) Fix bug where `hl.init` could silently overwrite the global random seed.; - (hail#12079) Fix bug in handling of missing (aka NA) fields in grouped aggregation and distinct by key.; - (hail#12056) Fix `hl.export_vcf` to actually create tabix files when requested.; - (hail#12020) Fix bug in `hl.experimental.densify` which manifested as an `AssertionError` about dtypes. ---. ## Version 0.2.97. Released 2022-06-30. ### New Features. - (hail#11756) `hb.BatchPoolExecutor` and Python jobs both now also support async functions. ### Bug fixes. - (hail#11962) Fix error (logged as (hail#11891)) in VCF combiner when exactly 10 or 100 files are combined.; - (hail#11969) Fix `import_table` and `import_lines` to use multiple partitions when `force_bgz` is used.; - (hail#11964) Fix erroneous ""Bucket is a requester pays bucket but no user project provided."" errors in Google Dataproc by updating to the latest Dataproc image version. ---. ## Version 0.2.96. Released 2022-06-21. ### New Features. - (hail#11833) `hl.rand_unif` now has default arguments of 0.0 and 1.0. ### Bug fixes. - (hail#11905) Fix erroneous FileNotFoundError in glob patterns; - (hail#11921) and (hail#11910) Fix file clobbering during text export with speculative execution.; - (hail#11920) Fix array out of bounds error when tree aggregating a multiple of 50 partitions.; - (hail#11937) Fixed correctness bug in scan order for `Table.annotate` and `MatrixTable.annotate_rows` in certain circumstances.; - (hail#11887) Escape VCF description strings when exporting.; - (hail#11886) Fix an error in an example in the docs for `h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:47595,Testability,assert,assertion,47595,"l team is accessible at both; https://hail.zulipchat.com and https://discuss.hail.is . ---. ## Version 0.2.91. Release 2022-03-18. ### Bug fixes. - (hail#11614) Update `hail.utils.tutorial.get_movie_lens` to use `https` instead of `http`. Movie; Lens has stopped serving data over insecure HTTP.; - (hail#11563) Fix issue [hail-is/hail#11562](https://github.com/hail-is/hail/issues/11562).; - (hail#11611) Fix a bug that prevents the display of `hl.ggplot.geom_hline` and; `hl.ggplot.geom_vline`. ---. ## Version 0.2.90. Release 2022-03-11. ### Critical BlockMatrix from_numpy correctness bug. - (hail#11555) `BlockMatrix.from_numpy` did not work correctly. Version 1.0 of org.scalanlp.breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48357,Testability,assert,assertion,48357,"breeze, a dependency of Apache Spark; that hail also depends on, has a correctness bug that results in BlockMatrices that repeat the top left block of the block; matrix for every block. This affected anyone running Spark 3.0.x or 3.1.x. ### Bug fixes. - (hail#11556) Fixed assertion error ocassionally being thrown by valid joins where the join key was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:48655,Testability,assert,assertion,48655,was a prefix of the left key. ### Versioning. - (hail#11551) Support Python 3.10. ---. ## Version 0.2.89. Release 2022-03-04. - (hail#11452) Fix `impute_sex_chromosome_ploidy` docs. ---. ## Version 0.2.88. Release 2022-03-01. This release addresses the deploy issues in the 0.2.87 release of Hail. ---. ## Version 0.2.87. Release 2022-02-28. An error in the deploy process required us to yank this release from PyPI. Please do not use this; release. ### Bug fixes. - (hail#11401) Fixed bug where `from_pandas` didn't support missing strings. ---. ## Version 0.2.86. Release 2022-02-25. ### Bug fixes. - (hail#11374) Fixed bug where certain pipelines that read in PLINK files would give assertion error.; - (hail#11401) Fixed bug where `from_pandas` didn't support missing ints. ### Performance improvements. - (hail#11306) Newly written tables that have no duplicate keys will be faster to join against. ---. ## Version 0.2.85. Release 2022-02-14. ### Bug fixes. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues about having too many open file handles. ### New features. - (hail#11300) `geom_histogram` infers min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; ,MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:49630,Testability,log,log,49630,"es. - (hail#11355) Fixed assertion errors being hit relating to RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues about having too many open file handles. ### New features. - (hail#11300) `geom_histogram` infers min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; - (hail#11276) Fixed `log` argument in `hail.plot.pdf`.; - (hail#11256) Fixed memory leak in LD Prune. ### New features. - (hail#11274) Added `geom_col` to `hail.ggplot`. ### hailctl dataproc. - (hail#11280) Updated dataproc image version to one not affected by log4j vulnerabilities. ---. ## Version 0.2.82. Release 2022-01-24. ### Bug fixes. - (hail#11209) Significantly improved usefulness and speed of `Table.to_pandas`, resolved several bugs with output. ### New features. - (hail#11247) Introduces a new experimental plotting interface `hail.ggplot`, based on R's ggplot library.; - (hail#11173) Many math functions like `hail.sqrt` now automatically broadcast over ndarrays. ### Performance Improvements. - (hail#11216) Significantly improve performance of `parse_locus_interval`. ### Python and Java Support. - (hail#11219) We no longer officially support Python 3.6, though it may continue to work in the short term.; - (hail#11220) We support buildi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:49693,Testability,log,log,49693,"o RVDPartitioner.; - (hail#11344) Fix error where hail ggplot would mislabel points after more than 10 distinct colors were used. ### New features. - (hail#11332) Added `geom_ribbon` and `geom_area` to hail ggplot. ---. ## Version 0.2.84. Release 2022-02-10. ### Bug fixes. - (hail#11328) Fix bug where occasionally files written to disk would be unreadable.; - (hail#11331) Fix bug that potentially caused files written to disk to be unreadable.; - (hail#11312) Fix aggregator memory leak.; - (hail#11340) Fix bug where repeatedly annotating same field name could cause failure to compile.; - (hail#11342) Fix to possible issues about having too many open file handles. ### New features. - (hail#11300) `geom_histogram` infers min and max values automatically.; - (hail#11317) Add support for `alpha` aesthetic and `identity` position to `geom_histogram`. ---. ## Version 0.2.83. Release 2022-02-01. ### Bug fixes. - (hail#11268) Fixed `log` argument in `hail.plot.histogram`.; - (hail#11276) Fixed `log` argument in `hail.plot.pdf`.; - (hail#11256) Fixed memory leak in LD Prune. ### New features. - (hail#11274) Added `geom_col` to `hail.ggplot`. ### hailctl dataproc. - (hail#11280) Updated dataproc image version to one not affected by log4j vulnerabilities. ---. ## Version 0.2.82. Release 2022-01-24. ### Bug fixes. - (hail#11209) Significantly improved usefulness and speed of `Table.to_pandas`, resolved several bugs with output. ### New features. - (hail#11247) Introduces a new experimental plotting interface `hail.ggplot`, based on R's ggplot library.; - (hail#11173) Many math functions like `hail.sqrt` now automatically broadcast over ndarrays. ### Performance Improvements. - (hail#11216) Significantly improve performance of `parse_locus_interval`. ### Python and Java Support. - (hail#11219) We no longer officially support Python 3.6, though it may continue to work in the short term.; - (hail#11220) We support building hail with Java 11. ### File Format. - The native file format",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:54634,Testability,log,logic,54634,"row_major` on both `BlockMatrix` and `Table`. ---. ## Version 0.2.74. Released 2021-07-26. ### Bug fixes. - (hail#10697) Fixed bug in `read_table` when the table has missing keys and `_n_partitions` is specified.; - (hail#10695) Fixed bug in hl.experimental.loop causing incorrect results when loop state contained pointers. ---. ## Version 0.2.73. Released 2021-07-22. ### Bug fixes. - (hail#10684) Fixed a rare bug reading arrays from disk where short arrays would have their first elements corrupted and long arrays would cause segfaults.; - (hail#10523) Fixed bug where liftover would fail with ""Could not initialize class"" errors. ---. ## Version 0.2.72. Released 2021-07-19. ### New Features. - (hail#10655) Revamped many hail error messages to give useful python stack traces.; - (hail#10663) Added `DictExpression.items()` to mirror python's `dict.items()`.; - (hail#10657) `hl.map` now supports mapping over multiple lists like Python's built-in `map`. ### Bug fixes. - (hail#10662) Fixed partitioning logic in `hl.import_plink`.; - (hail#10669) `NDArrayNumericExpression.sum()` now works correctly on ndarrays of booleans. ---. ## Version 0.2.71. Released 2021-07-08. ### New Features. - (hail#10632) Added support for weighted linear regression to `hl.linear_regression_rows`.; - (hail#10635) Added `hl.nd.maximum` and `hl.nd.minimum`.; - (hail#10602) Added `hl.starmap`. ### Bug fixes. - (hail#10038) Fixed crashes when writing/reading matrix tables with 0 partitions.; - (hail#10624) Fixed out of bounds bug with `_quantile_from_cdf`. ### hailctl dataproc. - (hail#10633) Added `--scopes` parameter to `hailctl dataproc start`. ---. ## Version 0.2.70. Released 2021-06-21. ---. ## Version 0.2.69. Released 2021-06-14. ### New Features. - (hail#10592) Added `hl.get_hgdp` function.; - (hail#10555) Added `hl.hadoop_scheme_supported` function.; - (hail#10551) Indexing ndarrays now supports ellipses. ### Bug fixes. - (hail#10553) Dividing two integers now returns a `float64`, not a `floa",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:55726,Testability,log,logs,55726,"s of booleans. ---. ## Version 0.2.71. Released 2021-07-08. ### New Features. - (hail#10632) Added support for weighted linear regression to `hl.linear_regression_rows`.; - (hail#10635) Added `hl.nd.maximum` and `hl.nd.minimum`.; - (hail#10602) Added `hl.starmap`. ### Bug fixes. - (hail#10038) Fixed crashes when writing/reading matrix tables with 0 partitions.; - (hail#10624) Fixed out of bounds bug with `_quantile_from_cdf`. ### hailctl dataproc. - (hail#10633) Added `--scopes` parameter to `hailctl dataproc start`. ---. ## Version 0.2.70. Released 2021-06-21. ---. ## Version 0.2.69. Released 2021-06-14. ### New Features. - (hail#10592) Added `hl.get_hgdp` function.; - (hail#10555) Added `hl.hadoop_scheme_supported` function.; - (hail#10551) Indexing ndarrays now supports ellipses. ### Bug fixes. - (hail#10553) Dividing two integers now returns a `float64`, not a `float32`.; - (hail#10595) Don't include nans in `lambda_gc_agg`. ### hailctl dataproc. - (hail#10574) Hail logs will now be stored in `/home/hail` by default. ---. ## Version 0.2.68. Released 2021-05-27. ---. ## Version 0.2.67. ### Critical performance fix. Released 2021-05-06. - (hail#10451) Fixed a memory leak / performance bug triggered by `hl.literal(...).contains(...)`. ---. ## Version 0.2.66. Released 2021-05-03. ### New features. - (hail#10398) Added new method `BlockMatrix.to_ndarray`.; - (hail#10251) Added suport for haploid GT calls to VCF combiner. ---. ## Version 0.2.65. Released 2021-04-14. ### Default Spark Version Change. - Starting from version 0.2.65, Hail uses Spark 3.1.1 by default. This will also allow the use of all python versions >= 3.6. By building hail from source, it is still possible to use older versions of Spark. ### New features. - (hail#10290) Added `hl.nd.solve`.; - (hail#10187) Added `NDArrayNumericExpression.sum`. ### Performance improvements. - (hail#10233) Loops created with `hl.experimental.loop` will now clean up unneeded memory between iterations. ### Bug fixes. - (h",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:63892,Testability,log,logic,63892,"se the ""Hail"" kernel. ### File Format. - The native file format version is now 1.5.0. Older versions of Hail will not; be able to read tables or matrix tables written by this version of Hail. ---. ## Version 0.2.54. Released 2020-08-07. ### VCF Combiner. - (hail#9224)(hail#9237) **Breaking change**: Users are now required to pass a partitioning argument to the command-line interface or `run_combiner` method. See documentation for details.; - (hail#8963) Improved performance of VCF combiner by ~4x. ### New features. - (hail#9209) Add `hl.agg.ndarray_sum` aggregator. ### Bug fixes. - (hail#9206)(hail#9207) Improved error messages from invalid usages of Hail expressions.; - (hail#9223) Fixed error in bounds checking for NDArray slicing. ---. ## Version 0.2.53. Released 2020-07-30. ### Bug fixes. - (hail#9173) Use less confusing column key behavior in MT.show.; - (hail#9172) Add a missing Python dependency to Hail: google-cloud-storage.; - (hail#9170) Change Hail tree aggregate depth logic to correctly respect the; branching factor set in `hl.init`. ---. ## Version 0.2.52. Released 2020-07-29. ### Bug fixes. - (hail#8944)(hail#9169) Fixed crash (error 134 or SIGSEGV) in `MatrixTable.annotate_cols`, `hl.sample_qc`, and more. ---. ## Version 0.2.51. Released 2020-07-28. ### Bug fixes. - (hail#9161) Fix bug that prevented concatenating ndarrays that are fields of a table.; - (hail#9152) Fix bounds in NDArray slicing.; - (hail#9161) Fix bugs calculating *row_id* in `hl.import_matrix_table`. ---. ## Version 0.2.50. Released 2020-07-23. ### Bug fixes. - (hail#9114) CHANGELOG: Fixed crash when using repeated calls to `hl.filter_intervals`. ### New features. - (hail#9101) Add `hl.nd.{concat, hstack, vstack}` to concatenate ndarrays.; - (hail#9105) Add `hl.nd.{eye, identity}` to create identity matrix ndarrays.; - (hail#9093) Add `hl.nd.inv` to invert ndarrays.; - (hail#9063) Add `BlockMatrix.tree_matmul` to improve matrix multiply performance with a large inner dimension. ---. #",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68354,Testability,assert,assertion,68354,"n: null"" in `{Table, MatrixTable}.write`. ---. ## Version 0.2.42. Released 2020-05-27. ### New Features. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unn",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68429,Testability,assert,assertion,68429,"ures. - (hail#8822) Add optional non-centrality parameter to `hl.pchisqtail`.; - (hail#8861) Add `contig_recoding` option to `hl.experimental.run_combiner`. ### Bug fixes. - (hail#8863) Fixes VCF combiner to successfully import GVCFs with alleles called as <NON_REF>.; - (hail#8845) Fixed issue where accessing an element of an ndarray in a call to Table.transmute would fail.; - (hail#8855) Fix crash in `filter_intervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containin",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:68863,Testability,assert,assertion,68863,"ntervals`. ---. ## Version 0.2.41. Released 2020-05-15. ### Bug fixes. - (hail#8799)(hail#8786) Fix ArrayIndexOutOfBoundsException seen in pipelines that reuse a tuple value. ### hailctl dataproc. - (hail#8790) Use configured compute zone as default for `hailctl dataproc connect` and `hailctl dataproc modify`. ---. ## Version 0.2.40. Released 2020-05-12. ### VCF Combiner. - (hail#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:69270,Testability,log,logging,69270,"#8706) Add option to key by both locus and alleles for final output. ### Bug fixes. - (hail#8729) Fix assertion error in `Table.group_by(...).aggregate(...)`; - (hail#8708) Fix assertion error in reading tables and matrix tables with `_intervals` option.; - (hail#8756) Fix return type of `LocusExpression.window` to use locus's reference genome instead of default RG. ---. ## Version 0.2.39. Released 2020-04-29. ### Bug fixes. - (hail#8615) Fix contig ordering in the CanFam3 (dog) reference genome.; - (hail#8622) Fix bug that causes inscrutable JVM Bytecode errors.; - (hail#8645) Ease unnecessarily strict assertion that caused errors when; aggregating by key (e.g. `hl.experimental.spread`).; - (hail#8621) `hl.nd.array` now supports arrays with no elements; (e.g. `hl.nd.array([]).reshape((0, 5))`) and, consequently, matmul with an; inner dimension of zero. ### New features. - (hail#8571) `hl.init(skip_logging_configuration=True)` will skip configuration; of Log4j. Users may use this to configure their own logging.; - (hail#8588) Users who manually build Python wheels will experience less; unnecessary output when doing so.; - (hail#8572) Add `hl.parse_json` which converts a string containing JSON into a; Hail object. ### Performance Improvements. - (hail#8535) Increase speed of `import_vcf`.; - (hail#8618) Increase speed of Jupyter Notebook file listing and Notebook; creation when buckets contain many objects.; - (hail#8613) `hl.experimental.export_entries_by_col` stages files for improved; reliability and performance. ### Documentation; - (hail#8619) Improve installation documentation to suggest better performing; LAPACK and BLAS libraries.; - (hail#8647) Clarify that a LAPACK or BLAS library is a *requirement* for a; complete Hail installation.; - (hail#8654) Add link to document describing the creation of a Microsoft Azure; HDInsight Hail cluster. ---. ## Version 0.2.38. Released 2020-04-21. ### Critical Linreg Aggregator Correctness Bug. - (hail#8575) Fixed a correct",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:77227,Testability,assert,assertion,77227," array index out of bounds errors in Hail pipelines.; - (hail#7832) Add `spark_conf` argument to `hl.init`, permitting configuration of Spark runtime for a Hail session.; - (hail#7823) Added datetime functions `hl.experimental.strptime` and `hl.experimental.strftime`.; - (hail#7888) Added `hl.nd.array` constructor from nested standard arrays. ### File size. - (hail#7923) Fixed compression problem since 0.2.23 resulting in larger-than-expected matrix table files for datasets with few entry fields (e.g. GT-only datasets). ### Performance. - (hail#7867) Fix performance regression leading to extra scans of data when `order_by` and `key_by` appeared close together.; - (hail#7901) Fix performance regression leading to extra scans of data when `group_by/aggregate` and `key_by` appeared close together.; - (hail#7830) Improve performance of array arithmetic. ### Bug fixes. - (hail#7922) Fix still-not-well-understood serialization error about ApproxCDFCombiner.; - (hail#7906) Fix optimizer error by relaxing unnecessary assertion.; - (hail#7788) Fix possible memory leak in `ht.tail` and `ht.head`.; - (hail#7796) Fix bug in ingesting numpy arrays not in row-major orientation. ---. ## Version 0.2.30. Released 2019-12-20. ### Performance; - (hail#7771) Fixed extreme performance regression in scans.; - (hail#7764) Fixed `mt.entry_field.take` performance regression. ### New features; - (hail#7614) Added experimental support for loops with `hl.experimental.loop`. ### Miscellaneous; - (hail#7745) Changed `export_vcf` to only use scientific notation when necessary. ---. ## Version 0.2.29. Released 2019-12-17. ### Bug fixes; - (hail#7229) Fixed `hl.maximal_independent_set` tie breaker functionality.; - (hail#7732) Fixed incompatibility with old files leading to incorrect data read when filtering intervals after `read_matrix_table`.; - (hail#7642) Fixed crash when constant-folding functions that throw errors.; - (hail#7611) Fixed `hl.hadoop_ls` to handle glob patterns correctly.; - (hai",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:84011,Testability,log,log,84011,"7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#7086) Improved performance of JSON import.; - (hail#6981) Improved performance of Hail min/max/mean operators. Improved performance of `split_multi_hts` by an additional 33%.; - (hail#7082)(hail#7096)(hail#7098) Improved performance of large pipelines involving many `annotate` calls. ---. ## Version 0.2.22. Released 2019-09-12. ### New features; - (hail#7013) Added `contig_recoding` to `import_bed` and `import_locus_intervals`. ### Performance; - (hail#6969) Improved performance of `hl.agg.mean`, `hl.agg.stats`, and `hl.agg.corr`.; - (hail#6987) Improved performance of `import_matrix_table`.; - (ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:87267,Testability,assert,assertion,87267,"emory management inside `annotate_cols` with; aggregations. This was causing memory leaks and segfaults. ### Bug fixes; - (hail#6769) Fixed non-functional `hl.lambda_gc` method.; - (hail#6847) Fixed bug in handling of NaN in `hl.agg.min` and `hl.agg.max`.; These will now properly ignore NaN (the intended semantics). Note that; `hl.min` and `hl.max` propagate NaN; use `hl.nanmin` and `hl.nanmax`; to ignore NaN. ### New features; - (hail#6847) Added `hl.nanmin` and `hl.nanmax` functions. -----. ## Version 0.2.19. Released 2019-08-01. ### Critical performance bug fix. - (hail#6629) Fixed a critical performance bug introduced in (hail#6266).; This bug led to long hang times when reading in Hail tables and matrix; tables **written in version 0.2.18**. ### Bug fixes; - (hail#6757) Fixed correctness bug in optimizations applied to the; combination of `Table.order_by` with `hl.desc` arguments and `show()`,; leading to tables sorted in ascending, not descending order.; - (hail#6770) Fixed assertion error caused by `Table.expand_types()`,; which was used by `Table.to_spark` and `Table.to_pandas`. ### Performance Improvements. - (hail#6666) Slightly improve performance of `hl.pca` and; `hl.hwe_normalized_pca`.; - (hail#6669) Improve performance of `hl.split_multi` and; `hl.split_multi_hts`.; - (hail#6644) Optimize core code generation primitives, leading to; across-the-board performance improvements.; - (hail#6775) Fixed a major performance problem related to reading block; matrices. ### `hailctl dataproc`. - (hail#6760) Fixed the address pointed at by `ui` in `connect`, after; Google changed proxy settings that rendered the UI URL incorrect. Also; added new address `hist/spark-history`. -----. ## Version 0.2.18. Released 2019-07-12. ### Critical performance bug fix. - (hail#6605) Resolved code generation issue leading a performance; regression of 1-3 orders of magnitude in Hail pipelines using; constant strings or literals. This includes almost every pipeline!; **This issue ha",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:91731,Testability,log,log,91731,"of Hail. -----. ## Version 0.2.16. Released 2019-06-19. ### `hailctl`. - (hail#6357) Accommodated Google Dataproc bug causing cluster creation failures. ### Bug fixes. - (hail#6378) Fixed problem in how `entry_float_type` was being handled in `import_vcf`. -----. ## Version 0.2.15. Released 2019-06-14. After some infrastructural changes to our development process, we should be; getting back to frequent releases. ### `hailctl`. Starting in 0.2.15, `pip` installations of Hail come bundled with a command-; line tool, `hailctl`. This tool subsumes the functionality of `cloudtools`,; which is now deprecated. See the; [release thread on the forum](https://discuss.hail.is/t/new-command-line-utility-hailctl/981); for more information. ### New features. - (hail#5932)(hail#6115) `hl.import_bed` abd `hl.import_locus_intervals` now; accept keyword arguments to pass through to `hl.import_table`, which is used; internally. This permits parameters like `min_partitions` to be set.; - (hail#5980) Added `log` option to `hl.plot.histogram2d`.; - (hail#5937) Added `all_matches` parameter to `Table.index` and; `MatrixTable.index_{rows, cols, entries}`, which produces an array of all; rows in the indexed object matching the index key. This makes it possible to,; for example, annotate all intervals overlapping a locus.; - (hail#5913) Added functionality that makes arrays of structs easier to work; with.; - (hail#6089) Added HTML output to `Expression.show` when running in a notebook.; - (hail#6172) `hl.split_multi_hts` now uses the original `GQ` value if the `PL`; is missing.; - (hail#6123) Added `hl.binary_search` to search sorted numeric arrays.; - (hail#6224) Moved implementation of `hl.concordance` from backend to Python.; Performance directly from `read()` is slightly worse, but inside larger; pipelines this function will be optimized much better than before, and it; will benefit improvements to general infrastructure.; - (hail#6214) Updated Hail Python dependencies.; - (hail#5979) A",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:97592,Testability,log,log,97592,"e duplicates.; - (hail#5725) Docs now consistently refer to `hl.agg` not `agg`.; - (hail#5730)(hail#5782) Taught `import_bgen` to optimize its `variants` argument. ### Experimental. - (hail#5732) The `hl.agg.approx_quantiles` aggregate computes an approximation; of the quantiles of an expression.; - (hail#5693)(hail#5396) `Table._multi_way_zip_join` now correctly handles keys; that have been truncated. -----. ## Version 0.2.12. Released 2019-03-28. ### New features. - (hail#5614) Add support for multiple missing values in `hl.import_table`.; - (hail#5666) Produce HTML table output for `Table.show()` when running in Jupyter notebook. ### Bug fixes. - (hail#5603)(hail#5697) Fixed issue where `min_partitions` on `hl.import_table` was non-functional.; - (hail#5611) Fix `hl.nirvana` crash. ### Experimental. - (hail#5524) Add `summarize` functions to Table, MatrixTable, and Expression.; - (hail#5570) Add `hl.agg.approx_cdf` aggregator for approximate density calculation.; - (hail#5571) Add `log` parameter to `hl.plot.histogram`.; - (hail#5601) Add `hl.plot.joint_plot`, extend functionality of `hl.plot.scatter`.; - (hail#5608) Add LD score simulation framework.; - (hail#5628) Add `hl.experimental.full_outer_join_mt` for full outer joins on `MatrixTable`s. -----. ## Version 0.2.11. Released 2019-03-06. ### New features. - (hail#5374) Add default arguments to `hl.add_sequence` for running on GCP.; - (hail#5481) Added `sample_cols` method to `MatrixTable`.; - (hail#5501) Exposed `MatrixTable.unfilter_entries`. See `filter_entries` documentation for more information.; - (hail#5480) Added `n_cols` argument to `MatrixTable.head`.; - (hail#5529) Added `Table.{semi_join, anti_join}` and `MatrixTable.{semi_join_rows, semi_join_cols, anti_join_rows, anti_join_cols}`.; - (hail#5528) Added `{MatrixTable, Table}.checkpoint` methods as wrappers around `write` / `read_{matrix_table, table}`. ### Bug fixes. - (hail#5416) Resolved issue wherein VEP and certain regressions were recomputed on",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:103755,Testability,assert,assertions,103755,"`, `>=`) to support expressions of every type.; - (hail#4927) Expanded functionality of `Table.order_by` to support ordering by arbitrary expressions, instead of just top-level fields.; - (hail#4926) Expanded default GRCh38 contig recoding behavior in `import_plink`. ### Performance improvements. - (hail#4952) Resolved lingering issues related to (hail#4909). ### Bug fixes. - (hail#4941) Fixed variable scoping error in regression methods.; - (hail#4857) Fixed bug in maximal_independent_set appearing when nodes were named something other than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed ass",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104399,Testability,log,logging,104399,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104592,Testability,assert,assertion,104592,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104693,Testability,assert,assertion,104693,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:104934,Testability,assert,assertion,104934,"er than `i` and `j`.; - (hail#4932) Fixed possible error in `export_plink` related to tolerance of writer process failure.; - (hail#4920) Fixed bad error message in `Table.order_by`. -----. ## Version 0.2.5. Released 2018-12-07. ### New features. - (hail#4845) The [or_error](https://hail.is/docs/0.2/functions/core.html#hail.expr.builders.CaseBuilder.or_error) method in `hl.case` and `hl.switch` statements now takes a string expression rather than a string literal, allowing more informative messages for errors and assertions.; - (hail#4865) We use this new `or_error` functionality in methods that require biallelic variants to include an offending variant in the error message.; - (hail#4820) Added [hl.reversed](https://hail.is/docs/0.2/functions/collections.html#hail.expr.functions.reversed) for reversing arrays and strings.; - (hail#4895) Added `include_strand` option to the [hl.liftover](https://hail.is/docs/0.2/functions/genetics.html#hail.expr.functions.liftover) function. ### Performance improvements. - (hail#4907)(hail#4911) Addressed one aspect of bad scaling in enormous literal values (triggered by a list of 300,000 sample IDs) related to logging.; - (hail#4909)(hail#4914) Fixed a check in Table/MatrixTable initialization that scaled O(n^2) with the total number of fields. ### Bug fixes. - (hail#4754)(hail#4799) Fixed optimizer assertion errors related to certain types of pipelines using ``group_rows_by``.; - (hail#4888) Fixed assertion error in BlockMatrix.sum.; - (hail#4871) Fixed possible error in locally sorting nested collections.; - (hail#4889) Fixed break in compatibility with extremely old MatrixTable/Table files.; - (hail#4527)(hail#4761) Fixed optimizer assertion error sometimes encountered with ``hl.split_multi[_hts]``. -----. ## Version 0.2.4: Beginning of history!. We didn't start manually curating information about user-facing changes until version 0.2.4. The full commit history is available [here](https://github.com/hail-is/hail/commits/main).; ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:14314,Usability,clear,clearly,14314,"ct results for identity by descent in Query-on-Batch.; - (hail#14122) Ensure that stack traces are transmitted from workers to the driver to the client.; - (hail#14105) When a VCF contains missing values in array fields, Hail now suggests using `array_elements_required=False`. ### Deprecations. - (hail#13987) Deprecate `default_reference` parameter to `hl.init`, users should use `hl.default_reference` with an argument to set new default references usually shortly after `hl.init`. ## Version 0.2.126. Released 2023-10-30. ### Bug Fixes. - (hail#13939) Fix a bug introduced in 0.2.125 which could cause dict literals created in python to be decoded incorrectly, causing runtime errors or, potentially, incorrect results.; - (hail#13751) Correct the broadcasting of ndarrays containing at least one dimension of length zero. This previously produced incorrect results. ## Version 0.2.125. Released 2023-10-26. ### New Features. - (hail#13682) `hl.export_vcf` now clearly reports all Table or Matrix Table fields which cannot be represented in a VCF. - (hail#13355) Improve the Hail compiler to more reliably rewrite `Table.filter` and `MatrixTable.filter_rows` to use `hl.filter_intervals`. Before this change some queries required reading all partitions even though only a small number of partitions match the filter. - (hail#13787) Improve speed of reading hail format datasets from disk. Simple pipelines may see as much as a halving in latency. - (hail#13849) Fix (hail#13788), improving the error message when `hl.logistic_regression_rows` is provided row or entry annotations for the dependent variable. - (hail#13888) `hl.default_reference` can now be passed an argument to change the default reference genome. ### Bug Fixes. - (hail#13702) Fix (hail#13699) and (hail#13693). Since 0.2.96, pipelines that combined random functions (e.g. `hl.rand_unif`) with `index(..., all_matches=True)` could fail with a `ClassCastException`. - (hail#13707) Fix (hail#13633). `hl.maximum_independent_set` ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:30907,Usability,simpl,simple,30907," column had exactly one value for all rows and was mapped to either the `shape` or the `color` aesthetic for `geom_point`. ---. ## Version 0.2.114. Released 2023-04-19. ### New Features. - (hail#12880) Added `hl.vds.store_ref_block_max_len` to patch old VDSes to make interval filtering faster. ### Bug Fixes. - (hail#12860) Fixed memory leak in shuffles in Query-on-Batch. ---. ## Version 0.2.113. Released 2023-04-07. ### New Features. - (hail#12798) Query-on-Batch now supports `BlockMatrix.write(..., stage_locally=True)`.; - (hail#12793) Query-on-Batch now supports `hl.poisson_regression_rows`.; - (hail#12801) Hitting CTRL-C while interactively using Query-on-Batch cancels the underlying batch.; - (hail#12810) `hl.array` can now convert 1-d ndarrays into the equivalent list.; - (hail#12851) `hl.variant_qc` no longer requires a locus field.; - (hail#12816) In Query-on-Batch, `hl.logistic_regression('firth', ...)` is now supported.; - (hail#12854) In Query-on-Batch, simple pipelines with large numbers of partitions should be substantially faster. ### Bug Fixes. - (hail#12783) Fixed bug where logs were not properly transmitted to Python.; - (hail#12812) Fixed bug where `Table/MT._calculate_new_partitions` returned unbalanced intervals with whole-stage code generation runtime.; - (hail#12839) Fixed `hailctl dataproc` jupyter notebooks to be compatible with Spark 3.3, which have been broken since 0.2.110.; - (hail#12855) In Query-on-Batch, allow writing to requester pays buckets, which was broken before this release. ---. ## Version 0.2.112. Released 2023-03-15. ### Bug Fixes. - (hail#12784) Removed an internal caching mechanism in Query on Batch that caused stalls in pipelines with large intermediates. ---. ## Version 0.2.111. Released 2023-03-13. ### New Features. - (hail#12581) In Query on Batch, users can specify which regions to have jobs run in. ### Bug Fixes. - (hail#12772) Fix `hailctl hdinsight submit` to pass args to the files. ---. ## Version 0.2.110. Released 2",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:37805,Usability,progress bar,progress bar,37805,"function for reading tables with indices from Python.; - (hail#12139) Random number generation has been updated, but shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details.; - (hail#11884) Added `Job.always_copy_output` when using the `ServiceBackend`. The default behavior is `False`, which is a breaking change from the previous behavior to always copy output files regardless of the job's completion state.; - (hail#12139) Brand new random number generation, shouldn't affect most users. If you need to manually set seeds, see https://hail.is/docs/0.2/functions/random.html for details. ### Bug Fixes; - (hail#12487) Fixed a bug causing rare but deterministic job failures deserializing data in Query-on-Batch.; - (hail#12535) QoB will now error if the user reads from and writes to the same path. QoB also now respects the user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fi",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:38676,Usability,progress bar,progress bars,38676," user's configuration of `disable_progress_bar`. When `disable_progress_bar` is unspecified, QoB only disables the progress bar for non-interactive sessions.; - (hail#12517) Fix a performance regression that appears when using `hl.split_multi_hts` among other methods. ---. ## Version 0.2.105. Released 2022-10-31 . ### New Features. - (hail#12293) Added support for `hail.MatrixTable`s to `hail.ggplot`. ### Bug Fixes. - (hail#12384) Fixed a critical bug that disabled tree aggregation and scan executions in 0.2.104, leading to out-of-memory errors.; - (hail#12265) Fix long-standing bug wherein `hl.agg.collect_as_set` and `hl.agg.counter` error when applied to types which, in Python, are unhashable. For example, `hl.agg.counter(t.list_of_genes)` will not error when `t.list_of_genes` is a list. Instead, the counter dictionary will use `FrozenList` keys from the `frozenlist` package. ---. ## Version 0.2.104. Release 2022-10-19. ### New Features. - (hail#12346): Introduced new progress bars which include total time elapsed and look cool. ---. ## Version 0.2.103. Release 2022-10-18. ### Bug Fixes. - (hail#12305): Fixed a rare crash reading tables/matrixtables with _intervals. ---. ## Version 0.2.102. Released 2022-10-06. ### New Features. - (hail#12218) Missing values are now supported in primitive columns in `Table.to_pandas`.; - (hail#12254) Cross-product-style legends for data groups have been replaced with factored ones (consistent with `ggplot2`'s implementation) for `hail.ggplot.geom_point`, and support has been added for custom legend group labels.; - (hail#12268) `VariantDataset` now implements `union_rows` for combining datasets with the same samples but disjoint variants. ### Bug Fixes. - (hail#12278) Fixed bug made more likely by 0.2.101 in which Hail errors when interacting with a NumPy integer or floating point type.; - (hail#12277) Fixed bug in reading tables/matrixtables with partition intervals that led to error or segfault. ---. ## Version 0.2.101. Released",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:45280,Usability,progress bar,progress bar,45280,"ximation of the probability density function of its argument. ### Bug fixes. - (hail#11815) Fix incorrectly missing entries in to_dense_mt at the position of ref block END.; - (hail#11828) Fix `hl.init` to not ignore its `sc` argument. This bug was introduced in 0.2.94.; - (hail#11830) Fix an error and relax a timeout which caused `hailtop.aiotools.copy` to hang.; - (hail#11778) Fix a (different) error which could cause hangs in `hailtop.aiotools.copy`. ---. ## Version 0.2.94. Released 2022-04-26. ### Deprecation. - (hail#11765) Deprecated and removed linear mixed model functionality. ### Beta features. - (hail#11782) `hl.import_table` is up to twice as fast for small tables. ### New features. - (hail#11428) `hailtop.batch.build_python_image` now accepts a `show_docker_output` argument to toggle printing docker's output to the terminal while building container images; - (hail#11725) `hl.ggplot` now supports `facet_wrap`; - (hail#11776) `hailtop.aiotools.copy` will always show a progress bar when `--verbose` is passed. ### `hailctl dataproc`; - (hail#11710) support pass-through arguments to `connect`. ### Bug fixes. - (hail#11792) Resolved issue where corrupted tables could be created with whole-stage code generation enabled. ---. ## Version 0.2.93. Release 2022-03-27. ### Beta features. - Several issues with the beta version of Hail Query on Hail Batch are addressed in this release. ---. ## Version 0.2.92. Release 2022-03-25. ### New features. - (hail#11613) Add `hl.ggplot` support for `scale_fill_hue`, `scale_color_hue`, and `scale_fill_manual`,; `scale_color_manual`. This allows for an infinite number of discrete colors.; - (hail#11608) Add all remaining and all versions of extant public gnomAD datasets to the Hail; Annotation Database and Datasets API. Current as of March 23rd 2022.; - (hail#11662) Add the `weight` aesthetic `geom_bar`. ### Beta features. - This version of Hail includes all the necessary client-side infrastructure to execute Hail Query; pipelines ",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md:83392,Usability,progress bar,progress bar,83392,".2.24. Released 2019-10-03. ### `hailctl dataproc`; - (hail#7185) Resolve issue in dependencies that led to a Jupyter update breaking cluster creation. ### New features; - (hail#7071) Add `permit_shuffle` flag to `hl.{split_multi, split_multi_hts}` to allow processing of datasets with both multiallelics and duplciate loci.; - (hail#7121) Add `hl.contig_length` function.; - (hail#7130) Add `window` method on `LocusExpression`, which creates an interval around a locus.; - (hail#7172) Permit `hl.init(sc=sc)` with pip-installed packages, given the right configuration options. ### Bug fixes; - (hail#7070) Fix unintentionally strict type error in `MatrixTable.union_rows`.; - (hail#7170) Fix issues created downstream of `BlockMatrix.T`.; - (hail#7146) Fix bad handling of edge cases in `BlockMatrix.filter`.; - (hail#7182) Fix problem parsing VCFs where lines end in an INFO field of type flag. ---. ## Version 0.2.23. Released 2019-09-23. ### `hailctl dataproc`; - (hail#7087) Added back progress bar to notebooks, with links to the correct Spark UI url.; - (hail#7104) Increased disk requested when using `--vep` to address the ""colony collapse"" cluster error mode. ### Bug fixes; - (hail#7066) Fixed generated code when methods from multiple reference genomes appear together.; - (hail#7077) Fixed crash in `hl.agg.group_by`. ### New features; - (hail#7009) Introduced analysis pass in Python that mostly obviates the `hl.bind` and `hl.rbind` operators; idiomatic Python that generates Hail expressions will perform much better.; - (hail#7076) Improved memory management in generated code, add additional log statements about allocated memory to improve debugging.; - (hail#7085) Warn only once about schema mismatches during JSON import (used in VEP, Nirvana, and sometimes `import_table`.; - (hail#7106) `hl.agg.call_stats` can now accept a number of alleles for its `alleles` parameter, useful when dealing with biallelic calls without the alleles array at hand. ### Performance; - (hail#708",MatchSource.DOCS,hail/python/hail/docs/change_log.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/python/hail/docs/change_log.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:1019,Availability,avail,available,1019,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:353,Modifiability,variab,variable,353,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:416,Modifiability,variab,variable,416,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:651,Modifiability,variab,variables,651,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:1085,Performance,perform,perform,1085,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:1102,Performance,cache,cache-blocking,1102,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:1117,Performance,optimiz,optimization,1117,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:394,Safety,detect,detection,394,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md:1095,Usability,simpl,simple,1095,"# Vectorized Hail; These are a few pointers to help orient you. ## Building for a non-native architecture. By default this code builds for the widest registers your current machine; supports. To prevent this set these two CXXFLAGS *and specify an architecture*; before calling `make`:. ```; -DHAIL_OVERRIDE_ARCH; -DHAIL_OVERRIDE_WIDTH=4; ```. The first variable prevents automatic architecture detection. The second variable states how many 64-bit values should be packed into a vector; intrinsic. Unfortunately, this cannot be set to one because libsimdpp did not; define `extract<0>` for size-one vectors. To specify an architecture, set one of the variables listed in the; [libsimdpp documentation](http://p12tic.github.io/libsimdpp/v2.0%7Erc2/libsimdpp/arch/selection.html). ## `uint64vector`. In `ibs.h`, we define `uint64vector` in terms of `libsimdpp` 64-bit vectors. By; default, we set the length of the vector to `SIMDPP_FAST_INT64_SIZE`, which is; set to the length (in 64-bit units) of the longest register available on this; machine. ## Cache Optimization. In `ibsMat` we perform a simple cache-blocking optimization. We assume that the; input genotype arrays are multiples of the block size; (i.e. `CACHE_SIZE_IN_MATRIX_ROWS`). ## Alignment. We do not assume any provided memory is 32-bit aligned.; ",MatchSource.DOCS,hail/src/main/c/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/hail/src/main/c/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:2300,Availability,echo,echo,2300,"leted successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. D",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:2751,Availability,down,download,2751," you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4284,Availability,down,download-secret,4284,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4353,Availability,down,download-secret,4353,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:231,Deployability,install,installed,231,"# Hail on Azure. This is a work in progress for setting up hail infrasture on Azure. The; following should be executed in the `$HAIL/infra/azure` directory unless; otherwise noted. Prerequisites:. - You must have `jq`, `terraform` installed.; - Export `HAIL` as the root of the checked out Hail repository; - Generate a public-private SSH (using RSA) key at `~/.ssh/batch_worker_ssh_rsa`. ## Authenticating with the Azure CLI. You will need an Azure account. Install the Azure CLI by running the following; (on Mac) and log in:. ```; brew install azure-cli; az login; ```. ## Running Terraform. Every resource in Azure must belong to a Resource Group. First, obtain; a resource group and make sure you have Owner permissions for that; resource group. You will also need a storage account and container for remotely storing; terraform state. The following command creates these and stores their names in; `remote_storage.tfvars`:. ```; ./bootstrap.sh create_terraform_remote_storage <RESOURCE_GROUP>; ```. Initialize terraform:. ```; ./bootstrap.sh init_terraform <RESOURCE_GROUP>; ```. Create a `global.tfvars` file with the necessary variables from; $HAIL/infra/azure/variables.tf. Run terraform:. ```; terraform apply -var-file=global.tfvars; ```. Once terraform has completed successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. T",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:539,Deployability,install,install,539,"# Hail on Azure. This is a work in progress for setting up hail infrasture on Azure. The; following should be executed in the `$HAIL/infra/azure` directory unless; otherwise noted. Prerequisites:. - You must have `jq`, `terraform` installed.; - Export `HAIL` as the root of the checked out Hail repository; - Generate a public-private SSH (using RSA) key at `~/.ssh/batch_worker_ssh_rsa`. ## Authenticating with the Azure CLI. You will need an Azure account. Install the Azure CLI by running the following; (on Mac) and log in:. ```; brew install azure-cli; az login; ```. ## Running Terraform. Every resource in Azure must belong to a Resource Group. First, obtain; a resource group and make sure you have Owner permissions for that; resource group. You will also need a storage account and container for remotely storing; terraform state. The following command creates these and stores their names in; `remote_storage.tfvars`:. ```; ./bootstrap.sh create_terraform_remote_storage <RESOURCE_GROUP>; ```. Initialize terraform:. ```; ./bootstrap.sh init_terraform <RESOURCE_GROUP>; ```. Create a `global.tfvars` file with the necessary variables from; $HAIL/infra/azure/variables.tf. Run terraform:. ```; terraform apply -var-file=global.tfvars; ```. Once terraform has completed successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. T",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:3032,Deployability,deploy,deployment,3032,"UBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the change",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:3220,Deployability,deploy,deployment,3220,"l | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:3366,Deployability,deploy,deploy,3366," the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4251,Deployability,deploy,deploy,4251,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4906,Deployability,deploy,deploy,4906,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:1135,Modifiability,variab,variables,1135,"ure` directory unless; otherwise noted. Prerequisites:. - You must have `jq`, `terraform` installed.; - Export `HAIL` as the root of the checked out Hail repository; - Generate a public-private SSH (using RSA) key at `~/.ssh/batch_worker_ssh_rsa`. ## Authenticating with the Azure CLI. You will need an Azure account. Install the Azure CLI by running the following; (on Mac) and log in:. ```; brew install azure-cli; az login; ```. ## Running Terraform. Every resource in Azure must belong to a Resource Group. First, obtain; a resource group and make sure you have Owner permissions for that; resource group. You will also need a storage account and container for remotely storing; terraform state. The following command creates these and stores their names in; `remote_storage.tfvars`:. ```; ./bootstrap.sh create_terraform_remote_storage <RESOURCE_GROUP>; ```. Initialize terraform:. ```; ./bootstrap.sh init_terraform <RESOURCE_GROUP>; ```. Create a `global.tfvars` file with the necessary variables from; $HAIL/infra/azure/variables.tf. Run terraform:. ```; terraform apply -var-file=global.tfvars; ```. Once terraform has completed successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doi",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:1169,Modifiability,variab,variables,1169,"ure` directory unless; otherwise noted. Prerequisites:. - You must have `jq`, `terraform` installed.; - Export `HAIL` as the root of the checked out Hail repository; - Generate a public-private SSH (using RSA) key at `~/.ssh/batch_worker_ssh_rsa`. ## Authenticating with the Azure CLI. You will need an Azure account. Install the Azure CLI by running the following; (on Mac) and log in:. ```; brew install azure-cli; az login; ```. ## Running Terraform. Every resource in Azure must belong to a Resource Group. First, obtain; a resource group and make sure you have Owner permissions for that; resource group. You will also need a storage account and container for remotely storing; terraform state. The following command creates these and stores their names in; `remote_storage.tfvars`:. ```; ./bootstrap.sh create_terraform_remote_storage <RESOURCE_GROUP>; ```. Initialize terraform:. ```; ./bootstrap.sh init_terraform <RESOURCE_GROUP>; ```. Create a `global.tfvars` file with the necessary variables from; $HAIL/infra/azure/variables.tf. Run terraform:. ```; terraform apply -var-file=global.tfvars; ```. Once terraform has completed successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doi",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:1573,Modifiability,config,configured,1573,"gin; ```. ## Running Terraform. Every resource in Azure must belong to a Resource Group. First, obtain; a resource group and make sure you have Owner permissions for that; resource group. You will also need a storage account and container for remotely storing; terraform state. The following command creates these and stores their names in; `remote_storage.tfvars`:. ```; ./bootstrap.sh create_terraform_remote_storage <RESOURCE_GROUP>; ```. Initialize terraform:. ```; ./bootstrap.sh init_terraform <RESOURCE_GROUP>; ```. Create a `global.tfvars` file with the necessary variables from; $HAIL/infra/azure/variables.tf. Run terraform:. ```; terraform apply -var-file=global.tfvars; ```. Once terraform has completed successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:3898,Modifiability,variab,variable,3898,"tes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4307,Modifiability,config,config,4307,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4345,Modifiability,config,config,4345,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4385,Modifiability,config,config,4385,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4420,Modifiability,config,config,4420,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4899,Modifiability,config,config,4899,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:2764,Security,authenticat,authenticate,2764," you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:2818,Security,authenticat,authenticate,2818,"min consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in let",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:2970,Security,authenticat,authentication,2970,"ess on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:3486,Security,certificate,certificates,3486,". In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hai",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:520,Testability,log,log,520,"# Hail on Azure. This is a work in progress for setting up hail infrasture on Azure. The; following should be executed in the `$HAIL/infra/azure` directory unless; otherwise noted. Prerequisites:. - You must have `jq`, `terraform` installed.; - Export `HAIL` as the root of the checked out Hail repository; - Generate a public-private SSH (using RSA) key at `~/.ssh/batch_worker_ssh_rsa`. ## Authenticating with the Azure CLI. You will need an Azure account. Install the Azure CLI by running the following; (on Mac) and log in:. ```; brew install azure-cli; az login; ```. ## Running Terraform. Every resource in Azure must belong to a Resource Group. First, obtain; a resource group and make sure you have Owner permissions for that; resource group. You will also need a storage account and container for remotely storing; terraform state. The following command creates these and stores their names in; `remote_storage.tfvars`:. ```; ./bootstrap.sh create_terraform_remote_storage <RESOURCE_GROUP>; ```. Initialize terraform:. ```; ./bootstrap.sh init_terraform <RESOURCE_GROUP>; ```. Create a `global.tfvars` file with the necessary variables from; $HAIL/infra/azure/variables.tf. Run terraform:. ```; terraform apply -var-file=global.tfvars; ```. Once terraform has completed successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. T",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:561,Testability,log,login,561,"# Hail on Azure. This is a work in progress for setting up hail infrasture on Azure. The; following should be executed in the `$HAIL/infra/azure` directory unless; otherwise noted. Prerequisites:. - You must have `jq`, `terraform` installed.; - Export `HAIL` as the root of the checked out Hail repository; - Generate a public-private SSH (using RSA) key at `~/.ssh/batch_worker_ssh_rsa`. ## Authenticating with the Azure CLI. You will need an Azure account. Install the Azure CLI by running the following; (on Mac) and log in:. ```; brew install azure-cli; az login; ```. ## Running Terraform. Every resource in Azure must belong to a Resource Group. First, obtain; a resource group and make sure you have Owner permissions for that; resource group. You will also need a storage account and container for remotely storing; terraform state. The following command creates these and stores their names in; `remote_storage.tfvars`:. ```; ./bootstrap.sh create_terraform_remote_storage <RESOURCE_GROUP>; ```. Initialize terraform:. ```; ./bootstrap.sh init_terraform <RESOURCE_GROUP>; ```. Create a `global.tfvars` file with the necessary variables from; $HAIL/infra/azure/variables.tf. Run terraform:. ```; terraform apply -var-file=global.tfvars; ```. Once terraform has completed successfully, you must create an A record for the; domain of your choosing pointing at the `gateway_ip` with a DNS provider. The; `gateway_ip` may be retrieved by executing the following command. ```; terraform output -raw gateway_ip; ```. There is one resource which, unfortunately, cannot be configured directly with; Terraform. The service principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. T",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:2584,Testability,log,log,2584,"ce principal used by the `auth` service needs ""admin; consent"" to create new service accounts for new users. After you first run; terraform and whenever you recreate the auth service principal, you must grant; this new service principal admin consent:. ```; ./bootstrap.sh grant_auth_sp_admin_consent; ```. ## Bootstrap the cluster. We'll complete the rest of the process on a VM. To create one, run. ```; ./create_bootstrap_vm.sh <RESOURCE_GROUP> <SUBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if th",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:4669,Testability,log,logged,4669,". ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the changes.; You can then move on from this step. Build the batch worker image by running the following in $HAIL/batch:. ```; ./az-create-worker-image.sh; ```. Finally, run the following to deploy Hail in the cluster. ```; download-secret global-config && sudo cp -r contents /global-config; download-secret database-server-config && sudo cp -r contents /sql-config; cd ~/hail/infra/azure; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> deploy_batch; ```. Create the initial (developer) user. The OBJECT_ID is the Azure Active; Directory user's object ID. You can find the current object id locally if you're logged in using:. ```; az ad signed-in-user show | jq '.objectId'; ```. ```; ./bootstrap.sh bootstrap <REPO>/hail:<BRANCH> create_initial_user <USERNAME> <OBJECT_ID>; ```. Deploy the gateway:. ```; make -C $HAIL/gateway envoy-xds-config deploy; ```; ",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md:3022,Usability,pause,pause,3022,"UBSCRIPTION_ID>; ```. Find the public ip of the created bootstrap vm doing the following:. ```; BOOTSTRAP_VM=$(az vm list -g hail | jq -r '.[].name'); PUBLIC_IP=$(az vm show -d -n $BOOTSTRAP_VM -g hail --query ""publicIps"" -o tsv); echo $BOOTSTRAP_VM $PUBLIC_IP; ```. SSH into the VM (ssh -i ~/.ssh/id_rsa <username>@$PUBLIC_IP). Clone the hail repository:. ```; git clone https://github.com/<repo_name>/hail.git; ```. In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). In the $HAIL/infra/azure directory, run. ```; ./bootstrap.sh setup_az; ```. to download and authenticate with the azure CLI. Run the following to authenticate docker and kubectl with the new; container registry and kubernetes cluster, respectively. ```; azsetcluster <RESOURCE_GROUP>; ```. The ACR authentication token only lasts three hours. If you pause the deployment; process after this point, you may have to rerun `azsetcluster` before continuing. Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. During the deploy while running into issues you may have to run the; above command multiple times. Each time it will try to create certificates; using letsencrypt. You may reach a limit on the number of attempts possible; withing a 24hr period, or it may fail if the specified certs already exist.; If this happens it will retrieve the exiting certs, but the deploy_unmanaged step will fail. If the final letsencrypt step in deploy_unmanaged fails, you will have to; comment out the ""set +x"" line in letsencrypt.sh. Then set the environment ; variable `DRY_RUN=1`. Re-run the deploy_unmanaged step again and copy the; kubectl secret from stdout. Apply the secret manually using `kubectl apply` and revert the change",MatchSource.DOCS,infra/azure/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/azure/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8625,Availability,echo,echo,8625," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:1401,Deployability,deploy,deployment,1401," container.googleapis.com \; compute.googleapis.com \; cloudkms.googleapis.com \; cloudresourcemanager.googleapis.com \; servicenetworking.googleapis.com \; sqladmin.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible wit",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:1496,Deployability,configurat,configuration,1496,"in.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:;",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:1536,Deployability,deploy,deployments,1536,"in.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:;",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:4758,Deployability,configurat,configuration,4758,"y; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/so",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:6125,Deployability,integrat,integration,6125,"erraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/ci_config.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/ci_config.enc.json. sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/terraform_sa_key.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Clou",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:7020,Deployability,install,install,7020," add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8184,Deployability,deploy,deployment,8184," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8865,Deployability,deploy,deploy,8865," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:638,Energy Efficiency,monitor,monitoring,638,"This is a work in progress to use Terraform to manage our cloud; infrastructure. Instructions:. - You will need a GCP project. Configure `gcloud` to point at your project:. ```; gcloud config set project <gcp-project-id>; gcloud config set compute/zone <gcp-zone>; ```. - Enable the GCP services needed by Hail:. ```; gcloud services enable \; container.googleapis.com \; compute.googleapis.com \; cloudkms.googleapis.com \; cloudresourcemanager.googleapis.com \; servicenetworking.googleapis.com \; sqladmin.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:1888,Energy Efficiency,schedul,schedule,1888,"le Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubu",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:2087,Energy Efficiency,schedul,schedule,2087,"redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note tha",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:4732,Integrability,depend,dependency,4732,"y; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/so",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:6125,Integrability,integrat,integration,6125,"erraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/ci_config.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/ci_config.enc.json. sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/terraform_sa_key.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Clou",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:185,Modifiability,config,config,185,"This is a work in progress to use Terraform to manage our cloud; infrastructure. Instructions:. - You will need a GCP project. Configure `gcloud` to point at your project:. ```; gcloud config set project <gcp-project-id>; gcloud config set compute/zone <gcp-zone>; ```. - Enable the GCP services needed by Hail:. ```; gcloud services enable \; container.googleapis.com \; compute.googleapis.com \; cloudkms.googleapis.com \; cloudresourcemanager.googleapis.com \; servicenetworking.googleapis.com \; sqladmin.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:229,Modifiability,config,config,229,"This is a work in progress to use Terraform to manage our cloud; infrastructure. Instructions:. - You will need a GCP project. Configure `gcloud` to point at your project:. ```; gcloud config set project <gcp-project-id>; gcloud config set compute/zone <gcp-zone>; ```. - Enable the GCP services needed by Hail:. ```; gcloud services enable \; container.googleapis.com \; compute.googleapis.com \; cloudkms.googleapis.com \; cloudresourcemanager.googleapis.com \; servicenetworking.googleapis.com \; sqladmin.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:1496,Modifiability,config,configuration,1496,"in.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:;",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:4758,Modifiability,config,configuration,4758,"y; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/so",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:6939,Modifiability,config,config,6939,"ops/cryptoKeys/sops-key /tmp/terraform_sa_key.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, r",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8453,Modifiability,config,config,8453," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8509,Modifiability,config,config,8509," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8554,Modifiability,config,config,8554," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8653,Modifiability,config,config,8653," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:8858,Modifiability,config,config,8858," 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway envoy-xds-config deploy`. - Create the initial (developer) user. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> create_initial_user <USERNAME> <EMAIL>; ```. Additional users can be added by the initial user by going to auth.<domain>/users.; ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:6993,Performance,load,load,6993,"_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGI",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:1470,Safety,avoid,avoids,1470,"in.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:;",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:4717,Safety,avoid,avoid,4717,"y; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/so",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3115,Security,access,access,3115,"dule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```.",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3176,Security,access,access,3176,"ust be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key f",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3242,Security,access,access,3242,"tion>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud km",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3359,Security,authenticat,authentication,3359,"torage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --loca",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3404,Security,secur,secure,3404,"torage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --loca",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3434,Security,access,access-tokens,3434,"torage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --loca",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3497,Security,access,access,3497,"hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3532,Security,access,access,3532,"hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:3601,Security,access,access,3601,"_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:4348,Security,encrypt,encryption,4348,"://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:4650,Security,access,access,4650,"resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.j",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:5423,Security,encrypt,encrypt,5423,"ts/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/ci_config.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/ci_config.enc.json. sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/terraform_sa_key.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/inf",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:5648,Security,encrypt,encrypt,5648,"outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/ci_config.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/ci_config.enc.json. sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/terraform_sa_key.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:5829,Security,encrypt,encrypt,5829,"t name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --role='roles/owner'. gcloud iam service-accounts keys create /tmp/terraform_sa_key.json --iam-account=terraform@<project-id>.iam.gserviceaccount.com; ```. - Encrypt the above files and add them to the repository. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/ci_config.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/ci_config.enc.json. sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/terraform_sa_key.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:6358,Security,encrypt,encrypt,6358,"t --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/auth_oauth2_client_secret.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/auth_oauth2_client_secret.enc.json. # Optional; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/ci_config.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/ci_config.enc.json. sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/terraform_sa_key.json > $HAIL/infra/gcp/$GITHUB_ORGANIZATION/terraform_sa_key.enc.json. git add $HAIL/infra/gcp/$GITHUB_ORGANIZATION/*. # git commit and push as desired.; ```. - If you want Zulip integration for alerts from CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github ",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:7130,Security,access,access,7130,"m CI and Grafana, create a zuliprc file:. ```sh; cat /tmp/zuliprc <<EOF; [api]; key=SECRET_KEY_HERE; email=YOUR_BOT_EMAIL_HERE; site=YOUR_SITE_HERE; EOF; ```. - Encrypt the zuliprc with SOPS:. ```sh; sops --encrypt --gcp-kms projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key /tmp/zuliprc \; >$HAIL/infra/gcp/$GITHUB_ORGANIZATION/zuliprc.enc; ```. - Install terraform. - Run `terraform init`. - Run `terraform apply -var-file=$GITHUB_ORGANIZATION/global.tfvars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the s",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:7811,Security,authenticat,authenticate,7811," ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \(.value) > /global-config/\(.key)"") | .[]' | bash; ```. - Bootstrap the cluster. ```; ./bootstrap.sh bootstrap $GITHUB_ORGANIZATION/hail:<BRANCH> deploy_batch; ```. - Deploy the gateway: run `make -C $HAIL/gateway en",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:580,Testability,log,logging,580,"This is a work in progress to use Terraform to manage our cloud; infrastructure. Instructions:. - You will need a GCP project. Configure `gcloud` to point at your project:. ```; gcloud config set project <gcp-project-id>; gcloud config set compute/zone <gcp-zone>; ```. - Enable the GCP services needed by Hail:. ```; gcloud services enable \; container.googleapis.com \; compute.googleapis.com \; cloudkms.googleapis.com \; cloudresourcemanager.googleapis.com \; servicenetworking.googleapis.com \; sqladmin.googleapis.com \; serviceusage.googleapis.com \; dns.googleapis.com \; logging.googleapis.com \; cloudprofiler.googleapis.com \; monitoring.googleapis.com \; iam.googleapis.com \; artifactregistry.googleapis.com \; cloudbilling.googleapis.com; ```. - Delete the default network if it exists. Enabling the networking; API creates it. - Go to the Google Cloud console, API & Services, Credentials.; Configure the consent screen. Add the scope:; https://www.googleapis.com/auth/userinfo.email. Back in Credentials, create an OAuth; client ID. Authorize the redirect URIs:. - https://auth.<domain>/oauth2callback; - http://127.0.0.1/oauth2callback. Download the client secret as `/tmp/auth_oauth2_client_secret.json`. - Create `infra/gcp/$GITHUB_ORGANIZATION/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:2273,Testability,log,logs,2273,"ON/global.tfvars` based on the template below, where `$GITHUB_ORGANIZATION` corresponds to the GitHub organization used for your Hail Batch deployment (e.g. [`hail-is`](https://github.com/hail-is/hail)). This avoids collisions between configuration files from different Hail deployments. ```; # organization_domain is a string that is the domain of the organization; # E.g. ""hail.is""; organization_domain = ""<domain>"". # The GitHub organization hosting your Hail Batch repository, e.g. ""hail-is"".; github_organization = ""<github-organization>"". # batch_gcp_regions is a JSON array of string, the names of the gcp; # regions to schedule over in Batch. E.g. ""[\""us-central1\""]""; batch_gcp_regions = ""<batch-gcp-regions>"". gcp_project = ""<gcp-project-id>"". # This is the bucket location that spans the regions you're going to; # schedule across in Batch. If you are running on one region, it can; # just be that region. E.g. ""US""; batch_logs_bucket_location = ""<bucket-location>"". # The storage class for the batch logs bucket. It should span the; # batch regions and be compatible with the bucket location.; batch_logs_bucket_storage_class = ""MULTI_REGIONAL"". # Similarly, bucket locations and storage classes are specified; # for other services:; hail_query_bucket_location = ""<bucket-location>""; hail_query_bucket_storage_class = ""MULTI_REGIONAL""; hail_test_gcs_bucket_location = ""<bucket-location>""; hail_test_gcs_bucket_storage_class = ""MULTI_REGIONAL"". gcp_region = ""<gcp-region>"". gcp_zone = ""<gcp-zone>"". gcp_location = ""<gcp-region>"". domain = ""<domain>"". # If set to true, pull the base ubuntu image from Artifact Registry.; # Otherwise, assumes GCR.; use_artifact_registry = false; ```. - You can optionally create a `/tmp/ci_config.json` file to enable CI triggered by GitHub; events. Note that `github_oauth_token` is not necessarily an OAuth2 access token. In fact, it; should be a fine-grained personal access token. The currently public documentation on fine-grained; access tokens is not",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:4215,Testability,log,login,4215,"ently public documentation on fine-grained; access tokens is not very good. Check this [page in; `github/docs`](https://github.com/github/docs/blob/main/content/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens.md); for information on how to create a personal access token that is privileged to access the; `hail-is` organization. Note in particular that personal access tokens have a ""resource owner""; field which is fixed at creation time. The token can only read or write to repositories owned by; the ""resource owner"". ```json; {; ""bucket_location"": ""<gcp-zone>"",; ""bucket_storage_class"": ""STANDARD"",; ""deploy_steps"": [; ""deploy_batch"",; ""test_batch_0"",; ""deploy_ci""; ],; ""github_context"": ""ci-gcp"",; ""github_oauth_token"": ""<TOKEN>"",; ""github_user1_oauth_token"": ""<TOKEN>"",; ""watched_branches"": [; [; ""hail-is/hail:main"",; true,; false; ]; ]; }; ```. - Install [sops](https://github.com/mozilla/sops). - Set up a key for sops to use:. ```sh; gcloud auth application-default login. gcloud kms keyrings create sops --location global. gcloud kms keys create sops-key --location global --keyring sops --purpose encryption. gcloud kms keys list --location global --keyring sops; ```. You should see:. ```sh; NAME PURPOSE PRIMARY_STATE; projects/<gcp-project-id>/locations/global/keyRings/sops/cryptoKeys/sops-key ENCRYPT_DECRYPT ENABLED; ```. This key can be shared with other developers in your team, controlling access through IAM. It needs to be created outside of Terraform to avoid a cyclic dependency: the Terraform configuration needs to decrypt `sops` files. - Create a service account for Terraform with Owner role. We use; service account name `terraform`. Create a JSON service account key; and place it in `/tmp/terraform_sa_key.json`. ```; gcloud iam service-accounts create terraform --display-name=""Terraform Account"". gcloud projects add-iam-policy-binding <project-id> --member='serviceAccount:terraform@<project-id>.iam.gserviceaccount.com' --r",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md:7598,Testability,log,log,7598,"vars`. At the; time of writing, this takes ~15m. - Terraform created a GKE cluster named `vdc`. Configure `kubectl`; to point at the vdc cluster:. ```; gcloud container clusters get-credentials --zone <gcp-zone> vdc; ```. Register `domain` with a DNS registry with the `ip` field in the; Kubernetes global-config. This should point to the kubernetes; external load balancer. You can now install Hail:. - Create a VM on the internal network, standard-8, 100GB PD-SSD,; Ubuntu 22.04 TLS, allow full access to all Cloud APIs, use the; Terraform service account. 10GB will run out of space. We assume; the rest of the commands are run on the VM. You will need to; connect to this instance with ssh. You may want to add a suiteable; ssh forwarding rule to the default network. - Clone the Hail Github repository:. ```; git clone https://github.com/hail-is/hail.git; ```. - In the $HAIL/infra directory, run. ```; ./install_bootstrap_dependencies.sh; ```. At this point, log out and ssh back in (so that changes to group settings; for Docker can be applied). The following steps should be completed from; the $HAIL/infra/gcp directory, unless otherwise stated. - Run the following to authenticate docker and kubectl with the new artifact; registry and kubernetes cluster, respectively. The `GKE_ZONE` is the zone of; the GKE cluster and the `GAR_REGION` is the region of the artifact registry. ```; ./bootstrap.sh configure_gcloud <GKE_ZONE> <GAR_REGION>; ```. - Edit `$HAIL/letsencrypt/subdomains.txt` to include just the services you plan; to use in this deployment, e.g. `auth`, `batch` and `batch-driver`. - Deploy unmanaged resources by running. ```; ./bootstrap.sh deploy_unmanaged; ```. - Create the batch worker VM image. Run:. ```; NAMESPACE=default $HAIL/batch/gcp-create-worker-image.sh; ```. - Download the global-config to be used by `bootstrap.py`. ```; mkdir /global-config; kubectl -n default get secret global-config -o json | jq -r '.data | map_values(@base64d) | to_entries|map(""echo -n \",MatchSource.DOCS,infra/gcp/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:34,Deployability,deploy,deploy,34,"If you're a third-party trying to deploy Hail, look at `../gcp`. Hail team, this directory is an underestimate of our infrastructure. We are iteratively adding more; infrastructure. Infrastructure may be missing because importing into terraform would require a; destroy/create. ---. Changes from `../gcp`:. Create a bucket in which to store terraform state. Use the same region in which you plan to create; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ``",MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:1488,Deployability,update,update,1488,reate; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ```. Create `backend.hcl`:. ```; cat >infra/gcp-broad/$GITHUB_ORGANIZATION/backend.hcl <<EOF; bucket = $TERRAFORM_STATE_BUCKET; kms_encryption_key = $TERRAFORM_KEY_NAME; EOF; ```. Initialize Terraform:. ```; terraform init -backend-config=hail-is/backend.hcl -var-file=hail-is/global.tfvars; ```. Then inspect the Terraform plan:. ```; terraform plan -var-file=hail-is/global.tfvars -out=tfplan; ```; ,MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:1223,Modifiability,variab,variable,1223," third-party trying to deploy Hail, look at `../gcp`. Hail team, this directory is an underestimate of our infrastructure. We are iteratively adding more; infrastructure. Infrastructure may be missing because importing into terraform would require a; destroy/create. ---. Changes from `../gcp`:. Create a bucket in which to store terraform state. Use the same region in which you plan to create; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ```. Create ",MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:2231,Modifiability,config,config,2231,reate; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ```. Create `backend.hcl`:. ```; cat >infra/gcp-broad/$GITHUB_ORGANIZATION/backend.hcl <<EOF; bucket = $TERRAFORM_STATE_BUCKET; kms_encryption_key = $TERRAFORM_KEY_NAME; EOF; ```. Initialize Terraform:. ```; terraform init -backend-config=hail-is/backend.hcl -var-file=hail-is/global.tfvars; ```. Then inspect the Terraform plan:. ```; terraform plan -var-file=hail-is/global.tfvars -out=tfplan; ```; ,MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:724,Security,encrypt,encrypt,724,"If you're a third-party trying to deploy Hail, look at `../gcp`. Hail team, this directory is an underestimate of our infrastructure. We are iteratively adding more; infrastructure. Infrastructure may be missing because importing into terraform would require a; destroy/create. ---. Changes from `../gcp`:. Create a bucket in which to store terraform state. Use the same region in which you plan to create; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ``",MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:971,Security,encrypt,encryption,971," third-party trying to deploy Hail, look at `../gcp`. Hail team, this directory is an underestimate of our infrastructure. We are iteratively adding more; infrastructure. Infrastructure may be missing because importing into terraform would require a; destroy/create. ---. Changes from `../gcp`:. Create a bucket in which to store terraform state. Use the same region in which you plan to create; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ```. Create ",MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:1322,Security,authoriz,authorize,1322,reate; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ```. Create `backend.hcl`:. ```; cat >infra/gcp-broad/$GITHUB_ORGANIZATION/backend.hcl <<EOF; bucket = $TERRAFORM_STATE_BUCKET; kms_encryption_key = $TERRAFORM_KEY_NAME; EOF; ```. Initialize Terraform:. ```; terraform init -backend-config=hail-is/backend.hcl -var-file=hail-is/global.tfvars; ```. Then inspect the Terraform plan:. ```; terraform plan -var-file=hail-is/global.tfvars -out=tfplan; ```; ,MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:1429,Security,authoriz,authorize-cmek,1429,reate; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ```. Create `backend.hcl`:. ```; cat >infra/gcp-broad/$GITHUB_ORGANIZATION/backend.hcl <<EOF; bucket = $TERRAFORM_STATE_BUCKET; kms_encryption_key = $TERRAFORM_KEY_NAME; EOF; ```. Initialize Terraform:. ```; terraform init -backend-config=hail-is/backend.hcl -var-file=hail-is/global.tfvars; ```. Then inspect the Terraform plan:. ```; terraform plan -var-file=hail-is/global.tfvars -out=tfplan; ```; ,MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md:1537,Security,encrypt,encryption-key,1537,reate; the k8s cluster. ```; PROJECT=YOUR GCP PROJECT HERE; LOCATION=us-central1; TERRAFORM_STATE_BUCKET=gs://terraform-state-$(cat /dev/urandom | LC_ALL=C tr -dc 'a-z0-9' | head -c 5); gsutil mb -l us-central1 $TERRAFORM_STATE_BUCKET; gsutil -m uniformbucketlevelaccess set on $TERRAFORM_STATE_BUCKET; ```. Create a key to encrypt terraform state. ```; gcloud kms keyrings create terraform-state-us-central1 \; --location $LOCATION; gcloud kms keys create terraform-state-us-central1-key \; --location $LOCATION \; 	 --keyring terraform-state-us-central1 \; 	 --purpose encryption; gcloud projects add-iam-policy-binding \; <project-id> \; --member='user:YOUR_EMAIL' \; 	 --role='roles/owner'; gcloud kms keys list \; --location $LOCATION \; 	 --keyring terraform-state-us-central1; ```; Store the Terraform key name in a variable for future use:; ```; TERRAFORM_KEY_NAME=...; ```; Finish the KMS setup:; ```; gsutil kms authorize -p $PROJECT \; -k $TERRAFORM_KEY_NAME; gcloud storage service-agent \; --project=$PROJECT \; 	 --authorize-cmek=$TERRAFORM_KEY_NAME; gcloud storage buckets update \; $TERRAFORM_STATE_BUCKET \; 	 --default-encryption-key=$TERRAFORM_KEY_NAME; ```. I found that I had to explicitly grant read permissions to my account even though it was an Owner:. ```; YOUR_USER_EMAIL=...; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectViewer \; $TERRAFORM_STATE_BUCKET; gcloud storage buckets add-iam-policy-binding \; --member user:$YOUR_USER_EMAIL \; 	 --role roles/storage.objectCreator \; $TERRAFORM_STATE_BUCKET; ```. Create `backend.hcl`:. ```; cat >infra/gcp-broad/$GITHUB_ORGANIZATION/backend.hcl <<EOF; bucket = $TERRAFORM_STATE_BUCKET; kms_encryption_key = $TERRAFORM_KEY_NAME; EOF; ```. Initialize Terraform:. ```; terraform init -backend-config=hail-is/backend.hcl -var-file=hail-is/global.tfvars; ```. Then inspect the Terraform plan:. ```; terraform plan -var-file=hail-is/global.tfvars -out=tfplan; ```; ,MatchSource.DOCS,infra/gcp-broad/README.md,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/infra/gcp-broad/README.md
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1813,Availability,error,errored,1813,"e the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2917,Availability,down,down,2917,"g up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1051,Deployability,pipeline,pipeline,1051,"===; CollectDistributedArray Call-Caching; ====================================. Introduction; ==========; See `Fast Restarts for Failed Queries <https://github.com/hail-is/hail-rfcs/pull/1>`_. Proposed Change Specification; =============================. Experience tells us that the majority of time spent on expensive and; scientifically interesting queries is within the tasks generated by; :code:`CollectDistributedArray` (:code:`CDA`).; This is because many of the table operations in hail's :code:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1532,Deployability,update,updates,1532,"e:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be comput",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2935,Deployability,pipeline,pipeline,2935,"g up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:8603,Deployability,update,update,8603," that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb))",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:8851,Deployability,update,updates,8851,"hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semha",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:738,Energy Efficiency,reduce,reduce,738,"====================================; CollectDistributedArray Call-Caching; ====================================. Introduction; ==========; See `Fast Restarts for Failed Queries <https://github.com/hail-is/hail-rfcs/pull/1>`_. Proposed Change Specification; =============================. Experience tells us that the majority of time spent on expensive and; scientifically interesting queries is within the tasks generated by; :code:`CollectDistributedArray` (:code:`CDA`).; This is because many of the table operations in hail's :code:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5667,Energy Efficiency,reduce,reduces,5667," computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(read",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7553,Integrability,depend,depend,7553,"se TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update t",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:10040,Integrability,interface,interface,10040,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3950,Modifiability,variab,variables,3950,"; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ==========================. The reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :cod",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5941,Modifiability,extend,extended,5941,"ith different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir)",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7215,Modifiability,extend,extend,7215,"we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7444,Modifiability,extend,extend,7444,"y.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-val",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9088,Modifiability,extend,extend,9088,"ry driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. co",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9610,Modifiability,extend,extend,9610,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1134,Performance,perform,performs,1134,"//github.com/hail-is/hail-rfcs/pull/1>`_. Proposed Change Specification; =============================. Experience tells us that the majority of time spent on expensive and; scientifically interesting queries is within the tasks generated by; :code:`CollectDistributedArray` (:code:`CDA`).; This is because many of the table operations in hail's :code:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an ide",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1192,Performance,cache,cache,1192,"//github.com/hail-is/hail-rfcs/pull/1>`_. Proposed Change Specification; =============================. Experience tells us that the majority of time spent on expensive and; scientifically interesting queries is within the tasks generated by; :code:`CollectDistributedArray` (:code:`CDA`).; This is because many of the table operations in hail's :code:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an ide",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1229,Performance,perform,performed,1229,"//github.com/hail-is/hail-rfcs/pull/1>`_. Proposed Change Specification; =============================. Experience tells us that the majority of time spent on expensive and; scientifically interesting queries is within the tasks generated by; :code:`CollectDistributedArray` (:code:`CDA`).; This is because many of the table operations in hail's :code:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an ide",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1277,Performance,cache,cache,1277,"hat the majority of time spent on expensive and; scientifically interesting queries is within the tasks generated by; :code:`CollectDistributedArray` (:code:`CDA`).; This is because many of the table operations in hail's :code:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, com",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1426,Performance,cache,cache,1426,"ted by; :code:`CollectDistributedArray` (:code:`CDA`).; This is because many of the table operations in hail's :code:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic*",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1554,Performance,cache,cache,1554,"e:`IR` are lowered; into one or more :code:`CDA` operations.; Consequently, we focus our attention on caching the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be comput",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1649,Performance,cache,cached,1649,"ng the intermediate results of; these tasks. :code:`CDA` can be thought of as a distributed map-reduce operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :c",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:1723,Performance,cache,cache,1723,"educe operation, from some; input ""context"" for each partition in a table (eg, the path to the file; where the partition is serialised), a computation on that partition, and some; combiner for the results of those computations.; For what follows, let an *activation* be a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious a",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2022,Performance,cache,cache,2022,"a particular invocation of a; :code:`CDA` pipeline (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an acti",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2067,Performance,cache,cache,2067,"e (implemented via :code:`collectDArray`). At a high-level, when the driver performs an *activation*, it will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynam",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2145,Performance,cache,cache,2145," will look in its; *execution cache* to see if it had successfully performed that *activation*; in the past.; The *cache* contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will """,MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2991,Performance,perform,performing,2991,"g up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3191,Performance,cache,cache,3191,"uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts`",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3213,Performance,cache,cached,3213,"uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts`",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3256,Performance,cache,cache,3256,"ic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a s",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3334,Performance,cache,cache,3334,"computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3355,Performance,cache,cachedir,3355,"computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3855,Performance,cache,cachedir,3855,"f that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ==========================. The reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3880,Performance,cache,cache,3880,"f that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ==========================. The reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:4101,Performance,cache,cache,4101,"ivation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ==========================. The reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's tra",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:4153,Performance,cache,cachedir,4153,"ring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ==========================. The reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def le",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:4259,Performance,cache,cache,4259,"e dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ==========================. The reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and comp",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9532,Performance,load,loadString,9532,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9990,Performance,cache,cache,9990,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:10295,Performance,cache,cache,10295,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:10407,Performance,cache,cache,10407,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2282,Security,hash,hash,2282," contains the results for all the successful partition computations.; The driver compares the tasks for each partition with the results in the cache; and removes those tasks that have already been completed.; It then executes any remaining work and updates the execution cache with their; results.; If all the work completes successfully, the driver returns the now-cached; results to be used in the the rest of the query.; The driver will cache the results of successful *activations* only.; Failed *activations* (ie. those that errored) will be handled in the usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:2847,Security,checksum,checksum,2847,"e usual way,; potentially failing the query. We require two things to determine if the driver had successfully executed an; operation:. 1. a way of looking up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:3111,Security,hash,hash,3111,"g up *activations* in a *cache*, and; 2. then design of the execution cache itself. Semantic Hashing; ----------------; To lookup operations in the cache, we need a way of producing an identifier; that uniquely represents a particular *activation*.; We do this by defining a *semantic hash* for the activation, comprised of:. a) a *static* component computed from the :code:`IR` that generated the; operation; b) a *dynamic* component for the particular activation instance. For most :code:`IR` nodes, the *static* component can be computed purely from; their inputs plus some contribution uniquely representing the semantics of that; class of :code:`IR`.; For :code:`IR` nodes that read external files, we have to be a little more; cautious and ensure that those files haven't changed since we last read them.; Thus, we need to include some kind of checksum or digest of that file.; This static component can be passed down the lowering pipeline to the code; generator and driver, which, when performing an activation, can mix the static; component with a dynamically generated activation id to form the semantic hash. Execution Cache; ---------------. Users will ""bring their own""\ :sup:`TM` cache directory where cached; computations will be stored.; This cache dir will be an prefix in local or cloud storage.; The driver will store cache files named ``{cachedir}/{semhash}``, where. - `cachdir` is a user-defined location, defaulting to; `{tmp}/hail/{hail-pip-version}`; - `tmp` is either the local tempdir for spark and local backends, or the; remote tempdir for `QoB`. These files will contain accumulated activation results, indexed by their; partition number. Examples; ========. To opt in or out of fast-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:4680,Security,hash,hash,4680,"t-restarts, users will set hail flags in their python; client:. .. code-block:: python. >> hl._set_flags(use_fast_restarts='1'); >> hl._set_flags(cachedir='gs://my-bucket/cache/0'). Alternatively, users can set the corresponding environment variables at the; command line prior to starting their python session:. .. code-block:: sh. >> HAIL_USE_FAST_RESTARTS=1 HAIL_CACHE_DIR='gs://my-bucket/cache/0' ipython. Notes:. - The definition of the ``cachedir`` does not imply; ``use_fast_restarts``.; - If ``use_fast_restarts`` is defined, hail will write cache entries to; a subfolder of the ``tmpdir`` by default. Implementation Description; ==========================. The reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operat",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5387,Security,hash,hashes,5387,"e reader should note that implementation examples below are for illustrative; purposes only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block::",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5408,Security,hash,hash,5408,"poses only and that the real implementation may differ slightly. Semantic Hashes; ---------------. Computing Static Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; va",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5548,Security,hash,hash,5548,"^^^^^^^^^^^^^^^^^^^^^^^. See :code:`SemanticHash.scala`. The static component of a semantic hash for the :code:`IR` is computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5743,Security,hash,hashes,5743," computed in a; level-order traversal of the nodes in the :code:`IR`.; The particular ordering itself doesn't matter, only that an ordering is defined.; We also need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(read",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5819,Security,hash,hash,5819,"lso need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5917,Security,hash,hash,5917,"lso need to keep track of :code:`IR` shape when traversing;; it's possible to define two :code:`IR` trees with different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5929,Security,hash,hash,5929,"ith different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir)",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:5991,Security,hash,hash,5991,"ith different shape but look; identical when flattened to a list.; We'll include an encoding of the node's trace (the path from the root node) to; account for this. .. code-block:: scala. def levelOrder(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir)",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7141,Security,hash,hashing,7141,"we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7189,Security,hash,hashes,7189,"we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7226,Security,hash,hash,7226,"we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7296,Security,hash,hash,7296," for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7427,Security,hash,hash,7427,"scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7451,Security,hash,hash,7451,"y.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-val",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7499,Security,hash,hash,7499,"y.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-val",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7640,Security,hash,hash,7640,"se TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update t",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7729,Security,hash,hash,7729,"ach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7782,Security,hash,hashCode,7782,"ag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` val",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7867,Security,hash,hashed,7867,"ffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final c",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7942,Security,hash,hash,7942,"ffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final c",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:8560,Security,hash,hash,8560," that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb))",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9309,Security,hash,hash,9309,"onent in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; versi",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9347,Security,hash,hash,9347,"onent in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; versi",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9857,Security,hash,hash,9857,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:10449,Security,hash,hash,10449,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:6089,Usability,simpl,simple,6089,"(node: BaseIR): Iterator[(BaseIR, Trace)]. Since the ``IR`` contains references and compiler-generated names, we need to; normalise the names in the :code:`IR` (see :scala:`NormalizeNames.scala`); to get consistent hashes. The semantic hash is defined for the whole :code:`IR` (as apposed to prefixes; of the :code:`IR` tree, see Alternatives below).; Thus, we'll compute the hash as early as possible to minimise the computational; cost as the :scala:`IR` gets lowered and expanded.; This also reduces the number of :code:`BaseIR` operations we need to define; semantic hashes for (ie. only those that can be constructed in python). Generally, a hash function takes a seed and some data (typically a stream of; numbers or bytes) and produces a hash.; That hash can be extended with more data by feeding it back to the hash function; as the seed.; What's needed is a way to encode the :code:`IR` as a byte stream.; A simple :code:`toString` is not sufficient as some nodes read data from; external blob-storage;; we need to ensure that the data hasn't changed since we last ran the query.; Furthermore, we can't define an encoding for some :code:`IR` nodes, so we need; a way to bail out:. .. code-block:: scala. def encode(fs: FS, ir: BaseIR, trace: Trace): Option[Array[Byte]] = {; val buffer =; Array.newBuilder[Byte] ++= encodeTrace(trace). ir match {; case Ref(name, _) =>; buffer ++=; encodeClass(classOf[Ref]) ++=; name.getBytes. case TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a wa",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:7648,Usability,simpl,simply,7648,"se TableRead(_, _, reader) =>; buffer ++=; encodeClass(classOf[TableRead]) ++=; encodeClass(reader.getClass). reader.pathsUsed.foreach { p =>; // encode the contents of the file (md5 digest, etag, other); // to ensure it hasn't been modified since last time the query; // was ran (if ever).; buffer ++= encodeFile(fs, p); }. case ir if DependsOnlyOnInputs(ir) =>; buffer ++= encodeClass(ir.getClass). case _ if DontKnowHowToDefineSemhash(ir) =>; return None. case ... =>; }. Some(buffer); }. Then, assuming we have an appropriate hashing algorithm, seed and a way of; combining hashes, we can create and extend the hash with the contribution of; each node:. .. code-block:: scala. var hash = Algorithm.SEED; for ((node, trace) <- levelOrder(nameNormalizedIr)) {; encode(fs, node, trace) match {; case Some(bytes) => hash = Algorithm.extend(hash, bytes); case _ => return None; }; }; Some(hash). Observations:. - For all :code:`IR` nodes that depend only on their children and have no; additional parameterisation, their semantic hash is simply some unique; encoding for what that node means. - Implemented this as the hash code of the :scala:`IR`'s class; - :code:`Class.hashCode` is repeatable across JVM sessions. - Note that the node's children will be hashed in the traversal; - There are times when we can't define a semantic hash (such as reading a; table from a RVD). In these cases, we'll just return :scala:`None`. Computing Dynamic Component; ^^^^^^^^^^^^^^^^^^^^^^^^^^^. The query driver is a single-threaded system that compiles and executes the; same queries in a repeatable way.; That is, if a query generates one or more :code:`CDA` nodes, those nodes will be; emitted in the same order.; This, we can use the static component in the same way as random number; generator state:. - When a :scala:`CDA` node is emitted, we can fork the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update t",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst:9953,Usability,simpl,simply,9953,"the semhash key-value; - We ""mix"" one value with the :code:`CDA`'s dynamic id to generate the semantic; hash for that particular activation; - and update the static component state with the forked value for the next; :code:`CDA` node. To do this, we can add the function :code:`nextHash` to the; :code:`ExecuteContext` that returns a new `Hash` value to be mixed with the; dynamic component and updates internal state:. .. code-block:: scala. final case class IrMetadata(semhash: Option[Int]) {; private[this] var counter: Int = 0. def nextHash: Option[Int] = {; val bytes = intToBytes(counter); counter += 1; semhash.map(Algorithm.extend(_, bytes)); }; }. Then, in :scala:`Emit.scala`:. .. code-block:: scala. case cda: CollectDistributedArray =>; ...; semhash <- newLocal[Integer](""semhash""); emitI(dynamicID).consume(; ifMissing = nextHash.foreach { hash =>; assign(semhash, boxToInteger(hash)); },; ifPresent = { dynamicID =>; nextHash.foreach { staticHash =>; val dynamicHash =; invokeScalaObject(; String.getClass,; ""getBytes"",; Array(classOf[String]),; Array(dynamicID.loadString(cb)); ). val combined =; invokeScalaObject(; Algorithm.getClass,; ""extend"",; Array(classOf[Int], classOf[Array[Byte]]),; Array(staticHash, dynamicHash); ). assign(semhash, boxToInteger(combined)); }; }; ). // call `collectDArray` with semhash. Using :code:`Option` allows us to encode if we can compute a semantic hash; for the given :code:`IR`.; In the case when one cannot be computed, :code:`collectDArray` simply skips; reading and updating a cache. Execution Cache; ---------------. Given an interface for an :code:`ExecutionCache`` of the form:. .. code-block:: code. trait ExecutionCache {; def lookup(h: SemanticHash): Array[(Int, Array[Byte])]; def put(h: SemanticHash, res: Array[(Int, Array[Byte])]): Unit; }. We can implement a file-system cache that uses a file prefix plus the current; version of Hail to generate a ""root"" directory, under which all cache files are; stored by their semantic hash.; ",MatchSource.DOCS,dev-docs/hail-query/fast-restarts.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/hail-query/fast-restarts.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:5855,Availability,down,downstream,5855," deleted, their corresponding resources are; deleted as well. Batch Front End; ^^^^^^^^^^^^^^^. The Batch Front End is a Kubernetes service responsible for handling; user requests such as creating batches, updating batches, and viewing; job logs. How the Batch Front End Python service works is described in; more detail later in this document. When users submit requests to; authenticated endpoints (everything except for /healthcheck), the; Batch service sends a request to the Auth service to see if the token; submitted in the request is valid and in exchange get information; about the user. The Batch Front End can also send requests to the; Batch Driver notifying the driver that a batch has been created or; needs to be cancelled (""push notification""). The application is stateless; and 3 copies are running simultaneously. The Front End; extensively updates and queries the MySQL database to obtain the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. W",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:6262,Availability,avail,available,6262,"k), the; Batch service sends a request to the Auth service to see if the token; submitted in the request is valid and in exchange get information; about the user. The Batch Front End can also send requests to the; Batch Driver notifying the driver that a batch has been created or; needs to be cancelled (""push notification""). The application is stateless; and 3 copies are running simultaneously. The Front End; extensively updates and queries the MySQL database to obtain the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not with the Kubernetes pods. They are created with a default service; account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured bo",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:7371,Availability,down,download,7371,"h worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not with the Kubernetes pods. They are created with a default service; account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured boot disk; image that has Docker preinstalled. Startup scripts then initialize; the worker VM, download the worker server application image from a; container registry, and then create the worker Docker container. Once; the worker container is running, it notifies the Batch Driver that it; is active and starts executing jobs. MySQL Database; --------------. All Batch and Auth state is stored in a cloud-provider managed MySQL; database. We use SSL certificates to secure communication between; Kubernetes services and the database. Worker VMs cannot talk directly; to the database. Cloud Storage; -------------. Users store the data they want to compute on in Cloud Storage (Google; Cloud Storage or Azure Blob Storage). All Batch created files such as; user job specs, job log files, job status files, and job resource; usage monitoring files are stored in cloud storage. Container Registry; ------------------. Container images used to execute user jobs as well as the images used; in our Kubernetes services are stored in a cloud provider managed; Container Registry (Google Artifact Registry and Azure Container; Registry).",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:8847,Availability,avail,available,8847,"rs store the data they want to compute on in Cloud Storage (Google; Cloud Storage or Azure Blob Storage). All Batch created files such as; user job specs, job log files, job status files, and job resource; usage monitoring files are stored in cloud storage. Container Registry; ------------------. Container images used to execute user jobs as well as the images used; in our Kubernetes services are stored in a cloud provider managed; Container Registry (Google Artifact Registry and Azure Container; Registry). Terraform; ---------. TBD. Bootstrapping; -------------. TBD. Application Details; ===================. Batch Lifecycle; ---------------. 1. A user submits a request to the Batch front end service to create a; batch along with job specifications.; 2. The Batch front end service records the batch and job information; into a MySQL database and writes the job specifications to cloud; storage.; 3. The Batch driver notices that there is work available either; through a push request from the Batch front end or by polling the; state in the MySQL database and spins up worker VMs.; 4. The worker VMs startup and notify the Batch driver they are active; and have resources to run jobs.; 5. The Batch driver schedules jobs to run on the active workers.; 6. The worker VM downloads the job specification from cloud storage,; downloads any input files the job needs from cloud storage, creates; a container for the job to execute in, executes the code inside the; container, uploads any logs and output files that have been; generated, and then notifies the Batch driver that the job has; completed.; 7. Once all jobs have completed, the batch is set to complete in the; database. Any callbacks that have been specified on batch; completion are called.; 8. Meanwhile, the user can find the status of their batch through the; UI or using a Python client library to get the batch status, cancel; the batch, list the jobs in the batch and their statuses, and wait; for the batch or an individual ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:9173,Availability,down,downloads,9173," Container Registry (Google Artifact Registry and Azure Container; Registry). Terraform; ---------. TBD. Bootstrapping; -------------. TBD. Application Details; ===================. Batch Lifecycle; ---------------. 1. A user submits a request to the Batch front end service to create a; batch along with job specifications.; 2. The Batch front end service records the batch and job information; into a MySQL database and writes the job specifications to cloud; storage.; 3. The Batch driver notices that there is work available either; through a push request from the Batch front end or by polling the; state in the MySQL database and spins up worker VMs.; 4. The worker VMs startup and notify the Batch driver they are active; and have resources to run jobs.; 5. The Batch driver schedules jobs to run on the active workers.; 6. The worker VM downloads the job specification from cloud storage,; downloads any input files the job needs from cloud storage, creates; a container for the job to execute in, executes the code inside the; container, uploads any logs and output files that have been; generated, and then notifies the Batch driver that the job has; completed.; 7. Once all jobs have completed, the batch is set to complete in the; database. Any callbacks that have been specified on batch; completion are called.; 8. Meanwhile, the user can find the status of their batch through the; UI or using a Python client library to get the batch status, cancel; the batch, list the jobs in the batch and their statuses, and wait; for the batch or an individual job to complete. The implementation; of the wait operation is by continuously polling the Batch Front; End until the batch state is ""complete"". Data Model; ----------. The core concepts in the Batch data model are billing projects,; batches, jobs, updates, attempts, and resources. A **billing project** is a mechanism for cost accounting, cost control, and; enabling the ability to share information about batches and jobs; across user",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:9226,Availability,down,downloads,9226," Container Registry (Google Artifact Registry and Azure Container; Registry). Terraform; ---------. TBD. Bootstrapping; -------------. TBD. Application Details; ===================. Batch Lifecycle; ---------------. 1. A user submits a request to the Batch front end service to create a; batch along with job specifications.; 2. The Batch front end service records the batch and job information; into a MySQL database and writes the job specifications to cloud; storage.; 3. The Batch driver notices that there is work available either; through a push request from the Batch front end or by polling the; state in the MySQL database and spins up worker VMs.; 4. The worker VMs startup and notify the Batch driver they are active; and have resources to run jobs.; 5. The Batch driver schedules jobs to run on the active workers.; 6. The worker VM downloads the job specification from cloud storage,; downloads any input files the job needs from cloud storage, creates; a container for the job to execute in, executes the code inside the; container, uploads any logs and output files that have been; generated, and then notifies the Batch driver that the job has; completed.; 7. Once all jobs have completed, the batch is set to complete in the; database. Any callbacks that have been specified on batch; completion are called.; 8. Meanwhile, the user can find the status of their batch through the; UI or using a Python client library to get the batch status, cancel; the batch, list the jobs in the batch and their statuses, and wait; for the batch or an individual job to complete. The implementation; of the wait operation is by continuously polling the Batch Front; End until the batch state is ""complete"". Data Model; ----------. The core concepts in the Batch data model are billing projects,; batches, jobs, updates, attempts, and resources. A **billing project** is a mechanism for cost accounting, cost control, and; enabling the ability to share information about batches and jobs; across user",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:13574,Availability,error,error,13574,"ource. Resource rates are in units; that are dependent on the type of resource. For example, VM rates are; denominated in USD per core-hour. Each attempt has a set of resources; associated with it along with their usage in a resource-dependent set; of units. For example, a 1 core job has a usage value of 1000 (this; value is in mCPU). To compute the aggregate cost of a job, we sum up; all of the usages multiplied by the rates and then multiplied by the; duration the attempt has been running. State Diagram; -------------. A job can be in one of the following states:. - Pending: 1+ parent jobs have not completed yet; - Ready: No pending parent jobs.; - Creating: Creating a VM for job private jobs.; - Running: Job is running on a worker VM.; - Success: Job completed successfully.; - Failed: Job failed.; - Cancelled: Job was cancelled either by the system, by the user, or; because at least one of its parents failed.; - Error: Job failed due to an error in creating the container, an out; of memory error, or a Batch bug (ex: user tries to use a nonexistent; image). The allowed state transitions are: Pending -> Ready Ready ->; {Creating, Running, Cancelled} Creating -> {Running, Cancelled}; Running -> {Success, Failed, Error, Cancelled}. A job's initial state depends on the states of its parent jobs. If it; has no parent jobs, its initial state is Ready. A batch can be in one of the following states:. - completed: All jobs are in a completed state {Success, Failed,; Error, Cancelled}; - running: At least one job is in a non-completed state {Pending,; Ready, Running}. The batch and job states are critical for database performance and; must be indexed appropriately. Batch Front End; ---------------. The Batch Front End service (batch) is a stateless web service that; handles requests from the user. The front end exposes a REST API; interface for handling user requests such as creating a batch,; updating a batch, creating jobs in a batch, getting the status of a; batch, getti",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:13625,Availability,error,error,13625,"ource. Resource rates are in units; that are dependent on the type of resource. For example, VM rates are; denominated in USD per core-hour. Each attempt has a set of resources; associated with it along with their usage in a resource-dependent set; of units. For example, a 1 core job has a usage value of 1000 (this; value is in mCPU). To compute the aggregate cost of a job, we sum up; all of the usages multiplied by the rates and then multiplied by the; duration the attempt has been running. State Diagram; -------------. A job can be in one of the following states:. - Pending: 1+ parent jobs have not completed yet; - Ready: No pending parent jobs.; - Creating: Creating a VM for job private jobs.; - Running: Job is running on a worker VM.; - Success: Job completed successfully.; - Failed: Job failed.; - Cancelled: Job was cancelled either by the system, by the user, or; because at least one of its parents failed.; - Error: Job failed due to an error in creating the container, an out; of memory error, or a Batch bug (ex: user tries to use a nonexistent; image). The allowed state transitions are: Pending -> Ready Ready ->; {Creating, Running, Cancelled} Creating -> {Running, Cancelled}; Running -> {Success, Failed, Error, Cancelled}. A job's initial state depends on the states of its parent jobs. If it; has no parent jobs, its initial state is Ready. A batch can be in one of the following states:. - completed: All jobs are in a completed state {Success, Failed,; Error, Cancelled}; - running: At least one job is in a non-completed state {Pending,; Ready, Running}. The batch and job states are critical for database performance and; must be indexed appropriately. Batch Front End; ---------------. The Batch Front End service (batch) is a stateless web service that; handles requests from the user. The front end exposes a REST API; interface for handling user requests such as creating a batch,; updating a batch, creating jobs in a batch, getting the status of a; batch, getti",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:17753,Availability,failure,failures,17753,"en; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer than 1,024 jobs and the; specifications fit in fewer than 1KiB. at; ``/api/v1alpha/batches/{batch_id}/create-fast`` and; ``/api/v1alpha/batches/{batch_id}/update-fast``. Listing Batches and Jobs; ^^^^^^^^^^^^^^^^^^^^^^^^. To find all matching batches and jobs either via the UI or the Python; client library, a user provides a query filtering string as well as an; optional starting ID. The server then sends the next 50 records in; response and it is up to the client to send the next request with the; ID of the last record returned in the subsequent request. Batch Driver; ------------. The Batch Driver is a Kubernetes service that creates a fleet of; worker VMs in response to user workloads and has mechanisms in place; for sharing resources fairly across users. It also has many background; processes to make sure orphaned resources such as disks and VMs are; cleaned up, billing prices for resources are up to date, and; cancelling batches with more than N failures if specified by the; user. The service can be located on a preemptible machine, but we use; a non-preemptible machine to minimize downtime, especially when the; cluster is large. There can only be one driver service in existence at; any one time. There is an Envoy side car container in the batch driver; pod to handle TLS handshakes to avoid excess CPU usage of the batch; driver. Instance Collections; ^^^^^^^^^^^^^^^^^^^^. The batch driver maintains two different types of collections of; workers. There are **pools** that are multi-tenant and have a; dedicated worker type that is shared across all jobs. Pools can; support both preemptible and nonpreemptible VMs. Right now, there are; three types of machine types we support that correspond to low memory; (~1GB memory / core), standard (~4GB memory / core), and high memory; (~8GB memory / core) machines. These are correspondingly the; ""highcpu"", ""stan",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:17892,Availability,downtime,downtime,17892,"1alpha/batches/{batch_id}/create-fast`` and; ``/api/v1alpha/batches/{batch_id}/update-fast``. Listing Batches and Jobs; ^^^^^^^^^^^^^^^^^^^^^^^^. To find all matching batches and jobs either via the UI or the Python; client library, a user provides a query filtering string as well as an; optional starting ID. The server then sends the next 50 records in; response and it is up to the client to send the next request with the; ID of the last record returned in the subsequent request. Batch Driver; ------------. The Batch Driver is a Kubernetes service that creates a fleet of; worker VMs in response to user workloads and has mechanisms in place; for sharing resources fairly across users. It also has many background; processes to make sure orphaned resources such as disks and VMs are; cleaned up, billing prices for resources are up to date, and; cancelling batches with more than N failures if specified by the; user. The service can be located on a preemptible machine, but we use; a non-preemptible machine to minimize downtime, especially when the; cluster is large. There can only be one driver service in existence at; any one time. There is an Envoy side car container in the batch driver; pod to handle TLS handshakes to avoid excess CPU usage of the batch; driver. Instance Collections; ^^^^^^^^^^^^^^^^^^^^. The batch driver maintains two different types of collections of; workers. There are **pools** that are multi-tenant and have a; dedicated worker type that is shared across all jobs. Pools can; support both preemptible and nonpreemptible VMs. Right now, there are; three types of machine types we support that correspond to low memory; (~1GB memory / core), standard (~4GB memory / core), and high memory; (~8GB memory / core) machines. These are correspondingly the; ""highcpu"", ""standard"", and ""highmem"" pools. Each pool has its own; scheduler and autoscaler. In addition, there's a single job private; instance manager that creates a worker VM per job and is used if the; wo",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:34642,Availability,down,downloads,34642,"lable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Docker Jobs are regular jobs that use a user-defined; image and the user-defined source code. JVM jobs are specially; designed for the Query on Batch (QoB) use case. The worker downloads; an approved JAR file to execute a user's query that is stored in cloud; storage. All containers the worker creates are by using `crun` and not; Docker. When the worker has not received any work to do and no jobs; are currently running, it will deactivate itself and shut itself down. Known Issues; ------------. - The current database structure serializes MJC operations because the; table ``batches_n_jobs_in_complete_states`` has one row per batch; and each MJC operation tries to update the same row in this; table.; - ``commit_update`` is slow for large updates because we have to; compute the job states by scanning the states of all of a job's; parents.; - If a large batch has multiple distinct regions specified that are not; interweaved, the autoscaler and scheduler can deadlock.; ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:34931,Availability,down,down,34931,"lable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Docker Jobs are regular jobs that use a user-defined; image and the user-defined source code. JVM jobs are specially; designed for the Query on Batch (QoB) use case. The worker downloads; an approved JAR file to execute a user's query that is stored in cloud; storage. All containers the worker creates are by using `crun` and not; Docker. When the worker has not received any work to do and no jobs; are currently running, it will deactivate itself and shut itself down. Known Issues; ------------. - The current database structure serializes MJC operations because the; table ``batches_n_jobs_in_complete_states`` has one row per batch; and each MJC operation tries to update the same row in this; table.; - ``commit_update`` is slow for large updates because we have to; compute the job states by scanning the states of all of a job's; parents.; - If a large batch has multiple distinct regions specified that are not; interweaved, the autoscaler and scheduler can deadlock.; ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:184,Deployability,deploy,deployments,184,"============; Batch Design; ============. .. sectnum::; .. contents::. ********; Overview; ********. Hail Batch is a multi-tenant batch job processing system. The Hail; team maintains deployments in GCP and Azure. There are also a few; deployments outside of the control of the Hail team as well as alpha; support in Terra. Hail Batch has two main use cases: (1) a batch job; processing system that executes arbitrary bash or Python code in; containerized environments that are generated using a Python client; library that handles file localization and job dependencies in a; user-friendly manner (hailtop.batch) and (2) as the backend for; running Hail Query on Batch (QoB) inside containers running Hail team; approved JVM byte code. Typical users of hailtop.batch are looking to execute code for a; stand-alone scientific tool that can be run massively in parallel such; as across samples in a dataset and regions in a genome. Their; workloads usually consist of a single scatter layer with no; dependencies between jobs with sizes on the order of 100s to 100Ks of; jobs. The largest batch that has been processed by the Hail Batch; system is ~16 million jobs. Likewise, QoB consists of a single,; nonpreemptible driver job and subsequent sets of updates of jobs to; the directed acyclic graph (DAG) for subsequent stages of worker; jobs. There is a single job per partition within a stage. The number; of jobs within a stage can be on the order of 100K jobs. ****************************; How the Current System Works; ****************************. The Batch system is a set of services and infrastructure components; that work in concert to allow users to submit requests describing; workloads or sets of jobs to run and then executes the jobs on a set; of worker VMs. There is both a UI and a REST API for interacting with; Batch. The infrastructure required for a working Hail Batch system; consists of a Kubernetes cluster, a container registry, blob storage,; a MySQL database, and virtual m",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:236,Deployability,deploy,deployments,236,"============; Batch Design; ============. .. sectnum::; .. contents::. ********; Overview; ********. Hail Batch is a multi-tenant batch job processing system. The Hail; team maintains deployments in GCP and Azure. There are also a few; deployments outside of the control of the Hail team as well as alpha; support in Terra. Hail Batch has two main use cases: (1) a batch job; processing system that executes arbitrary bash or Python code in; containerized environments that are generated using a Python client; library that handles file localization and job dependencies in a; user-friendly manner (hailtop.batch) and (2) as the backend for; running Hail Query on Batch (QoB) inside containers running Hail team; approved JVM byte code. Typical users of hailtop.batch are looking to execute code for a; stand-alone scientific tool that can be run massively in parallel such; as across samples in a dataset and regions in a genome. Their; workloads usually consist of a single scatter layer with no; dependencies between jobs with sizes on the order of 100s to 100Ks of; jobs. The largest batch that has been processed by the Hail Batch; system is ~16 million jobs. Likewise, QoB consists of a single,; nonpreemptible driver job and subsequent sets of updates of jobs to; the directed acyclic graph (DAG) for subsequent stages of worker; jobs. There is a single job per partition within a stage. The number; of jobs within a stage can be on the order of 100K jobs. ****************************; How the Current System Works; ****************************. The Batch system is a set of services and infrastructure components; that work in concert to allow users to submit requests describing; workloads or sets of jobs to run and then executes the jobs on a set; of worker VMs. There is both a UI and a REST API for interacting with; Batch. The infrastructure required for a working Hail Batch system; consists of a Kubernetes cluster, a container registry, blob storage,; a MySQL database, and virtual m",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:1251,Deployability,update,updates,1251,"de of the control of the Hail team as well as alpha; support in Terra. Hail Batch has two main use cases: (1) a batch job; processing system that executes arbitrary bash or Python code in; containerized environments that are generated using a Python client; library that handles file localization and job dependencies in a; user-friendly manner (hailtop.batch) and (2) as the backend for; running Hail Query on Batch (QoB) inside containers running Hail team; approved JVM byte code. Typical users of hailtop.batch are looking to execute code for a; stand-alone scientific tool that can be run massively in parallel such; as across samples in a dataset and regions in a genome. Their; workloads usually consist of a single scatter layer with no; dependencies between jobs with sizes on the order of 100s to 100Ks of; jobs. The largest batch that has been processed by the Hail Batch; system is ~16 million jobs. Likewise, QoB consists of a single,; nonpreemptible driver job and subsequent sets of updates of jobs to; the directed acyclic graph (DAG) for subsequent stages of worker; jobs. There is a single job per partition within a stage. The number; of jobs within a stage can be on the order of 100K jobs. ****************************; How the Current System Works; ****************************. The Batch system is a set of services and infrastructure components; that work in concert to allow users to submit requests describing; workloads or sets of jobs to run and then executes the jobs on a set; of worker VMs. There is both a UI and a REST API for interacting with; Batch. The infrastructure required for a working Hail Batch system; consists of a Kubernetes cluster, a container registry, blob storage,; a MySQL database, and virtual machines (VMs). In this document, we describe; the purpose of each infrastructural component and how they all work in; concert to create a working Batch system. We also expand on how both; of the Batch Python web servers are implemented in detail such a",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:3995,Deployability,deploy,deployment,3995,"d cloud-provider-managed; external load balancer. It is associated with a statically; known external IP Address. This is the entry point in which external; users send requests to the Batch system such as submitting batches and; getting information on their jobs. There is a an Envoy server behind; the load balancer that forwards requests to the appropriate service. Internal Gateway; ^^^^^^^^^^^^^^^^. Internal Gateway is a Kubernetes service and associated cloud-provider-managed; internal load balancer. Unlike the Gateway, the Internal; Gateway is associated with a statically known **internal** IP address; that is only accessible from virtual machines within our private; network. This endpoint is how Batch worker VMs are able to talk to the; Batch Driver Kubernetes Service directly without going through the public; internet. Auth / Auth-Driver; ^^^^^^^^^^^^^^^^^^. The Auth Kubernetes service is responsible for creating new users,; logging in existing users, authenticating requests from logged in; users, verifying developer status for accessing protected services; like a batch deployment in a developer namespace. We will soon be; changing how authentication / authorization is implemented. Currently,; for REST API requests, a user provides an authorization bearer header; with a Hail-issued token. This token is generated when users login and; has a default expiration date for 30 days. UI web requests have an; associated cookie that includes the token. The Auth Driver service is; responsible for creating new user resources such as service accounts,; secondary Kubernetes namespaces for developers, Kubernetes secrets; that store the user's active Hail authorization token and their Google; service account or Azure service principal certificates, which allows; users to access their resources required to execute jobs such as; Docker images and data stored in Google Cloud Storage or Azure Blob; Storage. When a user is deleted, their corresponding resources are; deleted as well. ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:5702,Deployability,update,updates,5702,"obs such as; Docker images and data stored in Google Cloud Storage or Azure Blob; Storage. When a user is deleted, their corresponding resources are; deleted as well. Batch Front End; ^^^^^^^^^^^^^^^. The Batch Front End is a Kubernetes service responsible for handling; user requests such as creating batches, updating batches, and viewing; job logs. How the Batch Front End Python service works is described in; more detail later in this document. When users submit requests to; authenticated endpoints (everything except for /healthcheck), the; Batch service sends a request to the Auth service to see if the token; submitted in the request is valid and in exchange get information; about the user. The Batch Front End can also send requests to the; Batch Driver notifying the driver that a batch has been created or; needs to be cancelled (""push notification""). The application is stateless; and 3 copies are running simultaneously. The Front End; extensively updates and queries the MySQL database to obtain the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; re",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:6312,Deployability,update,update,6312,"k), the; Batch service sends a request to the Auth service to see if the token; submitted in the request is valid and in exchange get information; about the user. The Batch Front End can also send requests to the; Batch Driver notifying the driver that a batch has been created or; needs to be cancelled (""push notification""). The application is stateless; and 3 copies are running simultaneously. The Front End; extensively updates and queries the MySQL database to obtain the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not with the Kubernetes pods. They are created with a default service; account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured bo",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:9958,Deployability,continuous,continuously,9958," worker VMs.; 4. The worker VMs startup and notify the Batch driver they are active; and have resources to run jobs.; 5. The Batch driver schedules jobs to run on the active workers.; 6. The worker VM downloads the job specification from cloud storage,; downloads any input files the job needs from cloud storage, creates; a container for the job to execute in, executes the code inside the; container, uploads any logs and output files that have been; generated, and then notifies the Batch driver that the job has; completed.; 7. Once all jobs have completed, the batch is set to complete in the; database. Any callbacks that have been specified on batch; completion are called.; 8. Meanwhile, the user can find the status of their batch through the; UI or using a Python client library to get the batch status, cancel; the batch, list the jobs in the batch and their statuses, and wait; for the batch or an individual job to complete. The implementation; of the wait operation is by continuously polling the Batch Front; End until the batch state is ""complete"". Data Model; ----------. The core concepts in the Batch data model are billing projects,; batches, jobs, updates, attempts, and resources. A **billing project** is a mechanism for cost accounting, cost control, and; enabling the ability to share information about batches and jobs; across users. Each billing project has a list of authorized users and; a billing limit. Any users in the billing project can view information; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:10141,Deployability,update,updates,10141,"es jobs to run on the active workers.; 6. The worker VM downloads the job specification from cloud storage,; downloads any input files the job needs from cloud storage, creates; a container for the job to execute in, executes the code inside the; container, uploads any logs and output files that have been; generated, and then notifies the Batch driver that the job has; completed.; 7. Once all jobs have completed, the batch is set to complete in the; database. Any callbacks that have been specified on batch; completion are called.; 8. Meanwhile, the user can find the status of their batch through the; UI or using a Python client library to get the batch status, cancel; the batch, list the jobs in the batch and their statuses, and wait; for the batch or an individual job to complete. The implementation; of the wait operation is by continuously polling the Batch Front; End until the batch state is ""complete"". Data Model; ----------. The core concepts in the Batch data model are billing projects,; batches, jobs, updates, attempts, and resources. A **billing project** is a mechanism for cost accounting, cost control, and; enabling the ability to share information about batches and jobs; across users. Each billing project has a list of authorized users and; a billing limit. Any users in the billing project can view information; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:10904,Deployability,update,updates,10904,"al job to complete. The implementation; of the wait operation is by continuously polling the Batch Front; End until the batch state is ""complete"". Data Model; ----------. The core concepts in the Batch data model are billing projects,; batches, jobs, updates, attempts, and resources. A **billing project** is a mechanism for cost accounting, cost control, and; enabling the ability to share information about batches and jobs; across users. Each billing project has a list of authorized users and; a billing limit. Any users in the billing project can view information; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:10920,Deployability,update,update,10920," wait operation is by continuously polling the Batch Front; End until the batch state is ""complete"". Data Model; ----------. The core concepts in the Batch data model are billing projects,; batches, jobs, updates, attempts, and resources. A **billing project** is a mechanism for cost accounting, cost control, and; enabling the ability to share information about batches and jobs; across users. Each billing project has a list of authorized users and; a billing limit. Any users in the billing project can view information; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11120,Deployability,update,updates,11120,"projects,; batches, jobs, updates, attempts, and resources. A **billing project** is a mechanism for cost accounting, cost control, and; enabling the ability to share information about batches and jobs; across users. Each billing project has a list of authorized users and; a billing limit. Any users in the billing project can view information; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The e",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11173,Deployability,update,update,11173,"unting, cost control, and; enabling the ability to share information about batches and jobs; across users. Each billing project has a list of authorized users and; a billing limit. Any users in the billing project can view information; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt a",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11256,Deployability,update,update,11256,"unting, cost control, and; enabling the ability to share information about batches and jobs; across users. Each billing project has a list of authorized users and; a billing limit. Any users in the billing project can view information; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt a",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11341,Deployability,update,update,11341,"formation; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; pre",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11404,Deployability,update,updates,11404,"formation; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; pre",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11515,Deployability,update,update,11515,"formation; about batches created in that billing project. Developers can; add/delete users in a billing project and modify billing limits. Right; now, these operations are manually done after a Batch user submits a; formal request to the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; pre",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11635,Deployability,update,update,11635,"the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; preemptible n1-standard-16 VM in us-central1) combined with a version; tag. Each resource has a rate that is used to compute cost when; multiplied by the usage of the resource. Resource rates are in units; that are dependent on the type o",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:11668,Deployability,update,update,11668,"the Hail team. Note that the Hail billing project is; different than a GCP billing project. A **batch** is a set of **jobs**. Each batch is associated with a; single billing project. A batch also consists of a set of; **updates**. Each update contains a distinct set of jobs. Updates are; distinct submissions of jobs to an existing batch in the system. They; are used as a way to add jobs to a batch. A batch is always created; with 0 updates and 0 total jobs. To add jobs to a batch, an update; must be created with an additional API call and the number of jobs in; the update must be known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; preemptible n1-standard-16 VM in us-central1) combined with a version; tag. Each resource has a rate that is used to compute cost when; multiplied by the usage of the resource. Resource rates are in units; that are dependent on the type o",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:12311,Deployability,configurat,configurations,12311," known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; preemptible n1-standard-16 VM in us-central1) combined with a version; tag. Each resource has a rate that is used to compute cost when; multiplied by the usage of the resource. Resource rates are in units; that are dependent on the type of resource. For example, VM rates are; denominated in USD per core-hour. Each attempt has a set of resources; associated with it along with their usage in a resource-dependent set; of units. For example, a 1 core job has a usage value of 1000 (this; value is in mCPU). To compute the aggregate cost of a job, we sum up; all of the usages multiplied by the rates and then multiplied by the; duration the attempt has been running. State Diagram; -------------. A job can be in one of the following states:. - Pending: 1+ parent jobs have not completed yet; - Ready: No pending parent job",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:15098,Deployability,update,update,15098,"Error, Cancelled}; - running: At least one job is in a non-completed state {Pending,; Ready, Running}. The batch and job states are critical for database performance and; must be indexed appropriately. Batch Front End; ---------------. The Batch Front End service (batch) is a stateless web service that; handles requests from the user. The front end exposes a REST API; interface for handling user requests such as creating a batch,; updating a batch, creating jobs in a batch, getting the status of a; batch, getting the status of a job, listing all the batches in a; billing project, and listing all of the jobs in a batch. There are; usually 3 copies of the batch front end service running at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallelism. This is necessary for batches with more; than a million jobs. Flow for Creating and Updating Batches; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following flow is used to create a new batch or update an existing; batch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a P",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:15496,Deployability,update,update,15496,"ing a batch, creating jobs in a batch, getting the status of a; batch, getting the status of a job, listing all the batches in a; billing project, and listing all of the jobs in a batch. There are; usually 3 copies of the batch front end service running at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallelism. This is necessary for batches with more; than a million jobs. Flow for Creating and Updating Batches; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following flow is used to create a new batch or update an existing; batch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:15634,Deployability,update,update,15634,"f a job, listing all the batches in a; billing project, and listing all of the jobs in a batch. There are; usually 3 copies of the batch front end service running at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallelism. This is necessary for batches with more; than a million jobs. Flow for Creating and Updating Batches; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following flow is used to create a new batch or update an existing; batch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast pat",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:15806,Deployability,update,update,15806,"nning at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallelism. This is necessary for batches with more; than a million jobs. Flow for Creating and Updating Batches; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following flow is used to create a new batch or update an existing; batch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast paths for creating and updating batches when; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer t",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:15870,Deployability,update,updates,15870,"nning at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallelism. This is necessary for batches with more; than a million jobs. Flow for Creating and Updating Batches; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following flow is used to create a new batch or update an existing; batch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast paths for creating and updating batches when; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer t",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:16081,Deployability,update,update,16081,"tch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast paths for creating and updating batches when; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer than 1,024 jobs and the; specifications fit in fewer than 1KiB. at; ``/api/v1alpha/batches/{batch_id}/create-fast`` and; ``/api/v1alpha/batches/{batch_id}/update-fast``. Listing Batches and Jobs; ^^^^^^^^^^^^^^^^^^^^^^^^. To find all matching batches and jobs either via the UI or the Python; client library, a user provides a query",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:16152,Deployability,update,updates,16152,"tch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast paths for creating and updating batches when; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer than 1,024 jobs and the; specifications fit in fewer than 1KiB. at; ``/api/v1alpha/batches/{batch_id}/create-fast`` and; ``/api/v1alpha/batches/{batch_id}/update-fast``. Listing Batches and Jobs; ^^^^^^^^^^^^^^^^^^^^^^^^. To find all matching batches and jobs either via the UI or the Python; client library, a user provides a query",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:16240,Deployability,update,update,16240,"a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast paths for creating and updating batches when; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer than 1,024 jobs and the; specifications fit in fewer than 1KiB. at; ``/api/v1alpha/batches/{batch_id}/create-fast`` and; ``/api/v1alpha/batches/{batch_id}/update-fast``. Listing Batches and Jobs; ^^^^^^^^^^^^^^^^^^^^^^^^. To find all matching batches and jobs either via the UI or the Python; client library, a user provides a query filtering string as well as an; optional starting ID. The server then sends the next 50 recor",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:16588,Deployability,update,updates,16588," that batch if the request contains a; reservation with more than 1 job. The new batch id and possibly the; new update id are returned to the client. 2. The client library submits job specifications in 6-way parallelism; in groups of jobs, called bunches, for the newly created batch update as a POST; request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/jobs/create``. The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast paths for creating and updating batches when; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer than 1,024 jobs and the; specifications fit in fewer than 1KiB. at; ``/api/v1alpha/batches/{batch_id}/create-fast`` and; ``/api/v1alpha/batches/{batch_id}/update-fast``. Listing Batches and Jobs; ^^^^^^^^^^^^^^^^^^^^^^^^. To find all matching batches and jobs either via the UI or the Python; client library, a user provides a query filtering string as well as an; optional starting ID. The server then sends the next 50 records in; response and it is up to the client to send the next request with the; ID of the last record returned in the subsequent request. Batch Driver; ------------. The Batch Driver is a Kubernetes service that creates a fleet of; worker VMs in response to user workloads and has mechanisms in place; for shar",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:16943,Deployability,update,update-fast,16943," The; front end service creates new entries into the jobs table as well; as associated tables such as the table that stores the attributes; for the job. 3. The user commits the update by sending a POST request to; ``/api/v1alpha/batches/{batch_id}/updates/{update_id}/commit``. After; this, no additional jobs can be submitted for that update. The; front end service executes a SQL stored procedure in the database; that does some bookkeeping to transition these staged jobs into; jobs the batch driver will be able to process and run. The flow for updating an existing batch is almost identical to the one; above except step 1 submits a request to; ``/api/v1alpha/batches/{batch_id}/updates/create``. There are also two fast paths for creating and updating batches when; all jobs fit in a single HTTP request. At time of writing, our client; code uses this path when there are fewer than 1,024 jobs and the; specifications fit in fewer than 1KiB. at; ``/api/v1alpha/batches/{batch_id}/create-fast`` and; ``/api/v1alpha/batches/{batch_id}/update-fast``. Listing Batches and Jobs; ^^^^^^^^^^^^^^^^^^^^^^^^. To find all matching batches and jobs either via the UI or the Python; client library, a user provides a query filtering string as well as an; optional starting ID. The server then sends the next 50 records in; response and it is up to the client to send the next request with the; ID of the last record returned in the subsequent request. Batch Driver; ------------. The Batch Driver is a Kubernetes service that creates a fleet of; worker VMs in response to user workloads and has mechanisms in place; for sharing resources fairly across users. It also has many background; processes to make sure orphaned resources such as disks and VMs are; cleaned up, billing prices for resources are up to date, and; cancelling batches with more than N failures if specified by the; user. The service can be located on a preemptible machine, but we use; a non-preemptible machine to minimize downtime, es",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23134,Deployability,update,update,23134,"re.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the atte",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23785,Deployability,update,update,23785,"behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the resources it is using. If the attempt does not exist; yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to Running if; it is not already and not been cancelled or completed already. We then; update the start time of the attempt to",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:24668,Deployability,update,update,24668,"es. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the resources it is using. If the attempt does not exist; yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to Running if; it is not already and not been cancelled or completed already. We then; update the start time of the attempt to that given by the; worker. Lastly, we execute a separate database query that inserts the; appropriate resources for that attempt into the database. MJC is a database operation that is initiated by the worker VM when; the job completes. The worker sends the start and end time of the; attempt along with the resources it is using. If the attempt does not; exist yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to the; appropriate completed state if it is not already and not been; cancelled or completed already. We then update the start and end times; of the attempt to that given by the worker. We then find all of the; children of the completed job and subtract the number of pending; parents by one. If the child job(s) now have no pending parents, they; are set to have a state of Ready. We also check if this is the last",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:24776,Deployability,update,update,24776," - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the resources it is using. If the attempt does not exist; yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to Running if; it is not already and not been cancelled or completed already. We then; update the start time of the attempt to that given by the; worker. Lastly, we execute a separate database query that inserts the; appropriate resources for that attempt into the database. MJC is a database operation that is initiated by the worker VM when; the job completes. The worker sends the start and end time of the; attempt along with the resources it is using. If the attempt does not; exist yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to the; appropriate completed state if it is not already and not been; cancelled or completed already. We then update the start and end times; of the attempt to that given by the worker. We then find all of the; children of the completed job and subtract the number of pending; parents by one. If the child job(s) now have no pending parents, they; are set to have a state of Ready. We also check if this is the last; job in the batch to complete. If so, we change the batch state to; completed. Lastly, we ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:25276,Deployability,update,update,25276,"the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the resources it is using. If the attempt does not exist; yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to Running if; it is not already and not been cancelled or completed already. We then; update the start time of the attempt to that given by the; worker. Lastly, we execute a separate database query that inserts the; appropriate resources for that attempt into the database. MJC is a database operation that is initiated by the worker VM when; the job completes. The worker sends the start and end time of the; attempt along with the resources it is using. If the attempt does not; exist yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to the; appropriate completed state if it is not already and not been; cancelled or completed already. We then update the start and end times; of the attempt to that given by the worker. We then find all of the; children of the completed job and subtract the number of pending; parents by one. If the child job(s) now have no pending parents, they; are set to have a state of Ready. We also check if this is the last; job in the batch to complete. If so, we change the batch state to; completed. Lastly, we execute a separate database query that inserts; the appropriate resources for that attempt into the database. When we are looking at overall Batch performance, we look at the; metrics of SJ and MJC rates per second for heavy workloads (ex: 1000s; of no-op true jobs). We historically scheduled at 80 jobs per second. We; endeavor to schedule much faster. Canceller; ^^^^^^^^^. The canceller consists of three background loops that cancel any; ready, running, or creating jobs in batches that have been cancelled; or the job speci",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:25408,Deployability,update,update,25408,"s running. The worker sends the start time of the attempt; along with the resources it is using. If the attempt does not exist; yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to Running if; it is not already and not been cancelled or completed already. We then; update the start time of the attempt to that given by the; worker. Lastly, we execute a separate database query that inserts the; appropriate resources for that attempt into the database. MJC is a database operation that is initiated by the worker VM when; the job completes. The worker sends the start and end time of the; attempt along with the resources it is using. If the attempt does not; exist yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to the; appropriate completed state if it is not already and not been; cancelled or completed already. We then update the start and end times; of the attempt to that given by the worker. We then find all of the; children of the completed job and subtract the number of pending; parents by one. If the child job(s) now have no pending parents, they; are set to have a state of Ready. We also check if this is the last; job in the batch to complete. If so, we change the batch state to; completed. Lastly, we execute a separate database query that inserts; the appropriate resources for that attempt into the database. When we are looking at overall Batch performance, we look at the; metrics of SJ and MJC rates per second for heavy workloads (ex: 1000s; of no-op true jobs). We historically scheduled at 80 jobs per second. We; endeavor to schedule much faster. Canceller; ^^^^^^^^^. The canceller consists of three background loops that cancel any; ready, running, or creating jobs in batches that have been cancelled; or the job specifically has been cancelled (ie. a parent failed). Fair; share is computed by taking the number of cancellabl",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:26855,Deployability,update,update,26855," are looking at overall Batch performance, we look at the; metrics of SJ and MJC rates per second for heavy workloads (ex: 1000s; of no-op true jobs). We historically scheduled at 80 jobs per second. We; endeavor to schedule much faster. Canceller; ^^^^^^^^^. The canceller consists of three background loops that cancel any; ready, running, or creating jobs in batches that have been cancelled; or the job specifically has been cancelled (ie. a parent failed). Fair; share is computed by taking the number of cancellable jobs in each; category and dividing by the total number of cancellable jobs and; multiplying by 300 jobs to cancel in each iteration with a minimum of; 20 jobs per user. Billing Updates; ^^^^^^^^^^^^^^^. To provide users with real time billing and effectively enforce; billing limits, we have the worker send us the job attempts it has; running as well as the current time approximately every 1 minute. We; then update the rollup_time for each job which is guaranteed to be; greater than or equal to the start time and less than or equal to the; end time. The rollup time is then used in billing calculations to; figure out the duration the job has been running thus far. Quota Exhaustion; ^^^^^^^^^^^^^^^^. There is a mechanism in GCP by which we monitor our current quotas and; assign jobs that can be run in any region to a different region if; we've exceeded our quota. Cloud Price Monitoring; ^^^^^^^^^^^^^^^^^^^^^^. We periodically call the corresponding cloud APIs to get up to date; billing information and update the current rates of each product used; accordingly. Case Studies; ^^^^^^^^^^^^. This section describes some of the emergent behaviors that occur with; multiple components acting together. Preemption; """""""""""""""""""". Preemption is a special case of ""dead node"" detection. 1. The ``batch-driver`` service has a background loop in ``instance_collection/base.py``; that checks the status of all instances. - If a running instance is not reachable then a ``failed_r",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:27458,Deployability,update,update,27458,"le jobs in each; category and dividing by the total number of cancellable jobs and; multiplying by 300 jobs to cancel in each iteration with a minimum of; 20 jobs per user. Billing Updates; ^^^^^^^^^^^^^^^. To provide users with real time billing and effectively enforce; billing limits, we have the worker send us the job attempts it has; running as well as the current time approximately every 1 minute. We; then update the rollup_time for each job which is guaranteed to be; greater than or equal to the start time and less than or equal to the; end time. The rollup time is then used in billing calculations to; figure out the duration the job has been running thus far. Quota Exhaustion; ^^^^^^^^^^^^^^^^. There is a mechanism in GCP by which we monitor our current quotas and; assign jobs that can be run in any region to a different region if; we've exceeded our quota. Cloud Price Monitoring; ^^^^^^^^^^^^^^^^^^^^^^. We periodically call the corresponding cloud APIs to get up to date; billing information and update the current rates of each product used; accordingly. Case Studies; ^^^^^^^^^^^^. This section describes some of the emergent behaviors that occur with; multiple components acting together. Preemption; """""""""""""""""""". Preemption is a special case of ""dead node"" detection. 1. The ``batch-driver`` service has a background loop in ``instance_collection/base.py``; that checks the status of all instances. - If a running instance is not reachable then a ``failed_request_count`` is incremented.; - If the ``failed_request_count`` exceeds a threshold, the instance is deleted.; - As part of deletion, the database's ``deactivate_instance`` stored procedure is called.; - During the stored procedure, any jobs that are running on the instance are marked as ``Ready``. 2. The newly ``Ready`` jobs will be picked up by the next iteration of the schedule; loop (eg in``instance_collection/pool.py``). - The scheduler is also what creates a new attempt record in the database for the new a",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:29088,Deployability,update,updated,29088,"alled.; - During the stored procedure, any jobs that are running on the instance are marked as ``Ready``. 2. The newly ``Ready`` jobs will be picked up by the next iteration of the schedule; loop (eg in``instance_collection/pool.py``). - The scheduler is also what creates a new attempt record in the database for the new attempt. Database; --------. The batch database has a series of tables, triggers, and stored; procedures that are used to keep track of the state of billing; projects, batches, jobs, attempts, resources, and instances. We; previously discussed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll end up serializing the schedule operations as each one; waits for the exclusive write lock. To avoid this, we have up to; 200 rows per value we want to represent where each row has a unique; ""token"". This way concurrent transactions can update rows; simultaneously and the probability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancella",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:29292,Deployability,update,update,29292,"icked up by the next iteration of the schedule; loop (eg in``instance_collection/pool.py``). - The scheduler is also what creates a new attempt record in the database for the new attempt. Database; --------. The batch database has a series of tables, triggers, and stored; procedures that are used to keep track of the state of billing; projects, batches, jobs, attempts, resources, and instances. We; previously discussed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll end up serializing the schedule operations as each one; waits for the exclusive write lock. To avoid this, we have up to; 200 rows per value we want to represent where each row has a unique; ""token"". This way concurrent transactions can update rows; simultaneously and the probability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:29639,Deployability,update,update,29639,"ed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll end up serializing the schedule operations as each one; waits for the exclusive write lock. To avoid this, we have up to; 200 rows per value we want to represent where each row has a unique; ""token"". This way concurrent transactions can update rows; simultaneously and the probability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query speed is linear in the number of total; attempts when computing the cost for a batch by scanning over the; entire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt durati",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:30653,Deployability,update,update,30653,"ability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query speed is linear in the number of total; attempts when computing the cost for a batch by scanning over the; entire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt duration timestamps or inserting a new attempt resource; updates the corresponding batch in the table. This table is; ""tokenized"" as described above to prevent serialization of attempt; update events. Likewise, we have similar aggregation tables for; billing projects as well as billing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the numb",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:30733,Deployability,update,updates,30733,"ability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query speed is linear in the number of total; attempts when computing the cost for a batch by scanning over the; entire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt duration timestamps or inserting a new attempt resource; updates the corresponding batch in the table. This table is; ""tokenized"" as described above to prevent serialization of attempt; update events. Likewise, we have similar aggregation tables for; billing projects as well as billing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the numb",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:30862,Deployability,update,update,30862,"to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query speed is linear in the number of total; attempts when computing the cost for a batch by scanning over the; entire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt duration timestamps or inserting a new attempt resource; updates the corresponding batch in the table. This table is; ""tokenized"" as described above to prevent serialization of attempt; update events. Likewise, we have similar aggregation tables for; billing projects as well as billing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:31093,Deployability,update,updates,31093,"ellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query speed is linear in the number of total; attempts when computing the cost for a batch by scanning over the; entire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt duration timestamps or inserting a new attempt resource; updates the corresponding batch in the table. This table is; ""tokenized"" as described above to prevent serialization of attempt; update events. Likewise, we have similar aggregation tables for; billing projects as well as billing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Canc",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:31490,Deployability,update,updates,31490,"ntire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt duration timestamps or inserting a new attempt resource; updates the corresponding batch in the table. This table is; ""tokenized"" as described above to prevent serialization of attempt; update events. Likewise, we have similar aggregation tables for; billing projects as well as billing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible su",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:31945,Deployability,update,updated,31945,"illing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:32017,Deployability,update,updates,32017,"`; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:33372,Deployability,update,update,33372,"em. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby avoiding scheduling them in the first; place. We also execute a similar query for the autoscaler. The only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled is in the fair share calculation via; the ``user_inst_coll_resources`` table. To accomplish a fast update of; this table, we currently keep track of the number of **cancellable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Do",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:33854,Deployability,update,update,33854,"for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby avoiding scheduling them in the first; place. We also execute a similar query for the autoscaler. The only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled is in the fair share calculation via; the ``user_inst_coll_resources`` table. To accomplish a fast update of; this table, we currently keep track of the number of **cancellable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Docker Jobs are regular jobs that use a user-defined; image and the user-defined source code. JVM jobs are specially; designed for the Query on Batch (QoB) use case. The worker downloads; an approved JAR file to execute a user's query that is stored in cloud; storage. All containers the worker creates ar",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:34171,Deployability,update,updates,34171,"only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled is in the fair share calculation via; the ``user_inst_coll_resources`` table. To accomplish a fast update of; this table, we currently keep track of the number of **cancellable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Docker Jobs are regular jobs that use a user-defined; image and the user-defined source code. JVM jobs are specially; designed for the Query on Batch (QoB) use case. The worker downloads; an approved JAR file to execute a user's query that is stored in cloud; storage. All containers the worker creates are by using `crun` and not; Docker. When the worker has not received any work to do and no jobs; are currently running, it will deactivate itself and shut itself down. Known Issues; ------------. - The current database structure serializes MJC operations because the; table ``batches_n_jobs_in_complete_states`` has one row per batch; and each MJC operation tries to update the same row in this;",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:35136,Deployability,update,update,35136,"lable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Docker Jobs are regular jobs that use a user-defined; image and the user-defined source code. JVM jobs are specially; designed for the Query on Batch (QoB) use case. The worker downloads; an approved JAR file to execute a user's query that is stored in cloud; storage. All containers the worker creates are by using `crun` and not; Docker. When the worker has not received any work to do and no jobs; are currently running, it will deactivate itself and shut itself down. Known Issues; ------------. - The current database structure serializes MJC operations because the; table ``batches_n_jobs_in_complete_states`` has one row per batch; and each MJC operation tries to update the same row in this; table.; - ``commit_update`` is slow for large updates because we have to; compute the job states by scanning the states of all of a job's; parents.; - If a large batch has multiple distinct regions specified that are not; interweaved, the autoscaler and scheduler can deadlock.; ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:35211,Deployability,update,updates,35211,"lable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Docker Jobs are regular jobs that use a user-defined; image and the user-defined source code. JVM jobs are specially; designed for the Query on Batch (QoB) use case. The worker downloads; an approved JAR file to execute a user's query that is stored in cloud; storage. All containers the worker creates are by using `crun` and not; Docker. When the worker has not received any work to do and no jobs; are currently running, it will deactivate itself and shut itself down. Known Issues; ------------. - The current database structure serializes MJC operations because the; table ``batches_n_jobs_in_complete_states`` has one row per batch; and each MJC operation tries to update the same row in this; table.; - ``commit_update`` is slow for large updates because we have to; compute the job states by scanning the states of all of a job's; parents.; - If a large batch has multiple distinct regions specified that are not; interweaved, the autoscaler and scheduler can deadlock.; ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:6018,Energy Efficiency,schedul,scheduling,6018," user requests such as creating batches, updating batches, and viewing; job logs. How the Batch Front End Python service works is described in; more detail later in this document. When users submit requests to; authenticated endpoints (everything except for /healthcheck), the; Batch service sends a request to the Auth service to see if the token; submitted in the request is valid and in exchange get information; about the user. The Batch Front End can also send requests to the; Batch Driver notifying the driver that a batch has been created or; needs to be cancelled (""push notification""). The application is stateless; and 3 copies are running simultaneously. The Front End; extensively updates and queries the MySQL database to obtain the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not w",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:6353,Energy Efficiency,schedul,schedule,6353,"k), the; Batch service sends a request to the Auth service to see if the token; submitted in the request is valid and in exchange get information; about the user. The Batch Front End can also send requests to the; Batch Driver notifying the driver that a batch has been created or; needs to be cancelled (""push notification""). The application is stateless; and 3 copies are running simultaneously. The Front End; extensively updates and queries the MySQL database to obtain the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not with the Kubernetes pods. They are created with a default service; account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured bo",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:6426,Energy Efficiency,schedul,schedules,6426,"mation; about the user. The Batch Front End can also send requests to the; Batch Driver notifying the driver that a batch has been created or; needs to be cancelled (""push notification""). The application is stateless; and 3 copies are running simultaneously. The Front End; extensively updates and queries the MySQL database to obtain the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not with the Kubernetes pods. They are created with a default service; account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured boot disk; image that has Docker preinstalled. Startup scripts then initialize; the worker VM, download the worker server application image f",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:6789,Energy Efficiency,reduce,reduce,6789,"in the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not with the Kubernetes pods. They are created with a default service; account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured boot disk; image that has Docker preinstalled. Startup scripts then initialize; the worker VM, download the worker server application image from a; container registry, and then create the worker Docker container. Once; the worker container is running, it notifies the Batch Driver that it; is active and starts executing jobs. MySQL Database; --------------. All Batch and Auth state is stored in a cloud-provider managed MySQL; database. We use SSL certificates to secure ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:8105,Energy Efficiency,monitor,monitoring,8105,"account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured boot disk; image that has Docker preinstalled. Startup scripts then initialize; the worker VM, download the worker server application image from a; container registry, and then create the worker Docker container. Once; the worker container is running, it notifies the Batch Driver that it; is active and starts executing jobs. MySQL Database; --------------. All Batch and Auth state is stored in a cloud-provider managed MySQL; database. We use SSL certificates to secure communication between; Kubernetes services and the database. Worker VMs cannot talk directly; to the database. Cloud Storage; -------------. Users store the data they want to compute on in Cloud Storage (Google; Cloud Storage or Azure Blob Storage). All Batch created files such as; user job specs, job log files, job status files, and job resource; usage monitoring files are stored in cloud storage. Container Registry; ------------------. Container images used to execute user jobs as well as the images used; in our Kubernetes services are stored in a cloud provider managed; Container Registry (Google Artifact Registry and Azure Container; Registry). Terraform; ---------. TBD. Bootstrapping; -------------. TBD. Application Details; ===================. Batch Lifecycle; ---------------. 1. A user submits a request to the Batch front end service to create a; batch along with job specifications.; 2. The Batch front end service records the batch and job information; into a MySQL database and writes the job specifications to cloud; storage.; 3. The Batch driver notices that there is work available either; through a push request from the Batch front end or by polling the; state in the MySQL database and spins up worker VMs.; 4. The worker VMs startup and notify the Batch driver they are active; and have resource",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:9110,Energy Efficiency,schedul,schedules,9110,"re stored in cloud storage. Container Registry; ------------------. Container images used to execute user jobs as well as the images used; in our Kubernetes services are stored in a cloud provider managed; Container Registry (Google Artifact Registry and Azure Container; Registry). Terraform; ---------. TBD. Bootstrapping; -------------. TBD. Application Details; ===================. Batch Lifecycle; ---------------. 1. A user submits a request to the Batch front end service to create a; batch along with job specifications.; 2. The Batch front end service records the batch and job information; into a MySQL database and writes the job specifications to cloud; storage.; 3. The Batch driver notices that there is work available either; through a push request from the Batch front end or by polling the; state in the MySQL database and spins up worker VMs.; 4. The worker VMs startup and notify the Batch driver they are active; and have resources to run jobs.; 5. The Batch driver schedules jobs to run on the active workers.; 6. The worker VM downloads the job specification from cloud storage,; downloads any input files the job needs from cloud storage, creates; a container for the job to execute in, executes the code inside the; container, uploads any logs and output files that have been; generated, and then notifies the Batch driver that the job has; completed.; 7. Once all jobs have completed, the batch is set to complete in the; database. Any callbacks that have been specified on batch; completion are called.; 8. Meanwhile, the user can find the status of their batch through the; UI or using a Python client library to get the batch status, cancel; the batch, list the jobs in the batch and their statuses, and wait; for the batch or an individual job to complete. The implementation; of the wait operation is by continuously polling the Batch Front; End until the batch state is ""complete"". Data Model; ----------. The core concepts in the Batch data model are billing projects",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:18723,Energy Efficiency,schedul,scheduler,18723,"ling batches with more than N failures if specified by the; user. The service can be located on a preemptible machine, but we use; a non-preemptible machine to minimize downtime, especially when the; cluster is large. There can only be one driver service in existence at; any one time. There is an Envoy side car container in the batch driver; pod to handle TLS handshakes to avoid excess CPU usage of the batch; driver. Instance Collections; ^^^^^^^^^^^^^^^^^^^^. The batch driver maintains two different types of collections of; workers. There are **pools** that are multi-tenant and have a; dedicated worker type that is shared across all jobs. Pools can; support both preemptible and nonpreemptible VMs. Right now, there are; three types of machine types we support that correspond to low memory; (~1GB memory / core), standard (~4GB memory / core), and high memory; (~8GB memory / core) machines. These are correspondingly the; ""highcpu"", ""standard"", and ""highmem"" pools. Each pool has its own; scheduler and autoscaler. In addition, there's a single job private; instance manager that creates a worker VM per job and is used if the; worker requests a specific machine type. This is used commonly for; jobs that require more memory than a 16 core machine can provide. Fair Share; ^^^^^^^^^^. In order to avoid having one user starve other users from getting; their jobs run, we use the following fair share algorithm. We start; with the user who has the fewest cores running. We then allocate as; many cores as possible that are live in the cluster until we reach the; number of cores the next user has currently running. We then divide up; the remaining cores equally amongst the two users until we reach the; number of cores the next user has running. We repeat until we have; either exhausted all free cores in the cluster or have satisfied all; user resource requests. The query to get the number of ready cores in the fair; share algorithm is fast because we aggregate across a global table;",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:19212,Energy Efficiency,allocate,allocate,19212,"ools** that are multi-tenant and have a; dedicated worker type that is shared across all jobs. Pools can; support both preemptible and nonpreemptible VMs. Right now, there are; three types of machine types we support that correspond to low memory; (~1GB memory / core), standard (~4GB memory / core), and high memory; (~8GB memory / core) machines. These are correspondingly the; ""highcpu"", ""standard"", and ""highmem"" pools. Each pool has its own; scheduler and autoscaler. In addition, there's a single job private; instance manager that creates a worker VM per job and is used if the; worker requests a specific machine type. This is used commonly for; jobs that require more memory than a 16 core machine can provide. Fair Share; ^^^^^^^^^^. In order to avoid having one user starve other users from getting; their jobs run, we use the following fair share algorithm. We start; with the user who has the fewest cores running. We then allocate as; many cores as possible that are live in the cluster until we reach the; number of cores the next user has currently running. We then divide up; the remaining cores equally amongst the two users until we reach the; number of cores the next user has running. We repeat until we have; either exhausted all free cores in the cluster or have satisfied all; user resource requests. The query to get the number of ready cores in the fair; share algorithm is fast because we aggregate across a global table; ``user_inst_coll_resources`` that has a limited number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autoscaler takes the number of; ready cores total across all users and divides up that amount by the; number of cores per worker to get the number of instances that are; required. It then spins up a ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:19934,Energy Efficiency,charge,charge,19934,"ine can provide. Fair Share; ^^^^^^^^^^. In order to avoid having one user starve other users from getting; their jobs run, we use the following fair share algorithm. We start; with the user who has the fewest cores running. We then allocate as; many cores as possible that are live in the cluster until we reach the; number of cores the next user has currently running. We then divide up; the remaining cores equally amongst the two users until we reach the; number of cores the next user has running. We repeat until we have; either exhausted all free cores in the cluster or have satisfied all; user resource requests. The query to get the number of ready cores in the fair; share algorithm is fast because we aggregate across a global table; ``user_inst_coll_resources`` that has a limited number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autoscaler takes the number of; ready cores total across all users and divides up that amount by the; number of cores per worker to get the number of instances that are; required. It then spins up a configurable number of instances each; time the autoscaler runs to avoid cloud provider API rate limits. This; approach works well for large workloads that have long running; jobs. However, the autoscaler can produce more cores than the; scheduler can keep busy with work. This happens when there are many; jobs with a short execution time. Due to differences in resource prices across regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:20514,Energy Efficiency,schedul,scheduler,20514,"ave; either exhausted all free cores in the cluster or have satisfied all; user resource requests. The query to get the number of ready cores in the fair; share algorithm is fast because we aggregate across a global table; ``user_inst_coll_resources`` that has a limited number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autoscaler takes the number of; ready cores total across all users and divides up that amount by the; number of cores per worker to get the number of instances that are; required. It then spins up a configurable number of instances each; time the autoscaler runs to avoid cloud provider API rate limits. This; approach works well for large workloads that have long running; jobs. However, the autoscaler can produce more cores than the; scheduler can keep busy with work. This happens when there are many; jobs with a short execution time. Due to differences in resource prices across regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler win",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:20892,Energy Efficiency,schedul,scheduled,20892," number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autoscaler takes the number of; ready cores total across all users and divides up that amount by the; number of cores per worker to get the number of instances that are; required. It then spins up a configurable number of instances each; time the autoscaler runs to avoid cloud provider API rate limits. This; approach works well for large workloads that have long running; jobs. However, the autoscaler can produce more cores than the; scheduler can keep busy with work. This happens when there are many; jobs with a short execution time. Due to differences in resource prices across regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit o",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:21252,Energy Efficiency,schedul,scheduling,21252," get the number of instances that are; required. It then spins up a configurable number of instances each; time the autoscaler runs to avoid cloud provider API rate limits. This; approach works well for large workloads that have long running; jobs. However, the autoscaler can produce more cores than the; scheduler can keep busy with work. This happens when there are many; jobs with a short execution time. Due to differences in resource prices across regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the reg",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:21975,Energy Efficiency,schedul,scheduling,21975,"perations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22052,Energy Efficiency,schedul,scheduler,22052,"perations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22079,Energy Efficiency,schedul,scheduled,22079,"perations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22176,Energy Efficiency,schedul,scheduling,22176,"ure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22478,Energy Efficiency,schedul,scheduler,22478,"er is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wai",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22513,Energy Efficiency,schedul,schedule,22513,"er is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wai",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22583,Energy Efficiency,schedul,scheduling,22583,"er is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wai",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22737,Energy Efficiency,schedul,scheduler,22737,"his query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22822,Energy Efficiency,schedul,scheduling,22822,"fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:22994,Energy Efficiency,schedul,scheduler,22994,"re.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the atte",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23058,Energy Efficiency,schedul,scheduler,23058,"re.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the atte",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23291,Energy Efficiency,schedul,scheduling,23291,"number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23398,Energy Efficiency,schedul,scheduler,23398,"number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23462,Energy Efficiency,schedul,scheduling,23462,"number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23500,Energy Efficiency,schedul,scheduling,23500,"chedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23545,Energy Efficiency,schedul,scheduling,23545,"chedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23672,Energy Efficiency,schedul,schedule,23672,"'s fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the resources it is using. If the attempt does not exist; yet, we create the attempt and subtract the free cores from the; in",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23975,Energy Efficiency,schedul,scheduled,23975,"ut two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is a database operation that is initiated by the worker VM when; the job starts running. The worker sends the start time of the attempt; along with the resources it is using. If the attempt does not exist; yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to Running if; it is not already and not been cancelled or completed already. We then; update the start time of the attempt to that given by the; worker. Lastly, we execute a separate database query that inserts the; appropriate resources for that at",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:26088,Energy Efficiency,schedul,scheduled,26088,"the; attempt along with the resources it is using. If the attempt does not; exist yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to the; appropriate completed state if it is not already and not been; cancelled or completed already. We then update the start and end times; of the attempt to that given by the worker. We then find all of the; children of the completed job and subtract the number of pending; parents by one. If the child job(s) now have no pending parents, they; are set to have a state of Ready. We also check if this is the last; job in the batch to complete. If so, we change the batch state to; completed. Lastly, we execute a separate database query that inserts; the appropriate resources for that attempt into the database. When we are looking at overall Batch performance, we look at the; metrics of SJ and MJC rates per second for heavy workloads (ex: 1000s; of no-op true jobs). We historically scheduled at 80 jobs per second. We; endeavor to schedule much faster. Canceller; ^^^^^^^^^. The canceller consists of three background loops that cancel any; ready, running, or creating jobs in batches that have been cancelled; or the job specifically has been cancelled (ie. a parent failed). Fair; share is computed by taking the number of cancellable jobs in each; category and dividing by the total number of cancellable jobs and; multiplying by 300 jobs to cancel in each iteration with a minimum of; 20 jobs per user. Billing Updates; ^^^^^^^^^^^^^^^. To provide users with real time billing and effectively enforce; billing limits, we have the worker send us the job attempts it has; running as well as the current time approximately every 1 minute. We; then update the rollup_time for each job which is guaranteed to be; greater than or equal to the start time and less than or equal to the; end time. The rollup time is then used in billing calculations to; figure out the duration the job has been",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:26137,Energy Efficiency,schedul,schedule,26137,"using. If the attempt does not; exist yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to the; appropriate completed state if it is not already and not been; cancelled or completed already. We then update the start and end times; of the attempt to that given by the worker. We then find all of the; children of the completed job and subtract the number of pending; parents by one. If the child job(s) now have no pending parents, they; are set to have a state of Ready. We also check if this is the last; job in the batch to complete. If so, we change the batch state to; completed. Lastly, we execute a separate database query that inserts; the appropriate resources for that attempt into the database. When we are looking at overall Batch performance, we look at the; metrics of SJ and MJC rates per second for heavy workloads (ex: 1000s; of no-op true jobs). We historically scheduled at 80 jobs per second. We; endeavor to schedule much faster. Canceller; ^^^^^^^^^. The canceller consists of three background loops that cancel any; ready, running, or creating jobs in batches that have been cancelled; or the job specifically has been cancelled (ie. a parent failed). Fair; share is computed by taking the number of cancellable jobs in each; category and dividing by the total number of cancellable jobs and; multiplying by 300 jobs to cancel in each iteration with a minimum of; 20 jobs per user. Billing Updates; ^^^^^^^^^^^^^^^. To provide users with real time billing and effectively enforce; billing limits, we have the worker send us the job attempts it has; running as well as the current time approximately every 1 minute. We; then update the rollup_time for each job which is guaranteed to be; greater than or equal to the start time and less than or equal to the; end time. The rollup time is then used in billing calculations to; figure out the duration the job has been running thus far. Quota Exhaustion; ^^^^^^",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:27191,Energy Efficiency,monitor,monitor,27191,"t cancel any; ready, running, or creating jobs in batches that have been cancelled; or the job specifically has been cancelled (ie. a parent failed). Fair; share is computed by taking the number of cancellable jobs in each; category and dividing by the total number of cancellable jobs and; multiplying by 300 jobs to cancel in each iteration with a minimum of; 20 jobs per user. Billing Updates; ^^^^^^^^^^^^^^^. To provide users with real time billing and effectively enforce; billing limits, we have the worker send us the job attempts it has; running as well as the current time approximately every 1 minute. We; then update the rollup_time for each job which is guaranteed to be; greater than or equal to the start time and less than or equal to the; end time. The rollup time is then used in billing calculations to; figure out the duration the job has been running thus far. Quota Exhaustion; ^^^^^^^^^^^^^^^^. There is a mechanism in GCP by which we monitor our current quotas and; assign jobs that can be run in any region to a different region if; we've exceeded our quota. Cloud Price Monitoring; ^^^^^^^^^^^^^^^^^^^^^^. We periodically call the corresponding cloud APIs to get up to date; billing information and update the current rates of each product used; accordingly. Case Studies; ^^^^^^^^^^^^. This section describes some of the emergent behaviors that occur with; multiple components acting together. Preemption; """""""""""""""""""". Preemption is a special case of ""dead node"" detection. 1. The ``batch-driver`` service has a background loop in ``instance_collection/base.py``; that checks the status of all instances. - If a running instance is not reachable then a ``failed_request_count`` is incremented.; - If the ``failed_request_count`` exceeds a threshold, the instance is deleted.; - As part of deletion, the database's ``deactivate_instance`` stored procedure is called.; - During the stored procedure, any jobs that are running on the instance are marked as ``Ready``. 2. The ne",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:28299,Energy Efficiency,schedul,schedule,28299," if; we've exceeded our quota. Cloud Price Monitoring; ^^^^^^^^^^^^^^^^^^^^^^. We periodically call the corresponding cloud APIs to get up to date; billing information and update the current rates of each product used; accordingly. Case Studies; ^^^^^^^^^^^^. This section describes some of the emergent behaviors that occur with; multiple components acting together. Preemption; """""""""""""""""""". Preemption is a special case of ""dead node"" detection. 1. The ``batch-driver`` service has a background loop in ``instance_collection/base.py``; that checks the status of all instances. - If a running instance is not reachable then a ``failed_request_count`` is incremented.; - If the ``failed_request_count`` exceeds a threshold, the instance is deleted.; - As part of deletion, the database's ``deactivate_instance`` stored procedure is called.; - During the stored procedure, any jobs that are running on the instance are marked as ``Ready``. 2. The newly ``Ready`` jobs will be picked up by the next iteration of the schedule; loop (eg in``instance_collection/pool.py``). - The scheduler is also what creates a new attempt record in the database for the new attempt. Database; --------. The batch database has a series of tables, triggers, and stored; procedures that are used to keep track of the state of billing; projects, batches, jobs, attempts, resources, and instances. We; previously discussed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll nee",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:28360,Energy Efficiency,schedul,scheduler,28360,"ing cloud APIs to get up to date; billing information and update the current rates of each product used; accordingly. Case Studies; ^^^^^^^^^^^^. This section describes some of the emergent behaviors that occur with; multiple components acting together. Preemption; """""""""""""""""""". Preemption is a special case of ""dead node"" detection. 1. The ``batch-driver`` service has a background loop in ``instance_collection/base.py``; that checks the status of all instances. - If a running instance is not reachable then a ``failed_request_count`` is incremented.; - If the ``failed_request_count`` exceeds a threshold, the instance is deleted.; - As part of deletion, the database's ``deactivate_instance`` stored procedure is called.; - During the stored procedure, any jobs that are running on the instance are marked as ``Ready``. 2. The newly ``Ready`` jobs will be picked up by the next iteration of the schedule; loop (eg in``instance_collection/pool.py``). - The scheduler is also what creates a new attempt record in the database for the new attempt. Database; --------. The batch database has a series of tables, triggers, and stored; procedures that are used to keep track of the state of billing; projects, batches, jobs, attempts, resources, and instances. We; previously discussed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:29143,Energy Efficiency,reduce,reduce,29143,"alled.; - During the stored procedure, any jobs that are running on the instance are marked as ``Ready``. 2. The newly ``Ready`` jobs will be picked up by the next iteration of the schedule; loop (eg in``instance_collection/pool.py``). - The scheduler is also what creates a new attempt record in the database for the new attempt. Database; --------. The batch database has a series of tables, triggers, and stored; procedures that are used to keep track of the state of billing; projects, batches, jobs, attempts, resources, and instances. We; previously discussed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll end up serializing the schedule operations as each one; waits for the exclusive write lock. To avoid this, we have up to; 200 rows per value we want to represent where each row has a unique; ""token"". This way concurrent transactions can update rows; simultaneously and the probability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancella",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:29321,Energy Efficiency,schedul,schedule,29321,"icked up by the next iteration of the schedule; loop (eg in``instance_collection/pool.py``). - The scheduler is also what creates a new attempt record in the database for the new attempt. Database; --------. The batch database has a series of tables, triggers, and stored; procedures that are used to keep track of the state of billing; projects, batches, jobs, attempts, resources, and instances. We; previously discussed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll end up serializing the schedule operations as each one; waits for the exclusive write lock. To avoid this, we have up to; 200 rows per value we want to represent where each row has a unique; ""token"". This way concurrent transactions can update rows; simultaneously and the probability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:29425,Energy Efficiency,schedul,schedule,29425," database for the new attempt. Database; --------. The batch database has a series of tables, triggers, and stored; procedures that are used to keep track of the state of billing; projects, batches, jobs, attempts, resources, and instances. We; previously discussed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll end up serializing the schedule operations as each one; waits for the exclusive write lock. To avoid this, we have up to; 200 rows per value we want to represent where each row has a unique; ""token"". This way concurrent transactions can update rows; simultaneously and the probability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:32258,Energy Efficiency,monitor,monitors,32258,"n; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby avoiding scheduling them in the first; place. We also execute a similar query for the autoscaler. The only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled i",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:32717,Energy Efficiency,schedul,scheduler,32717,"nning cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby avoiding scheduling them in the first; place. We also execute a similar query for the autoscaler. The only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled is in the fair share calculation via; the ``user_inst_coll_resources`` table. To accomplish a fast update of; this table, we currently keep track of the number of **cancellable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:32756,Energy Efficiency,schedul,schedule,32756,"nning cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby avoiding scheduling them in the first; place. We also execute a similar query for the autoscaler. The only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled is in the fair share calculation via; the ``user_inst_coll_resources`` table. To accomplish a fast update of; this table, we currently keep track of the number of **cancellable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:32945,Energy Efficiency,schedul,scheduler,32945," The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby avoiding scheduling them in the first; place. We also execute a similar query for the autoscaler. The only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled is in the fair share calculation via; the ``user_inst_coll_resources`` table. To accomplish a fast update of; this table, we currently keep track of the number of **cancellable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cance",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:33071,Energy Efficiency,schedul,scheduling,33071," The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs for batches that have been cancelled. We set a ""flag"" in; the database indicating the batch has been cancelled via the; ``batches_cancelled`` table. This allows the query the scheduler; executes to find Ready jobs to run to not read rows for jobs in batches that; have been cancelled thereby avoiding scheduling them in the first; place. We also execute a similar query for the autoscaler. The only; place where we need to quickly know how many cores we have that are; ready and have not been cancelled is in the fair share calculation via; the ``user_inst_coll_resources`` table. To accomplish a fast update of; this table, we currently keep track of the number of **cancellable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cance",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:35419,Energy Efficiency,schedul,scheduler,35419,"lable**; resources per batch in a tokenized table; ``batch_inst_coll_cancellable_resources`` such as the number of; cancellable ready cores. When we execute a cancellation operation, we; quickly count the number of cancellable ready cores or other similar; values from the ``batch_inst_coll_cancellable_resources`` table and; subtract those numbers from the ``user_inst_coll_resources`` table to; have an O(1) update such that the fair share computation can quickly; adjust to the change in demand for resources. The background canceller loops iterate through the cancelled jobs as; described above and are marked as Cancelled in the database and; handled accordingly one by one. Once a batch has been cancelled, no subsequent updates are allowed to; the batch. Batch Workers; -------------. Workers are Python web servers running on virtual machines. The Python; web server activates itself with the Batch driver and then accepts; requests to execute jobs. Jobs can take the form of either Docker Jobs; or JVM Jobs. The Docker Jobs are regular jobs that use a user-defined; image and the user-defined source code. JVM jobs are specially; designed for the Query on Batch (QoB) use case. The worker downloads; an approved JAR file to execute a user's query that is stored in cloud; storage. All containers the worker creates are by using `crun` and not; Docker. When the worker has not received any work to do and no jobs; are currently running, it will deactivate itself and shut itself down. Known Issues; ------------. - The current database structure serializes MJC operations because the; table ``batches_n_jobs_in_complete_states`` has one row per batch; and each MJC operation tries to update the same row in this; table.; - ``commit_update`` is slow for large updates because we have to; compute the job states by scanning the states of all of a job's; parents.; - If a large batch has multiple distinct regions specified that are not; interweaved, the autoscaler and scheduler can deadlock.; ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:558,Integrability,depend,dependencies,558,"============; Batch Design; ============. .. sectnum::; .. contents::. ********; Overview; ********. Hail Batch is a multi-tenant batch job processing system. The Hail; team maintains deployments in GCP and Azure. There are also a few; deployments outside of the control of the Hail team as well as alpha; support in Terra. Hail Batch has two main use cases: (1) a batch job; processing system that executes arbitrary bash or Python code in; containerized environments that are generated using a Python client; library that handles file localization and job dependencies in a; user-friendly manner (hailtop.batch) and (2) as the backend for; running Hail Query on Batch (QoB) inside containers running Hail team; approved JVM byte code. Typical users of hailtop.batch are looking to execute code for a; stand-alone scientific tool that can be run massively in parallel such; as across samples in a dataset and regions in a genome. Their; workloads usually consist of a single scatter layer with no; dependencies between jobs with sizes on the order of 100s to 100Ks of; jobs. The largest batch that has been processed by the Hail Batch; system is ~16 million jobs. Likewise, QoB consists of a single,; nonpreemptible driver job and subsequent sets of updates of jobs to; the directed acyclic graph (DAG) for subsequent stages of worker; jobs. There is a single job per partition within a stage. The number; of jobs within a stage can be on the order of 100K jobs. ****************************; How the Current System Works; ****************************. The Batch system is a set of services and infrastructure components; that work in concert to allow users to submit requests describing; workloads or sets of jobs to run and then executes the jobs on a set; of worker VMs. There is both a UI and a REST API for interacting with; Batch. The infrastructure required for a working Hail Batch system; consists of a Kubernetes cluster, a container registry, blob storage,; a MySQL database, and virtual m",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:999,Integrability,depend,dependencies,999,"==========; Batch Design; ============. .. sectnum::; .. contents::. ********; Overview; ********. Hail Batch is a multi-tenant batch job processing system. The Hail; team maintains deployments in GCP and Azure. There are also a few; deployments outside of the control of the Hail team as well as alpha; support in Terra. Hail Batch has two main use cases: (1) a batch job; processing system that executes arbitrary bash or Python code in; containerized environments that are generated using a Python client; library that handles file localization and job dependencies in a; user-friendly manner (hailtop.batch) and (2) as the backend for; running Hail Query on Batch (QoB) inside containers running Hail team; approved JVM byte code. Typical users of hailtop.batch are looking to execute code for a; stand-alone scientific tool that can be run massively in parallel such; as across samples in a dataset and regions in a genome. Their; workloads usually consist of a single scatter layer with no; dependencies between jobs with sizes on the order of 100s to 100Ks of; jobs. The largest batch that has been processed by the Hail Batch; system is ~16 million jobs. Likewise, QoB consists of a single,; nonpreemptible driver job and subsequent sets of updates of jobs to; the directed acyclic graph (DAG) for subsequent stages of worker; jobs. There is a single job per partition within a stage. The number; of jobs within a stage can be on the order of 100K jobs. ****************************; How the Current System Works; ****************************. The Batch system is a set of services and infrastructure components; that work in concert to allow users to submit requests describing; workloads or sets of jobs to run and then executes the jobs on a set; of worker VMs. There is both a UI and a REST API for interacting with; Batch. The infrastructure required for a working Hail Batch system; consists of a Kubernetes cluster, a container registry, blob storage,; a MySQL database, and virtual mac",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:12662,Integrability,depend,dependent,12662,"ted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; preemptible n1-standard-16 VM in us-central1) combined with a version; tag. Each resource has a rate that is used to compute cost when; multiplied by the usage of the resource. Resource rates are in units; that are dependent on the type of resource. For example, VM rates are; denominated in USD per core-hour. Each attempt has a set of resources; associated with it along with their usage in a resource-dependent set; of units. For example, a 1 core job has a usage value of 1000 (this; value is in mCPU). To compute the aggregate cost of a job, we sum up; all of the usages multiplied by the rates and then multiplied by the; duration the attempt has been running. State Diagram; -------------. A job can be in one of the following states:. - Pending: 1+ parent jobs have not completed yet; - Ready: No pending parent jobs.; - Creating: Creating a VM for job private jobs.; - Running: Job is running on a worker VM.; - Success: Job completed successfully.; - Failed: Job failed.; - Cancelled: Job was cancelled either by the system, by the user, or; because at least one of its parents failed.; - Error: Job failed due to an error in creating the container, an out; of memory error, or a Batch bug (ex: user tri",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:12851,Integrability,depend,dependent,12851,"s an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; preemptible n1-standard-16 VM in us-central1) combined with a version; tag. Each resource has a rate that is used to compute cost when; multiplied by the usage of the resource. Resource rates are in units; that are dependent on the type of resource. For example, VM rates are; denominated in USD per core-hour. Each attempt has a set of resources; associated with it along with their usage in a resource-dependent set; of units. For example, a 1 core job has a usage value of 1000 (this; value is in mCPU). To compute the aggregate cost of a job, we sum up; all of the usages multiplied by the rates and then multiplied by the; duration the attempt has been running. State Diagram; -------------. A job can be in one of the following states:. - Pending: 1+ parent jobs have not completed yet; - Ready: No pending parent jobs.; - Creating: Creating a VM for job private jobs.; - Running: Job is running on a worker VM.; - Success: Job completed successfully.; - Failed: Job failed.; - Cancelled: Job was cancelled either by the system, by the user, or; because at least one of its parents failed.; - Error: Job failed due to an error in creating the container, an out; of memory error, or a Batch bug (ex: user tries to use a nonexistent; image). The allowed state transitions are: Pending -> Ready Ready ->; {Creating, Running, Cancelled} Creating -> {Running, Cancelle",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:13890,Integrability,depend,depends,13890,"ob has a usage value of 1000 (this; value is in mCPU). To compute the aggregate cost of a job, we sum up; all of the usages multiplied by the rates and then multiplied by the; duration the attempt has been running. State Diagram; -------------. A job can be in one of the following states:. - Pending: 1+ parent jobs have not completed yet; - Ready: No pending parent jobs.; - Creating: Creating a VM for job private jobs.; - Running: Job is running on a worker VM.; - Success: Job completed successfully.; - Failed: Job failed.; - Cancelled: Job was cancelled either by the system, by the user, or; because at least one of its parents failed.; - Error: Job failed due to an error in creating the container, an out; of memory error, or a Batch bug (ex: user tries to use a nonexistent; image). The allowed state transitions are: Pending -> Ready Ready ->; {Creating, Running, Cancelled} Creating -> {Running, Cancelled}; Running -> {Success, Failed, Error, Cancelled}. A job's initial state depends on the states of its parent jobs. If it; has no parent jobs, its initial state is Ready. A batch can be in one of the following states:. - completed: All jobs are in a completed state {Success, Failed,; Error, Cancelled}; - running: At least one job is in a non-completed state {Pending,; Ready, Running}. The batch and job states are critical for database performance and; must be indexed appropriately. Batch Front End; ---------------. The Batch Front End service (batch) is a stateless web service that; handles requests from the user. The front end exposes a REST API; interface for handling user requests such as creating a batch,; updating a batch, creating jobs in a batch, getting the status of a; batch, getting the status of a job, listing all the batches in a; billing project, and listing all of the jobs in a batch. There are; usually 3 copies of the batch front end service running at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallel",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:14472,Integrability,interface,interface,14472," creating the container, an out; of memory error, or a Batch bug (ex: user tries to use a nonexistent; image). The allowed state transitions are: Pending -> Ready Ready ->; {Creating, Running, Cancelled} Creating -> {Running, Cancelled}; Running -> {Success, Failed, Error, Cancelled}. A job's initial state depends on the states of its parent jobs. If it; has no parent jobs, its initial state is Ready. A batch can be in one of the following states:. - completed: All jobs are in a completed state {Success, Failed,; Error, Cancelled}; - running: At least one job is in a non-completed state {Pending,; Ready, Running}. The batch and job states are critical for database performance and; must be indexed appropriately. Batch Front End; ---------------. The Batch Front End service (batch) is a stateless web service that; handles requests from the user. The front end exposes a REST API; interface for handling user requests such as creating a batch,; updating a batch, creating jobs in a batch, getting the status of a; batch, getting the status of a job, listing all the batches in a; billing project, and listing all of the jobs in a batch. There are; usually 3 copies of the batch front end service running at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallelism. This is necessary for batches with more; than a million jobs. Flow for Creating and Updating Batches; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following flow is used to create a new batch or update an existing; batch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/create``. A new entry for the batch is; inserted into the database along with any associated tables. For; example, if a user provides attributes (labels) on the batch, that; information is populated into the ``batch_attributes`` table. A new; update is also created for that batch if the request contains a; reservation with more",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:12311,Modifiability,config,configurations,12311," known at the time of the API call. The reason for; this is because an update reserves a block of job IDs in order to; allow multiple updates to a batch to be submitted simultaneously; without the need for locking as well as for jobs within the update to; be able to reference each other before the actual job IDs are; known. Once all of the jobs for a given batch update have been; submitted, the update must be committed in order for the jobs to be; visible in the UI and processed by the batch driver. A job can have **attempts**. An attempt is an individual execution; attempt of a job running on a worker VM. There can be multiple; attempts if a job is preempted. If a job is cancelled before it has a; chance to run, it will have zero attempts. An attempt has the; **instance** name that it ran on, the start time, and the end; time. The end time must always be greater than the start time. All; billing tracking is done at the level of an attempt as different; attempts for the same job can have different resource pricing if the; VM configurations are different (4 core worker vs 16 core worker). Billing is tracked by **resources**. A resource is a product (example:; preemptible n1-standard-16 VM in us-central1) combined with a version; tag. Each resource has a rate that is used to compute cost when; multiplied by the usage of the resource. Resource rates are in units; that are dependent on the type of resource. For example, VM rates are; denominated in USD per core-hour. Each attempt has a set of resources; associated with it along with their usage in a resource-dependent set; of units. For example, a 1 core job has a usage value of 1000 (this; value is in mCPU). To compute the aggregate cost of a job, we sum up; all of the usages multiplied by the rates and then multiplied by the; duration the attempt has been running. State Diagram; -------------. A job can be in one of the following states:. - Pending: 1+ parent jobs have not completed yet; - Ready: No pending parent job",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:20276,Modifiability,config,configurable,20276,"ext user has currently running. We then divide up; the remaining cores equally amongst the two users until we reach the; number of cores the next user has running. We repeat until we have; either exhausted all free cores in the cluster or have satisfied all; user resource requests. The query to get the number of ready cores in the fair; share algorithm is fast because we aggregate across a global table; ``user_inst_coll_resources`` that has a limited number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autoscaler takes the number of; ready cores total across all users and divides up that amount by the; number of cores per worker to get the number of instances that are; required. It then spins up a configurable number of instances each; time the autoscaler runs to avoid cloud provider API rate limits. This; approach works well for large workloads that have long running; jobs. However, the autoscaler can produce more cores than the; scheduler can keep busy with work. This happens when there are many; jobs with a short execution time. Due to differences in resource prices across regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:31854,Modifiability,parameteriz,parameterized,31854," table. This table is; ""tokenized"" as described above to prevent serialization of attempt; update events. Likewise, we have similar aggregation tables for; billing projects as well as billing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Cancellation; ^^^^^^^^^^^^. A user can trigger a cancellation of a batch via the cancel button in; the UI or a REST request. The batch system also monitors how much has; been spent in a billing project. Once that limit has been exceeded,; all running batches in the billing project are cancelled. Cancellation is the most complicated part of the Batch system. The; goal is to make cancellation as fast as possible such that we don't; waste resources spinning up worker VMs and running user jobs that are; ultimately going to get cancelled. Therefore, we need a way of quickly; notifying the autoscaler and scheduler to not spin up resources or; schedule jobs fo",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:2939,Performance,load,load,2939,"ts of a Kubernetes cluster, a container registry, blob storage,; a MySQL database, and virtual machines (VMs). In this document, we describe; the purpose of each infrastructural component and how they all work in; concert to create a working Batch system. We also expand on how both; of the Batch Python web servers are implemented in detail such as; database representations, how cancellation works, how the autoscaler; works, and how billing works. Lastly, we describe what happens on the; worker VMs. Infrastructure; ==============. The Batch system consists of the following Kubernetes; services and cloud infrastructure components:. - Kubernetes Services; - Gateway (gateway); - Internal Gateway (internal-gateway); - Auth (auth); - Auth Driver (auth-driver); - Batch Front End (batch); - Batch Driver (batch-driver); - Worker VMs; - MySQL Database; - Cloud Storage; - Container Registry. Kubernetes Services; -------------------. Gateway; ^^^^^^^. Gateway is a Kubernetes service and associated cloud-provider-managed; external load balancer. It is associated with a statically; known external IP Address. This is the entry point in which external; users send requests to the Batch system such as submitting batches and; getting information on their jobs. There is a an Envoy server behind; the load balancer that forwards requests to the appropriate service. Internal Gateway; ^^^^^^^^^^^^^^^^. Internal Gateway is a Kubernetes service and associated cloud-provider-managed; internal load balancer. Unlike the Gateway, the Internal; Gateway is associated with a statically known **internal** IP address; that is only accessible from virtual machines within our private; network. This endpoint is how Batch worker VMs are able to talk to the; Batch Driver Kubernetes Service directly without going through the public; internet. Auth / Auth-Driver; ^^^^^^^^^^^^^^^^^^. The Auth Kubernetes service is responsible for creating new users,; logging in existing users, authenticating requests from log",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:3206,Performance,load,load,3206,"rs are implemented in detail such as; database representations, how cancellation works, how the autoscaler; works, and how billing works. Lastly, we describe what happens on the; worker VMs. Infrastructure; ==============. The Batch system consists of the following Kubernetes; services and cloud infrastructure components:. - Kubernetes Services; - Gateway (gateway); - Internal Gateway (internal-gateway); - Auth (auth); - Auth Driver (auth-driver); - Batch Front End (batch); - Batch Driver (batch-driver); - Worker VMs; - MySQL Database; - Cloud Storage; - Container Registry. Kubernetes Services; -------------------. Gateway; ^^^^^^^. Gateway is a Kubernetes service and associated cloud-provider-managed; external load balancer. It is associated with a statically; known external IP Address. This is the entry point in which external; users send requests to the Batch system such as submitting batches and; getting information on their jobs. There is a an Envoy server behind; the load balancer that forwards requests to the appropriate service. Internal Gateway; ^^^^^^^^^^^^^^^^. Internal Gateway is a Kubernetes service and associated cloud-provider-managed; internal load balancer. Unlike the Gateway, the Internal; Gateway is associated with a statically known **internal** IP address; that is only accessible from virtual machines within our private; network. This endpoint is how Batch worker VMs are able to talk to the; Batch Driver Kubernetes Service directly without going through the public; internet. Auth / Auth-Driver; ^^^^^^^^^^^^^^^^^^. The Auth Kubernetes service is responsible for creating new users,; logging in existing users, authenticating requests from logged in; users, verifying developer status for accessing protected services; like a batch deployment in a developer namespace. We will soon be; changing how authentication / authorization is implemented. Currently,; for REST API requests, a user provides an authorization bearer header; with a Hail-issued token. ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:3396,Performance,load,load,3396,"stly, we describe what happens on the; worker VMs. Infrastructure; ==============. The Batch system consists of the following Kubernetes; services and cloud infrastructure components:. - Kubernetes Services; - Gateway (gateway); - Internal Gateway (internal-gateway); - Auth (auth); - Auth Driver (auth-driver); - Batch Front End (batch); - Batch Driver (batch-driver); - Worker VMs; - MySQL Database; - Cloud Storage; - Container Registry. Kubernetes Services; -------------------. Gateway; ^^^^^^^. Gateway is a Kubernetes service and associated cloud-provider-managed; external load balancer. It is associated with a statically; known external IP Address. This is the entry point in which external; users send requests to the Batch system such as submitting batches and; getting information on their jobs. There is a an Envoy server behind; the load balancer that forwards requests to the appropriate service. Internal Gateway; ^^^^^^^^^^^^^^^^. Internal Gateway is a Kubernetes service and associated cloud-provider-managed; internal load balancer. Unlike the Gateway, the Internal; Gateway is associated with a statically known **internal** IP address; that is only accessible from virtual machines within our private; network. This endpoint is how Batch worker VMs are able to talk to the; Batch Driver Kubernetes Service directly without going through the public; internet. Auth / Auth-Driver; ^^^^^^^^^^^^^^^^^^. The Auth Kubernetes service is responsible for creating new users,; logging in existing users, authenticating requests from logged in; users, verifying developer status for accessing protected services; like a batch deployment in a developer namespace. We will soon be; changing how authentication / authorization is implemented. Currently,; for REST API requests, a user provides an authorization bearer header; with a Hail-issued token. This token is generated when users login and; has a default expiration date for 30 days. UI web requests have an; associated cookie that inc",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:6805,Performance,load,load,6805,"in the; information necessary to fulfill user requests. It also writes job; specs to cloud storage for use downstream by the worker VMs. Batch Driver; ^^^^^^^^^^^^. The Batch Driver is a Kubernetes service responsible for provisioning; worker VMs in response to demand, scheduling jobs on free worker VMs,; and cancelling jobs that no longer should be run. The Driver is; stateless, but only 1 copy can be running at a single time. This is; because our current strategy for knowing how many free cores per VM; are available requires a single process to accurately update the; number of free cores when we schedule a job on a VM. The Driver; communicates with worker VMs when it schedules or unschedules; jobs. The worker VMs then communicate back to the Driver when a worker; is ready to activate itself and start receiving work, notifying a job; has been completed, and deactivating itself when it is idle. The Batch; Driver has a second container inside the pod that is an Envoy server; responsible for maintaining TLS handshakes so as to reduce the CPU; load on the actual Python web server. Worker VMs; ----------. Worker VMs are virtual machines that are created outside of the; Kubernetes cluster. They share a network with the Kubernetes VMs, but; not with the Kubernetes pods. They are created with a default service; account that has permissions to read and write files to cloud storage; such as job specs and job logs as well as delete VMs (so it can delete; itself). Virtual machines are created with a preconfigured boot disk; image that has Docker preinstalled. Startup scripts then initialize; the worker VM, download the worker server application image from a; container registry, and then create the worker Docker container. Once; the worker container is running, it notifies the Batch Driver that it; is active and starts executing jobs. MySQL Database; --------------. All Batch and Auth state is stored in a cloud-provider managed MySQL; database. We use SSL certificates to secure ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:14255,Performance,perform,performance,14255,"pending parent jobs.; - Creating: Creating a VM for job private jobs.; - Running: Job is running on a worker VM.; - Success: Job completed successfully.; - Failed: Job failed.; - Cancelled: Job was cancelled either by the system, by the user, or; because at least one of its parents failed.; - Error: Job failed due to an error in creating the container, an out; of memory error, or a Batch bug (ex: user tries to use a nonexistent; image). The allowed state transitions are: Pending -> Ready Ready ->; {Creating, Running, Cancelled} Creating -> {Running, Cancelled}; Running -> {Success, Failed, Error, Cancelled}. A job's initial state depends on the states of its parent jobs. If it; has no parent jobs, its initial state is Ready. A batch can be in one of the following states:. - completed: All jobs are in a completed state {Success, Failed,; Error, Cancelled}; - running: At least one job is in a non-completed state {Pending,; Ready, Running}. The batch and job states are critical for database performance and; must be indexed appropriately. Batch Front End; ---------------. The Batch Front End service (batch) is a stateless web service that; handles requests from the user. The front end exposes a REST API; interface for handling user requests such as creating a batch,; updating a batch, creating jobs in a batch, getting the status of a; batch, getting the status of a job, listing all the batches in a; billing project, and listing all of the jobs in a batch. There are; usually 3 copies of the batch front end service running at a given; time to be able to handle requests to create jobs in a batch with a; high degree of parallelism. This is necessary for batches with more; than a million jobs. Flow for Creating and Updating Batches; ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^. The following flow is used to create a new batch or update an existing; batch with a set of job specifications:. 1. The client library submits a POST request to create a new batch at; ``/api/v1alpha/batches/",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:21816,Performance,queue,queue,21816," can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autosca",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23068,Performance,perform,performs,23068,"re.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the atte",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:25951,Performance,perform,performance,25951,"that is initiated by the worker VM when; the job completes. The worker sends the start and end time of the; attempt along with the resources it is using. If the attempt does not; exist yet, we create the attempt and subtract the free cores from the; instance in the database. We then update the job state to the; appropriate completed state if it is not already and not been; cancelled or completed already. We then update the start and end times; of the attempt to that given by the worker. We then find all of the; children of the completed job and subtract the number of pending; parents by one. If the child job(s) now have no pending parents, they; are set to have a state of Ready. We also check if this is the last; job in the batch to complete. If so, we change the batch state to; completed. Lastly, we execute a separate database query that inserts; the appropriate resources for that attempt into the database. When we are looking at overall Batch performance, we look at the; metrics of SJ and MJC rates per second for heavy workloads (ex: 1000s; of no-op true jobs). We historically scheduled at 80 jobs per second. We; endeavor to schedule much faster. Canceller; ^^^^^^^^^. The canceller consists of three background loops that cancel any; ready, running, or creating jobs in batches that have been cancelled; or the job specifically has been cancelled (ie. a parent failed). Fair; share is computed by taking the number of cancellable jobs in each; category and dividing by the total number of cancellable jobs and; multiplying by 300 jobs to cancel in each iteration with a minimum of; 20 jobs per user. Billing Updates; ^^^^^^^^^^^^^^^. To provide users with real time billing and effectively enforce; billing limits, we have the worker send us the job attempts it has; running as well as the current time approximately every 1 minute. We; then update the rollup_time for each job which is guaranteed to be; greater than or equal to the start time and less than or equal to the; end",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:29611,Performance,concurren,concurrent,29611,"ed how the database operations SJ, MJS, and MJC; work. There are three key principles in how the database is structured. 1. Any values that are dynamic should be separated from tables that; have static state. For example, to represent that a batch is; cancelled, we have a separate ``batches_cancelled`` table rather; than adding a cancelled field to the ``batches`` table. 2. Any tables with state that is updated in parallel should be; ""tokenized"" in order to reduce contention for updating rows. For; example, when keeping track of the number of running jobs per user; per instance collection, we'll need to update this count for every; schedule job operation. If there is only one row representing this; value, we'll end up serializing the schedule operations as each one; waits for the exclusive write lock. To avoid this, we have up to; 200 rows per value we want to represent where each row has a unique; ""token"". This way concurrent transactions can update rows; simultaneously and the probability of serialized writes is; equivalent to the birthday problem in mathematics. Note that there; is a drawback to this approach in that queries to obtain the actual; value are more complicated to write as they include an aggregation; and the number of rows to store this in the database can make; queries slower and data more expensive to store. Key tables have triggers on them to support billing, job state counts,; and fast cancellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query speed is linear in the number of total; attempts when computing the cost for a batch by scanning over the; entire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt durati",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:31075,Performance,perform,perform,31075,"ellation which will be described in more detail below. Billing; ^^^^^^^. Billing is implemented by keeping track of the resources each attempt; uses as well as the duration of time each attempt runs for. It is; trivial to write a query to compute the cost per attempt or even per; job. However, the query speed is linear in the number of total; attempts when computing the cost for a batch by scanning over the; entire table which is a non-starter for bigger batches. Therefore, we; keep an ``aggregated_batch_resources`` table where each update to the; attempt duration timestamps or inserting a new attempt resource; updates the corresponding batch in the table. This table is; ""tokenized"" as described above to prevent serialization of attempt; update events. Likewise, we have similar aggregation tables for; billing projects as well as billing project by date. There are two; triggers, one on each of the ``attempts`` and ``attempt_resources``; table that perform the usage updates and insert the appropriate rows; to these billing tables every time the attempt rollup time is changed; or a new resource is inserted for an attempt. Having these aggregation; tables means we can query the cost of a billing project, billing; project by date, batch, or job by scanning at most 200 records making; this query fast enough for a UI page. The workers send the driver; periodic updates every minute with the elapsed time jobs have been; running for such that we can have ""real-time billing"". Job State Tracking; ^^^^^^^^^^^^^^^^^^. To quickly be able to count the number of ready jobs, ready cores,; running jobs, running cores, creating jobs, and creating cores for; computing fair share, we maintain a very small ""tokenized"" table that; is parameterized by user and instance collection. The values in this; table are automatically updated as a job's state is changed through; the job state diagram. The updates to the ``user_inst_coll_resources``; table happen in a trigger on the ``jobs`` table. Canc",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:18099,Safety,avoid,avoid,18099,"thon; client library, a user provides a query filtering string as well as an; optional starting ID. The server then sends the next 50 records in; response and it is up to the client to send the next request with the; ID of the last record returned in the subsequent request. Batch Driver; ------------. The Batch Driver is a Kubernetes service that creates a fleet of; worker VMs in response to user workloads and has mechanisms in place; for sharing resources fairly across users. It also has many background; processes to make sure orphaned resources such as disks and VMs are; cleaned up, billing prices for resources are up to date, and; cancelling batches with more than N failures if specified by the; user. The service can be located on a preemptible machine, but we use; a non-preemptible machine to minimize downtime, especially when the; cluster is large. There can only be one driver service in existence at; any one time. There is an Envoy side car container in the batch driver; pod to handle TLS handshakes to avoid excess CPU usage of the batch; driver. Instance Collections; ^^^^^^^^^^^^^^^^^^^^. The batch driver maintains two different types of collections of; workers. There are **pools** that are multi-tenant and have a; dedicated worker type that is shared across all jobs. Pools can; support both preemptible and nonpreemptible VMs. Right now, there are; three types of machine types we support that correspond to low memory; (~1GB memory / core), standard (~4GB memory / core), and high memory; (~8GB memory / core) machines. These are correspondingly the; ""highcpu"", ""standard"", and ""highmem"" pools. Each pool has its own; scheduler and autoscaler. In addition, there's a single job private; instance manager that creates a worker VM per job and is used if the; worker requests a specific machine type. This is used commonly for; jobs that require more memory than a 16 core machine can provide. Fair Share; ^^^^^^^^^^. In order to avoid having one user starve other users fro",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:19032,Safety,avoid,avoid,19032,"LS handshakes to avoid excess CPU usage of the batch; driver. Instance Collections; ^^^^^^^^^^^^^^^^^^^^. The batch driver maintains two different types of collections of; workers. There are **pools** that are multi-tenant and have a; dedicated worker type that is shared across all jobs. Pools can; support both preemptible and nonpreemptible VMs. Right now, there are; three types of machine types we support that correspond to low memory; (~1GB memory / core), standard (~4GB memory / core), and high memory; (~8GB memory / core) machines. These are correspondingly the; ""highcpu"", ""standard"", and ""highmem"" pools. Each pool has its own; scheduler and autoscaler. In addition, there's a single job private; instance manager that creates a worker VM per job and is used if the; worker requests a specific machine type. This is used commonly for; jobs that require more memory than a 16 core machine can provide. Fair Share; ^^^^^^^^^^. In order to avoid having one user starve other users from getting; their jobs run, we use the following fair share algorithm. We start; with the user who has the fewest cores running. We then allocate as; many cores as possible that are live in the cluster until we reach the; number of cores the next user has currently running. We then divide up; the remaining cores equally amongst the two users until we reach the; number of cores the next user has running. We repeat until we have; either exhausted all free cores in the cluster or have satisfied all; user resource requests. The query to get the number of ready cores in the fair; share algorithm is fast because we aggregate across a global table; ``user_inst_coll_resources`` that has a limited number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autos",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:20343,Safety,avoid,avoid,20343,"ext user has currently running. We then divide up; the remaining cores equally amongst the two users until we reach the; number of cores the next user has running. We repeat until we have; either exhausted all free cores in the cluster or have satisfied all; user resource requests. The query to get the number of ready cores in the fair; share algorithm is fast because we aggregate across a global table; ``user_inst_coll_resources`` that has a limited number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autoscaler takes the number of; ready cores total across all users and divides up that amount by the; number of cores per worker to get the number of instances that are; required. It then spins up a configurable number of instances each; time the autoscaler runs to avoid cloud provider API rate limits. This; approach works well for large workloads that have long running; jobs. However, the autoscaler can produce more cores than the; scheduler can keep busy with work. This happens when there are many; jobs with a short execution time. Due to differences in resource prices across regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:20825,Safety,avoid,avoid,20825," number of rows; maintaining counts of the number of ready cores per instance; collection and user. Autoscaler; ^^^^^^^^^^. At a high level, the autoscaler is in charge of figuring out how many; worker VMs are required to run all of the jobs that are ready to run; without wasting resources. The simplest autoscaler takes the number of; ready cores total across all users and divides up that amount by the; number of cores per worker to get the number of instances that are; required. It then spins up a configurable number of instances each; time the autoscaler runs to avoid cloud provider API rate limits. This; approach works well for large workloads that have long running; jobs. However, the autoscaler can produce more cores than the; scheduler can keep busy with work. This happens when there are many; jobs with a short execution time. Due to differences in resource prices across regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit o",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:21684,Safety,avoid,avoid,21684,"ross regions and extra fees; for inter-region data transfer, the autoscaler needs to be aware of; the regions a job can run in when scaling up the cluster in order to; avoid suboptimal cluster utilization or jobs not being able to be; scheduled due to a lack of resources. The current autoscaler works by running every 15 seconds and executing; the following operations to determine the optimal number of instances; to spin up per region:. 1. Get the fair share resource allocations for each user across all; regions and figure out the share for each user out of 300 (this; represents number of scheduling opportunities this user gets; relative to other users).; 2. For every user, sort the ""Ready"" jobs by regions the job can run in; and take the first N jobs where N is equal to the user share; computed in (1) multiplied by the autoscaler window, which is; currently set to 2.5 minutes. The logic behind this number is it; takes ~2.5 minutes to spin up a new instance so we only want to; look at a small window at a time to avoid spinning up too many; instances. It also makes this query feasible to set a limit on it; and only look at the head of the job queue.; 3. Take the union of the result sets for all of the users in (2) in; fair share order. Do another pass over the result set where we; assign each job a scheduling iteration which represents an estimate; of which iteration of the scheduler that job will be scheduled in; assuming the user's fair share.; 4. Sort the result set by user fair share and the scheduling iteration; and the regions that job can run in. Aggregate the free cores by; regions in order in the result set. This becomes the number of free; cores to use when computing the number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocati",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst:23275,Safety,timeout,timeout,23275,"number of required instances and; the possible regions the instance can be spun up in. Scheduler; ^^^^^^^^^. The scheduler finds the set of jobs to schedule by iterating through; each user in fair share order and then scheduling jobs with a ""Ready""; state until the user's fair share allocation has been met. The result; set for each user is sorted by regions so that the scheduler matches; what the autoscaler is trying to provision for. The logic behind; scheduling is not very sophisticated so it is possible to have a job; get stuck if for example it requires 8 cores, but two instances are; live with 4 cores each. Once the scheduler has assigned jobs to their respective instances,; the scheduler performs the work necessary to grab any secrets from; Kubernetes, update the job state and add an attempt in the database,; and then communicate with the worker VM to start running the; job. There must be a timeout on this scheduling attempt that is short; (1 second) in order to ensure that a delay in one job doesn't cause; the scheduler to get stuck waiting for that one job to be finished; scheduling. We wait at the end of the scheduling iteration for all; jobs to finish scheduling. If we didn't wait, then we might try and; reschedule the same job multiple times before the original operation; to schedule the job in the database completes. Job State Updates; ^^^^^^^^^^^^^^^^^. There are three main job state update operations:; - SJ: Schedule Job; - MJS: Mark job started; - MJC: Mark job completed. SJ is a database operation (stored procedure) that happens on the; driver before the job has been scheduled on the worker VM. In the; stored procedure, we check whether an attempt already exists for this; job. If it does not, we create the attempt and subtract the free cores; from the instance in the database. If it does exist, then we don't do; anything. We check the batch has not been cancelled or completed and; the instance is active before setting the job state to Running. MJS is ",MatchSource.DOCS,dev-docs/services/batch/design.rst,hail-is,hail,0.2.133,https://hail.is,https://github.com/hail-is/hail/tree/0.2.133/dev-docs/services/batch/design.rst
