id,quality_attribute,keyword,matched_word,match_idx,sentence,source,author,repo,version,wiki,url
https://github.com/su2code/SU2/issues/643#issuecomment-463561018:1444,Deployability,release,release,1444,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
https://github.com/su2code/SU2/issues/643#issuecomment-463561018:178,Integrability,rout,routines,178,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
https://github.com/su2code/SU2/issues/643#issuecomment-463561018:465,Integrability,interface,interfaces,465,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
https://github.com/su2code/SU2/issues/643#issuecomment-463561018:876,Integrability,depend,depend,876,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
https://github.com/su2code/SU2/issues/643#issuecomment-463561018:1215,Testability,test,testcase,1215,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
https://github.com/su2code/SU2/issues/643#issuecomment-463561018:459,Usability,clear,clear,459,"On both questions the answer is yes. Option 1 can be implemented right now but will require the creation of temporary objects. Option 2 can directly forward the data to the blas routines. The tool I am developing is no tool for a specific linear algebra package. The idea is, that the tool parses the header files of the library. The user has then to define which objects are active lvalues and the derivatives for each operation in the library. For small an clear interfaces this is no problem and works already quite good. For large libraries like Eigen I adopted a whitelisting approach. That is, every function needs to be manually whitelisted to trigger the expression generation of the tool. In a prototype way I have also implemented an approach where only the active lvalues need to be defined and the tool looks then for all required functions and other objects that depend on these active objects. Long story short, the tool is designed to handle ""any"" library. It is even possible to mix several libraries together. My current status on this project is, that I am now through with the parsing of the header files and the generation of the expressions. This works quite well for Eigen which is a hardcore testcase, since every possible programming tweak in C++ is used here. The next step is to add the AD part to the expression generation process. I hope that in one or two month this will be finished and I can provide a first beta release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463561018
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:72,Deployability,update,update,72,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:886,Energy Efficiency,efficient,efficient,886,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:969,Integrability,depend,dependency,969,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:95,Performance,perform,performance,95,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:203,Performance,perform,performance,203,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:293,Performance,perform,performance,293,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:619,Performance,perform,performance,619,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:765,Performance,perform,perform,765,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-463591821:837,Performance,perform,performance,837,"Thanks Max that sounds very promising indeed. To everyone else, a quick update on the issue of performance vs. MKL.; I played a bit with @vdweide 's case and it does not seem trivial to get those 10% of performance back, at least not without a lot of restructuring.; I did however measure the performance of native gemm in Eigen to be ""only"" 2.5 times worse than MKL, after some emails we determined that this was because with the Intel compiler Eigen was not using AVX instructions but with g++ those instructions could be enabled by setting the -march flag appropriately. So far the conclusions are:; - Get 0% to 10% performance loss if you are using MKL (one could always bypass Eigen and call mkl directly).; - Write clean code compatible with AD and that will perform better than most easy implementations.; - Eventually get better performance of the discrete adjoint via the more efficient differentiation of operations with matrix-like objects.; - Have an extra dependency that does not need to be compiled.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-463591821
https://github.com/su2code/SU2/issues/643#issuecomment-592951260:118,Usability,simpl,simpler,118,"Closing this for now. After talking with @oleburghardt and @talbring there are features being worked on that are much simpler to develop using Eigen, we may see a PR for that in the not too distant future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/643#issuecomment-592951260
https://github.com/su2code/SU2/issues/644#issuecomment-461567798:143,Integrability,rout,routine,143,"I think there are two options, but both will require checking the code. . 1) Go into grid_movement_structure.cpp and hack the Rigid_Pitching() routine to use your own function in time. Not elegant, but should just be a couple of lines to change. 2) A more general feature was implemented in the past to specify movement of surfaces in time by position of all surface nodes, but should be checked to make sure it is still working as expected. To use it, select 'EXTERNAL' as the grid movement type and provide a file with the surface node positions for each time step. Check in CSurfaceMovement::SetExternal_Deformation() for more info. If you are interested in developing a better solution as a contribution, we are always open!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/644#issuecomment-461567798
https://github.com/su2code/SU2/issues/645#issuecomment-460483539:879,Availability,down,down,879,"Given that this isn't the first attempt at consolidating communication & discussion threads (including slack and SU2 IDS); could you describe in a little more detail how the discussions on rocket.chat will be different from those on github threads like this one, or from the threads on cfd-online/forums/su2?. I'm sure it's a great service, and I can tell that you've put a lot of thought into what to use, I just feel like it's the third or fourth time I've had to sign up for something new just in order to stay in the loop, and each time I get a little more concerned that I will end up accidentally missing the next platform change and never hearing SU2 news again (which would make me sad - I know i haven't been participating much lately, but I do often read the pull request discussions when an interesting one pops up in my email). . FYI, the SU2 IDS website seems to be down - is that temporary or has it already been retired? If rocket.chat works out, will that mean that both slack and SU2 IDS will be retired?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-460483539
https://github.com/su2code/SU2/issues/645#issuecomment-464602965:325,Deployability,update,updates,325,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965
https://github.com/su2code/SU2/issues/645#issuecomment-464602965:149,Modifiability,evolve,evolve,149,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965
https://github.com/su2code/SU2/issues/645#issuecomment-464602965:651,Usability,feedback,feedback,651,"@hlkline : it is true that we have been experimenting a lot to find the best formula, and no doubt we will continue to tweak things as we constantly evolve. But, one constant you can always trust is that the repo will be the home for important decisions on issues and PRs, so there is no need to worry about missing critical updates. . With slack and now rocket chat, we are looking to improve communication efficiency as people collaborate on particular developments in the code (say in pairs or small groups), or perhaps in the future, it can be opened to the public as a sort of support channel. This is to be seen as we gather some experience and feedback.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-464602965
https://github.com/su2code/SU2/issues/645#issuecomment-494262838:95,Integrability,message,message,95,"Status?; At may 21, 9AM europe time, 2019; I am getting a ; ""This Workspace has been Stopped""; message from URL; https://su2.rocket.chat/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-494262838
https://github.com/su2code/SU2/issues/645#issuecomment-515048317:80,Testability,log,log,80,"For the time being, lets use Gitter to communicate! Its free and you can simply log in with your github account. https://gitter.im/su2code/community",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515048317
https://github.com/su2code/SU2/issues/645#issuecomment-515048317:73,Usability,simpl,simply,73,"For the time being, lets use Gitter to communicate! Its free and you can simply log in with your github account. https://gitter.im/su2code/community",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515048317
https://github.com/su2code/SU2/issues/645#issuecomment-515093449:131,Security,access,access,131,"There might be a problem here: If I understood correctly once you login to Gritter using your GitHub account, it opens all the git access that you have to all the community that is in the Gritter group.; I have, and probably other people also do, access to GitHub locations (other than SU2) which are not open for the public (like Github of commercial companies). In the Gritter login page, I could see all these locations but could not remove those that are not SU2 related.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515093449
https://github.com/su2code/SU2/issues/645#issuecomment-515093449:247,Security,access,access,247,"There might be a problem here: If I understood correctly once you login to Gritter using your GitHub account, it opens all the git access that you have to all the community that is in the Gritter group.; I have, and probably other people also do, access to GitHub locations (other than SU2) which are not open for the public (like Github of commercial companies). In the Gritter login page, I could see all these locations but could not remove those that are not SU2 related.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515093449
https://github.com/su2code/SU2/issues/645#issuecomment-515093449:66,Testability,log,login,66,"There might be a problem here: If I understood correctly once you login to Gritter using your GitHub account, it opens all the git access that you have to all the community that is in the Gritter group.; I have, and probably other people also do, access to GitHub locations (other than SU2) which are not open for the public (like Github of commercial companies). In the Gritter login page, I could see all these locations but could not remove those that are not SU2 related.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515093449
https://github.com/su2code/SU2/issues/645#issuecomment-515093449:379,Testability,log,login,379,"There might be a problem here: If I understood correctly once you login to Gritter using your GitHub account, it opens all the git access that you have to all the community that is in the Gritter group.; I have, and probably other people also do, access to GitHub locations (other than SU2) which are not open for the public (like Github of commercial companies). In the Gritter login page, I could see all these locations but could not remove those that are not SU2 related.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515093449
https://github.com/su2code/SU2/issues/645#issuecomment-515101184:33,Security,access,access,33,You have to restrict third-party access in the options of the other project (https://help.github.com/en/articles/enabling-oauth-app-access-restrictions-for-your-organization),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515101184
https://github.com/su2code/SU2/issues/645#issuecomment-515101184:132,Security,access,access-restrictions-for-your-organization,132,You have to restrict third-party access in the options of the other project (https://help.github.com/en/articles/enabling-oauth-app-access-restrictions-for-your-organization),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/645#issuecomment-515101184
https://github.com/su2code/SU2/issues/646#issuecomment-459997523:306,Performance,perform,performing,306,"@BBArrosDias : thanks for the question. At the moment, there are no plans for Cmake. If this is a major pain point for the community (or if someone in the community has already added it and would like to contribute it), we are happy to consider it. Overall, folks seem fairly pleased with how autotools is performing on many different platforms.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/646#issuecomment-459997523
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3725,Availability,toler,tolerance,3725," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2535,Deployability,integrat,integration,2535,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2292,Integrability,interface,interface,2292,"ETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approxima",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2535,Integrability,integrat,integration,2535,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:1231,Modifiability,portab,portability,1231,"n on the library we choose, but he seems to be in favor of [PETSc](https://www.mcs.anl.gov/petsc/) from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details.; > ; > Another one that's come up in our discussions is [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) from LLNL which has a GNU LGPL. >@juanjosealonso ; >(...) While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense….but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). (...). >@erangit; >I also support external libraries usage (no need to repeat the many advantages as it is well described above) but I think we should be very wary of portability issues. For instance in SUMB, PETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conser",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:515,Performance,scalab,scalable-linear-solvers-multigrid-methods,515,">@bmunguia ; > @EduardoMolina and I have discussed this over the past few weeks and are also in favor of using an external library. I don't have a strong opinion on the library we choose, but he seems to be in favor of [PETSc](https://www.mcs.anl.gov/petsc/) from ANL, which has a 2-clause BSD license and is used by ADflow (formerly SUmb), among other solvers. Eduardo could probably provide more details.; > ; > Another one that's come up in our discussions is [HYPRE](https://computation.llnl.gov/projects/hypre-scalable-linear-solvers-multigrid-methods) from LLNL which has a GNU LGPL. >@juanjosealonso ; >(...) While PETSc is a wonderful library (and parallel), I would hesitate to use it as the solution for the problem that we are trying to solve: it is not the easiest thing to compile and it is most definitely not lightweight. If one also wanted to replace Krylov-space solvers and preconditioners in SU2 the PETSc might make more sense….but it still forces the developer to conform to their view of the world (including matrix setup and decomposition). (...). >@erangit; >I also support external libraries usage (no need to repeat the many advantages as it is well described above) but I think we should be very wary of portability issues. For instance in SUMB, PETSc was used for the Krylov solvers and more. While indeed it worked well and in parallel mode, each new implementation was a nightmare. LAPACK/BLAS package, on the other hand, provides a much easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2949,Performance,perform,performance,2949,"dweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3877,Performance,perform,performant,3877," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2446,Security,access,access,2446,"easier implementation experience. Certainly, this is not the only consideration but it should be taken into account. Currently, resulting from the significant contributions of the members of this developers group, SU2 implementation works like a charm. I think we should strive to conserve this feature, especially if we aim at attracting more users and developers into the community. (...). >@vdweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3453,Testability,test,test,3453," to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the Jacobians we construct to see if we can improve, or even try exact Jacobians with AD if we can afford it. A more advanced CFL ramping strategy could also be helpful here to get us closer to a solution before trying to aggressively converge. I think that is everyone.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:2821,Usability,feedback,feedback,2821,"dweide; >(...) @bmunguia and @EduardoMolina, what type of application did you have in mind for PETSc? The only thing I can think of is a full Newton solver. And no matter how much I like PETSc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460853218:3095,Usability,simpl,simply,3095,"Sc, @juanjosealonso and @erangit have a point here. Looks like I start to belong to the group of old conservatives as well.... >@economon ; >(...) If you really would like to give PETSc a shot, I recommend talking with @anilvar who had an interface for connecting it to SU2 in one of our branches. >@pcarruscag; >(...) being able to use PETSc or HYPRE would be interesting as it would give us access to AMG, and @talbring 's branch feature_template_linear_solver would make such an integration compatible with AD. (...). >@EduardoMolina; >(...) When Brian (@bmunguia ) and I mentioned PETSc, it was an idea to try a different Newton-Krylov (with preconditioner) library in order to improve the convergence of SU2.; Since the slow convergence of the SU2-FV is the main feedback that I received from other users from industry and academia, I think it worth try an external library and evaluate the performance. (...). >@pcarruscag ; >(...) That is something I am also interested in as for some of my structural cases the current linear solvers simply do not converge. (...). >@economon ; >I would add one practical comment for consideration: it is worth checking whether the main restriction we have is related to approximations in the Jacobian that limit the effective CFL we can use or whether the convergence of the linear solver itself is a problem (speed or complete lack of convergence). A quick test without resorting to another library is to increase the fill-in for ILU-preconditioned GMRES, which is very expensive/slow but should converge difficult problems, and to check how high we can take the CFL when allowing each nonlinear iteration to converge to a tight tolerance in the linear solver, say 1e-14 (you can output the linear solver residuals to verify convergence). If we can take the CFL higher with a more performant linear solver, then it could be worth the effort to try other options.; >If the CFL must remain low for stability, then perhaps we should look at the quality of the J",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460853218
https://github.com/su2code/SU2/issues/648#issuecomment-460875622:1200,Availability,avail,available,1200,"Following this discussion, I want to share certain points related to convergence -. 1- Some good/fast solution initialisation methods will be helpful to start with (commercial solver like Fluent uses Full Multigrid initialisation /FMG - euler initialisation, which provides fast initial guess to start with). 2- Switching from first order to second order gradually will be helpful. 3- Smart/tuned CFL ramping strategy (some commercial codes have tuned way of doing it where CFL range varies from subsonic to hypersonic Mach number). 4- As Dr. Economon mentioned exact Jacobians play important role (In SU2 code, HLLC, JST and Roe have exact/nearly exact Jacobians). I observed that with inconsistent discretization (with some of the problems), solution does not go with higher CFL even in later stages and takes more iterations to converge. 5- It will be desirable to arrive at fewer set/combination of Linear solver+preconditioner which covers broad range of problems. That will help in faster evolution of solution convergence strategies . 6- Handling poor quality cells in some way may be important from practical usage point of view with realistic geometries (I don’t know how much literature is available for such stuff). Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460875622
https://github.com/su2code/SU2/issues/648#issuecomment-460875622:391,Performance,tune,tuned,391,"Following this discussion, I want to share certain points related to convergence -. 1- Some good/fast solution initialisation methods will be helpful to start with (commercial solver like Fluent uses Full Multigrid initialisation /FMG - euler initialisation, which provides fast initial guess to start with). 2- Switching from first order to second order gradually will be helpful. 3- Smart/tuned CFL ramping strategy (some commercial codes have tuned way of doing it where CFL range varies from subsonic to hypersonic Mach number). 4- As Dr. Economon mentioned exact Jacobians play important role (In SU2 code, HLLC, JST and Roe have exact/nearly exact Jacobians). I observed that with inconsistent discretization (with some of the problems), solution does not go with higher CFL even in later stages and takes more iterations to converge. 5- It will be desirable to arrive at fewer set/combination of Linear solver+preconditioner which covers broad range of problems. That will help in faster evolution of solution convergence strategies . 6- Handling poor quality cells in some way may be important from practical usage point of view with realistic geometries (I don’t know how much literature is available for such stuff). Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460875622
https://github.com/su2code/SU2/issues/648#issuecomment-460875622:446,Performance,tune,tuned,446,"Following this discussion, I want to share certain points related to convergence -. 1- Some good/fast solution initialisation methods will be helpful to start with (commercial solver like Fluent uses Full Multigrid initialisation /FMG - euler initialisation, which provides fast initial guess to start with). 2- Switching from first order to second order gradually will be helpful. 3- Smart/tuned CFL ramping strategy (some commercial codes have tuned way of doing it where CFL range varies from subsonic to hypersonic Mach number). 4- As Dr. Economon mentioned exact Jacobians play important role (In SU2 code, HLLC, JST and Roe have exact/nearly exact Jacobians). I observed that with inconsistent discretization (with some of the problems), solution does not go with higher CFL even in later stages and takes more iterations to converge. 5- It will be desirable to arrive at fewer set/combination of Linear solver+preconditioner which covers broad range of problems. That will help in faster evolution of solution convergence strategies . 6- Handling poor quality cells in some way may be important from practical usage point of view with realistic geometries (I don’t know how much literature is available for such stuff). Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460875622
https://github.com/su2code/SU2/issues/648#issuecomment-460908007:389,Modifiability,flexible,flexible,389,"There is one thing that is not mentioned yet, which is rather important. I assume we are talking RANS here. In that case it does not make sense to ramp up the CFL number to values higher than 50 or so with the current segregated setup of mean flow, turbulence and possibly transition solvers (not even talking about multidisciplinary problems). The segregated character makes it extremely flexible for adding additional models, but it does not work for a full blown Newton solver. In that case you have to switch to a strong coupling between the mean flow and the turbulence solver, which will require a significant change in the data-structures. Also, computing the exact Jacobians for a second order scheme is not trivial and as Tom mentioned, it may be needed to use AD tools for that, which makes it quite costly. Furthermore the memory usage for storing the exact Jacobians is very big. An alternative would be to use a matrix free approach, i.e. use a Frechet derivative for the matrix vector products in the Krylov solver (although you still need a good preconditioner). When a coupled with a turbulence model (especially k-omega type models), this will be extremely sensitive to the epsilon parameter you have to choose. There are ways around this, e.g. using dual numbers and possibly with CoDiPack, but these will increase your computational cost by at least a factor of 4. I think it is definitely worth trying, but seen all the pitfalls you may run into, you may want to test things out first with a test solver before implementing it in SU2 itself. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460908007
https://github.com/su2code/SU2/issues/648#issuecomment-460908007:525,Modifiability,coupling,coupling,525,"There is one thing that is not mentioned yet, which is rather important. I assume we are talking RANS here. In that case it does not make sense to ramp up the CFL number to values higher than 50 or so with the current segregated setup of mean flow, turbulence and possibly transition solvers (not even talking about multidisciplinary problems). The segregated character makes it extremely flexible for adding additional models, but it does not work for a full blown Newton solver. In that case you have to switch to a strong coupling between the mean flow and the turbulence solver, which will require a significant change in the data-structures. Also, computing the exact Jacobians for a second order scheme is not trivial and as Tom mentioned, it may be needed to use AD tools for that, which makes it quite costly. Furthermore the memory usage for storing the exact Jacobians is very big. An alternative would be to use a matrix free approach, i.e. use a Frechet derivative for the matrix vector products in the Krylov solver (although you still need a good preconditioner). When a coupled with a turbulence model (especially k-omega type models), this will be extremely sensitive to the epsilon parameter you have to choose. There are ways around this, e.g. using dual numbers and possibly with CoDiPack, but these will increase your computational cost by at least a factor of 4. I think it is definitely worth trying, but seen all the pitfalls you may run into, you may want to test things out first with a test solver before implementing it in SU2 itself. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460908007
https://github.com/su2code/SU2/issues/648#issuecomment-460908007:1483,Testability,test,test,1483,"There is one thing that is not mentioned yet, which is rather important. I assume we are talking RANS here. In that case it does not make sense to ramp up the CFL number to values higher than 50 or so with the current segregated setup of mean flow, turbulence and possibly transition solvers (not even talking about multidisciplinary problems). The segregated character makes it extremely flexible for adding additional models, but it does not work for a full blown Newton solver. In that case you have to switch to a strong coupling between the mean flow and the turbulence solver, which will require a significant change in the data-structures. Also, computing the exact Jacobians for a second order scheme is not trivial and as Tom mentioned, it may be needed to use AD tools for that, which makes it quite costly. Furthermore the memory usage for storing the exact Jacobians is very big. An alternative would be to use a matrix free approach, i.e. use a Frechet derivative for the matrix vector products in the Krylov solver (although you still need a good preconditioner). When a coupled with a turbulence model (especially k-omega type models), this will be extremely sensitive to the epsilon parameter you have to choose. There are ways around this, e.g. using dual numbers and possibly with CoDiPack, but these will increase your computational cost by at least a factor of 4. I think it is definitely worth trying, but seen all the pitfalls you may run into, you may want to test things out first with a test solver before implementing it in SU2 itself. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460908007
https://github.com/su2code/SU2/issues/648#issuecomment-460908007:1512,Testability,test,test,1512,"There is one thing that is not mentioned yet, which is rather important. I assume we are talking RANS here. In that case it does not make sense to ramp up the CFL number to values higher than 50 or so with the current segregated setup of mean flow, turbulence and possibly transition solvers (not even talking about multidisciplinary problems). The segregated character makes it extremely flexible for adding additional models, but it does not work for a full blown Newton solver. In that case you have to switch to a strong coupling between the mean flow and the turbulence solver, which will require a significant change in the data-structures. Also, computing the exact Jacobians for a second order scheme is not trivial and as Tom mentioned, it may be needed to use AD tools for that, which makes it quite costly. Furthermore the memory usage for storing the exact Jacobians is very big. An alternative would be to use a matrix free approach, i.e. use a Frechet derivative for the matrix vector products in the Krylov solver (although you still need a good preconditioner). When a coupled with a turbulence model (especially k-omega type models), this will be extremely sensitive to the epsilon parameter you have to choose. There are ways around this, e.g. using dual numbers and possibly with CoDiPack, but these will increase your computational cost by at least a factor of 4. I think it is definitely worth trying, but seen all the pitfalls you may run into, you may want to test things out first with a test solver before implementing it in SU2 itself. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/648#issuecomment-460908007
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:284,Availability,Error,Error,284,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:499,Availability,Error,Error,499,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:639,Availability,error,error,639,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:795,Availability,Error,Error,795,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:820,Availability,error,errors,820,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:847,Availability,error,errors,847,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:291,Integrability,rout,routine,291,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:840,Security,expose,expose,840,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:19,Testability,test,testing,19,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:79,Testability,test,tests,79,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:122,Testability,test,tests,122,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:561,Testability,test,tests,561,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:607,Testability,test,tests,607,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:931,Testability,test,tests,931,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-462951152:245,Usability,simpl,simple,245,"If you look at the testing history, commit 4f5f3ed doesn't pass the regression tests, while commit 8551cac does. Only two tests are failing on 4f5f3ed: `discadj_topol_optim` and `discadj_fsi_airfoil`. The difference between the two commits is a simple change. I changed the `SU2_MPI::Error` routine to give a return status of `EXIT_FAILURE` instead of `0`. Since `0` is conventionally defined as a successful program exit, returning `EXIT_FAILURE` makes more sense than returning `0` when `SU2_MPI::Error` is called. So why did that change cause the regression tests to fail? My suspicion is that these two tests have been exiting with an error for some time, but these regressions were not picked up by Travis since SU2 kept on returning `0` (i.e. success). Changing the exit code of `SU2_MPI::Error` doesn't cause any errors, but it will expose errors that are (sometimes silently) occurring. @pcarruscag I think you added these tests. Any idea why they're failing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-462951152
https://github.com/su2code/SU2/pull/649#issuecomment-463602220:198,Testability,test,tests,198,They should be due to SU2_SOL not playing nice with the discrete adjoint for a while.; I think @economon put a fix for that in #641?; @clarkpede can you apply the EXIT_FAILURE change to #641? Those tests should pass there.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463602220
https://github.com/su2code/SU2/pull/649#issuecomment-463668790:612,Modifiability,config,config,612,"> Thanks for the PR! I just have a single question: Why Set_MPI_MaxLength needed to be called 2 times for periodic boundaries?; > ; > LGTM! If Travis pass, we are ready to merge.; > Eduardo. To be honest, I don't know. I just know that that:. + Without calling it twice, the max length is not initialized on some of the periodic halo nodes.; + When you do call it twice, the max length is initialized on all periodic halo nodes. Something similar happens when loading a solution from a restart file, where the solver needs to do something like this:. solver[MESH_0][FLOW_SOL]->Set_MPI_Solution(geometry[MESH_0], config);; solver[MESH_0][FLOW_SOL]->Set_MPI_Solution(geometry[MESH_0], config);. @economon Do you know why the MPI calls need to be made twice?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463668790
https://github.com/su2code/SU2/pull/649#issuecomment-463668790:683,Modifiability,config,config,683,"> Thanks for the PR! I just have a single question: Why Set_MPI_MaxLength needed to be called 2 times for periodic boundaries?; > ; > LGTM! If Travis pass, we are ready to merge.; > Eduardo. To be honest, I don't know. I just know that that:. + Without calling it twice, the max length is not initialized on some of the periodic halo nodes.; + When you do call it twice, the max length is initialized on all periodic halo nodes. Something similar happens when loading a solution from a restart file, where the solver needs to do something like this:. solver[MESH_0][FLOW_SOL]->Set_MPI_Solution(geometry[MESH_0], config);; solver[MESH_0][FLOW_SOL]->Set_MPI_Solution(geometry[MESH_0], config);. @economon Do you know why the MPI calls need to be made twice?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463668790
https://github.com/su2code/SU2/pull/649#issuecomment-463668790:460,Performance,load,loading,460,"> Thanks for the PR! I just have a single question: Why Set_MPI_MaxLength needed to be called 2 times for periodic boundaries?; > ; > LGTM! If Travis pass, we are ready to merge.; > Eduardo. To be honest, I don't know. I just know that that:. + Without calling it twice, the max length is not initialized on some of the periodic halo nodes.; + When you do call it twice, the max length is initialized on all periodic halo nodes. Something similar happens when loading a solution from a restart file, where the solver needs to do something like this:. solver[MESH_0][FLOW_SOL]->Set_MPI_Solution(geometry[MESH_0], config);; solver[MESH_0][FLOW_SOL]->Set_MPI_Solution(geometry[MESH_0], config);. @economon Do you know why the MPI calls need to be made twice?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463668790
https://github.com/su2code/SU2/pull/649#issuecomment-463711280:529,Deployability,update,updated,529,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
https://github.com/su2code/SU2/pull/649#issuecomment-463711280:632,Deployability,update,update,632,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
https://github.com/su2code/SU2/pull/649#issuecomment-463711280:673,Deployability,update,updated,673,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
https://github.com/su2code/SU2/pull/649#issuecomment-463711280:353,Integrability,synchroniz,synchronized,353,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
https://github.com/su2code/SU2/pull/649#issuecomment-463711280:975,Testability,test,testing,975,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
https://github.com/su2code/SU2/pull/649#issuecomment-463711280:724,Usability,clear,clear,724,"@clarkpede @EduardoMolina : yep, the issue is that the periodic and MPI communications are tangled up together in the current implementation. The main issue occurs when there are periodic points that are also ghost nodes. . Ideally the periodic and MPI would be separated, and the periodic communications would happen first so that all periodic BCs are synchronized before trying to send across partitions. Right now, the comms are mixed, so sometimes, we send old data at periodic points to their matching pair, which then gets updated in a later MPI comm. Therefore, the second call you have added to the MPI resends the periodic update to with the correct data that was updated with MPI in the first call. I hope this is clear.. Anyway, please go with this change as you have it. All of the MPI and periodic comms will be replaced with a cleaner/separated version right after v6.2.0 (you can see what I am working on in feature_mpi_periodic). I will likely need some help testing that soon :).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463711280
https://github.com/su2code/SU2/pull/649#issuecomment-463729246:46,Usability,clear,clear,46,Hi @clarkpede and @economon .; Thanks for the clear explanation.; Merging now. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/649#issuecomment-463729246
https://github.com/su2code/SU2/pull/650#issuecomment-464221279:291,Deployability,update,updated,291,"Residuals changed in testcase transonic_rotor_2D, I do not know why since it uses FGMRES and in that method I only changed the allocation.; I ran the case to convergence and [compared](https://github.com/su2code/SU2/files/2871054/transonic_stator_2D.zip) the output, everything matches so I updated the residuals.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/650#issuecomment-464221279
https://github.com/su2code/SU2/pull/650#issuecomment-464221279:21,Testability,test,testcase,21,"Residuals changed in testcase transonic_rotor_2D, I do not know why since it uses FGMRES and in that method I only changed the allocation.; I ran the case to convergence and [compared](https://github.com/su2code/SU2/files/2871054/transonic_stator_2D.zip) the output, everything matches so I updated the residuals.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/650#issuecomment-464221279
https://github.com/su2code/SU2/pull/650#issuecomment-474871738:100,Integrability,interface,interface,100,@pcarruscag All of the things look reasonable. The long-term goal would be to really have a generic interface for the linear solvers (at least that was my goal) so that we don't have to distinguish between mesh deformation and flow solution anymore inside of the CSysSolve class. Rather we pass objects for the solver and preconditioner and other options to the constructor. We can merge this in as soon as the tests pass.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/650#issuecomment-474871738
https://github.com/su2code/SU2/pull/650#issuecomment-474871738:411,Testability,test,tests,411,@pcarruscag All of the things look reasonable. The long-term goal would be to really have a generic interface for the linear solvers (at least that was my goal) so that we don't have to distinguish between mesh deformation and flow solution anymore inside of the CSysSolve class. Rather we pass objects for the solver and preconditioner and other options to the constructor. We can merge this in as soon as the tests pass.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/650#issuecomment-474871738
https://github.com/su2code/SU2/pull/650#issuecomment-475180235:101,Usability,simpl,simpler,101,"@talbring that is definitely the long term goal, this was only the first step to make the templating simpler.; Thanks @rsanfer.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/650#issuecomment-475180235
https://github.com/su2code/SU2/issues/651#issuecomment-464361840:31,Modifiability,config,config,31,"Wally,; Could please share the config file and point to the grid that you used?; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/651#issuecomment-464361840
https://github.com/su2code/SU2/pull/652#issuecomment-464328382:43,Testability,test,test,43,"Hi Tom,. I just have the mesh for the LS89 test case in the NICFD folder.; (Apparently, I had to change the extension to attach the file here but just revert it to .su2).; Let me know. Giulio. [mesh_vki_turbine_prepbc.txt](https://github.com/su2code/SU2/files/2871791/mesh_vki_turbine_prepbc.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-464328382
https://github.com/su2code/SU2/pull/652#issuecomment-464599593:193,Energy Efficiency,Green,Green,193,"@LaSerpe : thanks for the mesh!. @EduardoMolina : no huge rush on merging this one.. we should make sure everything is working ok. It would be very helpful if you can take a look at the Taylor-Green Vortex case again, like we looked at before, now that the parallelization is improved. The option to run is still there (TGV = YES), and I think you already have the meshes.. @pcarruscag : thanks for the comments (will address soon). Also, thanks for the reminder about the pre-accumulation. I disabled that since I had to rework the least squares routines for the periodic BC and I did not turn it back on. The variables may need to be adjusted now though",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-464599593
https://github.com/su2code/SU2/pull/652#issuecomment-464599593:547,Integrability,rout,routines,547,"@LaSerpe : thanks for the mesh!. @EduardoMolina : no huge rush on merging this one.. we should make sure everything is working ok. It would be very helpful if you can take a look at the Taylor-Green Vortex case again, like we looked at before, now that the parallelization is improved. The option to run is still there (TGV = YES), and I think you already have the meshes.. @pcarruscag : thanks for the comments (will address soon). Also, thanks for the reminder about the pre-accumulation. I disabled that since I had to rework the least squares routines for the periodic BC and I did not turn it back on. The variables may need to be adjusted now though",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-464599593
https://github.com/su2code/SU2/pull/652#issuecomment-464599593:611,Modifiability,variab,variables,611,"@LaSerpe : thanks for the mesh!. @EduardoMolina : no huge rush on merging this one.. we should make sure everything is working ok. It would be very helpful if you can take a look at the Taylor-Green Vortex case again, like we looked at before, now that the parallelization is improved. The option to run is still there (TGV = YES), and I think you already have the meshes.. @pcarruscag : thanks for the comments (will address soon). Also, thanks for the reminder about the pre-accumulation. I disabled that since I had to rework the least squares routines for the periodic BC and I did not turn it back on. The variables may need to be adjusted now though",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-464599593
https://github.com/su2code/SU2/pull/652#issuecomment-484730590:103,Deployability,update,updated,103,"This PR is ready from my point of view. All periodic / turbomachinery meshes and regressions have been updated (thanks @salvovitale), and I can confirm they converge with the new periodic implementation. Only a few other regression tests needed to be updated due to the refactoring of the MPI, but they were very minor. If the tests pass, then I recommend we merge very soon. Any final comments or reviews are most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-484730590
https://github.com/su2code/SU2/pull/652#issuecomment-484730590:251,Deployability,update,updated,251,"This PR is ready from my point of view. All periodic / turbomachinery meshes and regressions have been updated (thanks @salvovitale), and I can confirm they converge with the new periodic implementation. Only a few other regression tests needed to be updated due to the refactoring of the MPI, but they were very minor. If the tests pass, then I recommend we merge very soon. Any final comments or reviews are most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-484730590
https://github.com/su2code/SU2/pull/652#issuecomment-484730590:270,Modifiability,refactor,refactoring,270,"This PR is ready from my point of view. All periodic / turbomachinery meshes and regressions have been updated (thanks @salvovitale), and I can confirm they converge with the new periodic implementation. Only a few other regression tests needed to be updated due to the refactoring of the MPI, but they were very minor. If the tests pass, then I recommend we merge very soon. Any final comments or reviews are most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-484730590
https://github.com/su2code/SU2/pull/652#issuecomment-484730590:232,Testability,test,tests,232,"This PR is ready from my point of view. All periodic / turbomachinery meshes and regressions have been updated (thanks @salvovitale), and I can confirm they converge with the new periodic implementation. Only a few other regression tests needed to be updated due to the refactoring of the MPI, but they were very minor. If the tests pass, then I recommend we merge very soon. Any final comments or reviews are most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-484730590
https://github.com/su2code/SU2/pull/652#issuecomment-484730590:327,Testability,test,tests,327,"This PR is ready from my point of view. All periodic / turbomachinery meshes and regressions have been updated (thanks @salvovitale), and I can confirm they converge with the new periodic implementation. Only a few other regression tests needed to be updated due to the refactoring of the MPI, but they were very minor. If the tests pass, then I recommend we merge very soon. Any final comments or reviews are most welcome.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-484730590
https://github.com/su2code/SU2/pull/652#issuecomment-485054516:403,Availability,toler,tolerance,403,"Hi Tom,. Thanks for this great PR. I have two notes:; a) I have one grid (flow around a high lift airfoil) where the periodic boundaries are not placed entirely on fix plane, like y=0.0, but on a very small value and fluctuates around, i.e. y~1.e-5. Now, many bad match points are found in the last commit of this PR. Previously, I was able to run the same mesh in a different commit. Do you change the tolerance of the search algorithm? Or I need to make sure now that all the periodic BC nodes must be placed on a fix plane.; b) I would like to share the results of the Taylor Green Vortex with the community. Indeed, the results are good and they are comparable with the reference DNS solution. ; ![SU2_TGV_DissipationRate](https://user-images.githubusercontent.com/9790985/56451123-05708500-62df-11e9-8601-7a6cdb38123d.png). Thank you one more time. Best,. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-485054516
https://github.com/su2code/SU2/pull/652#issuecomment-485054516:579,Energy Efficiency,Green,Green,579,"Hi Tom,. Thanks for this great PR. I have two notes:; a) I have one grid (flow around a high lift airfoil) where the periodic boundaries are not placed entirely on fix plane, like y=0.0, but on a very small value and fluctuates around, i.e. y~1.e-5. Now, many bad match points are found in the last commit of this PR. Previously, I was able to run the same mesh in a different commit. Do you change the tolerance of the search algorithm? Or I need to make sure now that all the periodic BC nodes must be placed on a fix plane.; b) I would like to share the results of the Taylor Green Vortex with the community. Indeed, the results are good and they are comparable with the reference DNS solution. ; ![SU2_TGV_DissipationRate](https://user-images.githubusercontent.com/9790985/56451123-05708500-62df-11e9-8601-7a6cdb38123d.png). Thank you one more time. Best,. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-485054516
https://github.com/su2code/SU2/pull/652#issuecomment-485930910:113,Availability,toler,tolerance,113,"@EduardoMolina : Nice results! Thanks for the comments. You are seeing more warnings bc I did in fact change the tolerance that controls the warning. But, note that this tolerance only controls when to print the warnings, so the matches should have still be the same (nearest neighbor after transformation). . The reason is that the new implementation assumes a 1-to-1 matching of the nodes and surface elements on either side of the periodic face. To be consistent, the points/faces on either side should match exactly so that they can be summed into a complete dual control volume (this assumption is made in the implementation and the partial residuals are summed as such). Nice catch on the fem_solver check. I will add that to the conditional. Thanks for the review @rsanfer. I will submit the final version shortly and if the tests pass, I would propose we merge this one first, if alright with @pcarruscag (the reason being that I would likely need your help to update the implementation for templating in the end anyway :) ).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-485930910
https://github.com/su2code/SU2/pull/652#issuecomment-485930910:170,Availability,toler,tolerance,170,"@EduardoMolina : Nice results! Thanks for the comments. You are seeing more warnings bc I did in fact change the tolerance that controls the warning. But, note that this tolerance only controls when to print the warnings, so the matches should have still be the same (nearest neighbor after transformation). . The reason is that the new implementation assumes a 1-to-1 matching of the nodes and surface elements on either side of the periodic face. To be consistent, the points/faces on either side should match exactly so that they can be summed into a complete dual control volume (this assumption is made in the implementation and the partial residuals are summed as such). Nice catch on the fem_solver check. I will add that to the conditional. Thanks for the review @rsanfer. I will submit the final version shortly and if the tests pass, I would propose we merge this one first, if alright with @pcarruscag (the reason being that I would likely need your help to update the implementation for templating in the end anyway :) ).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-485930910
https://github.com/su2code/SU2/pull/652#issuecomment-485930910:969,Deployability,update,update,969,"@EduardoMolina : Nice results! Thanks for the comments. You are seeing more warnings bc I did in fact change the tolerance that controls the warning. But, note that this tolerance only controls when to print the warnings, so the matches should have still be the same (nearest neighbor after transformation). . The reason is that the new implementation assumes a 1-to-1 matching of the nodes and surface elements on either side of the periodic face. To be consistent, the points/faces on either side should match exactly so that they can be summed into a complete dual control volume (this assumption is made in the implementation and the partial residuals are summed as such). Nice catch on the fem_solver check. I will add that to the conditional. Thanks for the review @rsanfer. I will submit the final version shortly and if the tests pass, I would propose we merge this one first, if alright with @pcarruscag (the reason being that I would likely need your help to update the implementation for templating in the end anyway :) ).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-485930910
https://github.com/su2code/SU2/pull/652#issuecomment-485930910:832,Testability,test,tests,832,"@EduardoMolina : Nice results! Thanks for the comments. You are seeing more warnings bc I did in fact change the tolerance that controls the warning. But, note that this tolerance only controls when to print the warnings, so the matches should have still be the same (nearest neighbor after transformation). . The reason is that the new implementation assumes a 1-to-1 matching of the nodes and surface elements on either side of the periodic face. To be consistent, the points/faces on either side should match exactly so that they can be summed into a complete dual control volume (this assumption is made in the implementation and the partial residuals are summed as such). Nice catch on the fem_solver check. I will add that to the conditional. Thanks for the review @rsanfer. I will submit the final version shortly and if the tests pass, I would propose we merge this one first, if alright with @pcarruscag (the reason being that I would likely need your help to update the implementation for templating in the end anyway :) ).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/652#issuecomment-485930910
https://github.com/su2code/SU2/pull/653#issuecomment-485039016:159,Integrability,rout,routines,159,"Looks like the commented code was added here (https://github.com/su2code/SU2/commit/b5db893bcc57a67abbbe43ddd5a87753ec61d23b) but never activated. The Matrix* routines are not being used anywhere at the moment. Do you see some value in testing it out? Otherwise, might be best to remove so we aren't carrying around dead code.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/653#issuecomment-485039016
https://github.com/su2code/SU2/pull/653#issuecomment-485039016:236,Testability,test,testing,236,"Looks like the commented code was added here (https://github.com/su2code/SU2/commit/b5db893bcc57a67abbbe43ddd5a87753ec61d23b) but never activated. The Matrix* routines are not being used anywhere at the moment. Do you see some value in testing it out? Otherwise, might be best to remove so we aren't carrying around dead code.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/653#issuecomment-485039016
https://github.com/su2code/SU2/pull/653#issuecomment-485102720:75,Availability,robust,robust,75,"I see, I do not know what is the quickest way to invert a 5x5 matrix, most robust would probably be LU with pivoting (for which we have the code in the RBF class). Since that relates to how we handle small dense matrices I would say it relates to #643 so it would be good if the community got to a conclusion there.; In any case I want this PR to be only about templating, I can do that kind of cleanup when I:; - Try to activave the MKL optimizations for the discrete adjoint.; - Move the row/col elimination tasks from the structural solver and mesh deformation to CSysMatrix (as you suggested in #658).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/653#issuecomment-485102720
https://github.com/su2code/SU2/pull/653#issuecomment-485102720:438,Performance,optimiz,optimizations,438,"I see, I do not know what is the quickest way to invert a 5x5 matrix, most robust would probably be LU with pivoting (for which we have the code in the RBF class). Since that relates to how we handle small dense matrices I would say it relates to #643 so it would be good if the community got to a conclusion there.; In any case I want this PR to be only about templating, I can do that kind of cleanup when I:; - Try to activave the MKL optimizations for the discrete adjoint.; - Move the row/col elimination tasks from the structural solver and mesh deformation to CSysMatrix (as you suggested in #658).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/653#issuecomment-485102720
https://github.com/su2code/SU2/pull/653#issuecomment-485926000:138,Performance,perform,performance,138,"Sounds good to me. Then, I suggest we leave the comments for now, and you can come back to it when considering #643 further (or when some performance issues are considered) in a later PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/653#issuecomment-485926000
https://github.com/su2code/SU2/pull/656#issuecomment-469378927:528,Testability,test,testing,528,"@economon to your question above:; > Thanks again, @davetaflin !; > ; > Just a couple of comments/questions first in the review. Also, when users use SU2_SOL to generate solution files (instead of during runtime with your new implementation), will the older serial implementation still behave as expected for writing Tecplot files?. SU2_SOL still calls COutput::SetBaselineResult_Files, which, for TECPLOT_BINARY output, calls SetTecplotBinary_DomainMesh and SetTecplotBinary_DomainSolution. These are unchanged here, and in my testing, continue to output mesh and solution .szplt files (changed by Scott Imlay to .szplt from .plt).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/656#issuecomment-469378927
https://github.com/su2code/SU2/pull/656#issuecomment-472548914:106,Integrability,wrap,wrapper,106,"Sounds like this one is more or less ready too.. . @talbring, can you please check the changes to the MPI wrapper in this PR when you have some time?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/656#issuecomment-472548914
https://github.com/su2code/SU2/pull/657#issuecomment-467130865:26,Testability,test,tests,26,"Concerning the Regression tests: ; All failing test have a symmetry plane and are based on the inc-/compressible solver (so far so good). ; They are all based on the comparing the SU2 output, not by a file-diff like some AD cases do with the of_grad.dat file. That makes updating the regression test quite easy :) .; The difference between computed and stored values mostly quite small, apart from cases where a restart is done. I could change the solution_flow.dat where necessary if wanted.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-467130865
https://github.com/su2code/SU2/pull/657#issuecomment-467130865:47,Testability,test,test,47,"Concerning the Regression tests: ; All failing test have a symmetry plane and are based on the inc-/compressible solver (so far so good). ; They are all based on the comparing the SU2 output, not by a file-diff like some AD cases do with the of_grad.dat file. That makes updating the regression test quite easy :) .; The difference between computed and stored values mostly quite small, apart from cases where a restart is done. I could change the solution_flow.dat where necessary if wanted.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-467130865
https://github.com/su2code/SU2/pull/657#issuecomment-467130865:295,Testability,test,test,295,"Concerning the Regression tests: ; All failing test have a symmetry plane and are based on the inc-/compressible solver (so far so good). ; They are all based on the comparing the SU2 output, not by a file-diff like some AD cases do with the of_grad.dat file. That makes updating the regression test quite easy :) .; The difference between computed and stored values mostly quite small, apart from cases where a restart is done. I could change the solution_flow.dat where necessary if wanted.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-467130865
https://github.com/su2code/SU2/pull/657#issuecomment-468263411:617,Deployability,update,updated,617,"> Only thing not addressed yet is the symmetry BC for the turbulence models (we prob need to add something similar). TobiKattmann : do you have time to look at that as part of this PR? Or shall we do that separately?. The implementation for the turbulence models is correct as is. No flux is considered for the convective and viscous fluxes by inserting the symmetry conditions directly in the FV derivation. Convective fluxes vanish as velocity*normal=0, viscous fluxes vanish by grad(transported scalar)*n=0 on the symmetry faces of the boundary. Above I denoted that as ""direct flux"" approach. ; (I will attach an updated pdf here later). Although the ""reflected state"" approach is a more proactive approach and might be beneficial for convergence. Could be worth a shot if somebody really has an issue here, for now I leave it as is. **NEXT STEP** I will update the Regression test values at the failing cases. For cases with a restart (either primal or adjoint computations) I will update the restart_file and upload these in a seperate Testcases branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-468263411
https://github.com/su2code/SU2/pull/657#issuecomment-468263411:859,Deployability,update,update,859,"> Only thing not addressed yet is the symmetry BC for the turbulence models (we prob need to add something similar). TobiKattmann : do you have time to look at that as part of this PR? Or shall we do that separately?. The implementation for the turbulence models is correct as is. No flux is considered for the convective and viscous fluxes by inserting the symmetry conditions directly in the FV derivation. Convective fluxes vanish as velocity*normal=0, viscous fluxes vanish by grad(transported scalar)*n=0 on the symmetry faces of the boundary. Above I denoted that as ""direct flux"" approach. ; (I will attach an updated pdf here later). Although the ""reflected state"" approach is a more proactive approach and might be beneficial for convergence. Could be worth a shot if somebody really has an issue here, for now I leave it as is. **NEXT STEP** I will update the Regression test values at the failing cases. For cases with a restart (either primal or adjoint computations) I will update the restart_file and upload these in a seperate Testcases branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-468263411
https://github.com/su2code/SU2/pull/657#issuecomment-468263411:987,Deployability,update,update,987,"> Only thing not addressed yet is the symmetry BC for the turbulence models (we prob need to add something similar). TobiKattmann : do you have time to look at that as part of this PR? Or shall we do that separately?. The implementation for the turbulence models is correct as is. No flux is considered for the convective and viscous fluxes by inserting the symmetry conditions directly in the FV derivation. Convective fluxes vanish as velocity*normal=0, viscous fluxes vanish by grad(transported scalar)*n=0 on the symmetry faces of the boundary. Above I denoted that as ""direct flux"" approach. ; (I will attach an updated pdf here later). Although the ""reflected state"" approach is a more proactive approach and might be beneficial for convergence. Could be worth a shot if somebody really has an issue here, for now I leave it as is. **NEXT STEP** I will update the Regression test values at the failing cases. For cases with a restart (either primal or adjoint computations) I will update the restart_file and upload these in a seperate Testcases branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-468263411
https://github.com/su2code/SU2/pull/657#issuecomment-468263411:881,Testability,test,test,881,"> Only thing not addressed yet is the symmetry BC for the turbulence models (we prob need to add something similar). TobiKattmann : do you have time to look at that as part of this PR? Or shall we do that separately?. The implementation for the turbulence models is correct as is. No flux is considered for the convective and viscous fluxes by inserting the symmetry conditions directly in the FV derivation. Convective fluxes vanish as velocity*normal=0, viscous fluxes vanish by grad(transported scalar)*n=0 on the symmetry faces of the boundary. Above I denoted that as ""direct flux"" approach. ; (I will attach an updated pdf here later). Although the ""reflected state"" approach is a more proactive approach and might be beneficial for convergence. Could be worth a shot if somebody really has an issue here, for now I leave it as is. **NEXT STEP** I will update the Regression test values at the failing cases. For cases with a restart (either primal or adjoint computations) I will update the restart_file and upload these in a seperate Testcases branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-468263411
https://github.com/su2code/SU2/pull/657#issuecomment-468263411:1042,Testability,Test,Testcases,1042,"> Only thing not addressed yet is the symmetry BC for the turbulence models (we prob need to add something similar). TobiKattmann : do you have time to look at that as part of this PR? Or shall we do that separately?. The implementation for the turbulence models is correct as is. No flux is considered for the convective and viscous fluxes by inserting the symmetry conditions directly in the FV derivation. Convective fluxes vanish as velocity*normal=0, viscous fluxes vanish by grad(transported scalar)*n=0 on the symmetry faces of the boundary. Above I denoted that as ""direct flux"" approach. ; (I will attach an updated pdf here later). Although the ""reflected state"" approach is a more proactive approach and might be beneficial for convergence. Could be worth a shot if somebody really has an issue here, for now I leave it as is. **NEXT STEP** I will update the Regression test values at the failing cases. For cases with a restart (either primal or adjoint computations) I will update the restart_file and upload these in a seperate Testcases branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-468263411
https://github.com/su2code/SU2/pull/657#issuecomment-469173101:15,Testability,test,test,15,"All regression test values are corrected and for restarted/adjoint cases (euler/oneram6, disc_adj_heat, disc_adj_euler/arina2k) the solution_flow.dat was replaced. The respective Testcases branch is here https://github.com/su2code/Testcases/tree/bugfix_BC-sym-plane . From my side this PR could be merged (after merging the Testcases branch and reverting .travis.yml).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-469173101
https://github.com/su2code/SU2/pull/657#issuecomment-469173101:179,Testability,Test,Testcases,179,"All regression test values are corrected and for restarted/adjoint cases (euler/oneram6, disc_adj_heat, disc_adj_euler/arina2k) the solution_flow.dat was replaced. The respective Testcases branch is here https://github.com/su2code/Testcases/tree/bugfix_BC-sym-plane . From my side this PR could be merged (after merging the Testcases branch and reverting .travis.yml).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-469173101
https://github.com/su2code/SU2/pull/657#issuecomment-469173101:231,Testability,Test,Testcases,231,"All regression test values are corrected and for restarted/adjoint cases (euler/oneram6, disc_adj_heat, disc_adj_euler/arina2k) the solution_flow.dat was replaced. The respective Testcases branch is here https://github.com/su2code/Testcases/tree/bugfix_BC-sym-plane . From my side this PR could be merged (after merging the Testcases branch and reverting .travis.yml).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-469173101
https://github.com/su2code/SU2/pull/657#issuecomment-469173101:324,Testability,Test,Testcases,324,"All regression test values are corrected and for restarted/adjoint cases (euler/oneram6, disc_adj_heat, disc_adj_euler/arina2k) the solution_flow.dat was replaced. The respective Testcases branch is here https://github.com/su2code/Testcases/tree/bugfix_BC-sym-plane . From my side this PR could be merged (after merging the Testcases branch and reverting .travis.yml).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-469173101
https://github.com/su2code/SU2/pull/657#issuecomment-470926608:92,Integrability,rout,routines,92,@pcarruscag Indeed both implementations are very similar. But this is the case for a lot of routines in CEulerSolver and CIncEulerSolver at the moment. We can think about introducing a common base class for both in the future to remove this code duplication. But for now there is no other way except for moving the implementation to CSolver which we should avoid in my opinion.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-470926608
https://github.com/su2code/SU2/pull/657#issuecomment-470926608:357,Safety,avoid,avoid,357,@pcarruscag Indeed both implementations are very similar. But this is the case for a lot of routines in CEulerSolver and CIncEulerSolver at the moment. We can think about introducing a common base class for both in the future to remove this code duplication. But for now there is no other way except for moving the implementation to CSolver which we should avoid in my opinion.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-470926608
https://github.com/su2code/SU2/pull/657#issuecomment-471325872:98,Modifiability,inherit,inheriting,98,"@talbring, if you are concerned with implementing BC_Sym_Plane in CSolver and every derived class inheriting a default implementation, it can be named BC_Sym_Plane_Flow and then the compressible and incompressible solvers can call it from their implementation of BC_Sym_Plane. Anything is better than copy pasting code, as that will only make a future refactoring more difficult. By the way, I too think the implementation is very good and I really appreciate @TobiKattmann 's effort to document it from the theoretical and implementation point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-471325872
https://github.com/su2code/SU2/pull/657#issuecomment-471325872:352,Modifiability,refactor,refactoring,352,"@talbring, if you are concerned with implementing BC_Sym_Plane in CSolver and every derived class inheriting a default implementation, it can be named BC_Sym_Plane_Flow and then the compressible and incompressible solvers can call it from their implementation of BC_Sym_Plane. Anything is better than copy pasting code, as that will only make a future refactoring more difficult. By the way, I too think the implementation is very good and I really appreciate @TobiKattmann 's effort to document it from the theoretical and implementation point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-471325872
https://github.com/su2code/SU2/pull/657#issuecomment-472011300:594,Usability,clear,clear,594,"@pcarruscag I just had a chat with @TobiKattmann. Essentially there are two points that would, in our opinion, speak against moving the implementation to CSolver. 1. We dont know yet whether they might be some future differences in the implementations. ; 2. This defeats somehow the purpose of the class structure, as the base class should be free of specific implementations for a certain solver ... Although the intention would be to have it there only temporarily, we never know how long it actually stays there in the end. I don't mind having a little bit of code copy, if the structure is clear and easy to understand.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-472011300
https://github.com/su2code/SU2/pull/657#issuecomment-472547987:254,Energy Efficiency,reduce,reduce,254,"I think we are all in agreement then.. as @pcarruscag points out, we should always keep code duplication in mind and try to abstract when possible. But, let's do it gradually.. sometimes we need to balance this against keeping duplicate code if it helps reduce conflicts and allows for different parts of the code to evolve separately and in parallel by different developers. I think a good first step is what @talbring has in mind for the flow output.. exactly this type of mid-level flow output class will show up there I believe. We can see how well that goes and then port to the solver classes too. Will merge this in today so we can keep moving forward. Thanks all",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-472547987
https://github.com/su2code/SU2/pull/657#issuecomment-472547987:317,Modifiability,evolve,evolve,317,"I think we are all in agreement then.. as @pcarruscag points out, we should always keep code duplication in mind and try to abstract when possible. But, let's do it gradually.. sometimes we need to balance this against keeping duplicate code if it helps reduce conflicts and allows for different parts of the code to evolve separately and in parallel by different developers. I think a good first step is what @talbring has in mind for the flow output.. exactly this type of mid-level flow output class will show up there I believe. We can see how well that goes and then port to the solver classes too. Will merge this in today so we can keep moving forward. Thanks all",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/657#issuecomment-472547987
https://github.com/su2code/SU2/pull/658#issuecomment-467051581:123,Integrability,interface,interfaces,123,"This had to be more intricate than first impressions suggested...; The displacements applied by CElasticityMovement to FSI interfaces come from the vertices, but halo vertices do not have the correct (i.e. communicated) coordinates which means for those the force vector contributions were not being computed correctly.; The known blocks (prescribed displacement) of the displacement vector are now set and communicated before ""de-singularizing"" the matrix, that process then grabs displacements from the displacement vector instead of from the vertices.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/658#issuecomment-467051581
https://github.com/su2code/SU2/issues/659#issuecomment-469467911:170,Availability,error,error,170,It has occurred to me that perhaps I need to compile hdf5 on my system for the parallel integration of CGNS with OpenMPI? I think this might be why make is throwing that error. I'll report back after trying it. Amir,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/659#issuecomment-469467911
https://github.com/su2code/SU2/issues/659#issuecomment-469467911:88,Deployability,integrat,integration,88,It has occurred to me that perhaps I need to compile hdf5 on my system for the parallel integration of CGNS with OpenMPI? I think this might be why make is throwing that error. I'll report back after trying it. Amir,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/659#issuecomment-469467911
https://github.com/su2code/SU2/issues/659#issuecomment-469467911:88,Integrability,integrat,integration,88,It has occurred to me that perhaps I need to compile hdf5 on my system for the parallel integration of CGNS with OpenMPI? I think this might be why make is throwing that error. I'll report back after trying it. Amir,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/659#issuecomment-469467911
https://github.com/su2code/SU2/issues/659#issuecomment-469473720:256,Integrability,wrap,wrapper,256,"I do not think that it is related to CGNS in particular (and no need to build hdf5 anyway, we aren't using it), but rather, there are some MPI issues there. Looks like MPI_Keyval_free() is causing a problem? I think this was deprecated, so perhaps the MPI wrapper is having trouble with something in OpenMPI 4 (or maybe this function was completely removed in the new version). Thanks for reporting this. In the meantime, can you try with an earlier version of OpenMPI? v3 is working fine for me.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/659#issuecomment-469473720
https://github.com/su2code/SU2/issues/659#issuecomment-469707144:93,Deployability,update,update,93,I just noticed the same problem. It is related to the current medi version we use. I have to update it to the newest version I guess. Gonna look into it ...,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/659#issuecomment-469707144
https://github.com/su2code/SU2/issues/659#issuecomment-532002423:26,Deployability,install,install,26,add sudo in front of make install,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/659#issuecomment-532002423
https://github.com/su2code/SU2/issues/661#issuecomment-474048371:133,Modifiability,config,config,133,Hi: please use the SU2_DEF module (with DV_KIND= SURFACE_FILE) to create the new mesh first before running SU2_CFD. Try the attached config file and rename your new coordinates file to 'surface_positions.dat' ; [inv_goland.txt](https://github.com/su2code/SU2/files/2979714/inv_goland.txt),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/661#issuecomment-474048371
https://github.com/su2code/SU2/issues/662#issuecomment-478389641:219,Deployability,install,install,219,"Hello,; You need to use the appropriate environment variables, here is for example how I build one of my branches:; export CXXFLAGS=""-Wno-deprecated-declarations -O3 -march=corei7-avx -I/rds/general/user/me/home/pastix/install -I/rds/general/user/me/home/Eigen335""; export CPPFLAGS=""-DHAVE_PASTIX -DHAVE_LAPACK -DEIGEN_NO_DEBUG -DEIGEN_DONT_PARALLELIZE""; export LDFLAGS=""-L/rds/general/user/me/home/pastix/install -L/rds/general/user/me/home/scotch/lib -L/apps/intel/2017.6/mkl/lib/intel64/""; export LIBS=""-lpastix -lscotch -lptscotch -lptscotcherr -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lpthread -lm -ldl""; Regards,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/662#issuecomment-478389641
https://github.com/su2code/SU2/issues/662#issuecomment-478389641:406,Deployability,install,install,406,"Hello,; You need to use the appropriate environment variables, here is for example how I build one of my branches:; export CXXFLAGS=""-Wno-deprecated-declarations -O3 -march=corei7-avx -I/rds/general/user/me/home/pastix/install -I/rds/general/user/me/home/Eigen335""; export CPPFLAGS=""-DHAVE_PASTIX -DHAVE_LAPACK -DEIGEN_NO_DEBUG -DEIGEN_DONT_PARALLELIZE""; export LDFLAGS=""-L/rds/general/user/me/home/pastix/install -L/rds/general/user/me/home/scotch/lib -L/apps/intel/2017.6/mkl/lib/intel64/""; export LIBS=""-lpastix -lscotch -lptscotch -lptscotcherr -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lpthread -lm -ldl""; Regards,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/662#issuecomment-478389641
https://github.com/su2code/SU2/issues/662#issuecomment-478389641:52,Modifiability,variab,variables,52,"Hello,; You need to use the appropriate environment variables, here is for example how I build one of my branches:; export CXXFLAGS=""-Wno-deprecated-declarations -O3 -march=corei7-avx -I/rds/general/user/me/home/pastix/install -I/rds/general/user/me/home/Eigen335""; export CPPFLAGS=""-DHAVE_PASTIX -DHAVE_LAPACK -DEIGEN_NO_DEBUG -DEIGEN_DONT_PARALLELIZE""; export LDFLAGS=""-L/rds/general/user/me/home/pastix/install -L/rds/general/user/me/home/scotch/lib -L/apps/intel/2017.6/mkl/lib/intel64/""; export LIBS=""-lpastix -lscotch -lptscotch -lptscotcherr -lmkl_intel_lp64 -lmkl_sequential -lmkl_core -lpthread -lm -ldl""; Regards,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/662#issuecomment-478389641
https://github.com/su2code/SU2/pull/663#issuecomment-476253315:261,Safety,avoid,avoid,261,"Hi @rsanfer,; Did you consider using a derived class of CFEAVariable that augments it with the fluid tractions?; This would save you the memory of the data, the pointer, and the boolean (which due to alignment issues is probably not just 1 byte). It would also avoid the if statements.; Cheers for removing the methods returning pointers by the way.; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/663#issuecomment-476253315
https://github.com/su2code/SU2/pull/663#issuecomment-476578546:296,Energy Efficiency,efficient,efficiently,296,"Hi @pcarruscag ; in fact it was the boolean what I originally wanted to have there, so that it could easily be checked whether a node is a surface vertex without having to loop through the markers. Getting the memory savings this way just came naturally, but it's true that it could be done more efficiently. ; As it's not just the fluid tractions the ones involved, but also the surface pressures, I've reused an old CFEABoundVariable class that was there sitting unused (so, 2 for the price of 1!) to store those containers. It should lead to some additional memory savings.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/663#issuecomment-476578546
https://github.com/su2code/SU2/pull/667#issuecomment-479973816:525,Usability,learn,learn,525,"Yep, just an honest mistake. We'll fix it up. I know that things have been a little quiet in the repository lately, but there is a lot of motion happening behind the scenes as we prepare for the developers meeting next month (we have some exciting things in store). . Thanks for the patience, and I would also ask that, if folks in the community have some time, they please contribute to reviews. Expertise in the particular area is not required (I know it can seem intimidating, but don't be shy!), and it is a great way to learn the code and see what other folks are developing. The more input and discussion we have from various perspectives, the better.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-479973816
https://github.com/su2code/SU2/pull/667#issuecomment-480015080:158,Modifiability,evolve,evolved,158,"Thanks at all for being so responsive to this mishap. When I started contributing I learned that something like a 2-LGTM-rule was applying. But apparently it evolved to have someone merge a pull request if he or she can judge the content and feels comfortable with it, as the other approach ended up having a large list of unmerged pull requests **or** having two LGTM's of non-independent reviewers. @economon Maybe you can bring it up at the next meeting how we could address this little double bind?. So sorry again for the trouble (at least a revert of the very latest commit would not be too difficult). Still I'll wait if @pcarruscag and @talbring want to do now the way Tim suggested.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-480015080
https://github.com/su2code/SU2/pull/667#issuecomment-480015080:27,Usability,responsiv,responsive,27,"Thanks at all for being so responsive to this mishap. When I started contributing I learned that something like a 2-LGTM-rule was applying. But apparently it evolved to have someone merge a pull request if he or she can judge the content and feels comfortable with it, as the other approach ended up having a large list of unmerged pull requests **or** having two LGTM's of non-independent reviewers. @economon Maybe you can bring it up at the next meeting how we could address this little double bind?. So sorry again for the trouble (at least a revert of the very latest commit would not be too difficult). Still I'll wait if @pcarruscag and @talbring want to do now the way Tim suggested.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-480015080
https://github.com/su2code/SU2/pull/667#issuecomment-480015080:84,Usability,learn,learned,84,"Thanks at all for being so responsive to this mishap. When I started contributing I learned that something like a 2-LGTM-rule was applying. But apparently it evolved to have someone merge a pull request if he or she can judge the content and feels comfortable with it, as the other approach ended up having a large list of unmerged pull requests **or** having two LGTM's of non-independent reviewers. @economon Maybe you can bring it up at the next meeting how we could address this little double bind?. So sorry again for the trouble (at least a revert of the very latest commit would not be too difficult). Still I'll wait if @pcarruscag and @talbring want to do now the way Tim suggested.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/667#issuecomment-480015080
https://github.com/su2code/SU2/pull/670#issuecomment-501739120:13,Deployability,update,update,13,"So I want to update the `transonic_stator_2D` test case with a new restart file that matches the new numerics. Since it's a transonic case, the difference in production is significant. But what was the stopping criteria used while generating the restart file in [TestCases/turbomachinery/transonic_stator_2D](https://github.com/su2code/TestCases/tree/develop/turbomachinery/transonic_stator_2D)? Was it the same stopping criteria used in the [non-restart cfg file](https://github.com/su2code/SU2/blob/master/TestCases/turbomachinery/transonic_stator_2D/transonic_stator.cfg)? For that case, the solver stops at 2001 external iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/670#issuecomment-501739120
https://github.com/su2code/SU2/pull/670#issuecomment-501739120:46,Testability,test,test,46,"So I want to update the `transonic_stator_2D` test case with a new restart file that matches the new numerics. Since it's a transonic case, the difference in production is significant. But what was the stopping criteria used while generating the restart file in [TestCases/turbomachinery/transonic_stator_2D](https://github.com/su2code/TestCases/tree/develop/turbomachinery/transonic_stator_2D)? Was it the same stopping criteria used in the [non-restart cfg file](https://github.com/su2code/SU2/blob/master/TestCases/turbomachinery/transonic_stator_2D/transonic_stator.cfg)? For that case, the solver stops at 2001 external iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/670#issuecomment-501739120
https://github.com/su2code/SU2/pull/670#issuecomment-501739120:263,Testability,Test,TestCases,263,"So I want to update the `transonic_stator_2D` test case with a new restart file that matches the new numerics. Since it's a transonic case, the difference in production is significant. But what was the stopping criteria used while generating the restart file in [TestCases/turbomachinery/transonic_stator_2D](https://github.com/su2code/TestCases/tree/develop/turbomachinery/transonic_stator_2D)? Was it the same stopping criteria used in the [non-restart cfg file](https://github.com/su2code/SU2/blob/master/TestCases/turbomachinery/transonic_stator_2D/transonic_stator.cfg)? For that case, the solver stops at 2001 external iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/670#issuecomment-501739120
https://github.com/su2code/SU2/pull/670#issuecomment-501739120:336,Testability,Test,TestCases,336,"So I want to update the `transonic_stator_2D` test case with a new restart file that matches the new numerics. Since it's a transonic case, the difference in production is significant. But what was the stopping criteria used while generating the restart file in [TestCases/turbomachinery/transonic_stator_2D](https://github.com/su2code/TestCases/tree/develop/turbomachinery/transonic_stator_2D)? Was it the same stopping criteria used in the [non-restart cfg file](https://github.com/su2code/SU2/blob/master/TestCases/turbomachinery/transonic_stator_2D/transonic_stator.cfg)? For that case, the solver stops at 2001 external iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/670#issuecomment-501739120
https://github.com/su2code/SU2/pull/670#issuecomment-501739120:508,Testability,Test,TestCases,508,"So I want to update the `transonic_stator_2D` test case with a new restart file that matches the new numerics. Since it's a transonic case, the difference in production is significant. But what was the stopping criteria used while generating the restart file in [TestCases/turbomachinery/transonic_stator_2D](https://github.com/su2code/TestCases/tree/develop/turbomachinery/transonic_stator_2D)? Was it the same stopping criteria used in the [non-restart cfg file](https://github.com/su2code/SU2/blob/master/TestCases/turbomachinery/transonic_stator_2D/transonic_stator.cfg)? For that case, the solver stops at 2001 external iterations.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/670#issuecomment-501739120
https://github.com/su2code/SU2/pull/670#issuecomment-511499499:56,Testability,Test,TestCases,56,"For my part, this is ready to be merged in once su2code/TestCases#34 goes through. Only the transonic stator restart case is failing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/670#issuecomment-511499499
https://github.com/su2code/SU2/pull/670#issuecomment-511500047:16,Testability,test,test,16,Just merged the test. Let's get this merged next once it passes.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/670#issuecomment-511500047
https://github.com/su2code/SU2/pull/672#issuecomment-486373335:16,Usability,clear,clear,16,"I am not a 100% clear on all the things this new feature can do. From what I gather we can now set an initial flow field that is not just freestream condition everywhere? If this is the case, this is a hugely useful feature so thank you guys for doing that. . How exactly is this allowing for solution verification? Is it allowing you to run the same case with a bunch of different solver schemes? Can it run the solvers on a set of meshes or do you still have to run on each mesh refinement individually?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-486373335
https://github.com/su2code/SU2/pull/672#issuecomment-486418280:360,Usability,clear,clear,360,"Good point, Jayant. Maybe a brief tutorial and an example can be created so people know how to use this new feature? There will be a presentation by Edwin and Tom at the annual meeting that might also be helpful. Best,; Juan. On Apr 24, 2019, at 11:32 AM, Jayant Mukhopadhaya <notifications@github.com<mailto:notifications@github.com>> wrote:. I am not a 100% clear on all the things this new feature can do. From what I gather we can now set an initial flow field that is not just freestream condition everywhere? If this is the case, this is a hugely useful feature so thank you guys for doing that. How exactly is this allowing for solution verification? Is it allowing you to run the same case with a bunch of different solver schemes? Can it run the solvers on a set of meshes or do you still have to run on each mesh refinement individually?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/672#issuecomment-486373335>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRDJGI6HH6HEUDATJS3PSCRUZANCNFSM4HH7BJ7A>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-486418280
https://github.com/su2code/SU2/pull/672#issuecomment-486683930:318,Integrability,depend,dependent,318,"@jayantmukho, as @juanjosealonso indicated the verification efforts will be presented at the annual developers meeting. However, we may not have time to answer all questions there, so a tutorial may be a good thing to have. To answer your question about setting different initial conditions (as well as space and time dependent boundary conditions), yes you can do that with the class CUserDefinedSolution, although this was not the primary intention. The intention of these classes is to run a verification case, where you add source terms to the governing equations, such that a given solution is an exact solution to the modified equations. In this way you can do a thorough accuracy check of your discretization, as shown in the figures by @economon. Hope this answers your questions a bit.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-486683930
https://github.com/su2code/SU2/pull/672#issuecomment-495082856:381,Availability,down,down,381,"Completely in support of dividing the files!. I think it is time though to then also decide on an objective criteria for this for all developers to adhere to in the future. Shall we then formalize it as a single C++ class per file, i.e., each class has a .cpp and an .hpp (inline files merged into the .hpp files as in the new output)? Merging the inlines with the header may slow down compile times, but not sure how much. Would be good to also standardize the naming convention for these files. . Thoughts from others?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-495082856
https://github.com/su2code/SU2/pull/672#issuecomment-498834929:15,Usability,feedback,feedback,15,"Thanks for the feedback and suggestions. Nice teamwork! I am also plenty happy with this now. Last comment: it was mentioned at the meeting (maybe in the V&V working group), that it would be good to have a separate option for the user-defined solution, in the case of setting a custom initial condition or BC, that sits outside the KIND_VERIFICATION_SOLUTION option list. Doesn't have to necessarily be acted upon now, but want it on record.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/672#issuecomment-498834929
https://github.com/su2code/SU2/pull/676#issuecomment-489276631:43,Integrability,depend,depend,43,Merging this in - some other contributions depend upon it. Thanks @vdweide,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/676#issuecomment-489276631
https://github.com/su2code/SU2/issues/679#issuecomment-491813704:76,Modifiability,variab,variables,76,"Hi @amirkb91,; It sounds like you have done things the right way, so if the variables are not being reset after they are registered my next guess is that they are not being considered for pre-accumulation. Try running the code without pre-accumulation (there is a config option, no need to recompile) and see if that makes a difference.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491813704
https://github.com/su2code/SU2/issues/679#issuecomment-491813704:264,Modifiability,config,config,264,"Hi @amirkb91,; It sounds like you have done things the right way, so if the variables are not being reset after they are registered my next guess is that they are not being considered for pre-accumulation. Try running the code without pre-accumulation (there is a config option, no need to recompile) and see if that makes a difference.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491813704
https://github.com/su2code/SU2/issues/679#issuecomment-491887764:86,Modifiability,config,config,86,"Hi Pedro,. Thanks for your reply. I tried without the pre-accumulation (PREACC= NO in config file) and still the returned derivative is 0.; In the existing code, when design variables such as Temp and Pressure are registered as AD inputs, their values are re-set using appropriate Set__() functions from the config and solver classes. I have also done the same thing with the SA coefficients, by passing the values onto functions defined inside the config class which set them to the same values that are read before they are registered as AD inputs. . Still unfortunately the output gradient is zero. Anything else that might be worth trying?. Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491887764
https://github.com/su2code/SU2/issues/679#issuecomment-491887764:174,Modifiability,variab,variables,174,"Hi Pedro,. Thanks for your reply. I tried without the pre-accumulation (PREACC= NO in config file) and still the returned derivative is 0.; In the existing code, when design variables such as Temp and Pressure are registered as AD inputs, their values are re-set using appropriate Set__() functions from the config and solver classes. I have also done the same thing with the SA coefficients, by passing the values onto functions defined inside the config class which set them to the same values that are read before they are registered as AD inputs. . Still unfortunately the output gradient is zero. Anything else that might be worth trying?. Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491887764
https://github.com/su2code/SU2/issues/679#issuecomment-491887764:308,Modifiability,config,config,308,"Hi Pedro,. Thanks for your reply. I tried without the pre-accumulation (PREACC= NO in config file) and still the returned derivative is 0.; In the existing code, when design variables such as Temp and Pressure are registered as AD inputs, their values are re-set using appropriate Set__() functions from the config and solver classes. I have also done the same thing with the SA coefficients, by passing the values onto functions defined inside the config class which set them to the same values that are read before they are registered as AD inputs. . Still unfortunately the output gradient is zero. Anything else that might be worth trying?. Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491887764
https://github.com/su2code/SU2/issues/679#issuecomment-491887764:449,Modifiability,config,config,449,"Hi Pedro,. Thanks for your reply. I tried without the pre-accumulation (PREACC= NO in config file) and still the returned derivative is 0.; In the existing code, when design variables such as Temp and Pressure are registered as AD inputs, their values are re-set using appropriate Set__() functions from the config and solver classes. I have also done the same thing with the SA coefficients, by passing the values onto functions defined inside the config class which set them to the same values that are read before they are registered as AD inputs. . Still unfortunately the output gradient is zero. Anything else that might be worth trying?. Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491887764
https://github.com/su2code/SU2/issues/679#issuecomment-491910935:487,Deployability,update,update,487,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
https://github.com/su2code/SU2/issues/679#issuecomment-491910935:1041,Deployability,update,update,1041,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
https://github.com/su2code/SU2/issues/679#issuecomment-491910935:162,Modifiability,variab,variables,162,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
https://github.com/su2code/SU2/issues/679#issuecomment-491910935:788,Modifiability,variab,variable,788,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
https://github.com/su2code/SU2/issues/679#issuecomment-491910935:910,Security,access,access,910,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
https://github.com/su2code/SU2/issues/679#issuecomment-491910935:303,Usability,clear,clear,303,"The solver with the closest functionality to what you are trying to do is the elasticity solver, it may be worth having a look there. But in a nutshell there the variables we want to differentiate are held by (members of) the discrete adjoint solver, they are reset before being registered as inputs to clear the derivative information, and it is important that they are left alone during the recording phase.; You will see that the adjoint iteration class for this solver then needs to update the numerics classes (in SetDependencies), at least for the source term the SA coefficients are set in the constructor of the corresponding numerics so maybe this step is missing?; The key point is that whenever a coefficient is used you need to be able to trace its value back to the original variable you registered.; Also the derivatives should be extracted in the same order they were registered, and you cannot access them multiple times by calling ""GetDerivative"" on them repeatedly (not 100% sure if this restriction still exists after the update of CoDi).; If none of this makes sense point me to branch you are working on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-491910935
https://github.com/su2code/SU2/issues/679#issuecomment-492342990:147,Modifiability,variab,variable,147,"Hi Amir,; I just had a look and that is not going to work I'm afraid.; The numerics classes are not getting the value of the coefficients from the variable that you register as input, this happens because config returns cb1 by value, meaning that what you register as input is not CConfig::cb1_usrdef (seen by numerics) but CSolver::cb1_adj.; You can try registering CConfig::cb1_usrdef as input, making it a public variable would be the easiest thing. This is a hack and personally I don't like the idea of differentiating variables that belong to CConfig. I would add a cb1 member variable to numerics and a method to set it, this method would then be called after you register CSolver::cb1_adj as input to set CNumerics::cb1 = CSolver::cb1_adj and the numerics would no longer get values from the config by themselves in ComputeResidual.; I hope this makes sense but do have a look at the elasticity solver and try to mimic the strategy used there.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-492342990
https://github.com/su2code/SU2/issues/679#issuecomment-492342990:205,Modifiability,config,config,205,"Hi Amir,; I just had a look and that is not going to work I'm afraid.; The numerics classes are not getting the value of the coefficients from the variable that you register as input, this happens because config returns cb1 by value, meaning that what you register as input is not CConfig::cb1_usrdef (seen by numerics) but CSolver::cb1_adj.; You can try registering CConfig::cb1_usrdef as input, making it a public variable would be the easiest thing. This is a hack and personally I don't like the idea of differentiating variables that belong to CConfig. I would add a cb1 member variable to numerics and a method to set it, this method would then be called after you register CSolver::cb1_adj as input to set CNumerics::cb1 = CSolver::cb1_adj and the numerics would no longer get values from the config by themselves in ComputeResidual.; I hope this makes sense but do have a look at the elasticity solver and try to mimic the strategy used there.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-492342990
https://github.com/su2code/SU2/issues/679#issuecomment-492342990:416,Modifiability,variab,variable,416,"Hi Amir,; I just had a look and that is not going to work I'm afraid.; The numerics classes are not getting the value of the coefficients from the variable that you register as input, this happens because config returns cb1 by value, meaning that what you register as input is not CConfig::cb1_usrdef (seen by numerics) but CSolver::cb1_adj.; You can try registering CConfig::cb1_usrdef as input, making it a public variable would be the easiest thing. This is a hack and personally I don't like the idea of differentiating variables that belong to CConfig. I would add a cb1 member variable to numerics and a method to set it, this method would then be called after you register CSolver::cb1_adj as input to set CNumerics::cb1 = CSolver::cb1_adj and the numerics would no longer get values from the config by themselves in ComputeResidual.; I hope this makes sense but do have a look at the elasticity solver and try to mimic the strategy used there.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-492342990
https://github.com/su2code/SU2/issues/679#issuecomment-492342990:524,Modifiability,variab,variables,524,"Hi Amir,; I just had a look and that is not going to work I'm afraid.; The numerics classes are not getting the value of the coefficients from the variable that you register as input, this happens because config returns cb1 by value, meaning that what you register as input is not CConfig::cb1_usrdef (seen by numerics) but CSolver::cb1_adj.; You can try registering CConfig::cb1_usrdef as input, making it a public variable would be the easiest thing. This is a hack and personally I don't like the idea of differentiating variables that belong to CConfig. I would add a cb1 member variable to numerics and a method to set it, this method would then be called after you register CSolver::cb1_adj as input to set CNumerics::cb1 = CSolver::cb1_adj and the numerics would no longer get values from the config by themselves in ComputeResidual.; I hope this makes sense but do have a look at the elasticity solver and try to mimic the strategy used there.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-492342990
https://github.com/su2code/SU2/issues/679#issuecomment-492342990:583,Modifiability,variab,variable,583,"Hi Amir,; I just had a look and that is not going to work I'm afraid.; The numerics classes are not getting the value of the coefficients from the variable that you register as input, this happens because config returns cb1 by value, meaning that what you register as input is not CConfig::cb1_usrdef (seen by numerics) but CSolver::cb1_adj.; You can try registering CConfig::cb1_usrdef as input, making it a public variable would be the easiest thing. This is a hack and personally I don't like the idea of differentiating variables that belong to CConfig. I would add a cb1 member variable to numerics and a method to set it, this method would then be called after you register CSolver::cb1_adj as input to set CNumerics::cb1 = CSolver::cb1_adj and the numerics would no longer get values from the config by themselves in ComputeResidual.; I hope this makes sense but do have a look at the elasticity solver and try to mimic the strategy used there.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-492342990
https://github.com/su2code/SU2/issues/679#issuecomment-492342990:800,Modifiability,config,config,800,"Hi Amir,; I just had a look and that is not going to work I'm afraid.; The numerics classes are not getting the value of the coefficients from the variable that you register as input, this happens because config returns cb1 by value, meaning that what you register as input is not CConfig::cb1_usrdef (seen by numerics) but CSolver::cb1_adj.; You can try registering CConfig::cb1_usrdef as input, making it a public variable would be the easiest thing. This is a hack and personally I don't like the idea of differentiating variables that belong to CConfig. I would add a cb1 member variable to numerics and a method to set it, this method would then be called after you register CSolver::cb1_adj as input to set CNumerics::cb1 = CSolver::cb1_adj and the numerics would no longer get values from the config by themselves in ComputeResidual.; I hope this makes sense but do have a look at the elasticity solver and try to mimic the strategy used there.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-492342990
https://github.com/su2code/SU2/issues/679#issuecomment-493114732:133,Modifiability,variab,variable,133,"Hi Pedro,. Thanks, that makes a lot of sense actually. Out of curiosity I tried the hack you suggested. I set cb1_usrdef to a public variable in CConfig, and registered config->cb1_usrdef as the AD input (config is assigned as a pointer to CConfig already). In the numerics classes I also assigned cb1=config->cb1_usrdef, to ensure it's the same variable as the one registered as input in AD. This still yielded a gradient of zero.; I'm going to try your other solution. I agree it's a much better way of going about it. I'll let you know how it goes.; Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-493114732
https://github.com/su2code/SU2/issues/679#issuecomment-493114732:169,Modifiability,config,config,169,"Hi Pedro,. Thanks, that makes a lot of sense actually. Out of curiosity I tried the hack you suggested. I set cb1_usrdef to a public variable in CConfig, and registered config->cb1_usrdef as the AD input (config is assigned as a pointer to CConfig already). In the numerics classes I also assigned cb1=config->cb1_usrdef, to ensure it's the same variable as the one registered as input in AD. This still yielded a gradient of zero.; I'm going to try your other solution. I agree it's a much better way of going about it. I'll let you know how it goes.; Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-493114732
https://github.com/su2code/SU2/issues/679#issuecomment-493114732:205,Modifiability,config,config,205,"Hi Pedro,. Thanks, that makes a lot of sense actually. Out of curiosity I tried the hack you suggested. I set cb1_usrdef to a public variable in CConfig, and registered config->cb1_usrdef as the AD input (config is assigned as a pointer to CConfig already). In the numerics classes I also assigned cb1=config->cb1_usrdef, to ensure it's the same variable as the one registered as input in AD. This still yielded a gradient of zero.; I'm going to try your other solution. I agree it's a much better way of going about it. I'll let you know how it goes.; Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-493114732
https://github.com/su2code/SU2/issues/679#issuecomment-493114732:302,Modifiability,config,config,302,"Hi Pedro,. Thanks, that makes a lot of sense actually. Out of curiosity I tried the hack you suggested. I set cb1_usrdef to a public variable in CConfig, and registered config->cb1_usrdef as the AD input (config is assigned as a pointer to CConfig already). In the numerics classes I also assigned cb1=config->cb1_usrdef, to ensure it's the same variable as the one registered as input in AD. This still yielded a gradient of zero.; I'm going to try your other solution. I agree it's a much better way of going about it. I'll let you know how it goes.; Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-493114732
https://github.com/su2code/SU2/issues/679#issuecomment-493114732:346,Modifiability,variab,variable,346,"Hi Pedro,. Thanks, that makes a lot of sense actually. Out of curiosity I tried the hack you suggested. I set cb1_usrdef to a public variable in CConfig, and registered config->cb1_usrdef as the AD input (config is assigned as a pointer to CConfig already). In the numerics classes I also assigned cb1=config->cb1_usrdef, to ensure it's the same variable as the one registered as input in AD. This still yielded a gradient of zero.; I'm going to try your other solution. I agree it's a much better way of going about it. I'll let you know how it goes.; Thanks again,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-493114732
https://github.com/su2code/SU2/issues/679#issuecomment-494063905:736,Availability,error,error,736,"Hi Pedro,. I tried the other solution you suggested. I declared a new private variable inside the solver class, which I assigned as config->cb1_usrdef. I registered this as the AD input. I then set a method inside the solver class which returns this value when called.; In the Numerics class, instead of reading cb1 from Config as I used to, I read it from the Solver class, using the method mentioned above.; Now I couldn't create a Solver object inside numerics_structure.inl, since according to the compilation order the solver class is dependant on the numerics class (Solver_structure.hpp includes numerics_structure.hpp). So the compiler doesn't know about the solver class while inside the numerics.; To work around the compiler error, instead I included the solver header file inside the numerics src files (cpp). I then created the solver objects in the relevant numerics functions and called the method which returns the AD-registered cb1 variable.; This all compiles now, but the AD gradient is still returned as 0. Adding print statements to the functions inside the numerics src files revealed that they are getting a cb1 value of 0, which I assume it's because solver_adjoint_discrete.cpp is called after the numerics src files have read the value of cb1, which at that point would be 0.; Would you agree that it's probably best to update the numerics classes inside the adjoint iteration class for CDiscAdjSolver, similar to what's done inside CDiscAdjFEAIteration? Is this what you meant when you referred to the elasticity solver?. Thanks for your help,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494063905
https://github.com/su2code/SU2/issues/679#issuecomment-494063905:1346,Deployability,update,update,1346,"Hi Pedro,. I tried the other solution you suggested. I declared a new private variable inside the solver class, which I assigned as config->cb1_usrdef. I registered this as the AD input. I then set a method inside the solver class which returns this value when called.; In the Numerics class, instead of reading cb1 from Config as I used to, I read it from the Solver class, using the method mentioned above.; Now I couldn't create a Solver object inside numerics_structure.inl, since according to the compilation order the solver class is dependant on the numerics class (Solver_structure.hpp includes numerics_structure.hpp). So the compiler doesn't know about the solver class while inside the numerics.; To work around the compiler error, instead I included the solver header file inside the numerics src files (cpp). I then created the solver objects in the relevant numerics functions and called the method which returns the AD-registered cb1 variable.; This all compiles now, but the AD gradient is still returned as 0. Adding print statements to the functions inside the numerics src files revealed that they are getting a cb1 value of 0, which I assume it's because solver_adjoint_discrete.cpp is called after the numerics src files have read the value of cb1, which at that point would be 0.; Would you agree that it's probably best to update the numerics classes inside the adjoint iteration class for CDiscAdjSolver, similar to what's done inside CDiscAdjFEAIteration? Is this what you meant when you referred to the elasticity solver?. Thanks for your help,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494063905
https://github.com/su2code/SU2/issues/679#issuecomment-494063905:540,Integrability,depend,dependant,540,"Hi Pedro,. I tried the other solution you suggested. I declared a new private variable inside the solver class, which I assigned as config->cb1_usrdef. I registered this as the AD input. I then set a method inside the solver class which returns this value when called.; In the Numerics class, instead of reading cb1 from Config as I used to, I read it from the Solver class, using the method mentioned above.; Now I couldn't create a Solver object inside numerics_structure.inl, since according to the compilation order the solver class is dependant on the numerics class (Solver_structure.hpp includes numerics_structure.hpp). So the compiler doesn't know about the solver class while inside the numerics.; To work around the compiler error, instead I included the solver header file inside the numerics src files (cpp). I then created the solver objects in the relevant numerics functions and called the method which returns the AD-registered cb1 variable.; This all compiles now, but the AD gradient is still returned as 0. Adding print statements to the functions inside the numerics src files revealed that they are getting a cb1 value of 0, which I assume it's because solver_adjoint_discrete.cpp is called after the numerics src files have read the value of cb1, which at that point would be 0.; Would you agree that it's probably best to update the numerics classes inside the adjoint iteration class for CDiscAdjSolver, similar to what's done inside CDiscAdjFEAIteration? Is this what you meant when you referred to the elasticity solver?. Thanks for your help,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494063905
https://github.com/su2code/SU2/issues/679#issuecomment-494063905:78,Modifiability,variab,variable,78,"Hi Pedro,. I tried the other solution you suggested. I declared a new private variable inside the solver class, which I assigned as config->cb1_usrdef. I registered this as the AD input. I then set a method inside the solver class which returns this value when called.; In the Numerics class, instead of reading cb1 from Config as I used to, I read it from the Solver class, using the method mentioned above.; Now I couldn't create a Solver object inside numerics_structure.inl, since according to the compilation order the solver class is dependant on the numerics class (Solver_structure.hpp includes numerics_structure.hpp). So the compiler doesn't know about the solver class while inside the numerics.; To work around the compiler error, instead I included the solver header file inside the numerics src files (cpp). I then created the solver objects in the relevant numerics functions and called the method which returns the AD-registered cb1 variable.; This all compiles now, but the AD gradient is still returned as 0. Adding print statements to the functions inside the numerics src files revealed that they are getting a cb1 value of 0, which I assume it's because solver_adjoint_discrete.cpp is called after the numerics src files have read the value of cb1, which at that point would be 0.; Would you agree that it's probably best to update the numerics classes inside the adjoint iteration class for CDiscAdjSolver, similar to what's done inside CDiscAdjFEAIteration? Is this what you meant when you referred to the elasticity solver?. Thanks for your help,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494063905
https://github.com/su2code/SU2/issues/679#issuecomment-494063905:132,Modifiability,config,config,132,"Hi Pedro,. I tried the other solution you suggested. I declared a new private variable inside the solver class, which I assigned as config->cb1_usrdef. I registered this as the AD input. I then set a method inside the solver class which returns this value when called.; In the Numerics class, instead of reading cb1 from Config as I used to, I read it from the Solver class, using the method mentioned above.; Now I couldn't create a Solver object inside numerics_structure.inl, since according to the compilation order the solver class is dependant on the numerics class (Solver_structure.hpp includes numerics_structure.hpp). So the compiler doesn't know about the solver class while inside the numerics.; To work around the compiler error, instead I included the solver header file inside the numerics src files (cpp). I then created the solver objects in the relevant numerics functions and called the method which returns the AD-registered cb1 variable.; This all compiles now, but the AD gradient is still returned as 0. Adding print statements to the functions inside the numerics src files revealed that they are getting a cb1 value of 0, which I assume it's because solver_adjoint_discrete.cpp is called after the numerics src files have read the value of cb1, which at that point would be 0.; Would you agree that it's probably best to update the numerics classes inside the adjoint iteration class for CDiscAdjSolver, similar to what's done inside CDiscAdjFEAIteration? Is this what you meant when you referred to the elasticity solver?. Thanks for your help,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494063905
https://github.com/su2code/SU2/issues/679#issuecomment-494063905:321,Modifiability,Config,Config,321,"Hi Pedro,. I tried the other solution you suggested. I declared a new private variable inside the solver class, which I assigned as config->cb1_usrdef. I registered this as the AD input. I then set a method inside the solver class which returns this value when called.; In the Numerics class, instead of reading cb1 from Config as I used to, I read it from the Solver class, using the method mentioned above.; Now I couldn't create a Solver object inside numerics_structure.inl, since according to the compilation order the solver class is dependant on the numerics class (Solver_structure.hpp includes numerics_structure.hpp). So the compiler doesn't know about the solver class while inside the numerics.; To work around the compiler error, instead I included the solver header file inside the numerics src files (cpp). I then created the solver objects in the relevant numerics functions and called the method which returns the AD-registered cb1 variable.; This all compiles now, but the AD gradient is still returned as 0. Adding print statements to the functions inside the numerics src files revealed that they are getting a cb1 value of 0, which I assume it's because solver_adjoint_discrete.cpp is called after the numerics src files have read the value of cb1, which at that point would be 0.; Would you agree that it's probably best to update the numerics classes inside the adjoint iteration class for CDiscAdjSolver, similar to what's done inside CDiscAdjFEAIteration? Is this what you meant when you referred to the elasticity solver?. Thanks for your help,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494063905
https://github.com/su2code/SU2/issues/679#issuecomment-494063905:949,Modifiability,variab,variable,949,"Hi Pedro,. I tried the other solution you suggested. I declared a new private variable inside the solver class, which I assigned as config->cb1_usrdef. I registered this as the AD input. I then set a method inside the solver class which returns this value when called.; In the Numerics class, instead of reading cb1 from Config as I used to, I read it from the Solver class, using the method mentioned above.; Now I couldn't create a Solver object inside numerics_structure.inl, since according to the compilation order the solver class is dependant on the numerics class (Solver_structure.hpp includes numerics_structure.hpp). So the compiler doesn't know about the solver class while inside the numerics.; To work around the compiler error, instead I included the solver header file inside the numerics src files (cpp). I then created the solver objects in the relevant numerics functions and called the method which returns the AD-registered cb1 variable.; This all compiles now, but the AD gradient is still returned as 0. Adding print statements to the functions inside the numerics src files revealed that they are getting a cb1 value of 0, which I assume it's because solver_adjoint_discrete.cpp is called after the numerics src files have read the value of cb1, which at that point would be 0.; Would you agree that it's probably best to update the numerics classes inside the adjoint iteration class for CDiscAdjSolver, similar to what's done inside CDiscAdjFEAIteration? Is this what you meant when you referred to the elasticity solver?. Thanks for your help,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494063905
https://github.com/su2code/SU2/issues/679#issuecomment-494118969:213,Usability,clear,clear,213,"Hi Amir,; If you create a solver object inside numerics how will this new solver know about the solver that is actually using numerics? The way the code is written does not make the relations between classes very clear as the solver and numerics containers get passed around quite freely... But the solvers are clients of the numerics (I think there are good diagrams of this in some of the papers), i.e. the solvers call methods of the numerics and not the other way around.; It is the numerics that needs a method whereby the solver can set the value of cb1, this is more or less what is done in the elasticity solver, so yes, try to follow that ""recipe"" as close as possible and it should work.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-494118969
https://github.com/su2code/SU2/issues/679#issuecomment-498358987:163,Integrability,message,message,163,"Hi Amir,; I think you need to declare su2double CSolver::GetSA_cb1_solver(void) as virtual, i.e.:; virtual su2double CSolver::GetSA_cb1_solver(void);; I guess the message you added also does not get printed?; ""AKB: inside GetSA_cb1_solver returning cb1_adj as: ""; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498358987
https://github.com/su2code/SU2/issues/679#issuecomment-498383515:109,Integrability,message,message,109,"Hi Pedro,; Thanks. I already have done that, it's already declared as virtual inside the CSolver class.; The message does get printed. What's strange is that it prints cb1_adj=0., even though inside solver_adjoint_discrete.cpp, cb1_adj is assigned as cb1_adj = config->GetSA_cb1(); before being registered as an AD variable, and therefore is not 0.; Thanks; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498383515
https://github.com/su2code/SU2/issues/679#issuecomment-498383515:261,Modifiability,config,config,261,"Hi Pedro,; Thanks. I already have done that, it's already declared as virtual inside the CSolver class.; The message does get printed. What's strange is that it prints cb1_adj=0., even though inside solver_adjoint_discrete.cpp, cb1_adj is assigned as cb1_adj = config->GetSA_cb1(); before being registered as an AD variable, and therefore is not 0.; Thanks; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498383515
https://github.com/su2code/SU2/issues/679#issuecomment-498383515:315,Modifiability,variab,variable,315,"Hi Pedro,; Thanks. I already have done that, it's already declared as virtual inside the CSolver class.; The message does get printed. What's strange is that it prints cb1_adj=0., even though inside solver_adjoint_discrete.cpp, cb1_adj is assigned as cb1_adj = config->GetSA_cb1(); before being registered as an AD variable, and therefore is not 0.; Thanks; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498383515
https://github.com/su2code/SU2/issues/679#issuecomment-498417564:279,Modifiability,config,config,279,"Yup, it is being called as far as I can tell. I've also put a print statement inside the registervariables method inside solver right after cb1_adj is registered with AD, and sure enough the screen outputs my statement along with the correct value of cb1_adj as read in from the config class.; Seems that only when we are inside the Iteration class and calling the solver method to return cb1_adj from solver it returns it as 0. Could it be an issue with the scope of cb1_adj? (I also tried making it a public variable inside the class but didn't make a difference).; Or perhaps instead of trying to get the _value_ of cb1_adj from solver, I need to get a pointer pointing to the memory address of cb1_adj, and pass _that_ onto numerics?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498417564
https://github.com/su2code/SU2/issues/679#issuecomment-498417564:510,Modifiability,variab,variable,510,"Yup, it is being called as far as I can tell. I've also put a print statement inside the registervariables method inside solver right after cb1_adj is registered with AD, and sure enough the screen outputs my statement along with the correct value of cb1_adj as read in from the config class.; Seems that only when we are inside the Iteration class and calling the solver method to return cb1_adj from solver it returns it as 0. Could it be an issue with the scope of cb1_adj? (I also tried making it a public variable inside the class but didn't make a difference).; Or perhaps instead of trying to get the _value_ of cb1_adj from solver, I need to get a pointer pointing to the memory address of cb1_adj, and pass _that_ onto numerics?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498417564
https://github.com/su2code/SU2/issues/679#issuecomment-498429475:437,Modifiability,config,config,437,"Yes but it is being called on which solver? Don't forget there is one instance of DiscAdjSolver for the bulk flow and another for the turbulence, you are currently trying to get the value from solver_container[iZone][iInst][MESH_0][ADJTURB_SOL] so make sure RegisterVariables is called for this solver, you may be calling it for ADJFLOW_SOL instead, and that will still give you the right value of cb1 because it comes directly from the config. Edit: I would not mess around with pointers here... You can determine which solver object is being used at a given time by printing nVar to screen (which is 1 for SA and 4/5 for RANS).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498429475
https://github.com/su2code/SU2/issues/679#issuecomment-498749435:135,Availability,error,error,135,"Hey,. Yeah you're right, RegisterVariables was being called for ADJFLOW_SOL. Changing it so that it calls for ADJTURB_SOL throws a seg error (haven't investigated why yet). However, if I keep the RegisterVariables as is (for ADJFLOW_SOL) and instead I change the solver instance inside CDiscAdjFluidIteration::SetDependencies to solver_container[iZone][iInst][MESH_0][ADJFLOW_SOL], and try to get the value for cb1 from there, it does return the correct value. Also, the final sensitivity values become non-zero so AD is definitely doing something now. I assumed I had to use the solver_container with ADJTURB_SOL in SetDependencies since the disc_adj_turb flag inside driver_structure is set to true, and so the solver_container with ADJTURB_SOL is instantiated as a new CDiscAdjSolver during the numerics preprocessing. I guess it's a matter of consistency with the rest of the code though, so maybe my assumption was wrong. I'll test to see if the sensitivity values I'm getting are correct, will let you know.; Thanks so much for your help, hopefully this has been solved for good :); Cheers",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498749435
https://github.com/su2code/SU2/issues/679#issuecomment-498749435:932,Testability,test,test,932,"Hey,. Yeah you're right, RegisterVariables was being called for ADJFLOW_SOL. Changing it so that it calls for ADJTURB_SOL throws a seg error (haven't investigated why yet). However, if I keep the RegisterVariables as is (for ADJFLOW_SOL) and instead I change the solver instance inside CDiscAdjFluidIteration::SetDependencies to solver_container[iZone][iInst][MESH_0][ADJFLOW_SOL], and try to get the value for cb1 from there, it does return the correct value. Also, the final sensitivity values become non-zero so AD is definitely doing something now. I assumed I had to use the solver_container with ADJTURB_SOL in SetDependencies since the disc_adj_turb flag inside driver_structure is set to true, and so the solver_container with ADJTURB_SOL is instantiated as a new CDiscAdjSolver during the numerics preprocessing. I guess it's a matter of consistency with the rest of the code though, so maybe my assumption was wrong. I'll test to see if the sensitivity values I'm getting are correct, will let you know.; Thanks so much for your help, hopefully this has been solved for good :); Cheers",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-498749435
https://github.com/su2code/SU2/issues/679#issuecomment-500911599:74,Testability,test,tested,74,"Hi Pedro,. I can confirm that everything is now working correctly. I have tested the sensitivities against gradients from finite difference runs and the results match very closely.; I owe you a big thank you for your help with this, not only has my problem been solved but you also helped me learn a great deal about how the code works. Really appreciate it.; If we ever meet one day then drinks are on me :); Cheers,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-500911599
https://github.com/su2code/SU2/issues/679#issuecomment-500911599:292,Usability,learn,learn,292,"Hi Pedro,. I can confirm that everything is now working correctly. I have tested the sensitivities against gradients from finite difference runs and the results match very closely.; I owe you a big thank you for your help with this, not only has my problem been solved but you also helped me learn a great deal about how the code works. Really appreciate it.; If we ever meet one day then drinks are on me :); Cheers,; Amir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/679#issuecomment-500911599
https://github.com/su2code/SU2/pull/681#issuecomment-493543146:118,Testability,test,testcases,118,"Verification results [here](https://github.com/su2code/SU2/files/3192519/verif.pdf) along with pictures of the failed testcases, 5/6 new reference residuals are lower than before. Funny story the prism elements do not need negative weights in CVolumetric movement... Only the elasticity solver seems to need this, I tested both with a mesh with mixed elements. I have no explanation for this... the code is the ""same"" in both places.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-493543146
https://github.com/su2code/SU2/pull/681#issuecomment-493543146:316,Testability,test,tested,316,"Verification results [here](https://github.com/su2code/SU2/files/3192519/verif.pdf) along with pictures of the failed testcases, 5/6 new reference residuals are lower than before. Funny story the prism elements do not need negative weights in CVolumetric movement... Only the elasticity solver seems to need this, I tested both with a mesh with mixed elements. I have no explanation for this... the code is the ""same"" in both places.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-493543146
https://github.com/su2code/SU2/pull/681#issuecomment-495321715:228,Testability,test,testcase,228,"Thank you for the review @rsanfer.; I put the extra comments and ""centralized constants"" in the code.; Everything relating to the incompressible neo-Hookean material has been deleted, let me know if it was too much.; I'll put a testcase together with a healthy mix of elements, probably next week.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-495321715
https://github.com/su2code/SU2/pull/681#issuecomment-496400629:306,Availability,mainten,maintenance,306,"Thanks for the changes, @pcarruscag. I like PRs like this with 797 additions and 3220 deletions maintaining functionality :+1: The incompressible part of the FEA problem was, like some other features in the code, 90% ready but never totally finished, so to avoid confusion in users and developers and ease maintenance I think it's better for it to be removed until someone can take over and finalize the implementation.; Let me know when you've had some time to put that testcase, and we can get this merged in.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-496400629
https://github.com/su2code/SU2/pull/681#issuecomment-496400629:257,Safety,avoid,avoid,257,"Thanks for the changes, @pcarruscag. I like PRs like this with 797 additions and 3220 deletions maintaining functionality :+1: The incompressible part of the FEA problem was, like some other features in the code, 90% ready but never totally finished, so to avoid confusion in users and developers and ease maintenance I think it's better for it to be removed until someone can take over and finalize the implementation.; Let me know when you've had some time to put that testcase, and we can get this merged in.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-496400629
https://github.com/su2code/SU2/pull/681#issuecomment-496400629:471,Testability,test,testcase,471,"Thanks for the changes, @pcarruscag. I like PRs like this with 797 additions and 3220 deletions maintaining functionality :+1: The incompressible part of the FEA problem was, like some other features in the code, 90% ready but never totally finished, so to avoid confusion in users and developers and ease maintenance I think it's better for it to be removed until someone can take over and finalize the implementation.; Let me know when you've had some time to put that testcase, and we can get this merged in.; Cheers,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-496400629
https://github.com/su2code/SU2/pull/681#issuecomment-497805949:9,Testability,test,testcase,9,"@rsanfer testcase is in. I used the Knowles material model, I don't think there was a regression for it.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-497805949
https://github.com/su2code/SU2/pull/681#issuecomment-498316703:39,Testability,test,test,39,"Hi @pcarruscag,; thanks for adding the test case. This LGTM, from my side is ready. Let's allow as common practice some 24 h to see if anyone has additional comments, then we can merge it in.; Best,; Ruben",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/681#issuecomment-498316703
https://github.com/su2code/SU2/issues/683#issuecomment-493382428:90,Availability,Error,Error,90,"Thanks @timjim333. . I just tried the case using the newest develop version. I get . ```; Error in ""virtual void CPhysicalGeometry::SetBoundVolume()"": ; -------------------------------------------------------------------------; The surface element (0, 74472) doesn't have an associated volume element; ------------------------------ Error Exit -------------------------------; ```. So there seems to be an issue with the connectivity in the mesh file. Can anyone else try to run this case to see if we get some consistent information ?. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493382428
https://github.com/su2code/SU2/issues/683#issuecomment-493382428:333,Availability,Error,Error,333,"Thanks @timjim333. . I just tried the case using the newest develop version. I get . ```; Error in ""virtual void CPhysicalGeometry::SetBoundVolume()"": ; -------------------------------------------------------------------------; The surface element (0, 74472) doesn't have an associated volume element; ------------------------------ Error Exit -------------------------------; ```. So there seems to be an issue with the connectivity in the mesh file. Can anyone else try to run this case to see if we get some consistent information ?. Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493382428
https://github.com/su2code/SU2/issues/683#issuecomment-493404108:48,Availability,error,error,48,"I tried on 1, 4 and 24 cores and I get the same error message as @talbring. This indeed indicates that something is wrong with your grid. The fact that your computation is stuck is most likely caused by your MPI implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493404108
https://github.com/su2code/SU2/issues/683#issuecomment-493404108:54,Integrability,message,message,54,"I tried on 1, 4 and 24 cores and I get the same error message as @talbring. This indeed indicates that something is wrong with your grid. The fact that your computation is stuck is most likely caused by your MPI implementation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493404108
https://github.com/su2code/SU2/issues/683#issuecomment-493887466:94,Deployability,release,release,94,"Thanks for trying this out. @talbring I don't get the same - I guess it's because I'm using a release version as opposed to the develop. Is the develop stable enough for general use?. @vdweide you mentioned it could be an issue with MPI? As far as I can tell, everyone on the HPC is also referencing the same MPI - do you have any tips on how I might debug this?. Thanks again.; Tim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493887466
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:178,Availability,error,error,178,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:377,Availability,error,error,377,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:406,Availability,error,error,406,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:249,Deployability,release,release,249,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:184,Integrability,message,message,184,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:383,Integrability,message,message,383,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:412,Integrability,message,message,412,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493889597:434,Integrability,depend,depending,434,"@timjim333, create a sequential executable and run it on one core. It may take a couple of minutes, but it is not too bad. Then MPI is not used and you should definitely get the error message. I don't think there will be much of a difference in the release version and develop version for this problem. As far as the MPI is concerned, a one-sided communication is used for the error message. Sometimes the error message is not shown, depending on the MPI distribution and number of cores. Maybe this is something we have to look into. In any case, what MPI distribution are you using?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493889597
https://github.com/su2code/SU2/issues/683#issuecomment-493898336:117,Availability,avail,available,117,"@vdweide I'm using the Intel MPI Library for Linux* OS (Version 2018 Update 2 Build 20180125) - it's the one that is available on our supercomputer system at the moment. I was running on 40 cores. I also have a version of SU2 compiled with OpenMPI 3.0.0 on my personal workstation but I don't have the required RAM to get to the point where I get the error, however. It seems strange that it happens for this mesh only as I have run many other similar meshes successfully on the same HPC system - would that not trip the same issue if it were the MPI installation?; Thanks for your thoughts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493898336
https://github.com/su2code/SU2/issues/683#issuecomment-493898336:351,Availability,error,error,351,"@vdweide I'm using the Intel MPI Library for Linux* OS (Version 2018 Update 2 Build 20180125) - it's the one that is available on our supercomputer system at the moment. I was running on 40 cores. I also have a version of SU2 compiled with OpenMPI 3.0.0 on my personal workstation but I don't have the required RAM to get to the point where I get the error, however. It seems strange that it happens for this mesh only as I have run many other similar meshes successfully on the same HPC system - would that not trip the same issue if it were the MPI installation?; Thanks for your thoughts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493898336
https://github.com/su2code/SU2/issues/683#issuecomment-493898336:69,Deployability,Update,Update,69,"@vdweide I'm using the Intel MPI Library for Linux* OS (Version 2018 Update 2 Build 20180125) - it's the one that is available on our supercomputer system at the moment. I was running on 40 cores. I also have a version of SU2 compiled with OpenMPI 3.0.0 on my personal workstation but I don't have the required RAM to get to the point where I get the error, however. It seems strange that it happens for this mesh only as I have run many other similar meshes successfully on the same HPC system - would that not trip the same issue if it were the MPI installation?; Thanks for your thoughts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493898336
https://github.com/su2code/SU2/issues/683#issuecomment-493898336:551,Deployability,install,installation,551,"@vdweide I'm using the Intel MPI Library for Linux* OS (Version 2018 Update 2 Build 20180125) - it's the one that is available on our supercomputer system at the moment. I was running on 40 cores. I also have a version of SU2 compiled with OpenMPI 3.0.0 on my personal workstation but I don't have the required RAM to get to the point where I get the error, however. It seems strange that it happens for this mesh only as I have run many other similar meshes successfully on the same HPC system - would that not trip the same issue if it were the MPI installation?; Thanks for your thoughts!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493898336
https://github.com/su2code/SU2/issues/683#issuecomment-493914393:68,Availability,error,error,68,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393
https://github.com/su2code/SU2/issues/683#issuecomment-493914393:74,Integrability,message,message,74,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393
https://github.com/su2code/SU2/issues/683#issuecomment-493914393:62,Usability,clear,clear,62,"I am using Intel MPI as well, but on Ubuntu 18.04 and I get a clear error message. The likely reason why it hangs for you for this grid and not for the others is that this grid has an issue and the others do not. . Can you run it on one core of your supercomputer?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493914393
https://github.com/su2code/SU2/issues/683#issuecomment-493931406:52,Availability,error,error,52,"On running with a single core, I also get a similar error (attached below). In this case, I'm guessing that it doesn't like the 2D element? This seems strange as it managed to handle a few cases where flat cells were also present, do you have any thoughts on this?. Also, is it possible to identify the location of the cell based on the error message?; Many thanks,; Tim; ```; ------------------------ Geometry Preprocessing ------------------------; Setting point connectivity.; Renumbering points (Reverse Cuthill McKee Ordering).; Recomputing point connectivity.; Setting element connectivity. Error in ""virtual void CPhysicalGeometry::SetBoundVolume()"": ; -------------------------------------------------------------------------; The surface element (0, 133348) doesn't have an associated volume element; ------------------------------ Error Exit -------------------------------. application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0; SU2_CFD failed with retcode 1; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493931406
https://github.com/su2code/SU2/issues/683#issuecomment-493931406:337,Availability,error,error,337,"On running with a single core, I also get a similar error (attached below). In this case, I'm guessing that it doesn't like the 2D element? This seems strange as it managed to handle a few cases where flat cells were also present, do you have any thoughts on this?. Also, is it possible to identify the location of the cell based on the error message?; Many thanks,; Tim; ```; ------------------------ Geometry Preprocessing ------------------------; Setting point connectivity.; Renumbering points (Reverse Cuthill McKee Ordering).; Recomputing point connectivity.; Setting element connectivity. Error in ""virtual void CPhysicalGeometry::SetBoundVolume()"": ; -------------------------------------------------------------------------; The surface element (0, 133348) doesn't have an associated volume element; ------------------------------ Error Exit -------------------------------. application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0; SU2_CFD failed with retcode 1; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493931406
https://github.com/su2code/SU2/issues/683#issuecomment-493931406:597,Availability,Error,Error,597,"On running with a single core, I also get a similar error (attached below). In this case, I'm guessing that it doesn't like the 2D element? This seems strange as it managed to handle a few cases where flat cells were also present, do you have any thoughts on this?. Also, is it possible to identify the location of the cell based on the error message?; Many thanks,; Tim; ```; ------------------------ Geometry Preprocessing ------------------------; Setting point connectivity.; Renumbering points (Reverse Cuthill McKee Ordering).; Recomputing point connectivity.; Setting element connectivity. Error in ""virtual void CPhysicalGeometry::SetBoundVolume()"": ; -------------------------------------------------------------------------; The surface element (0, 133348) doesn't have an associated volume element; ------------------------------ Error Exit -------------------------------. application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0; SU2_CFD failed with retcode 1; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493931406
https://github.com/su2code/SU2/issues/683#issuecomment-493931406:841,Availability,Error,Error,841,"On running with a single core, I also get a similar error (attached below). In this case, I'm guessing that it doesn't like the 2D element? This seems strange as it managed to handle a few cases where flat cells were also present, do you have any thoughts on this?. Also, is it possible to identify the location of the cell based on the error message?; Many thanks,; Tim; ```; ------------------------ Geometry Preprocessing ------------------------; Setting point connectivity.; Renumbering points (Reverse Cuthill McKee Ordering).; Recomputing point connectivity.; Setting element connectivity. Error in ""virtual void CPhysicalGeometry::SetBoundVolume()"": ; -------------------------------------------------------------------------; The surface element (0, 133348) doesn't have an associated volume element; ------------------------------ Error Exit -------------------------------. application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0; SU2_CFD failed with retcode 1; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493931406
https://github.com/su2code/SU2/issues/683#issuecomment-493931406:343,Integrability,message,message,343,"On running with a single core, I also get a similar error (attached below). In this case, I'm guessing that it doesn't like the 2D element? This seems strange as it managed to handle a few cases where flat cells were also present, do you have any thoughts on this?. Also, is it possible to identify the location of the cell based on the error message?; Many thanks,; Tim; ```; ------------------------ Geometry Preprocessing ------------------------; Setting point connectivity.; Renumbering points (Reverse Cuthill McKee Ordering).; Recomputing point connectivity.; Setting element connectivity. Error in ""virtual void CPhysicalGeometry::SetBoundVolume()"": ; -------------------------------------------------------------------------; The surface element (0, 133348) doesn't have an associated volume element; ------------------------------ Error Exit -------------------------------. application called MPI_Abort(MPI_COMM_WORLD, 1) - process 0; SU2_CFD failed with retcode 1; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493931406
https://github.com/su2code/SU2/issues/683#issuecomment-493938679:7,Availability,error,error,7,"As the error message indicates, a surface element is not part of a volume element. At least, the solver is not able to find one. From the error message this happens for surface element 133348 of marker 0.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493938679
https://github.com/su2code/SU2/issues/683#issuecomment-493938679:138,Availability,error,error,138,"As the error message indicates, a surface element is not part of a volume element. At least, the solver is not able to find one. From the error message this happens for surface element 133348 of marker 0.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493938679
https://github.com/su2code/SU2/issues/683#issuecomment-493938679:13,Integrability,message,message,13,"As the error message indicates, a surface element is not part of a volume element. At least, the solver is not able to find one. From the error message this happens for surface element 133348 of marker 0.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493938679
https://github.com/su2code/SU2/issues/683#issuecomment-493938679:144,Integrability,message,message,144,"As the error message indicates, a surface element is not part of a volume element. At least, the solver is not able to find one. From the error message this happens for surface element 133348 of marker 0.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493938679
https://github.com/su2code/SU2/issues/683#issuecomment-493939877:63,Availability,error,error,63,"Actually, the part that worries me a bit, is the fact that the error handling does not seem to terminate the MPI job appropriately. @talbring, could this be caused by the one-sided communication that is used for this purpose?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-493939877
https://github.com/su2code/SU2/issues/683#issuecomment-494217280:183,Usability,guid,guiding,183,"All above,. Can any one share the experience of the mesh quality matrix acceptable by SU2. In Pointwise, one can follow maximum included angle, centroid skewness or equiangle skew as guiding parameters. I have observed that some of the commercial Solvers can accepts and run a very high max included angle (179.99 or so) also without trouble but some others have issues with the same. . Many times due to complex geometry, one ends up with these high numbers. . Any guidelines for SU2 on mesh quality is appreciated. Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494217280
https://github.com/su2code/SU2/issues/683#issuecomment-494217280:466,Usability,guid,guidelines,466,"All above,. Can any one share the experience of the mesh quality matrix acceptable by SU2. In Pointwise, one can follow maximum included angle, centroid skewness or equiangle skew as guiding parameters. I have observed that some of the commercial Solvers can accepts and run a very high max included angle (179.99 or so) also without trouble but some others have issues with the same. . Many times due to complex geometry, one ends up with these high numbers. . Any guidelines for SU2 on mesh quality is appreciated. Regards ; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494217280
https://github.com/su2code/SU2/issues/683#issuecomment-494393404:84,Availability,error,error,84,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404
https://github.com/su2code/SU2/issues/683#issuecomment-494393404:90,Integrability,message,messages,90,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404
https://github.com/su2code/SU2/issues/683#issuecomment-494393404:896,Usability,clear,clearly,896,"@timjim333, I checked your grid with just connectivity info and I get the following error messages. Boundary marker BODY, surface element 77477: No corresponding volume element found.; Coordinates of the points; 0.1815790.04981870.0020471; 0.181850.04994770.00205104; 0.1816670.04971090.00204381. Boundary marker BODY, surface element 133348: No corresponding volume element found.; Coordinates of the points; 0.1814850.04947420.00203657; 0.1813090.04968980.00204316; 0.181230.04944470.00204356. Boundary marker BODY, surface element 134774: No corresponding volume element found.; Coordinates of the points; 0.181230.04944470.00204356; 0.1813020.04923740.00202934; 0.1814850.04947420.00203657. Boundary marker BODY, surface element 135217: No corresponding volume element found.; Coordinates of the points; 0.1816670.04971090.00204381; 0.181850.04994770.00205104; 0.1815790.04981870.0020471. So clearly the grid is invalid.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494393404
https://github.com/su2code/SU2/issues/683#issuecomment-494663306:24,Deployability,update,update,24,@vdweide Thanks for the update. How does one bring up this information? Is this referring to a 2D cell where a 3D one is expected?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494663306
https://github.com/su2code/SU2/issues/683#issuecomment-494675549:187,Availability,error,error,187,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
https://github.com/su2code/SU2/issues/683#issuecomment-494675549:193,Integrability,message,message,193,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
https://github.com/su2code/SU2/issues/683#issuecomment-494675549:28,Testability,test,test,28,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
https://github.com/su2code/SU2/issues/683#issuecomment-494675549:2,Usability,simpl,simple,2,"I simple wrote a program to test the grid, which searches for the boundary elements in the single faces, i.e. faces that are only part of one volume element, of the volume grid. What the error message means is that for 4 triangular surface elements of boundary marker BODY there is no corresponding face of the volume elements that is only part of one volume element. . When I include the faces that are shared by two volume elements, only two boundary elements are not found. So in short, you have two boundary elements in boundary marker BODY that are no part of any volume element and two boundary elements that are shared by two volume elements.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494675549
https://github.com/su2code/SU2/issues/683#issuecomment-494932014:40,Usability,guid,guidelines,40,"@timjim333,. Yah, those are the general guidelines you mentioned but they do not always work in practical cases.; We will probably know more details when people will share their experiences and issues faced. I have tried meshes with max include angle 175 or below, they go well. Even upto 179 also go through.; But I had trouble recently while just giving a trial for 179.8 or more case.; One thing to note is, SU2 constructs dual mesh from the primal mesh we supply but anyway properties of the primal mesh will carry forward. Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-494932014
https://github.com/su2code/SU2/issues/683#issuecomment-495885490:255,Integrability,message,message,255,"@vdweide @talbring Ok, thanks you for all your thoughts and help troubleshooting this so far - I guess it might be the SU2 export plugin introducing this as I can't seem to identify the mesh issue within Pointwise itself. I'll contact support and leave a message here if any workarounds are found.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495885490
https://github.com/su2code/SU2/issues/683#issuecomment-495885490:130,Modifiability,plugin,plugin,130,"@vdweide @talbring Ok, thanks you for all your thoughts and help troubleshooting this so far - I guess it might be the SU2 export plugin introducing this as I can't seem to identify the mesh issue within Pointwise itself. I'll contact support and leave a message here if any workarounds are found.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495885490
https://github.com/su2code/SU2/issues/683#issuecomment-495921430:188,Availability,robust,robust,188,@timjim333. The guidelines you mentioned are perfect but geometry complexity/time constraints at times push it beyond those numbers. Infact most of the Solvers (especially commercial) are robust enough to take (as I mentioned) the mesh crossing these specific guidelines. I think SU2 also handles it reasonably well. Latest version of Pointwise has direct export to SU2 (I think 17.3 onwards or so). Did you try CGNS format? . Best; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495921430
https://github.com/su2code/SU2/issues/683#issuecomment-495921430:16,Usability,guid,guidelines,16,@timjim333. The guidelines you mentioned are perfect but geometry complexity/time constraints at times push it beyond those numbers. Infact most of the Solvers (especially commercial) are robust enough to take (as I mentioned) the mesh crossing these specific guidelines. I think SU2 also handles it reasonably well. Latest version of Pointwise has direct export to SU2 (I think 17.3 onwards or so). Did you try CGNS format? . Best; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495921430
https://github.com/su2code/SU2/issues/683#issuecomment-495921430:260,Usability,guid,guidelines,260,@timjim333. The guidelines you mentioned are perfect but geometry complexity/time constraints at times push it beyond those numbers. Infact most of the Solvers (especially commercial) are robust enough to take (as I mentioned) the mesh crossing these specific guidelines. I think SU2 also handles it reasonably well. Latest version of Pointwise has direct export to SU2 (I think 17.3 onwards or so). Did you try CGNS format? . Best; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/683#issuecomment-495921430
https://github.com/su2code/SU2/issues/684#issuecomment-495078497:399,Modifiability,config,config,399,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
https://github.com/su2code/SU2/issues/684#issuecomment-495078497:243,Safety,detect,detected,243,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
https://github.com/su2code/SU2/issues/684#issuecomment-495078497:322,Safety,detect,detect,322,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
https://github.com/su2code/SU2/issues/684#issuecomment-495078497:343,Safety,avoid,avoid,343,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
https://github.com/su2code/SU2/issues/684#issuecomment-495078497:72,Usability,simpl,simply,72,"@marcovanderbijl : thanks for the question. The original limit there is simply to impose an upper bound for memory considerations, since the first instantiation of the array of FFD boxes (before the number of FFD boxes embedded in the mesh is detected) needs a default value. We can of course change this to automatically detect the number to avoid the requirement or make it an input option in the config, but we have not run into this issue yet. For now, you should be able to increase that to a reasonable number without any issue. Please give it a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495078497
https://github.com/su2code/SU2/issues/684#issuecomment-495213847:88,Safety,detect,detection,88,"thanks! should I close issue,.. or will someone take it up and code auto FFD box number detection?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/684#issuecomment-495213847
https://github.com/su2code/SU2/issues/685#issuecomment-494828151:66,Modifiability,config,configure,66,"To see a major advantage, just compare the `meson.build` and the `configure.ac` file ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494828151
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:1107,Deployability,install,install,1107,"d Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/685?e",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:567,Integrability,depend,dependencies,567,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:1231,Integrability,depend,depends,1231,"ently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/685?email_source=notifications&email_token=AADV2HBMTJ7RZMV763KCYPLPWVKIXA5CNFSM4HOUXHQKYY3PNVWW",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:200,Modifiability,config,config,200,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:303,Modifiability,config,config,303,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:366,Modifiability,config,config,366,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:745,Modifiability,config,config,745,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:765,Modifiability,config,config,765,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:838,Modifiability,config,config,838,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:955,Modifiability,config,config,955,"Tim,. I can share some initial impressions. I’m trying to build the Mesa 3D graphics library, which recently switched to Meson and Ninja. They are pretty impressive. It looks like Meson uses both pkg-config and (more recently) CMake under the hood. For specific packages that don’t play nicely with pkg-config, it will look for other similar utilities, such as llvm-config for the LLVM library. I have a beef mostly with documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this becaus",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-494848848:1947,Modifiability,config,configure,1947," documentation, but that’s hardly unusual in the open source world, and maybe not so relevant to SU2, which doesn’t have the multitude of external dependencies that many open source projects do. I think the struggles I have had relate mostly to the non-transparent way that Meson interacts with the underlying utilities (pkg-config, CMake, llvm-config,…). For example, I had to fumble around to get Meson to find llvm-config in a non-standard location (adding that location to $PATH turned out to be the answer), as well as to get pkg-config to find its required pkgconfig directories in non-standard locations (adding them to $PKG_CONFIG_PATH was the answer there). I also had to build/install Python 3 (required by Meson), and found that the Python 3.7 has problems with OpenSSL (module _ssl), on which Meson depends, so I went back to Python 3.6. I imagine any pre-built Python 3.7 would be fine, though a related bug appears to still be open (https://bugs.python.org/issue34028). On Windows, Meson will output Visual Studio projects, which would make any Windows developer happy, but your source still has to be cross-platform friendly—not a problem for TecIO, but I don’t know if that’s true elsewhere in SU2. FWIW,. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Wednesday, May 22, 2019 7:31 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). To see a major advantage, just compare the meson.build and the configure.ac file ... —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/685?email_source=notifications&email_token=AADV2HBMTJ7RZMV763KCYPLPWVKIXA5CNFSM4HOUXHQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODV7HU5Y#issuecomment-494828151>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HCTYNNIVVXY7RSS5WTPWVKIXANCNFSM4HOUXHQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-494848848
https://github.com/su2code/SU2/issues/685#issuecomment-495097393:87,Availability,error,error,87,"meson.build does indeed look short and clean. Tried this on mac, and hit the following error (I guess the OS is more picky?):. ERROR: Could not detect Ninja v1.5 or newer. Any issue with updating to a newer ninja version in the bootstrap? . Also, for older git versions (like mine apparently), you may need to add the --init and --recursive flags to 'git submodule update'",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495097393
https://github.com/su2code/SU2/issues/685#issuecomment-495097393:127,Availability,ERROR,ERROR,127,"meson.build does indeed look short and clean. Tried this on mac, and hit the following error (I guess the OS is more picky?):. ERROR: Could not detect Ninja v1.5 or newer. Any issue with updating to a newer ninja version in the bootstrap? . Also, for older git versions (like mine apparently), you may need to add the --init and --recursive flags to 'git submodule update'",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495097393
https://github.com/su2code/SU2/issues/685#issuecomment-495097393:365,Deployability,update,update,365,"meson.build does indeed look short and clean. Tried this on mac, and hit the following error (I guess the OS is more picky?):. ERROR: Could not detect Ninja v1.5 or newer. Any issue with updating to a newer ninja version in the bootstrap? . Also, for older git versions (like mine apparently), you may need to add the --init and --recursive flags to 'git submodule update'",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495097393
https://github.com/su2code/SU2/issues/685#issuecomment-495097393:144,Safety,detect,detect,144,"meson.build does indeed look short and clean. Tried this on mac, and hit the following error (I guess the OS is more picky?):. ERROR: Could not detect Ninja v1.5 or newer. Any issue with updating to a newer ninja version in the bootstrap? . Also, for older git versions (like mine apparently), you may need to add the --init and --recursive flags to 'git submodule update'",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495097393
https://github.com/su2code/SU2/issues/685#issuecomment-495117437:805,Integrability,depend,dependencies,805,"@economon Hm ok, that is strange. The one that it builds is the newest on github (v1.9). On linux meson finds ninja if it is in the root directory of the source code (which should be there after bootstrapping), apparently that is not the case on mac. Can you check whether it works when you add the source dir in your path variable? Like @davetaflin also mentioned for windows, on mac you can also directly generated xcode files (by adding `--backend=xcode` to the meson call), then ninja is not required. But anyway, I will look for a solution to that problem. @davetaflin Thanks for your impressions. I would say the documentation is decent. The important things are there, which helped me setting it up. But I guess that we can also ask the developers if we have some problems when adding more complex dependencies (however, we then also should ask ourselves whether we really want to add them in this case). But is the conclusion that you'd also prefer meson over automake ? :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495117437
https://github.com/su2code/SU2/issues/685#issuecomment-495117437:323,Modifiability,variab,variable,323,"@economon Hm ok, that is strange. The one that it builds is the newest on github (v1.9). On linux meson finds ninja if it is in the root directory of the source code (which should be there after bootstrapping), apparently that is not the case on mac. Can you check whether it works when you add the source dir in your path variable? Like @davetaflin also mentioned for windows, on mac you can also directly generated xcode files (by adding `--backend=xcode` to the meson call), then ninja is not required. But anyway, I will look for a solution to that problem. @davetaflin Thanks for your impressions. I would say the documentation is decent. The important things are there, which helped me setting it up. But I guess that we can also ask the developers if we have some problems when adding more complex dependencies (however, we then also should ask ourselves whether we really want to add them in this case). But is the conclusion that you'd also prefer meson over automake ? :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495117437
https://github.com/su2code/SU2/issues/685#issuecomment-495299585:1315,Integrability,depend,dependencies,1315,"I would give a cautious yes, cautious because Meson appears quite new, and probably still has some wrinkles to iron out. It’s definitely worth a try. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Thursday, May 23, 2019 1:21 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Dave Taflin <d.taflin@tecplot.com>; Mention <mention@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). @economon<https://github.com/economon> Hm ok, that is strange. The one that it builds is the newest on github (v1.9). On linux meson finds ninja if it is in the root directory of the source code (which should be there after bootstrapping), apparently that is not the case on mac. Can you check whether it works when you add the source dir in your path variable? Like @davetaflin<https://github.com/davetaflin> also mentioned for windows, on mac you can also directly generated xcode files (by adding --backend=xcode to the meson call), then ninja is not required. But anyway, I will look for a solution to that problem. @davetaflin<https://github.com/davetaflin> Thanks for your impressions. I would say the documentation is decent. The important things are there, which helped me setting it up. But I guess that we can also ask the developers if we have some problems when adding more complex dependencies (however, we then also should ask ourselves whether we really want to add them in this case). But is the conclusion that you'd also prefer meson over automake ? :D. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/685?email_source=notifications&email_token=AADV2HBRMBCYV43557RMHRTPWZHYPA5CNFSM4HOUXHQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWBOI7I#issuecomment-495117437>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HB3AK7BY3OH5LY66R3PWZHYPANCNFSM4HOUXHQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495299585
https://github.com/su2code/SU2/issues/685#issuecomment-495299585:773,Modifiability,variab,variable,773,"I would give a cautious yes, cautious because Meson appears quite new, and probably still has some wrinkles to iron out. It’s definitely worth a try. Dave. From: Tim Albring [mailto:notifications@github.com]; Sent: Thursday, May 23, 2019 1:21 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Dave Taflin <d.taflin@tecplot.com>; Mention <mention@noreply.github.com>; Subject: Re: [su2code/SU2] Meson build system (#685). @economon<https://github.com/economon> Hm ok, that is strange. The one that it builds is the newest on github (v1.9). On linux meson finds ninja if it is in the root directory of the source code (which should be there after bootstrapping), apparently that is not the case on mac. Can you check whether it works when you add the source dir in your path variable? Like @davetaflin<https://github.com/davetaflin> also mentioned for windows, on mac you can also directly generated xcode files (by adding --backend=xcode to the meson call), then ninja is not required. But anyway, I will look for a solution to that problem. @davetaflin<https://github.com/davetaflin> Thanks for your impressions. I would say the documentation is decent. The important things are there, which helped me setting it up. But I guess that we can also ask the developers if we have some problems when adding more complex dependencies (however, we then also should ask ourselves whether we really want to add them in this case). But is the conclusion that you'd also prefer meson over automake ? :D. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/685?email_source=notifications&email_token=AADV2HBRMBCYV43557RMHRTPWZHYPA5CNFSM4HOUXHQKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODWBOI7I#issuecomment-495117437>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HB3AK7BY3OH5LY66R3PWZHYPANCNFSM4HOUXHQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495299585
https://github.com/su2code/SU2/issues/685#issuecomment-495368696:82,Availability,ERROR,ERROR,82,Just as @economon I also had to `git submodule update --init` and I had the same `ERROR: Could not detect Ninja v1.5 or newer`. I am running on a RHEL Server 7 with git 1.8.3; I got everything to run after running the `./bootstrap.py` in `externals/ninja/` and adding that very directory to my PATH.; Two small hints for everyone trying: ` ./ninja -C build -j #cores` and the SU2_CFD binary is then in `<repo-root>/build/SU2_CFD/src/`. The QuickStart ran fine for me. It also ran perfectly in parallel without further ado. Is there already an AD-build? I would like to see/make a build speed comparison with auto- and directdiff enabled.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495368696
https://github.com/su2code/SU2/issues/685#issuecomment-495368696:47,Deployability,update,update,47,Just as @economon I also had to `git submodule update --init` and I had the same `ERROR: Could not detect Ninja v1.5 or newer`. I am running on a RHEL Server 7 with git 1.8.3; I got everything to run after running the `./bootstrap.py` in `externals/ninja/` and adding that very directory to my PATH.; Two small hints for everyone trying: ` ./ninja -C build -j #cores` and the SU2_CFD binary is then in `<repo-root>/build/SU2_CFD/src/`. The QuickStart ran fine for me. It also ran perfectly in parallel without further ado. Is there already an AD-build? I would like to see/make a build speed comparison with auto- and directdiff enabled.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495368696
https://github.com/su2code/SU2/issues/685#issuecomment-495368696:99,Safety,detect,detect,99,Just as @economon I also had to `git submodule update --init` and I had the same `ERROR: Could not detect Ninja v1.5 or newer`. I am running on a RHEL Server 7 with git 1.8.3; I got everything to run after running the `./bootstrap.py` in `externals/ninja/` and adding that very directory to my PATH.; Two small hints for everyone trying: ` ./ninja -C build -j #cores` and the SU2_CFD binary is then in `<repo-root>/build/SU2_CFD/src/`. The QuickStart ran fine for me. It also ran perfectly in parallel without further ado. Is there already an AD-build? I would like to see/make a build speed comparison with auto- and directdiff enabled.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495368696
https://github.com/su2code/SU2/issues/685#issuecomment-495521918:51,Integrability,message,message,51,I don't understand it ... Do you get the following message when running meson ?. ```; Program ninja found: NO; Message: Ninja was not found. Bootstrapping ...; ```; Because then ninja should be build and placed into the source root folder where meson finds it. For me it works locally and on our cluster. You can enable AD by adding `-Denable-autodiff=true` and/or `-Denable-directdiff=true` to the meson call.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495521918
https://github.com/su2code/SU2/issues/685#issuecomment-495521918:111,Integrability,Message,Message,111,I don't understand it ... Do you get the following message when running meson ?. ```; Program ninja found: NO; Message: Ninja was not found. Bootstrapping ...; ```; Because then ninja should be build and placed into the source root folder where meson finds it. For me it works locally and on our cluster. You can enable AD by adding `-Denable-autodiff=true` and/or `-Denable-directdiff=true` to the meson call.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495521918
https://github.com/su2code/SU2/issues/685#issuecomment-495526026:120,Availability,avail,available,120,"@TobiKattmann just a comment to your hints, because I forgot to mention this: ninja always builds in parallel using all available cores, so `-j` is not necessary. Furthermore, the installation directory can be set with `--prefix=<dir>` when calling meson (and using `ninja -C build install` afterwards for installation)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495526026
https://github.com/su2code/SU2/issues/685#issuecomment-495526026:180,Deployability,install,installation,180,"@TobiKattmann just a comment to your hints, because I forgot to mention this: ninja always builds in parallel using all available cores, so `-j` is not necessary. Furthermore, the installation directory can be set with `--prefix=<dir>` when calling meson (and using `ninja -C build install` afterwards for installation)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495526026
https://github.com/su2code/SU2/issues/685#issuecomment-495526026:282,Deployability,install,install,282,"@TobiKattmann just a comment to your hints, because I forgot to mention this: ninja always builds in parallel using all available cores, so `-j` is not necessary. Furthermore, the installation directory can be set with `--prefix=<dir>` when calling meson (and using `ninja -C build install` afterwards for installation)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495526026
https://github.com/su2code/SU2/issues/685#issuecomment-495526026:306,Deployability,install,installation,306,"@TobiKattmann just a comment to your hints, because I forgot to mention this: ninja always builds in parallel using all available cores, so `-j` is not necessary. Furthermore, the installation directory can be set with `--prefix=<dir>` when calling meson (and using `ninja -C build install` afterwards for installation)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495526026
https://github.com/su2code/SU2/issues/685#issuecomment-495564089:124,Integrability,depend,depends,124,Apparently meson looks for ninja by just trying to execute the command `ninja` with the python call `Popen`. And I guess it depends on the python version (on our cluster we have 3.6) whether the current working dir is included in the search path or not ... Then it is unfortunately not possible skip the step in between to tell meson where to find ninja ... Then for now you'll have to do the following steps (as mentions by @TobiKattmann):. Build ninja in externals/ninja using `configure.py --bootstrap`; Add `externals/ninja` to the `PATH` variable; Run meson with `externals/meson/meson.py build`,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495564089
https://github.com/su2code/SU2/issues/685#issuecomment-495564089:480,Modifiability,config,configure,480,Apparently meson looks for ninja by just trying to execute the command `ninja` with the python call `Popen`. And I guess it depends on the python version (on our cluster we have 3.6) whether the current working dir is included in the search path or not ... Then it is unfortunately not possible skip the step in between to tell meson where to find ninja ... Then for now you'll have to do the following steps (as mentions by @TobiKattmann):. Build ninja in externals/ninja using `configure.py --bootstrap`; Add `externals/ninja` to the `PATH` variable; Run meson with `externals/meson/meson.py build`,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495564089
https://github.com/su2code/SU2/issues/685#issuecomment-495564089:543,Modifiability,variab,variable,543,Apparently meson looks for ninja by just trying to execute the command `ninja` with the python call `Popen`. And I guess it depends on the python version (on our cluster we have 3.6) whether the current working dir is included in the search path or not ... Then it is unfortunately not possible skip the step in between to tell meson where to find ninja ... Then for now you'll have to do the following steps (as mentions by @TobiKattmann):. Build ninja in externals/ninja using `configure.py --bootstrap`; Add `externals/ninja` to the `PATH` variable; Run meson with `externals/meson/meson.py build`,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-495564089
https://github.com/su2code/SU2/issues/685#issuecomment-498827230:658,Availability,robust,robust,658,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230
https://github.com/su2code/SU2/issues/685#issuecomment-498827230:637,Modifiability,flexible,flexible,637,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230
https://github.com/su2code/SU2/issues/685#issuecomment-498827230:614,Usability,simpl,simpler,614,"What advantages does meson provide over Cmake? I have experience with CMake, but not with meson. @talbring I'm not sure what you mean by ""the syntax is also not very comfortable and it has too many features which we actually don't need."". I recently did a survey of the some of the most popular open-source C++ libraries, both inside and outside and outside of scientific computing. The most popular build system was CMake (60% of the 15 open source libraries). If ""everyone else"" is using CMake, then why should we use meson? I'm not trying to be adversarial. I'm curious about why meson is better. Is the syntax simpler? Is meson more flexible? Is it more robust during changes? Is it faster?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-498827230
https://github.com/su2code/SU2/issues/685#issuecomment-500221287:373,Usability,simpl,simple,373,"@clarkpede A small discussion on the pros and cons can be found here: https://mesonbuild.com/Comparisons.html. Or https://medium.com/@germandiagogomez/getting-started-with-meson-build-system-and-c-83270f444bee Of course this article is just a personal opinion, but he makes some important points. . From my experience I can really say that the syntax of meson is extremely simple and intuitive. I managed to set it up for SU2 in like half a day, without having any prior knowledge on how it works. And it seems like that a lot of projects (for example all Gnome projects) are going to or are already using meson.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500221287
https://github.com/su2code/SU2/issues/685#issuecomment-500221287:384,Usability,intuit,intuitive,384,"@clarkpede A small discussion on the pros and cons can be found here: https://mesonbuild.com/Comparisons.html. Or https://medium.com/@germandiagogomez/getting-started-with-meson-build-system-and-c-83270f444bee Of course this article is just a personal opinion, but he makes some important points. . From my experience I can really say that the syntax of meson is extremely simple and intuitive. I managed to set it up for SU2 in like half a day, without having any prior knowledge on how it works. And it seems like that a lot of projects (for example all Gnome projects) are going to or are already using meson.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500221287
https://github.com/su2code/SU2/issues/685#issuecomment-500395507:337,Availability,down,download,337,"@talbring Thanks. That second link is very informative. I think that SU2 could really use a more advanced build process, and meson seems like a good candidate. As an example of why I think SU2 needs a better build process: Right now for AD builds, the build process listed in the tutorial asks you to use the `preconfigure.py` script to download and update the codi and medi git submodules. But there's a couple problems with the preconfigure script. It doesn't support out-of-source builds, and it expects all configure arguments to come in ""option=value"" pairs. A good build process (using CMake or meson) should allow adding submodules or external packages easily, without problems like these.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500395507
https://github.com/su2code/SU2/issues/685#issuecomment-500395507:350,Deployability,update,update,350,"@talbring Thanks. That second link is very informative. I think that SU2 could really use a more advanced build process, and meson seems like a good candidate. As an example of why I think SU2 needs a better build process: Right now for AD builds, the build process listed in the tutorial asks you to use the `preconfigure.py` script to download and update the codi and medi git submodules. But there's a couple problems with the preconfigure script. It doesn't support out-of-source builds, and it expects all configure arguments to come in ""option=value"" pairs. A good build process (using CMake or meson) should allow adding submodules or external packages easily, without problems like these.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500395507
https://github.com/su2code/SU2/issues/685#issuecomment-500395507:511,Modifiability,config,configure,511,"@talbring Thanks. That second link is very informative. I think that SU2 could really use a more advanced build process, and meson seems like a good candidate. As an example of why I think SU2 needs a better build process: Right now for AD builds, the build process listed in the tutorial asks you to use the `preconfigure.py` script to download and update the codi and medi git submodules. But there's a couple problems with the preconfigure script. It doesn't support out-of-source builds, and it expects all configure arguments to come in ""option=value"" pairs. A good build process (using CMake or meson) should allow adding submodules or external packages easily, without problems like these.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500395507
https://github.com/su2code/SU2/issues/685#issuecomment-500450833:147,Integrability,wrap,wraps,147,"Forgot to mention this, but the goal with a new build system is then to get rid of the preconfigure script altogether. Meson offers what they call wraps to automatically build and include dependencies (https://mesonbuild.com/Wrap-dependency-system-manual.html)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500450833
https://github.com/su2code/SU2/issues/685#issuecomment-500450833:188,Integrability,depend,dependencies,188,"Forgot to mention this, but the goal with a new build system is then to get rid of the preconfigure script altogether. Meson offers what they call wraps to automatically build and include dependencies (https://mesonbuild.com/Wrap-dependency-system-manual.html)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500450833
https://github.com/su2code/SU2/issues/685#issuecomment-500450833:225,Integrability,Wrap,Wrap-dependency-system-manual,225,"Forgot to mention this, but the goal with a new build system is then to get rid of the preconfigure script altogether. Meson offers what they call wraps to automatically build and include dependencies (https://mesonbuild.com/Wrap-dependency-system-manual.html)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/685#issuecomment-500450833
https://github.com/su2code/SU2/pull/686#issuecomment-494926280:27,Modifiability,config,config,27,"Thanks for cleaning up the config template. As far as I can tell, the Dirichlet and Neumann boundary conditions (around line 650) are not implemented in SU2 (they exist as placeholders). If this is true, keeping them in the config_template would be misleading. . Leaving this as a comment since I don't know if those markers are useful in places I haven't seen (like outside of SU2_CFD). Can someone confirm?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/686#issuecomment-494926280
https://github.com/su2code/SU2/pull/686#issuecomment-495053073:167,Deployability,update,updated,167,"@jtlau : you are correct that these are not currently in use. I believe BC_Dirichlet() and BC_Neumann() had been used in older solvers that have since been removed or updated (the wave solver comes to mind), but they are now just the empty hooks in case somebody would like to implement them for a solver in the future.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/686#issuecomment-495053073
https://github.com/su2code/SU2/pull/686#issuecomment-495058672:32,Modifiability,config,config,32,@economon should the options in config template be removed then?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/686#issuecomment-495058672
https://github.com/su2code/SU2/issues/688#issuecomment-495360476:59,Usability,learn,learn,59,"atm that still sounds like magic to me,... I really should learn this github stuff. But I was more hoping some experienced coder would pick this up instead of my messing up the code.; Also I dont yet understand the way you guys work with branches instead of regular forked code...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/688#issuecomment-495360476
https://github.com/su2code/SU2/issues/690#issuecomment-498694974:227,Modifiability,config,config,227,"Sorry for the late response, and thanks for getting back to me! That definitely looks like what I'm looking for. I've taken a look through the code and I'm not entirely sure about what the syntax for including such a bc in the config file would be. Is there an example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/690#issuecomment-498694974
https://github.com/su2code/SU2/issues/690#issuecomment-504792989:138,Integrability,depend,dependent,138,"@economon Hi, I've been looking at the code and I can't figure out how to use the custom BCs. Is there an example, preferably with a time dependent custom BC you could point me to? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/690#issuecomment-504792989
https://github.com/su2code/SU2/issues/690#issuecomment-505161925:74,Deployability,release,released,74,"@dean0927 : this is a very new feature, unfortunately, which is not quite released to the public yet and we do not yet have examples. However, you can take a look at the MMS cases at the following link and their configs to see how the options work. You will need to set KIND_VERIFICATION_SOLUTION= USER_DEFINED_SOLUTION, implement the solution/BC inside of the CUserDefinedSolution class, and then call BC_Custom() on the boundaries where you want it applied (MARKER_CUSTOM in the config)/. https://github.com/su2code/VandV/tree/master/mms/fvm_incomp_euler",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/690#issuecomment-505161925
https://github.com/su2code/SU2/issues/690#issuecomment-505161925:212,Modifiability,config,configs,212,"@dean0927 : this is a very new feature, unfortunately, which is not quite released to the public yet and we do not yet have examples. However, you can take a look at the MMS cases at the following link and their configs to see how the options work. You will need to set KIND_VERIFICATION_SOLUTION= USER_DEFINED_SOLUTION, implement the solution/BC inside of the CUserDefinedSolution class, and then call BC_Custom() on the boundaries where you want it applied (MARKER_CUSTOM in the config)/. https://github.com/su2code/VandV/tree/master/mms/fvm_incomp_euler",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/690#issuecomment-505161925
https://github.com/su2code/SU2/issues/690#issuecomment-505161925:481,Modifiability,config,config,481,"@dean0927 : this is a very new feature, unfortunately, which is not quite released to the public yet and we do not yet have examples. However, you can take a look at the MMS cases at the following link and their configs to see how the options work. You will need to set KIND_VERIFICATION_SOLUTION= USER_DEFINED_SOLUTION, implement the solution/BC inside of the CUserDefinedSolution class, and then call BC_Custom() on the boundaries where you want it applied (MARKER_CUSTOM in the config)/. https://github.com/su2code/VandV/tree/master/mms/fvm_incomp_euler",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/690#issuecomment-505161925
https://github.com/su2code/SU2/pull/691#issuecomment-497786734:30,Integrability,depend,depend,30,"Hi Wally,; I think that would depend, if the new scheme is part of a family that already exists it should be easier to implement, if not you do it from scratch... There is also the possibility of making life hard by trying to find common ground where there is none, e.g. the way CUSP is implemented in SU2 has something in common with the central schemes, but it did not feel right to attach an upwind scheme to the central family.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-497786734
https://github.com/su2code/SU2/pull/691#issuecomment-499205201:232,Energy Efficiency,reduce,reduced,232,"Hi Pedro,. It is indeed a good idea to keep similar schemes (with minor variations) under one umbrella, especially central scheme as only the dissipation term calculation differs. . - In case of AUSM+-up1/2 and SLAU1/2, each can be reduced by having a separate pressure flux definition. - But if we try to combine AUSM+-up and SLAU, will it be a clear/helpful implementation as mass flux definitions/calculations (which is substantial portion) are different (unlike the central scheme, where only dissipation term varies)?. - Also could you please shed some light on Jacobian part for these schemes (as you mentioned - “...Isolating the computation of mass and pressure fluxes could be an interesting way to compute the Jacobians of these schemes in a hybrid way ...”). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499205201
https://github.com/su2code/SU2/pull/691#issuecomment-499205201:346,Usability,clear,clear,346,"Hi Pedro,. It is indeed a good idea to keep similar schemes (with minor variations) under one umbrella, especially central scheme as only the dissipation term calculation differs. . - In case of AUSM+-up1/2 and SLAU1/2, each can be reduced by having a separate pressure flux definition. - But if we try to combine AUSM+-up and SLAU, will it be a clear/helpful implementation as mass flux definitions/calculations (which is substantial portion) are different (unlike the central scheme, where only dissipation term varies)?. - Also could you please shed some light on Jacobian part for these schemes (as you mentioned - “...Isolating the computation of mass and pressure fluxes could be an interesting way to compute the Jacobians of these schemes in a hybrid way ...”). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499205201
https://github.com/su2code/SU2/pull/691#issuecomment-499632402:287,Energy Efficiency,efficient,efficient,287,"Hi Pedro,. Thanks for sharing the nice idea. If it helps in ramping up the CFL than really good.... One query - generally how Jacobian computation by finite difference or AD tend to be in comparison to analytical Jacobians in terms of cost (time). Probably Analytical jacobians are more efficient but they are difficult to compute for a given scheme (is this mostly true?). . Thanks; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499632402
https://github.com/su2code/SU2/pull/691#issuecomment-499876619:159,Testability,test,testing,159,"Hi Amit,; That is also my intuition, I guess the only way to know if it is worth the extra cost is by doing.; Do you have a good supersonic case I can use for testing (all my work is subsonic)? Preferably something that converges well without initialization.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499876619
https://github.com/su2code/SU2/pull/691#issuecomment-499876619:26,Usability,intuit,intuition,26,"Hi Amit,; That is also my intuition, I guess the only way to know if it is worth the extra cost is by doing.; Do you have a good supersonic case I can use for testing (all my work is subsonic)? Preferably something that converges well without initialization.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-499876619
https://github.com/su2code/SU2/pull/691#issuecomment-500152158:398,Security,validat,validation,398,"Hi Pedro,. SU2 Testcase repo has 3 supersonic TestCases under euler folder (wedge, biparabolic and bluntbody), they all go well without initialization (you may be already aware of these euler cases). But I do not have any specific supersonic case for RANS or Laminar flow problems (some of them ideally be like nozzle flow or SHOCK-BL interaction).; May be need to have a look at NASA CFD site for validation and verification cases. Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500152158
https://github.com/su2code/SU2/pull/691#issuecomment-500152158:15,Testability,Test,Testcase,15,"Hi Pedro,. SU2 Testcase repo has 3 supersonic TestCases under euler folder (wedge, biparabolic and bluntbody), they all go well without initialization (you may be already aware of these euler cases). But I do not have any specific supersonic case for RANS or Laminar flow problems (some of them ideally be like nozzle flow or SHOCK-BL interaction).; May be need to have a look at NASA CFD site for validation and verification cases. Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500152158
https://github.com/su2code/SU2/pull/691#issuecomment-500152158:46,Testability,Test,TestCases,46,"Hi Pedro,. SU2 Testcase repo has 3 supersonic TestCases under euler folder (wedge, biparabolic and bluntbody), they all go well without initialization (you may be already aware of these euler cases). But I do not have any specific supersonic case for RANS or Laminar flow problems (some of them ideally be like nozzle flow or SHOCK-BL interaction).; May be need to have a look at NASA CFD site for validation and verification cases. Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500152158
https://github.com/su2code/SU2/pull/691#issuecomment-500227831:43,Testability,test,test,43,@pcarruscag @aeroamit I do not have a good test case. But am currently looking for one. Let me know if y'all find a good.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500227831
https://github.com/su2code/SU2/pull/691#issuecomment-500942445:382,Energy Efficiency,efficient,efficiently,382,"All for improving the abstractions if possible. We did something similar for the scalar upwinding and the viscous schemes already. . My only comments, which you can probably guess already, are to make sure we don't take a large performance hit by adding more layers (for example, one can make an argument to remove the entire set of CNumerics classes and implement the methods more efficiently directly in the solver class with vectorization, etc) and that we maintain the flexibility for folks to quickly add new convective schemes which was the original motivation for the existing structure (and more layers could complicate this). Sounds like you're already considering these things, but it is important to find the right balance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500942445
https://github.com/su2code/SU2/pull/691#issuecomment-500942445:259,Modifiability,layers,layers,259,"All for improving the abstractions if possible. We did something similar for the scalar upwinding and the viscous schemes already. . My only comments, which you can probably guess already, are to make sure we don't take a large performance hit by adding more layers (for example, one can make an argument to remove the entire set of CNumerics classes and implement the methods more efficiently directly in the solver class with vectorization, etc) and that we maintain the flexibility for folks to quickly add new convective schemes which was the original motivation for the existing structure (and more layers could complicate this). Sounds like you're already considering these things, but it is important to find the right balance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500942445
https://github.com/su2code/SU2/pull/691#issuecomment-500942445:604,Modifiability,layers,layers,604,"All for improving the abstractions if possible. We did something similar for the scalar upwinding and the viscous schemes already. . My only comments, which you can probably guess already, are to make sure we don't take a large performance hit by adding more layers (for example, one can make an argument to remove the entire set of CNumerics classes and implement the methods more efficiently directly in the solver class with vectorization, etc) and that we maintain the flexibility for folks to quickly add new convective schemes which was the original motivation for the existing structure (and more layers could complicate this). Sounds like you're already considering these things, but it is important to find the right balance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500942445
https://github.com/su2code/SU2/pull/691#issuecomment-500942445:228,Performance,perform,performance,228,"All for improving the abstractions if possible. We did something similar for the scalar upwinding and the viscous schemes already. . My only comments, which you can probably guess already, are to make sure we don't take a large performance hit by adding more layers (for example, one can make an argument to remove the entire set of CNumerics classes and implement the methods more efficiently directly in the solver class with vectorization, etc) and that we maintain the flexibility for folks to quickly add new convective schemes which was the original motivation for the existing structure (and more layers could complicate this). Sounds like you're already considering these things, but it is important to find the right balance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-500942445
https://github.com/su2code/SU2/pull/691#issuecomment-501745584:102,Availability,avail,available,102,"Right, that is the AUSM-family refactoring done with the hybrid Jacobians, Roe approximation is still available and it is the default.; So far:; - It was not practical to do finite differences of the mass flux and pressure by perturbing the conservatives, I had to do it on the primitives which then requires an extra Jacobian... So the approach is more expensive per iteration, which could be partially offset by using vector-mode forward-AD.; - However for some cases convergence is much better for the same CFL (wedge case with CFL=25) and in others (transonic airfoil, SST, low Re mesh) it allows much higher (4x) CFL to be used, which again results in lower time overall.; - The performance penalty from the extra layers does not seem to be big, but I have to measure that in a machine that is not doing other things at the same time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-501745584
https://github.com/su2code/SU2/pull/691#issuecomment-501745584:31,Modifiability,refactor,refactoring,31,"Right, that is the AUSM-family refactoring done with the hybrid Jacobians, Roe approximation is still available and it is the default.; So far:; - It was not practical to do finite differences of the mass flux and pressure by perturbing the conservatives, I had to do it on the primitives which then requires an extra Jacobian... So the approach is more expensive per iteration, which could be partially offset by using vector-mode forward-AD.; - However for some cases convergence is much better for the same CFL (wedge case with CFL=25) and in others (transonic airfoil, SST, low Re mesh) it allows much higher (4x) CFL to be used, which again results in lower time overall.; - The performance penalty from the extra layers does not seem to be big, but I have to measure that in a machine that is not doing other things at the same time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-501745584
https://github.com/su2code/SU2/pull/691#issuecomment-501745584:719,Modifiability,layers,layers,719,"Right, that is the AUSM-family refactoring done with the hybrid Jacobians, Roe approximation is still available and it is the default.; So far:; - It was not practical to do finite differences of the mass flux and pressure by perturbing the conservatives, I had to do it on the primitives which then requires an extra Jacobian... So the approach is more expensive per iteration, which could be partially offset by using vector-mode forward-AD.; - However for some cases convergence is much better for the same CFL (wedge case with CFL=25) and in others (transonic airfoil, SST, low Re mesh) it allows much higher (4x) CFL to be used, which again results in lower time overall.; - The performance penalty from the extra layers does not seem to be big, but I have to measure that in a machine that is not doing other things at the same time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-501745584
https://github.com/su2code/SU2/pull/691#issuecomment-501745584:684,Performance,perform,performance,684,"Right, that is the AUSM-family refactoring done with the hybrid Jacobians, Roe approximation is still available and it is the default.; So far:; - It was not practical to do finite differences of the mass flux and pressure by perturbing the conservatives, I had to do it on the primitives which then requires an extra Jacobian... So the approach is more expensive per iteration, which could be partially offset by using vector-mode forward-AD.; - However for some cases convergence is much better for the same CFL (wedge case with CFL=25) and in others (transonic airfoil, SST, low Re mesh) it allows much higher (4x) CFL to be used, which again results in lower time overall.; - The performance penalty from the extra layers does not seem to be big, but I have to measure that in a machine that is not doing other things at the same time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-501745584
https://github.com/su2code/SU2/pull/691#issuecomment-501794908:83,Usability,clear,cleared,83,"Great! Sounds good, just figured id bring it up to get some of these ancient issue cleared up. :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-501794908
https://github.com/su2code/SU2/pull/691#issuecomment-502193463:716,Availability,avail,available,716,"[Here](https://github.com/su2code/SU2/files/3291497/report.pdf) are some promising results, I took a transonic turbulent airfoil case I had, and a couple supersonic ones from the testcase repo (biparabolic and wedge). I kind of random selected the numerical scheme for each one and tried to make the settings fair. [These](https://github.com/su2code/SU2/files/3291494/files.zip) are the required files should anyone want to replicate the findings.; @aeroamit Thank you. I do not have much interest in low Mach applications and I am not familiar with the required preconditioning techniques so I am sorry but I will not be running that test myself. I have yet to test the discrete adjoint now that preaccumulation is available for these AUSM-family schemes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-502193463
https://github.com/su2code/SU2/pull/691#issuecomment-502193463:179,Testability,test,testcase,179,"[Here](https://github.com/su2code/SU2/files/3291497/report.pdf) are some promising results, I took a transonic turbulent airfoil case I had, and a couple supersonic ones from the testcase repo (biparabolic and wedge). I kind of random selected the numerical scheme for each one and tried to make the settings fair. [These](https://github.com/su2code/SU2/files/3291494/files.zip) are the required files should anyone want to replicate the findings.; @aeroamit Thank you. I do not have much interest in low Mach applications and I am not familiar with the required preconditioning techniques so I am sorry but I will not be running that test myself. I have yet to test the discrete adjoint now that preaccumulation is available for these AUSM-family schemes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-502193463
https://github.com/su2code/SU2/pull/691#issuecomment-502193463:635,Testability,test,test,635,"[Here](https://github.com/su2code/SU2/files/3291497/report.pdf) are some promising results, I took a transonic turbulent airfoil case I had, and a couple supersonic ones from the testcase repo (biparabolic and wedge). I kind of random selected the numerical scheme for each one and tried to make the settings fair. [These](https://github.com/su2code/SU2/files/3291494/files.zip) are the required files should anyone want to replicate the findings.; @aeroamit Thank you. I do not have much interest in low Mach applications and I am not familiar with the required preconditioning techniques so I am sorry but I will not be running that test myself. I have yet to test the discrete adjoint now that preaccumulation is available for these AUSM-family schemes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-502193463
https://github.com/su2code/SU2/pull/691#issuecomment-502193463:662,Testability,test,test,662,"[Here](https://github.com/su2code/SU2/files/3291497/report.pdf) are some promising results, I took a transonic turbulent airfoil case I had, and a couple supersonic ones from the testcase repo (biparabolic and wedge). I kind of random selected the numerical scheme for each one and tried to make the settings fair. [These](https://github.com/su2code/SU2/files/3291494/files.zip) are the required files should anyone want to replicate the findings.; @aeroamit Thank you. I do not have much interest in low Mach applications and I am not familiar with the required preconditioning techniques so I am sorry but I will not be running that test myself. I have yet to test the discrete adjoint now that preaccumulation is available for these AUSM-family schemes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-502193463
https://github.com/su2code/SU2/pull/691#issuecomment-502204535:287,Performance,perform,performance,287,Good to see the results. It will really help with schemes having inconsistent discretization for the implicit part. . One of the interesting thing (slide 3) is allowable CFL change with change in number of cores. ; What could be the possible reason behind that?. (edit - could it be the performance of preconditioner with change in number of partitions (size of individual partioned domain). Like LU-SGS alone will do best on single grid and things become poorer and stall with increasing number of partitions with standard parallel implementation. So basically quality of initial solution feeding to krylov solver every iteration is making this difference. ; May be... Just a thought) . Regards; Amit,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-502204535
https://github.com/su2code/SU2/pull/691#issuecomment-502767203:192,Availability,toler,tolerance,192,"Hi Amit,; That was my initial feeling too, all our linear preconditioners (except Jacobi) suffer with number of partitions, but the linear solver was still able to converge, and to even lower tolerance if needed.; The case would not blow up immediately, it converges nicely 4 orders of magnitude and then diverges, maybe some oscilations develops somewhere, but I do not see any point in the domain that stands out... I tried using GMRES instead of BCGSTAB, and converging the linear solution more, and using more MG residual smoothing cycles... I blame this mostly on the grid being too stretched.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-502767203
https://github.com/su2code/SU2/pull/691#issuecomment-503345696:36,Testability,test,test,36,"Hi @pcarruscag , All. I have done a test case for NACA 0012 airfoil at Mach 0.01 to check the effectiveness of hybrid jacobians (as requested by me earlier).; There are some interesting observations. Check out the attachment.; [Low_Speed_test.pdf](https://github.com/su2code/SU2/files/3303753/Low_Speed_test.pdf); [cfg_files.zip](https://github.com/su2code/SU2/files/3303763/cfg_files.zip); (cases ran on 2 cores); Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-503345696
https://github.com/su2code/SU2/pull/691#issuecomment-503725906:24,Testability,test,testing,24,"Hi Amit,; Thank you for testing the feature on those cases, I would never have guessed the convergence rate could be higher with Roe Jacobians. I got curious and played with the case too, I tried reducing the finite difference step and changing linear solvers but it made no difference.; It is especially intriguing that for two of the schemes Roe needs CFL of 0.01 (at which point it would possibly better to use explicit RK) and for the other two schemes of the same family the sky is the limit. I guess one of the conclusions is that it is good to have options.; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-503725906
https://github.com/su2code/SU2/pull/691#issuecomment-504050203:162,Security,access,access,162,"@economon that is what I propose for AUSM+up(2) and SLAU(2). Unfortunately their predecessor AUSM does not fit into the same generic form and so it will not have access to these numerical Jacobians. On the subject of accurate Jacobians, IMO matrix free is definitely the way to go (not just because of storage but because it would possibly require changing the edge loops, I did something similar in the past and it got messy).; Using forward AD to linearize the entire iteration and create some sort of Newton-nonlinear-GMRES monster solver preconditioned by the current 1st order Jacobians would indeed be interesting... I have no feeling for potential speed-up though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-504050203
https://github.com/su2code/SU2/pull/691#issuecomment-504124512:198,Availability,down,downward,198,"Hi,. @pcarruscag , I tried few more runs (Roe Jacobians with SLAU (2)) with this case and they ran well at CFL 500 for Mach 0.1 to 0.3 at M=0.4, it dips to ~400 and I think that trend will continue downward. I ran it for Mach 0.8 and CFL was restricted to ~25.0. So it’s a very surprising/peculiar behaviour observed with this case and as you rightly said that it is good to keep both the options. . @economon , can you share any experience of first vs second order analytical Jacobians (personal work, references/papers). Working out a second order Jacobian will be a really arduous task (and there can be other specific issues related to specific schemes as well). Consistent discretization with 1st order analytical Jacobian is likely to be better than inconsistent discretization for both 1st and 2nd order accurate simulations (in general). I was curious to look at any reference showing the real/comparative gains one will have with second order accurate analytical Jacobians. Another thing, many of the commercial codes use different strategies coupled with good linear solvers to have really good convergence rates (probably I mentioned this earlier as well). Thanks and Regards; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-504124512
https://github.com/su2code/SU2/pull/691#issuecomment-505615012:312,Performance,perform,performance,312,"One of the interesting paper -. "" Comparison of numerical and Analytical Jacobians"", Kirk J. Vanden, Paul D. Orkwis; AIAA, Vol 34, No. 6, June 1996. They computed the exact analytical Jacobian with symbolic manipulation. In conclusion they are showing that both analytical and numerical Jacobians showed similar performance and suggesting that for simpler numerical fluxes, analytical Jacobians should be the best way to go and for complex numerical fluxes, numerical Jacobian can be preferable choice (but if one can work out analytical, that should be good as well, I guess (one time effort) ). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505615012
https://github.com/su2code/SU2/pull/691#issuecomment-505615012:348,Usability,simpl,simpler,348,"One of the interesting paper -. "" Comparison of numerical and Analytical Jacobians"", Kirk J. Vanden, Paul D. Orkwis; AIAA, Vol 34, No. 6, June 1996. They computed the exact analytical Jacobian with symbolic manipulation. In conclusion they are showing that both analytical and numerical Jacobians showed similar performance and suggesting that for simpler numerical fluxes, analytical Jacobians should be the best way to go and for complex numerical fluxes, numerical Jacobian can be preferable choice (but if one can work out analytical, that should be good as well, I guess (one time effort) ). Best; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505615012
https://github.com/su2code/SU2/pull/691#issuecomment-505621705:172,Usability,simpl,simplifications,172,"@pcarruscag, Did you work out the analytical Jacobian for AUSM+-up? (holy cow). I have also worked out and implemented in my local machine for AUSM, up and up2 (with minor simplifications/assumptions, wherever seemed okay) . I was planning to consolidate things appropriately and refine it before pushing them to repo.; By the way, I am also observing the similar behavior with little time advantage for analytical part (a bit more refinement/cleaning in implementation from my side will be done) . So what should be the next plan ???. Cheers; Amit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-505621705
https://github.com/su2code/SU2/pull/691#issuecomment-506519519:77,Testability,test,test,77,"Hi Pedro,. Do you know why this PR is failing during Travis? I looked at the test cases and both are unsteady using Roe? ; BTW, I will be happy to review this PR.; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-506519519
https://github.com/su2code/SU2/pull/691#issuecomment-506526475:666,Modifiability,refactor,refactoring,666,"Hi Eduardo,; The channel 2D and supersonic vortex shedding cases are failing due to small changes in residuals, the operations in Roe were re-ordered a bit, and these cases run for many iterations, I am guessing it is just due to numerical precision. But I will have a look before updating the residuals.; The rotating cylinders case is the infamous one that appears to be sensitive to minute, and seemingly insignificant, changes as reported in #700, at the reference residuals the case is actually diverged.; Finally there is an AD case using JST that also fails because it is a file diff and we output 15 significant digits to that file. The change is due to the refactoring of central schemes that required changing the order in which variables are registered for pre-accumulation.; I do appreciate you taking the time to review this PR, especially since you are ""first author"" of the low Mach Roe schemes and there are no regressions for them, nevertheless I tested them before and after and it seems I did not break anything.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-506526475
https://github.com/su2code/SU2/pull/691#issuecomment-506526475:739,Modifiability,variab,variables,739,"Hi Eduardo,; The channel 2D and supersonic vortex shedding cases are failing due to small changes in residuals, the operations in Roe were re-ordered a bit, and these cases run for many iterations, I am guessing it is just due to numerical precision. But I will have a look before updating the residuals.; The rotating cylinders case is the infamous one that appears to be sensitive to minute, and seemingly insignificant, changes as reported in #700, at the reference residuals the case is actually diverged.; Finally there is an AD case using JST that also fails because it is a file diff and we output 15 significant digits to that file. The change is due to the refactoring of central schemes that required changing the order in which variables are registered for pre-accumulation.; I do appreciate you taking the time to review this PR, especially since you are ""first author"" of the low Mach Roe schemes and there are no regressions for them, nevertheless I tested them before and after and it seems I did not break anything.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-506526475
https://github.com/su2code/SU2/pull/691#issuecomment-506526475:964,Testability,test,tested,964,"Hi Eduardo,; The channel 2D and supersonic vortex shedding cases are failing due to small changes in residuals, the operations in Roe were re-ordered a bit, and these cases run for many iterations, I am guessing it is just due to numerical precision. But I will have a look before updating the residuals.; The rotating cylinders case is the infamous one that appears to be sensitive to minute, and seemingly insignificant, changes as reported in #700, at the reference residuals the case is actually diverged.; Finally there is an AD case using JST that also fails because it is a file diff and we output 15 significant digits to that file. The change is due to the refactoring of central schemes that required changing the order in which variables are registered for pre-accumulation.; I do appreciate you taking the time to review this PR, especially since you are ""first author"" of the low Mach Roe schemes and there are no regressions for them, nevertheless I tested them before and after and it seems I did not break anything.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-506526475
https://github.com/su2code/SU2/pull/691#issuecomment-507391680:241,Availability,toler,tolerance,241,"@EduardoMolina ; I ran the [channel_2D](https://github.com/su2code/SU2/files/3346960/channel_2D.zip) and the; [supersonic_vortex_shedding](https://github.com/su2code/SU2/files/3346962/supersonic_vortex_shedding.zip) testcases with a tighter tolerance on the linear solver to make sure the differences were not due to some change in number of iterations.; Some differences do accumulate over time but they are very small, for the channel_2D the final density field differs by 1e-6 at most (which is the output precision).; For the supersonic vortex shedding differences are greater, 2e-4 on average and up to 0.01 maximum, but the case is also larger and runs for longer. If I restart the case for a 6th time-step (from the same restart files) the initial residuals are the same.; I will update the other two cases when #700 gets merged as they changed there too.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-507391680
https://github.com/su2code/SU2/pull/691#issuecomment-507391680:787,Deployability,update,update,787,"@EduardoMolina ; I ran the [channel_2D](https://github.com/su2code/SU2/files/3346960/channel_2D.zip) and the; [supersonic_vortex_shedding](https://github.com/su2code/SU2/files/3346962/supersonic_vortex_shedding.zip) testcases with a tighter tolerance on the linear solver to make sure the differences were not due to some change in number of iterations.; Some differences do accumulate over time but they are very small, for the channel_2D the final density field differs by 1e-6 at most (which is the output precision).; For the supersonic vortex shedding differences are greater, 2e-4 on average and up to 0.01 maximum, but the case is also larger and runs for longer. If I restart the case for a 6th time-step (from the same restart files) the initial residuals are the same.; I will update the other two cases when #700 gets merged as they changed there too.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-507391680
https://github.com/su2code/SU2/pull/691#issuecomment-507391680:216,Testability,test,testcases,216,"@EduardoMolina ; I ran the [channel_2D](https://github.com/su2code/SU2/files/3346960/channel_2D.zip) and the; [supersonic_vortex_shedding](https://github.com/su2code/SU2/files/3346962/supersonic_vortex_shedding.zip) testcases with a tighter tolerance on the linear solver to make sure the differences were not due to some change in number of iterations.; Some differences do accumulate over time but they are very small, for the channel_2D the final density field differs by 1e-6 at most (which is the output precision).; For the supersonic vortex shedding differences are greater, 2e-4 on average and up to 0.01 maximum, but the case is also larger and runs for longer. If I restart the case for a 6th time-step (from the same restart files) the initial residuals are the same.; I will update the other two cases when #700 gets merged as they changed there too.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-507391680
https://github.com/su2code/SU2/pull/691#issuecomment-507808462:47,Testability,test,test,47,"Hi @pcarruscag ; I am also running a couple of test cases, mainly the RANS NASA Hump. Do you think it is a good idea to add since we don't have any test case covering the low Mach Roe implementation? If so, I am happy to add.; Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-507808462
https://github.com/su2code/SU2/pull/691#issuecomment-507808462:148,Testability,test,test,148,"Hi @pcarruscag ; I am also running a couple of test cases, mainly the RANS NASA Hump. Do you think it is a good idea to add since we don't have any test case covering the low Mach Roe implementation? If so, I am happy to add.; Best,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-507808462
https://github.com/su2code/SU2/pull/691#issuecomment-511142563:92,Performance,perform,performed,92,"Hi @pcarruscag ,. Sorry for the late response. . I went through all your implementation and performed some tests. . Although, I didn't see an improvement using the accurate jacobians in the subsonic test cases, as already mentioned here, and even in the transonic OneraM6 case from the repo. This implementation is very clean and in my opinion is a great improvement. . I hope that in other cases, the use of accurate jacobian will have a positive effect in the convergence. The only thing that I would like to bring is that in the future, you open a PR from su2 repo instead from your personal account. It is easier for the reviewers to compile and test. I will wait Travis pass to merge this PR. Thanks again. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511142563
https://github.com/su2code/SU2/pull/691#issuecomment-511142563:107,Testability,test,tests,107,"Hi @pcarruscag ,. Sorry for the late response. . I went through all your implementation and performed some tests. . Although, I didn't see an improvement using the accurate jacobians in the subsonic test cases, as already mentioned here, and even in the transonic OneraM6 case from the repo. This implementation is very clean and in my opinion is a great improvement. . I hope that in other cases, the use of accurate jacobian will have a positive effect in the convergence. The only thing that I would like to bring is that in the future, you open a PR from su2 repo instead from your personal account. It is easier for the reviewers to compile and test. I will wait Travis pass to merge this PR. Thanks again. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511142563
https://github.com/su2code/SU2/pull/691#issuecomment-511142563:199,Testability,test,test,199,"Hi @pcarruscag ,. Sorry for the late response. . I went through all your implementation and performed some tests. . Although, I didn't see an improvement using the accurate jacobians in the subsonic test cases, as already mentioned here, and even in the transonic OneraM6 case from the repo. This implementation is very clean and in my opinion is a great improvement. . I hope that in other cases, the use of accurate jacobian will have a positive effect in the convergence. The only thing that I would like to bring is that in the future, you open a PR from su2 repo instead from your personal account. It is easier for the reviewers to compile and test. I will wait Travis pass to merge this PR. Thanks again. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511142563
https://github.com/su2code/SU2/pull/691#issuecomment-511142563:650,Testability,test,test,650,"Hi @pcarruscag ,. Sorry for the late response. . I went through all your implementation and performed some tests. . Although, I didn't see an improvement using the accurate jacobians in the subsonic test cases, as already mentioned here, and even in the transonic OneraM6 case from the repo. This implementation is very clean and in my opinion is a great improvement. . I hope that in other cases, the use of accurate jacobian will have a positive effect in the convergence. The only thing that I would like to bring is that in the future, you open a PR from su2 repo instead from your personal account. It is easier for the reviewers to compile and test. I will wait Travis pass to merge this PR. Thanks again. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511142563
https://github.com/su2code/SU2/pull/691#issuecomment-511183603:321,Deployability,update,updated,321,Thank you @EduardoMolina.; In the future I will make sure the branch exists in the SU2 repo.; Yes unfortunately the accurate Jacobians for SLAU and AUSM+ are not silver bullets and their success seems to be very case dependent.; The rotating_cylinders case stopped diverging after merging the changes from #700 so I have updated all reference residuals.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511183603
https://github.com/su2code/SU2/pull/691#issuecomment-511183603:217,Integrability,depend,dependent,217,Thank you @EduardoMolina.; In the future I will make sure the branch exists in the SU2 repo.; Yes unfortunately the accurate Jacobians for SLAU and AUSM+ are not silver bullets and their success seems to be very case dependent.; The rotating_cylinders case stopped diverging after merging the changes from #700 so I have updated all reference residuals.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511183603
https://github.com/su2code/SU2/pull/691#issuecomment-511209774:245,Usability,learn,learn,245,"Hi @pcarruscag and @aeroamit ,. Thanks for the discussion and for share the ideas/results. I think this is the beauty of open-source, everyone is welcome to jump in and review all the pull requests. Certainly, as you said @aeroamit, we will all learn something fruitful when we review and merge each PR. Best regards,. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/691#issuecomment-511209774
https://github.com/su2code/SU2/issues/693#issuecomment-1519645066:326,Modifiability,variab,variables,326,"Hello,; is there any reply? What I understood from the original post, the DV value for FFD_TWIST is not straighforward. ; Why it is not taken in degrees? The comment says: _/--- The angle of rotation is computed based on a characteristic length of the wing, otherwise it is difficult to compare with other length based design variables. ---/; It could be easily done in reversed sense. Is there anything what I miss?; Nevermind, the config file comment could be done in better way, to help user understand the design variable setting. . Jan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/693#issuecomment-1519645066
https://github.com/su2code/SU2/issues/693#issuecomment-1519645066:433,Modifiability,config,config,433,"Hello,; is there any reply? What I understood from the original post, the DV value for FFD_TWIST is not straighforward. ; Why it is not taken in degrees? The comment says: _/--- The angle of rotation is computed based on a characteristic length of the wing, otherwise it is difficult to compare with other length based design variables. ---/; It could be easily done in reversed sense. Is there anything what I miss?; Nevermind, the config file comment could be done in better way, to help user understand the design variable setting. . Jan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/693#issuecomment-1519645066
https://github.com/su2code/SU2/issues/693#issuecomment-1519645066:517,Modifiability,variab,variable,517,"Hello,; is there any reply? What I understood from the original post, the DV value for FFD_TWIST is not straighforward. ; Why it is not taken in degrees? The comment says: _/--- The angle of rotation is computed based on a characteristic length of the wing, otherwise it is difficult to compare with other length based design variables. ---/; It could be easily done in reversed sense. Is there anything what I miss?; Nevermind, the config file comment could be done in better way, to help user understand the design variable setting. . Jan",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/693#issuecomment-1519645066
https://github.com/su2code/SU2/issues/696#issuecomment-500946690:382,Performance,load,loaded,382,"@vdweide : I have not hit this issues yet, although I have not been paying too close of attention to the file size (although I have used some large ones). We can make a quick test of this with free stream through a very large cube mesh. . This also goes hand in hand with large mesh support, in my mind, since you won't care about the restart files if you can't get your large mesh loaded :). We can add this to the list for the RPSVV group.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/696#issuecomment-500946690
https://github.com/su2code/SU2/issues/696#issuecomment-500946690:175,Testability,test,test,175,"@vdweide : I have not hit this issues yet, although I have not been paying too close of attention to the file size (although I have used some large ones). We can make a quick test of this with free stream through a very large cube mesh. . This also goes hand in hand with large mesh support, in my mind, since you won't care about the restart files if you can't get your large mesh loaded :). We can add this to the list for the RPSVV group.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/696#issuecomment-500946690
https://github.com/su2code/SU2/issues/696#issuecomment-500965914:87,Integrability,depend,depending,87,"@economon, I expect to run into problems for grids containing around 250 million DOFs, depending a bit on how many variables you store in the restart file. We can definitely do this test with a dummy grid. As you added this to the RPSVV group, let's close this issue here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/696#issuecomment-500965914
https://github.com/su2code/SU2/issues/696#issuecomment-500965914:115,Modifiability,variab,variables,115,"@economon, I expect to run into problems for grids containing around 250 million DOFs, depending a bit on how many variables you store in the restart file. We can definitely do this test with a dummy grid. As you added this to the RPSVV group, let's close this issue here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/696#issuecomment-500965914
https://github.com/su2code/SU2/issues/696#issuecomment-500965914:182,Testability,test,test,182,"@economon, I expect to run into problems for grids containing around 250 million DOFs, depending a bit on how many variables you store in the restart file. We can definitely do this test with a dummy grid. As you added this to the RPSVV group, let's close this issue here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/696#issuecomment-500965914
https://github.com/su2code/SU2/issues/698#issuecomment-499209118:62,Testability,test,testing,62,"An important, but currently missing, component of our current testing/quality assurance procedures, in my opinion. I would use it. For example, checking the output of the ComputeResidual() functions in each of the numerics classes are obvious candidates for this. I can think of many other ""units"" throughout the code, but this is another open discussion for the scope. @clarkpede could you give a couple of examples for the selection of the units in your use cases?. No experience w/ the other frameworks. As we now include some Boost for Tecio anyway, could be another opportunity to consolidate. As for PRs, this is open for me.. we discussed the +/- of requiring docs and tests in PRs at the developers meeting. There are pros and cons to be sure. Would like to hear what others think too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499209118
https://github.com/su2code/SU2/issues/698#issuecomment-499209118:676,Testability,test,tests,676,"An important, but currently missing, component of our current testing/quality assurance procedures, in my opinion. I would use it. For example, checking the output of the ComputeResidual() functions in each of the numerics classes are obvious candidates for this. I can think of many other ""units"" throughout the code, but this is another open discussion for the scope. @clarkpede could you give a couple of examples for the selection of the units in your use cases?. No experience w/ the other frameworks. As we now include some Boost for Tecio anyway, could be another opportunity to consolidate. As for PRs, this is open for me.. we discussed the +/- of requiring docs and tests in PRs at the developers meeting. There are pros and cons to be sure. Would like to hear what others think too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499209118
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1717,Availability,down,down,1717,", 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3344,Availability,avail,available,3344,"rite-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the follo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4254,Availability,avail,available,4254,"iating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3388,Deployability,integrat,integrated,3388,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1460,Energy Efficiency,power,power,1460,"here a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4849,Energy Efficiency,power,powerful,4849,"tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3388,Integrability,integrat,integrated,3388,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4404,Integrability,depend,dependencies,4404," commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this bec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3056,Modifiability,config,configure,3056,"ls a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working corre",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4429,Modifiability,flexible,flexible,4429," commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this bec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1179,Security,validat,validation,1179,"rth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1947,Security,validat,validation,1947,"economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:71,Testability,test,testing,71,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:464,Testability,test,testing,464,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:587,Testability,test,testing,587,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:821,Testability,test,testing,821,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:848,Testability,test,tests,848,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1001,Testability,test,testing,1001,"Clark,. Thanks for putting this idea out there. In my experience, unit testing has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1044,Testability,test,testing,1044,"has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a un",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1058,Testability,test,testing,1058,"has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a un",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1077,Testability,test,testing,1077,"has been an intrinsic part of the the modus operandi in many multi-physics codes at DoE and has been well worth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a un",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1190,Testability,test,testing,1190,"rth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1221,Testability,test,tests,1221,"rth the additional effort. In cases where it makes sense (as described by Clark and in the Stack Exchange discussion) I would advocate for using it moving forward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1357,Testability,test,test,1357,"rward. There may also be some issues that arise multiple times in existing code where a retroactive application of unit testing may also make sense. I am copying Pat Miller, formerly with DoE, who may have more experience on whether such unit testing approaches were useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-wr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1631,Testability,test,tests,1631,"e useful/worth the investment in some major codes he worked on. Best,. Juan. On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com<mailto:notifications@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development envir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1757,Testability,test,test,1757,"cations@github.com>> wrote:. I propose adding a unit-testing framework and unit-tests to SU2. After chatting with @economon<https://github.com/economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:1917,Testability,log,logical,1917,"economon>, I've decided to move the discussion here to get additional input. What is unit testing?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2011,Testability,test,test,2011,"?. For those not familiar with unit testing, unit testing allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for bu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2061,Testability,test,testing,2061,"sting allows the testing of small bits of behavior, ideally using isolated bits of code. It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./confi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2095,Testability,test,testing,2095,"It is not intended to replace validation testing or formal verification tests. Instead, it serves a unique purpose. Consider the three following use cases:. * You're developing a new feature, and you want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2354,Testability,test,tests-for-scientific-research-codes,2354," want to test it to see if it works. You could do a full simulation, but that takes a lot of time and computing power. You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is avai",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2467,Testability,test,testing,2467,"You want to check if your new behavior behaves as you suspect before you throw a lot of resources at it.; * You submit a PR and discover that one of the regression tests has failed. But...why? You know that something is broken, but its hard to track down what broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2703,Testability,test,testing,2703,"t broke. You want more granular test coverage that can demonstrate what broke.; * You are fixing a very small bug. You know that you should prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investmen",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:2879,Testability,Test,Tests,2879,"ld prove that your bug fix worked, but it doesn't seem logical to dedicate an entire validation case to one small bug fix. You want to write a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are fir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3020,Testability,test,tests,3020,"e a small test for a small fix. In all of these cases, unit testing fills a unique role. Unit testing increases time spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. T",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3110,Testability,test,testing,3110,"ime spent in development, but decreases the amount of time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3171,Testability,test,test,3171,"time spent in bug-fixing and maintaining. For more information, see this relevant Stack Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not beh",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3256,Testability,test,tests,3256,"ck Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3272,Testability,test,tests,3272,"ck Exchange question.<https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>. What do I propose?. My research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3408,Testability,test,tests,3408,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3444,Testability,test,testing,3444,"research group at UT Austing has implemented a unit testing framework on our branch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3515,Testability,test,tests,3515,"ch, which we're happy with. Some choices were arbitrary, and some choices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3569,Testability,test,testing,3569,"hoices were made based on our development environment. Those choices may be different for other groups. Here's what we have done:. The unit testing framework is compiled and run using autotools. For more information on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3762,Testability,test,tests,3762,"ormation on autotool's setup, see their documentation<https://www.gnu.org/software/automake/manual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3850,Testability,test,tests,3850,"anual/html_node/Tests.html>. Since autotools is the build system for SU2, this involves minimal changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:3921,Testability,test,tests,3921,"al changes. Using automake, the build process for building unit tests becomes:. '''; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; *",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4009,Testability,test,tests,4009,"'; ./bootstrap; ./configure; make; make check; '''. We use Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very sim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4119,Testability,test,test,4119,"oc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Qu",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4223,Testability,test,test,4223,"s a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4277,Testability,test,testing,4277," choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4543,Testability,test,testing,4543," commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this bec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4569,Testability,Test,Test,4569," testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4766,Testability,Test,Test,4766,"sts as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<ht",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4791,Testability,test,testing,4791,"tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4864,Testability,mock,mocking,4864,"tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4969,Testability,test,tests,4969," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5130,Testability,Test,Test,5130," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5144,Testability,Test,Test,5144," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5204,Testability,test,tests,5204," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5231,Testability,test,testing,5231," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5367,Testability,test,testing,5367," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5402,Testability,test,tests,5402," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:4108,Usability,simpl,simpler,4108," Boost's unit testing framework<https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>. This provides a convenient set of macros for instatiating tests, grouping tests into suites, and running checks. This choice was based on what is available in our development setup. We have integrated our unit tests into our Travis CI regression testing. Every time we push commits or submit a pull request, the unit tests are run and checked. What is my vision for unit testing in SU2?. I am not proposing that we start trying to get 100% code coverage with pre-existing code. That would not provide a good return on investment. Instead, I see people adding unit tests as they write new code and as they find bugs. For each new behavior added to SU2, tests are first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499250240:5035,Usability,simpl,simple,5035," first added to document the related existing behavior. These tests serve to check that the existing behavior isn't damaged by the new code. Then new tests are added to prove that the new behavior is working correctly. For bug fixes, the process is simpler. A test is added to confirm that something is not behaving as expected. Then the code is fixed to make the test pass. What frameworks are available?. For a unit testing framework, here are the most popular options, with the following pros and cons:. Roll-your-own. * Requires no external dependencies; * The most flexible option; * Involves the most work to setup; * Will lack some of the more advances features of mature unit-testing frameworks. Boost Test. * Can be header only, statically linked, or dynamically linked; * If statically or dynamically linked, then Boost is not very lightweight; * Easy to add if you're already using Boost. Google Test. * Most common unit-testing framework; * Can be easily combined with Google's powerful GMock mocking library; * Compiling and linking can be somewhat painful. Catch2. * Used by FEniCS; * Makes unit tests easily readable with lots of syntactic sugar.; * Has a very simple syntax; * Is header-only; * Requires C++11 compilation; * Not as feature rich as Google Test or Boost Test. Questions. * How do developers feel about adding unit tests to SU2?; * If a unit-testing framework were added to SU2, would you actually use it?; * Do developers have a preference (or experience with) any of the unit testing frameworks?; * Should unit tests be expected when submitting PRs?. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499250240
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:456,Availability,robust,robust,456,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2755,Availability,down,down,2755," Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be di",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4488,Availability,avail,available,4488," >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5450,Availability,avail,available,5450,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4538,Deployability,integrat,integrated,4538,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2487,Energy Efficiency,power,power,2487,"it testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6099,Energy Efficiency,power,powerful,6099," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4538,Integrability,integrat,integrated,4538,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5615,Integrability,depend,dependencies,5615,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4176,Modifiability,config,configure,4176," of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5642,Modifiability,flexible,flexible,5642,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:736,Security,expose,exposed,736,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2192,Security,validat,validation,2192," where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2996,Security,validat,validation,2996,"here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/aut",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:134,Testability,test,tests,134,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:190,Testability,test,tests,190,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:539,Testability,test,tests,539,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:606,Testability,test,tested,606,"I'll weigh in with a more in depth answer on a second email, but yes I've; found great value in being able to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is uni",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1042,Testability,test,testing,1042,"le to have a good set of unit tests. Particularly when you don't have good acceptance tests (hard in a fast; moving research code), it gives a developer confidence that new changes; aren't being fundamental assumptions in the code. It lets sub module; developers build ""armor"" around those assumptions. It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1453,Testability,test,testing,1453,"It is a bit of a cultural thing. People who want robust bits write more.; Some people wire less. At the bank I once worked at, unit tests were required for every module.; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1582,Testability,test,testing,1582,".; Some people wrote code that tested almost nothing. And it would get; through code review that way. Eventually, I added coverage analysis to the check in that exposed this; practice that gave a false assurance that things were ok. More when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1813,Testability,test,testing,1813,"re when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:1840,Testability,test,tests,1840,"re when I can think a bit more on this and get to a real keyboard!. Pat. On Wed, Jun 5, 2019 at 1:50 PM Juan Jose Alonso <jjalonso@stanford.edu>; wrote:. > Clark,; >; > Thanks for putting this idea out there. In my experience, unit testing; > has been an intrinsic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2003,Testability,test,testing,2003,"ic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2051,Testability,test,testing,2051,"ic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2065,Testability,test,testing,2065,"ic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2084,Testability,test,testing,2084,"ic part of the the modus operandi in many multi-physics; > codes at DoE and has been well worth the additional effort. In cases where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2203,Testability,test,testing,2203," where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2234,Testability,test,tests,2234," where; > it makes sense (as described by Clark and in the Stack Exchange discussion); > I would advocate for using it moving forward. There may also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2378,Testability,test,test,2378,"also be some; > issues that arise multiple times in existing code where a retroactive; > application of unit testing may also make sense. I am copying Pat Miller,; > formerly with DoE, who may have more experience on whether such unit; > testing approaches were useful/worth the investment in some major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2663,Testability,test,tests,2663,"major codes he; > worked on.; >; > Best,; >; > Juan; >; >; > On Jun 4, 2019, at 2:14 PM, Clark Pederson <notifications@github.com>; > wrote:; >; > I propose adding a unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2795,Testability,test,test,2795," unit-testing framework and unit-tests to SU2. After; > chatting with @economon <https://github.com/economon>, I've decided to; > move the discussion here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing fr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:2963,Testability,log,logical,2963,"here to get additional input.; > What is unit testing?; >; > For those not familiar with unit testing, unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/aut",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3060,Testability,test,test,3060,", unit testing allows the testing; > of small bits of behavior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves min",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3119,Testability,test,testing,3119,"avior, ideally using isolated bits of code. It is not; > intended to replace validation testing or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3153,Testability,test,testing,3153," or formal verification tests.; > Instead, it serves a unique purpose. Consider the three following use cases:; >; > - You're developing a new feature, and you want to test it to see if; > it works. You could do a full simulation, but that takes a lot of time and; > computing power. You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3428,Testability,test,tests-for-scientific-research-codes,3428," You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > avail",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3548,Testability,test,testing,3548," You want to check if your new behavior behaves as you; > suspect before you throw a lot of resources at it.; > - You submit a PR and discover that one of the regression tests has; > failed. But...why? You know that something is broken, but its hard to track; > down what broke. You want more granular test coverage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > avail",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3798,Testability,test,testing,3798,"rage that can demonstrate; > what broke.; > - You are fixing a very small bug. You know that you should prove that; > your bug fix worked, but it doesn't seem logical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:3981,Testability,Test,Tests,3981,"ogical to dedicate an entire; > validation case to one small bug fix. You want to write a small test for a; > small fix.; >; > In all of these cases, unit testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4131,Testability,test,tests,4131,"it testing fills a unique role. Unit testing; > increases time spent in development, but decreases the amount of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4241,Testability,test,testing,4241," of time spent; > in bug-fixing and maintaining.; >; > For more information, see this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4306,Testability,test,test,4306,"ee this relevant Stack Exchange question.; > <https://scicomp.stackexchange.com/questions/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simple",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4394,Testability,test,tests,4394,"s/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4413,Testability,test,tests,4413,"s/206/is-it-worthwhile-to-write-unit-tests-for-scientific-research-codes>; > What do I propose?; >; > My research group at UT Austing has implemented a unit testing framework; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4558,Testability,test,tests,4558,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4594,Testability,test,testing,4594,"ork; > on our branch, which we're happy with. Some choices were arbitrary, and; > some choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4668,Testability,test,tests,4668,"choices were made based on our development environment. Those choices; > may be different for other groups. Here's what we have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4728,Testability,test,testing,4728,"e have done:; >; > The unit testing framework is compiled and run using autotools. For more; > information on autotool's setup, see their documentation; > <https://www.gnu.org/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:4937,Testability,test,tests,4937,"rg/software/automake/manual/html_node/Tests.html>.; > Since autotools is the build system for SU2, this involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightwe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5028,Testability,test,tests,5028,"his involves minimal changes.; >; > Using automake, the build process for building unit tests becomes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-test",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5102,Testability,test,tests,5102,"comes:; >; > '''; > ./bootstrap; > ./configure; > make; > make check; > '''; >; > We use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Comp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5193,Testability,test,tests,5193," use Boost's unit testing framework; > <https://www.boost.org/doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Ma",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5309,Testability,test,test,5309,"ovides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Req",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5416,Testability,test,test,5416,"ouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google T",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5478,Testability,test,testing,5478,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5760,Testability,test,testing,5760,"> Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5795,Testability,Test,Test,5795," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6009,Testability,Test,Test,6009," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6039,Testability,test,testing,6039," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6114,Testability,mock,mocking,6114," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6233,Testability,test,tests,6233," are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6402,Testability,Test,Test,6402,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6416,Testability,Test,Test,6416,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6486,Testability,test,tests,6486,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6515,Testability,test,testing,6515,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6659,Testability,test,testing,6659,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6696,Testability,test,tests,6696,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:5298,Usability,simpl,simpler,5298,"doc/libs/1_70_0/libs/test/doc/html/index.html>.; > This provides a convenient set of macros for instatiating tests, grouping; > tests into suites, and running checks. This choice was based on what is; > available in our development setup.; >; > We have integrated our unit tests into our Travis CI regression testing.; > Every time we push commits or submit a pull request, the unit tests are run; > and checked.; > What is my vision for unit testing in SU2?; >; > I am *not* proposing that we start trying to get 100% code coverage with; > pre-existing code. That would not provide a good return on investment.; >; > Instead, I see people adding unit tests as they write new code and as they; > find bugs. For each new behavior added to SU2, tests are first added to; > document the related existing behavior. These tests serve to check that the; > existing behavior isn't damaged by the new code. Then new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499278427:6301,Usability,simpl,simple,6301,"en new tests are added; > to prove that the new behavior is working correctly. For bug fixes, the; > process is simpler. A test is added to confirm that something is not; > behaving as expected. Then the code is fixed to make the test pass.; > What frameworks are available?; >; > For a unit testing framework, here are the most popular options, with the; > following pros and cons:; > Roll-your-own; >; > - Requires no external dependencies; > - The most flexible option; > - Involves the most work to setup; > - Will lack some of the more advances features of mature unit-testing; > frameworks.; >; > Boost Test; >; > - Can be header only, statically linked, or dynamically linked; > - If statically or dynamically linked, then Boost is not very; > lightweight; > - Easy to add if you're already using Boost; >; > Google Test; >; > - Most common unit-testing framework; > - Can be easily combined with Google's powerful GMock mocking library; > - Compiling and linking can be somewhat painful; >; > Catch2; >; > - Used by FEniCS; > - Makes unit tests easily readable with lots of syntactic sugar.; > - Has a very simple syntax; > - Is header-only; > - Requires C++11 compilation; > - Not as feature rich as Google Test or Boost Test; >; > Questions; >; > - How do developers feel about adding unit tests to SU2?; > - If a unit-testing framework were added to SU2, would you actually; > use it?; > - Do developers have a preference (or experience with) any of the unit; > testing frameworks?; > - Should unit tests be expected when submitting PRs?; >; > —; > You are receiving this because you are subscribed to this thread.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/698?email_source=notifications&email_token=AA5FFRG5U3Z55N4W2XWQED3PY3LJ5A5CNFSM4HTDQXQKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4GXUGGLA>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AA5FFRHOPE2MUJ2Z5RRV4HTPY3LJ5ANCNFSM4HTDQXQA>; > .; >; >; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499278427
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1926,Availability,toler,tolerance,1926,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:2027,Availability,toler,tolerance,2027,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:216,Energy Efficiency,sensor,sensor,216,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:429,Energy Efficiency,sensor,sensor,429,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:635,Energy Efficiency,sensor,sensor,635,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:738,Energy Efficiency,sensor,sensor,738,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1267,Modifiability,config,config,1267,"github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a sim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1409,Modifiability,config,config,1409,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1900,Modifiability,config,config,1900,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:2069,Modifiability,config,config,2069,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:2272,Modifiability,config,config,2272,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:42,Testability,test,test,42,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:680,Testability,test,test,680,"As requested, here's an example of a unit test that I made. For context: There's a couple of different modes for the Roe-low-dissipation convective blending. If one of the ""DUCROS"" modes is selected, then the Ducros sensor values are used. Otherwise, they're ignored. Before commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_F",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1288,Testability,test,test,1288,"github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a sim",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:1774,Testability,Test,Test,1774,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:2304,Testability,test,test,2304,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-499999225:2297,Usability,simpl,simple,2297,"SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f), the `SetRoe_Dissipation` function checked to see if the sensor values were valid regardless of the type of blending selected. Commit [ac8b3bf](https://github.com/su2code/SU2/commit/ac8b3bf7636cc66ca7f47e15935942a6598e1a9f) changed the behavior to only check the sensor values if they will be used. The unit test sets the convective blending to `NTS`, feeds invalid sensor values into `SetRoe_Dissipation` and checks the output. ```cpp; // Used to set the Roe-low-dissipation option; void WriteCfgFile(unsigned short nDim, const char* filename,; std::string blending) {; std::ofstream cfg_file;. cfg_file.open(filename, ios::out);; cfg_file << ""PHYSICAL_PROBLEM= NAVIER_STOKES"" << std::endl;; cfg_file << ""ROE_LOW_DISSIPATION= "" << blending << std::endl;. cfg_file.close();; }. BOOST_AUTO_TEST_CASE(BadSensorsAllowedForNTS) {. /*--- Setup ---*/. const unsigned short nDim = 3;. /*--- Set up the config class for the test ---*/; char cfg_filename[100] = ""convective_blending_test.cfg"";; WriteCfgFile(nDim, cfg_filename, ""NTS"");; CConfig* config = new CConfig(cfg_filename, SU2_CFD, 0, 1, 2, VERB_NONE);; std::remove(cfg_filename);. /*--- Inputs ---*/; const su2double dissipation_i = 0.4;; const su2double dissipation_j = 0.6;; const su2double sensor_i = NAN; // Intentionally unphysical:; const su2double sensor_j = NAN; // Intentionally unphysical:. /*--- Outputs ---*/; su2double dissipation;. /*--- Test ---*/. CNumerics numerics;; numerics.SetRoe_Dissipation(dissipation_i, dissipation_j,; sensor_i, sensor_j,; dissipation, config);. const su2double tolerance = std::numeric_limits<su2double>::epsilon();; BOOST_CHECK_CLOSE_FRACTION(dissipation, 0.5, tolerance);. /*--- Teardown ---*/; delete config;; }; ```. There's a couple problems I would fix if I had more time. Ideally, I would be writing the cfg file to an in-memory stream and not to a file. And realistically, I shouldn't need to use a config file at all for a simple test like this.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-499999225
https://github.com/su2code/SU2/issues/698#issuecomment-500226914:741,Deployability,install,installation,741,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
https://github.com/su2code/SU2/issues/698#issuecomment-500226914:70,Testability,test,tests,70,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
https://github.com/su2code/SU2/issues/698#issuecomment-500226914:161,Testability,test,tests,161,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
https://github.com/su2code/SU2/issues/698#issuecomment-500226914:650,Usability,simpl,simple,650,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
https://github.com/su2code/SU2/issues/698#issuecomment-500226914:722,Usability,simpl,simple,722,"Thanks @clarkpede to take the initiative for this topic. I think unit-tests are a useful thing and we should think about having it in addition to the regression tests. Regarding the framework I am actually a little bit hesitant to use boost. Although we are already using it for tecio, in that case it is used in a part of the code which does not change frequently so it is fine if we are just shipping it. However, if we start introducing it into the actual development process people may want to use more and more features of boost and we will have a hard time maintaining versions, compatbilities and so on. And in my opinion we should keep it as simple and lightweight as possible (one of our biggest strengths is the simple compilation/installation, which actually attracts a lot of users). So in that regard Catch2 looks like a better candidat to me. But I am happy to hear more opinions on that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500226914
https://github.com/su2code/SU2/issues/698#issuecomment-500393344:331,Integrability,depend,dependency,331,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
https://github.com/su2code/SU2/issues/698#issuecomment-500393344:379,Integrability,rout,route,379,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
https://github.com/su2code/SU2/issues/698#issuecomment-500393344:457,Integrability,depend,dependency,457,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
https://github.com/su2code/SU2/issues/698#issuecomment-500393344:150,Testability,test,testing,150,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
https://github.com/su2code/SU2/issues/698#issuecomment-500393344:542,Testability,Test,Test,542,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
https://github.com/su2code/SU2/issues/698#issuecomment-500393344:606,Testability,test,testing,606,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
https://github.com/su2code/SU2/issues/698#issuecomment-500393344:573,Usability,simpl,simplest,573,"@talbring I agree with your assessment of Boost. I think it's a heavyweight solution to a lightweight use-case. We could always include just the unit-testing header (they offer a header-only version), but ""people may want to use more and more features of boost,"" as you point out. If we as developers want to add Boost as a formal dependency for SU2, then that seems like a fine route. But I have the feeling that many developers do not want to add a Boost dependency. Honestly, Boost UTF doesn't offer anything that we can't get from Google Test. Catch2 is definitely the simplest and easiest of the unit-testing frameworks I listed. The only sticking point is that it requires c++03, and that the full-feature version requires C++11.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500393344
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:235,Availability,down,down,235,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:706,Deployability,release,release,706,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:733,Deployability,release,release,733,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:392,Testability,Test,Test,392,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:650,Testability,Test,Test,650,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:848,Testability,test,tests,848,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:513,Usability,simpl,simpler,513,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-500411194:563,Usability,clear,clear,563,"I just found [a blog post](https://codingnest.com/the-future-of-catch2/) on the future directions of Catch2. There's a couple of important points for our discussion. The developer plans to adopt a hybrid approach, with:. 1. A stripped-down, header-only version.; 2. A full-feature, typical library (i.e. it must be compiled and linked). This approach is very similar to Boost's setup. Google Test does not offer a header-only version. Additionally, the developer plans to drop C++11 support, and move to C++14. A simpler branch will still support C++03. It's not clear which features are supported in the C++03 variant, and which ones aren't. Google Test is also moving to support only C++11 in their next release, but their current release fully supports pre-C++11. All of this discussion raises the question: Do we want to require C++11 for unit tests?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-500411194
https://github.com/su2code/SU2/issues/698#issuecomment-503685445:330,Integrability,depend,dependency,330,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445
https://github.com/su2code/SU2/issues/698#issuecomment-503685445:253,Testability,test,tests,253,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445
https://github.com/su2code/SU2/issues/698#issuecomment-503685445:383,Usability,simpl,simply,383,"We already require C++11 for some more advanced features, but it is always nice in my opinion to keep backward compatibility when possible. . However, this is not a deal breaker, I don't think, as most developers that want to use and add their own unit tests should have no problem with using C++11. If we can make it an optional dependency, to make sure the basic build still works simply, I think it could be ok.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-503685445
https://github.com/su2code/SU2/issues/698#issuecomment-548021997:20,Usability,pause,paused,20,This issue has been paused until after v7.0.0,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-548021997
https://github.com/su2code/SU2/issues/698#issuecomment-571293214:3,Deployability,update,updates,3,"No updates, but work will begin on this shortly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-571293214
https://github.com/su2code/SU2/issues/698#issuecomment-595945548:0,Deployability,Update,Updates,0,Updates were just pushed to the related PR.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/698#issuecomment-595945548
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:253,Modifiability,variab,variable,253,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:315,Modifiability,variab,variable,315,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:570,Modifiability,variab,variable,570,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:632,Modifiability,variab,variable,632,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:888,Modifiability,variab,variable,888,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:950,Modifiability,variab,variable,950,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:1170,Modifiability,config,config,1170,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498964784:1233,Modifiability,config,config,1233,"@economon , when I compile this branch with all the debug flags I get the following warnings. ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_Coord(CConfig*)’:; ../src/geometry_structure.cpp:15933:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_GridVel(CConfig*)’:; ../src/geometry_structure.cpp:16066:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;; ^~~~~~~~~~~~~~~; ../src/geometry_structure.cpp: In member function ‘virtual void CPhysicalGeometry::Set_MPI_OldCoord(CConfig*)’:; ../src/geometry_structure.cpp:16195:33: warning: variable ‘iPeriodic_Index’ set but not used [-Wunused-but-set-variable]; unsigned short iDim, iMarker, iPeriodic_Index, MarkerS, MarkerR;. Further inspection shows that iPeriodic_Index is used to retrieve the periodic transformations. However, these lines are commented. //angles = config->GetPeriodicRotation(iPeriodic_Index);; //translation = config->GetPeriodicTranslate(iPeriodic_Index);. Hence angles and translation get their default values of 0.0. Is this correct? These lines are not commented in develop. If it is correct, could you fix the compiler warning?. For the rest, I think this is a no-brainer and can be merged in quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498964784
https://github.com/su2code/SU2/pull/699#issuecomment-498966410:104,Integrability,rout,routines,104,"I see, those warnings didn’t pop up with LLVM on Mac. Actually, in a next pass, each of those Set_MPI_* routines that carry the warnings will be deleted. I didn’t do it yet, because git was getting confused with the spacings again. None of those routines are active anywhere any longer, so even just removing that index variable is fine to get rid of the warning",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498966410
https://github.com/su2code/SU2/pull/699#issuecomment-498966410:246,Integrability,rout,routines,246,"I see, those warnings didn’t pop up with LLVM on Mac. Actually, in a next pass, each of those Set_MPI_* routines that carry the warnings will be deleted. I didn’t do it yet, because git was getting confused with the spacings again. None of those routines are active anywhere any longer, so even just removing that index variable is fine to get rid of the warning",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498966410
https://github.com/su2code/SU2/pull/699#issuecomment-498966410:320,Modifiability,variab,variable,320,"I see, those warnings didn’t pop up with LLVM on Mac. Actually, in a next pass, each of those Set_MPI_* routines that carry the warnings will be deleted. I didn’t do it yet, because git was getting confused with the spacings again. None of those routines are active anywhere any longer, so even just removing that index variable is fine to get rid of the warning",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/699#issuecomment-498966410
https://github.com/su2code/SU2/pull/700#issuecomment-503201187:395,Availability,error,error,395,"[Here](https://github.com/su2code/SU2/files/3302370/benchmark.zip) are some comparisons for a case where the linear solver does little work (so not much benefit from this PR) and another where the linear solver has to work harder (18 iterations per iteration on average) and this makes a substantial difference.; I have started updated the residuals of things that seem consequence of round-off error, only one case requires closer inspection where things change several orders of magnitude (for the best).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-503201187
https://github.com/su2code/SU2/pull/700#issuecomment-503201187:328,Deployability,update,updated,328,"[Here](https://github.com/su2code/SU2/files/3302370/benchmark.zip) are some comparisons for a case where the linear solver does little work (so not much benefit from this PR) and another where the linear solver has to work harder (18 iterations per iteration on average) and this makes a substantial difference.; I have started updated the residuals of things that seem consequence of round-off error, only one case requires closer inspection where things change several orders of magnitude (for the best).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-503201187
https://github.com/su2code/SU2/pull/700#issuecomment-503201187:52,Testability,benchmark,benchmark,52,"[Here](https://github.com/su2code/SU2/files/3302370/benchmark.zip) are some comparisons for a case where the linear solver does little work (so not much benefit from this PR) and another where the linear solver has to work harder (18 iterations per iteration on average) and this makes a substantial difference.; I have started updated the residuals of things that seem consequence of round-off error, only one case requires closer inspection where things change several orders of magnitude (for the best).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-503201187
https://github.com/su2code/SU2/pull/700#issuecomment-503615855:72,Integrability,wrap,wrapper,72,"Thanks @talbring,; I moved the preconditioner and matrix-vector product wrapper classes to separate files, these are so light weight that I was thinking of leaving them in one file.; I also moved some inlines to the hpp but I kept the private inlines in the inl file, these are only needed in the cpp and so by including the inl from the cpp (instead of bottom of hpp) we might avoid triggering recompilation of more units when working on implementation details of CSysMatrix.; Finally I would like to move/rename the larger files on a separate PR, that way it will be easier to track changes.; What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-503615855
https://github.com/su2code/SU2/pull/700#issuecomment-503615855:378,Safety,avoid,avoid,378,"Thanks @talbring,; I moved the preconditioner and matrix-vector product wrapper classes to separate files, these are so light weight that I was thinking of leaving them in one file.; I also moved some inlines to the hpp but I kept the private inlines in the inl file, these are only needed in the cpp and so by including the inl from the cpp (instead of bottom of hpp) we might avoid triggering recompilation of more units when working on implementation details of CSysMatrix.; Finally I would like to move/rename the larger files on a separate PR, that way it will be easier to track changes.; What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-503615855
https://github.com/su2code/SU2/pull/700#issuecomment-503643650:91,Integrability,interface,interface,91,"The case with large change of residuals (3 orders) is the rotating cylinders case (sliding interface).; With this PR I get the following flow field at the last iteration:; ![image](https://user-images.githubusercontent.com/38071223/59783874-0ca11880-92b9-11e9-840e-20fd87ec17e9.png); With develop I get this one at time iter 2:; ![image](https://user-images.githubusercontent.com/38071223/59783928-2cd0d780-92b9-11e9-90bd-9155dd2a6b4e.png); And I think it is fair to say the case was actually blowing up before:; ![image](https://user-images.githubusercontent.com/38071223/59784008-5984ef00-92b9-11e9-89e0-d78eb0d76b90.png); If I change the linear preconditioner to the ILU the develop results are basically the same as with this PR. Why does the previous LU_SGS diverge and the current doesn't? No idea, maybe for a different limit condition it would go the other way...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-503643650
https://github.com/su2code/SU2/pull/700#issuecomment-505018141:17,Deployability,integrat,integration,17,"I tested the MKL integration with the discrete adjoint, and everything looks ok, turns out to be only about 5% faster on a per iteration basis (i.e. excluding recording times). I had to grab some work from my other ongoing PR's to run a case with reasonable CFL settings so I am not going to upload files for this test. @economon , @talbring , if you do not mind me moving the files with significant changes on a separate PR, I think this is ready to go.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505018141
https://github.com/su2code/SU2/pull/700#issuecomment-505018141:17,Integrability,integrat,integration,17,"I tested the MKL integration with the discrete adjoint, and everything looks ok, turns out to be only about 5% faster on a per iteration basis (i.e. excluding recording times). I had to grab some work from my other ongoing PR's to run a case with reasonable CFL settings so I am not going to upload files for this test. @economon , @talbring , if you do not mind me moving the files with significant changes on a separate PR, I think this is ready to go.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505018141
https://github.com/su2code/SU2/pull/700#issuecomment-505018141:2,Testability,test,tested,2,"I tested the MKL integration with the discrete adjoint, and everything looks ok, turns out to be only about 5% faster on a per iteration basis (i.e. excluding recording times). I had to grab some work from my other ongoing PR's to run a case with reasonable CFL settings so I am not going to upload files for this test. @economon , @talbring , if you do not mind me moving the files with significant changes on a separate PR, I think this is ready to go.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505018141
https://github.com/su2code/SU2/pull/700#issuecomment-505018141:314,Testability,test,test,314,"I tested the MKL integration with the discrete adjoint, and everything looks ok, turns out to be only about 5% faster on a per iteration basis (i.e. excluding recording times). I had to grab some work from my other ongoing PR's to run a case with reasonable CFL settings so I am not going to upload files for this test. @economon , @talbring , if you do not mind me moving the files with significant changes on a separate PR, I think this is ready to go.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505018141
https://github.com/su2code/SU2/pull/700#issuecomment-505188890:136,Energy Efficiency,allocate,allocate,136,"@talbring : as you know, the difference between disabled and active grid movement with 0 velocity is that the former case does not even allocate the memory for the grid velocity at each node, and many conditionals checking for grid movement throughout the solver (fluxes, BCs) are avoided. This was to save memory and effort when grid motion is not needed, however, maybe we need to now change the strategy for multizone problems which may have both fixed and moving zones (perhaps always active with 0 as default). . I am a little surprised they are not the same as well, but somewhere in the code path there must be an issue with this.. my guess is something related to BC_Fluid_Interface() or the transfer structure when grid movement is active on both sides but has a value of 0 on one of the interfaces.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505188890
https://github.com/su2code/SU2/pull/700#issuecomment-505188890:797,Integrability,interface,interfaces,797,"@talbring : as you know, the difference between disabled and active grid movement with 0 velocity is that the former case does not even allocate the memory for the grid velocity at each node, and many conditionals checking for grid movement throughout the solver (fluxes, BCs) are avoided. This was to save memory and effort when grid motion is not needed, however, maybe we need to now change the strategy for multizone problems which may have both fixed and moving zones (perhaps always active with 0 as default). . I am a little surprised they are not the same as well, but somewhere in the code path there must be an issue with this.. my guess is something related to BC_Fluid_Interface() or the transfer structure when grid movement is active on both sides but has a value of 0 on one of the interfaces.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505188890
https://github.com/su2code/SU2/pull/700#issuecomment-505188890:281,Safety,avoid,avoided,281,"@talbring : as you know, the difference between disabled and active grid movement with 0 velocity is that the former case does not even allocate the memory for the grid velocity at each node, and many conditionals checking for grid movement throughout the solver (fluxes, BCs) are avoided. This was to save memory and effort when grid motion is not needed, however, maybe we need to now change the strategy for multizone problems which may have both fixed and moving zones (perhaps always active with 0 as default). . I am a little surprised they are not the same as well, but somewhere in the code path there must be an issue with this.. my guess is something related to BC_Fluid_Interface() or the transfer structure when grid movement is active on both sides but has a value of 0 on one of the interfaces.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505188890
https://github.com/su2code/SU2/pull/700#issuecomment-505477458:124,Integrability,interface,interfaces,124,@pcarruscag For me its fine if you do it in a separate PR. @economon I also assume that is has something to do with how the interfaces are handled. We definitely have to check it. For now in PR #715 I enabled grid movement (in the config) also in fixed zones.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505477458
https://github.com/su2code/SU2/pull/700#issuecomment-505477458:231,Modifiability,config,config,231,@pcarruscag For me its fine if you do it in a separate PR. @economon I also assume that is has something to do with how the interfaces are handled. We definitely have to check it. For now in PR #715 I enabled grid movement (in the config) also in fixed zones.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/700#issuecomment-505477458
https://github.com/su2code/SU2/pull/702#issuecomment-500443357:468,Deployability,release,release,468,"@vdweide, our (Tecplot’s) development compiler has been GCC 5, which gives no warnings with those flags. With GCC 9, ignoring warnings from Boost and OpenMPI (on Fedora 30), I see three types of warnings: (1) clause does not guard… (misleading indentation), (2) Implicitly-declared operator= is deprecated, and (3) writing to an object of type…use copy-assignment or copy-initialization instead. (1) Is a side-effect of code obfuscation (the reason management lets us release this code), and is probably unavoidable.; (2) and (3) are probably addressable. I’ll put these on my to-do list. Thanks,. Dave. From: Edwin van der Weide [mailto:notifications@github.com]; Sent: Friday, June 7, 2019 12:05 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Dave Taflin <d.taflin@tecplot.com>; Mention <mention@noreply.github.com>; Subject: Re: [su2code/SU2] Eliminate Mac compiler warnings. (#702). @davetaflin<https://github.com/davetaflin>, could you also try to use the following compiler options for the g++ compiler?. -g -Wall -Wextra -Wno-unused-parameter -Wno-empty-body. Then I get a lot of warnings coming from the TecIO functionality. Quite a few of these warnings come from boost, so I don't think you can do a lot about those, but there are also a few in the TecIO files themselves. I run this on Ubuntu 18.04, g++ version 7.4.0, but I don't think the actual operating system and g++ version matter a lot. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/pull/702?email_source=notifications&email_token=AADV2HG7WERF4A6OXWTX5Y3PZICATA5CNFSM4HVJ2K32YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODXFAZRQ#issuecomment-499780806>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HGUXVSHGAERKPA4NSLPZICATANCNFSM4HVJ2K3Q>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/702#issuecomment-500443357
https://github.com/su2code/SU2/pull/705#issuecomment-501025544:14,Deployability,update,updated,14,"@pcarruscag I updated the jacobian. Regarding the flux, I am a bit confused as well. The paper referenced above says flux implemented is a higher-order scheme that employs the SLIP scheme's limiter. That being said, I do not have access to Blazek's book at the moment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/705#issuecomment-501025544
https://github.com/su2code/SU2/pull/705#issuecomment-501025544:230,Security,access,access,230,"@pcarruscag I updated the jacobian. Regarding the flux, I am a bit confused as well. The paper referenced above says flux implemented is a higher-order scheme that employs the SLIP scheme's limiter. That being said, I do not have access to Blazek's book at the moment.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/705#issuecomment-501025544
https://github.com/su2code/SU2/pull/709#issuecomment-501659521:139,Testability,test,tests,139,I also thought about that merging but unfortunately we are already at the time-limit of 90mins with only the normal compilation/regression tests. I will explore more the caching feature. I already did some tests in the meson_build branch on that.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/709#issuecomment-501659521
https://github.com/su2code/SU2/pull/709#issuecomment-501659521:206,Testability,test,tests,206,I also thought about that merging but unfortunately we are already at the time-limit of 90mins with only the normal compilation/regression tests. I will explore more the caching feature. I already did some tests in the meson_build branch on that.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/709#issuecomment-501659521
https://github.com/su2code/SU2/pull/709#issuecomment-502038526:198,Testability,test,tested,198,"Following my proposal in the last comment:. I disabled travis to run on develop, instead I set it master. BUT: in addition I set up a cron job in travis, so that at least once every week develop is tested. What do you say ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/709#issuecomment-502038526
https://github.com/su2code/SU2/pull/709#issuecomment-502061004:43,Testability,test,test,43,"Enabled it for develop again. Otherwise no test runs. Changed settings in travis to not build on pushes, only on PRs. Should save some computational work.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/709#issuecomment-502061004
https://github.com/su2code/SU2/pull/709#issuecomment-502652486:210,Availability,error,errors,210,"Any further comments on this ? Otherwise I assume that there is no objection and I will merge it in today. Btw. as you might have seen, I enabled codacy for the project in order to check the code for security, errors and code style.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/709#issuecomment-502652486
https://github.com/su2code/SU2/pull/709#issuecomment-502652486:200,Security,secur,security,200,"Any further comments on this ? Otherwise I assume that there is no objection and I will merge it in today. Btw. as you might have seen, I enabled codacy for the project in order to check the code for security, errors and code style.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/709#issuecomment-502652486
https://github.com/su2code/SU2/issues/711#issuecomment-540995151:284,Deployability,update,updates,284,"No not really, it is a fairly safe thing to change but it only makes sense to do it if the CFL is also increased. I did not make it default at the time because many cases would change over 2 lines of code...; Maybe it can be done now as part of #790? I can help you with the testcase updates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/711#issuecomment-540995151
https://github.com/su2code/SU2/issues/711#issuecomment-540995151:30,Safety,safe,safe,30,"No not really, it is a fairly safe thing to change but it only makes sense to do it if the CFL is also increased. I did not make it default at the time because many cases would change over 2 lines of code...; Maybe it can be done now as part of #790? I can help you with the testcase updates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/711#issuecomment-540995151
https://github.com/su2code/SU2/issues/711#issuecomment-540995151:275,Testability,test,testcase,275,"No not really, it is a fairly safe thing to change but it only makes sense to do it if the CFL is also increased. I did not make it default at the time because many cases would change over 2 lines of code...; Maybe it can be done now as part of #790? I can help you with the testcase updates.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/711#issuecomment-540995151
https://github.com/su2code/SU2/issues/712#issuecomment-502034357:44,Deployability,update,update,44,"Hi @dean0927,. can you try a `git submodule update` ? It seems like the submodules are not up-to-date in your case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/712#issuecomment-502034357
https://github.com/su2code/SU2/issues/712#issuecomment-502326561:48,Availability,down,downloading,48,"That worked, thanks! I was trying to install by downloading the zip file directly and not through git, which works for the master but not the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/712#issuecomment-502326561
https://github.com/su2code/SU2/issues/712#issuecomment-502326561:37,Deployability,install,install,37,"That worked, thanks! I was trying to install by downloading the zip file directly and not through git, which works for the master but not the develop branch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/712#issuecomment-502326561
https://github.com/su2code/SU2/issues/713#issuecomment-541622770:78,Modifiability,config,configs,78,"This problem appears to be solved, tested with current develop branch (hacked configs below).; [configs.zip](https://github.com/su2code/SU2/files/3724204/config.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/713#issuecomment-541622770
https://github.com/su2code/SU2/issues/713#issuecomment-541622770:96,Modifiability,config,configs,96,"This problem appears to be solved, tested with current develop branch (hacked configs below).; [configs.zip](https://github.com/su2code/SU2/files/3724204/config.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/713#issuecomment-541622770
https://github.com/su2code/SU2/issues/713#issuecomment-541622770:154,Modifiability,config,config,154,"This problem appears to be solved, tested with current develop branch (hacked configs below).; [configs.zip](https://github.com/su2code/SU2/files/3724204/config.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/713#issuecomment-541622770
https://github.com/su2code/SU2/issues/713#issuecomment-541622770:35,Testability,test,tested,35,"This problem appears to be solved, tested with current develop branch (hacked configs below).; [configs.zip](https://github.com/su2code/SU2/files/3724204/config.zip)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/713#issuecomment-541622770
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:190,Deployability,configurat,configuration,190,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:280,Deployability,configurat,configuration,280,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:474,Deployability,configurat,configuration,474,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:73,Modifiability,config,config,73,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:190,Modifiability,config,configuration,190,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:280,Modifiability,config,configuration,280,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:474,Modifiability,config,configuration,474,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/pull/715#issuecomment-514208185:119,Usability,clear,clearer,119,"Was playing around with the turbomachinery cases with the new multi-zone config. I like the new changes, makes it much clearer!. Just a remark, don't know if this is on purpose, but for the configuration parameter TURBOMACHINERY_KIND, you still need to supply them in the general configuration file for both zones (so in case of a two zone problem: TURBOMACHINERY_KIND = CENTRIFUGAL CENTRIFUGAL). Wouldnt it make more sense to have this per zone specified in the respective configuration file?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/715#issuecomment-514208185
https://github.com/su2code/SU2/issues/716#issuecomment-506768400:25,Usability,clear,clear,25,"Yes, I did not make that clear, the linear solver fraction of the time cannot be accelerated by this. But everything else can, from gradient/limiter computations to the Compute_Residual functions, as all those need to wait for data, it is however not very easy to measure how long that wait is compared to the rest of the computations.; In the 2015 joint work between Stanford and Intel they reported a 1.5x speed-up from this type of change for a case where the linear solver used 24% of the time. I do not know how heavy the CVariable infrastructure is now compared to then... We will see :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-506768400
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:661,Energy Efficiency,reduce,reduces,661,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:646,Integrability,interface,interface,646,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:394,Modifiability,variab,variables,394,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:494,Modifiability,extend,extend,494,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:629,Modifiability,variab,variables,629,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:138,Performance,perform,performance,138,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:298,Performance,perform,performance,298,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-507998889:160,Usability,clear,clear,160,"Hi @pcarruscag,; thank you very much for the insight and the well thought proposed solution. I wasn't aware that there was such a loss in performance, it seems clear that something needs to be done. The only question I have is regarding the following comment . > There are no free lunches and this performance improvement would come at the cost of losing the ability to have different types of variables in different parts of the domain. I'm using this feature more and more, I was planning to extend it in the structural solver to remove the `if fsi` statements, and I also used it in the rework of the mesh solver, as defining variables at the interface only reduces greatly the memory footprint (sort of like the node-vertex structures in geometry). You mention there are options to keep this versatility, how difficult do you think would be to implement them?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-507998889
https://github.com/su2code/SU2/issues/716#issuecomment-508082019:171,Energy Efficiency,allocate,allocates,171,"Hi @rsanfer,; I was afraid you were going to say that...; On the subject of memory savings, and taking the specific case of CFEAVariable, the class is 304 bytes before it allocates data, once data is allocated for a plain nonlinear 3D problem the effective size is 704 bytes, looking at the constructors, for such a problem we allocate 22 doubles or 176 bytes. So effectively 75% of the memory (equivalent to 66 doubles) is wasted.; It is important to note that this ""efficiency"" figure does not get much better even when this class allocates all it members (for which one needs fsi + adjoint + unsteady). This happens because operator `new []` needs to store the size of the allocation together with the data for when `delete []` is called so you get ""pointer + size + data"" rounded to a multiple of 16B because of the default alignment.; Therefore my opinion is that we can ""over allocate"" and still save memory, unless you need massive amounts of data for the boundary points(?)... But looking at CFEABoundVariable I don't think that is the case.; If we want to be optimum in terms of performance and memory usage, we would need to mimic the CGeometry strategy in CSolver.; If we do not want to mimic that structure we need to either be able to rely on some ordering of the special cases, e.g. boundary variables stored first, so that at runtime:; ```; double* Get(int iNode) {; if (iNode < nBoundary); return &special[iNode];; else; return &normal[iNode-nBoundary];; }; ```; If we cannot rely on some order we would need to tag nodes ""special"" or ""normal"" and then use some form of map for special cases... All this would cost a lot of indirection.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508082019
https://github.com/su2code/SU2/issues/716#issuecomment-508082019:200,Energy Efficiency,allocate,allocated,200,"Hi @rsanfer,; I was afraid you were going to say that...; On the subject of memory savings, and taking the specific case of CFEAVariable, the class is 304 bytes before it allocates data, once data is allocated for a plain nonlinear 3D problem the effective size is 704 bytes, looking at the constructors, for such a problem we allocate 22 doubles or 176 bytes. So effectively 75% of the memory (equivalent to 66 doubles) is wasted.; It is important to note that this ""efficiency"" figure does not get much better even when this class allocates all it members (for which one needs fsi + adjoint + unsteady). This happens because operator `new []` needs to store the size of the allocation together with the data for when `delete []` is called so you get ""pointer + size + data"" rounded to a multiple of 16B because of the default alignment.; Therefore my opinion is that we can ""over allocate"" and still save memory, unless you need massive amounts of data for the boundary points(?)... But looking at CFEABoundVariable I don't think that is the case.; If we want to be optimum in terms of performance and memory usage, we would need to mimic the CGeometry strategy in CSolver.; If we do not want to mimic that structure we need to either be able to rely on some ordering of the special cases, e.g. boundary variables stored first, so that at runtime:; ```; double* Get(int iNode) {; if (iNode < nBoundary); return &special[iNode];; else; return &normal[iNode-nBoundary];; }; ```; If we cannot rely on some order we would need to tag nodes ""special"" or ""normal"" and then use some form of map for special cases... All this would cost a lot of indirection.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508082019
https://github.com/su2code/SU2/issues/716#issuecomment-508082019:327,Energy Efficiency,allocate,allocate,327,"Hi @rsanfer,; I was afraid you were going to say that...; On the subject of memory savings, and taking the specific case of CFEAVariable, the class is 304 bytes before it allocates data, once data is allocated for a plain nonlinear 3D problem the effective size is 704 bytes, looking at the constructors, for such a problem we allocate 22 doubles or 176 bytes. So effectively 75% of the memory (equivalent to 66 doubles) is wasted.; It is important to note that this ""efficiency"" figure does not get much better even when this class allocates all it members (for which one needs fsi + adjoint + unsteady). This happens because operator `new []` needs to store the size of the allocation together with the data for when `delete []` is called so you get ""pointer + size + data"" rounded to a multiple of 16B because of the default alignment.; Therefore my opinion is that we can ""over allocate"" and still save memory, unless you need massive amounts of data for the boundary points(?)... But looking at CFEABoundVariable I don't think that is the case.; If we want to be optimum in terms of performance and memory usage, we would need to mimic the CGeometry strategy in CSolver.; If we do not want to mimic that structure we need to either be able to rely on some ordering of the special cases, e.g. boundary variables stored first, so that at runtime:; ```; double* Get(int iNode) {; if (iNode < nBoundary); return &special[iNode];; else; return &normal[iNode-nBoundary];; }; ```; If we cannot rely on some order we would need to tag nodes ""special"" or ""normal"" and then use some form of map for special cases... All this would cost a lot of indirection.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508082019
https://github.com/su2code/SU2/issues/716#issuecomment-508082019:533,Energy Efficiency,allocate,allocates,533,"Hi @rsanfer,; I was afraid you were going to say that...; On the subject of memory savings, and taking the specific case of CFEAVariable, the class is 304 bytes before it allocates data, once data is allocated for a plain nonlinear 3D problem the effective size is 704 bytes, looking at the constructors, for such a problem we allocate 22 doubles or 176 bytes. So effectively 75% of the memory (equivalent to 66 doubles) is wasted.; It is important to note that this ""efficiency"" figure does not get much better even when this class allocates all it members (for which one needs fsi + adjoint + unsteady). This happens because operator `new []` needs to store the size of the allocation together with the data for when `delete []` is called so you get ""pointer + size + data"" rounded to a multiple of 16B because of the default alignment.; Therefore my opinion is that we can ""over allocate"" and still save memory, unless you need massive amounts of data for the boundary points(?)... But looking at CFEABoundVariable I don't think that is the case.; If we want to be optimum in terms of performance and memory usage, we would need to mimic the CGeometry strategy in CSolver.; If we do not want to mimic that structure we need to either be able to rely on some ordering of the special cases, e.g. boundary variables stored first, so that at runtime:; ```; double* Get(int iNode) {; if (iNode < nBoundary); return &special[iNode];; else; return &normal[iNode-nBoundary];; }; ```; If we cannot rely on some order we would need to tag nodes ""special"" or ""normal"" and then use some form of map for special cases... All this would cost a lot of indirection.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508082019
https://github.com/su2code/SU2/issues/716#issuecomment-508082019:882,Energy Efficiency,allocate,allocate,882,"Hi @rsanfer,; I was afraid you were going to say that...; On the subject of memory savings, and taking the specific case of CFEAVariable, the class is 304 bytes before it allocates data, once data is allocated for a plain nonlinear 3D problem the effective size is 704 bytes, looking at the constructors, for such a problem we allocate 22 doubles or 176 bytes. So effectively 75% of the memory (equivalent to 66 doubles) is wasted.; It is important to note that this ""efficiency"" figure does not get much better even when this class allocates all it members (for which one needs fsi + adjoint + unsteady). This happens because operator `new []` needs to store the size of the allocation together with the data for when `delete []` is called so you get ""pointer + size + data"" rounded to a multiple of 16B because of the default alignment.; Therefore my opinion is that we can ""over allocate"" and still save memory, unless you need massive amounts of data for the boundary points(?)... But looking at CFEABoundVariable I don't think that is the case.; If we want to be optimum in terms of performance and memory usage, we would need to mimic the CGeometry strategy in CSolver.; If we do not want to mimic that structure we need to either be able to rely on some ordering of the special cases, e.g. boundary variables stored first, so that at runtime:; ```; double* Get(int iNode) {; if (iNode < nBoundary); return &special[iNode];; else; return &normal[iNode-nBoundary];; }; ```; If we cannot rely on some order we would need to tag nodes ""special"" or ""normal"" and then use some form of map for special cases... All this would cost a lot of indirection.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508082019
https://github.com/su2code/SU2/issues/716#issuecomment-508082019:1306,Modifiability,variab,variables,1306,"Hi @rsanfer,; I was afraid you were going to say that...; On the subject of memory savings, and taking the specific case of CFEAVariable, the class is 304 bytes before it allocates data, once data is allocated for a plain nonlinear 3D problem the effective size is 704 bytes, looking at the constructors, for such a problem we allocate 22 doubles or 176 bytes. So effectively 75% of the memory (equivalent to 66 doubles) is wasted.; It is important to note that this ""efficiency"" figure does not get much better even when this class allocates all it members (for which one needs fsi + adjoint + unsteady). This happens because operator `new []` needs to store the size of the allocation together with the data for when `delete []` is called so you get ""pointer + size + data"" rounded to a multiple of 16B because of the default alignment.; Therefore my opinion is that we can ""over allocate"" and still save memory, unless you need massive amounts of data for the boundary points(?)... But looking at CFEABoundVariable I don't think that is the case.; If we want to be optimum in terms of performance and memory usage, we would need to mimic the CGeometry strategy in CSolver.; If we do not want to mimic that structure we need to either be able to rely on some ordering of the special cases, e.g. boundary variables stored first, so that at runtime:; ```; double* Get(int iNode) {; if (iNode < nBoundary); return &special[iNode];; else; return &normal[iNode-nBoundary];; }; ```; If we cannot rely on some order we would need to tag nodes ""special"" or ""normal"" and then use some form of map for special cases... All this would cost a lot of indirection.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508082019
https://github.com/su2code/SU2/issues/716#issuecomment-508082019:1088,Performance,perform,performance,1088,"Hi @rsanfer,; I was afraid you were going to say that...; On the subject of memory savings, and taking the specific case of CFEAVariable, the class is 304 bytes before it allocates data, once data is allocated for a plain nonlinear 3D problem the effective size is 704 bytes, looking at the constructors, for such a problem we allocate 22 doubles or 176 bytes. So effectively 75% of the memory (equivalent to 66 doubles) is wasted.; It is important to note that this ""efficiency"" figure does not get much better even when this class allocates all it members (for which one needs fsi + adjoint + unsteady). This happens because operator `new []` needs to store the size of the allocation together with the data for when `delete []` is called so you get ""pointer + size + data"" rounded to a multiple of 16B because of the default alignment.; Therefore my opinion is that we can ""over allocate"" and still save memory, unless you need massive amounts of data for the boundary points(?)... But looking at CFEABoundVariable I don't think that is the case.; If we want to be optimum in terms of performance and memory usage, we would need to mimic the CGeometry strategy in CSolver.; If we do not want to mimic that structure we need to either be able to rely on some ordering of the special cases, e.g. boundary variables stored first, so that at runtime:; ```; double* Get(int iNode) {; if (iNode < nBoundary); return &special[iNode];; else; return &normal[iNode-nBoundary];; }; ```; If we cannot rely on some order we would need to tag nodes ""special"" or ""normal"" and then use some form of map for special cases... All this would cost a lot of indirection.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508082019
https://github.com/su2code/SU2/issues/716#issuecomment-508090169:452,Modifiability,variab,variable,452,"Hi @pcarruscag, thanks for the quick response. . There are still several possible memory reductions on the FEA solver by moving stuff to the vertices. Even though over-allocating would probably be fine for the structural solver as problems remain relatively small, I am replicating this structure for the mesh solver on the fluid side, and in there we should be careful not to add tons of doubles that are only necessary at the boundaries to the whole variable structure. I might also need a similar thing in the flow solver, e.g., to store boundary loads for the adjoint solver. I believe that relying on some ordering would be quite complex and require a lot of reworking of the code, everything in the solvers links directly to the point index, which gets renumbered at the beginning. So forcing the vertex nodes to go on to the initial positions doesn't seem like an easy one. And, as you say, maybe if we flag the nodes (as boundary or interior) we end up pretty much at the starting point. Possibly, the best alternative would be to replicate the structure in CGeometry in CSolver, therefore adding some CVertexVariable parent class and child for the different solvers. There are other boundary magnitudes that could be interesting to store as well. It would require some work, but given that there is a direct correspondence iMarker+iVertex -> iPoint, I would expect that to be the least invasive approach.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508090169
https://github.com/su2code/SU2/issues/716#issuecomment-508090169:550,Performance,load,loads,550,"Hi @pcarruscag, thanks for the quick response. . There are still several possible memory reductions on the FEA solver by moving stuff to the vertices. Even though over-allocating would probably be fine for the structural solver as problems remain relatively small, I am replicating this structure for the mesh solver on the fluid side, and in there we should be careful not to add tons of doubles that are only necessary at the boundaries to the whole variable structure. I might also need a similar thing in the flow solver, e.g., to store boundary loads for the adjoint solver. I believe that relying on some ordering would be quite complex and require a lot of reworking of the code, everything in the solvers links directly to the point index, which gets renumbered at the beginning. So forcing the vertex nodes to go on to the initial positions doesn't seem like an easy one. And, as you say, maybe if we flag the nodes (as boundary or interior) we end up pretty much at the starting point. Possibly, the best alternative would be to replicate the structure in CGeometry in CSolver, therefore adding some CVertexVariable parent class and child for the different solvers. There are other boundary magnitudes that could be interesting to store as well. It would require some work, but given that there is a direct correspondence iMarker+iVertex -> iPoint, I would expect that to be the least invasive approach.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-508090169
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:979,Availability,down,downcast,979,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:1236,Availability,mainten,maintenance,1236,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:1286,Availability,down,downcast,1286,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:1408,Availability,down,downcast,1408,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:905,Modifiability,variab,variables,905,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:329,Performance,optimiz,optimizations,329,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:1281,Safety,safe,safe,1281,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-509273008:1139,Usability,simpl,simple,1139,"On the subject of virtual functions I would like to put another idea forward.; After moving things around in #725 I noticed that we have tons of `inline virtual` methods.; The keyword `inline` has two meanings to the compiler:; - ""Dear merciful compiler please copy paste the body of this function and then do all your wonderful optimizations, if that pleases your excellency.""; - ""Dear forgiving compiler, you will find this method defined in multiple units, please don't be mad"" (i.e. ignore the one-definition-rule). `virtual` means determine what version of the method to call at runtime. This is not compatible with the first (and often the intended one) meaning of inline, therefore the compiler will in general not inline those methods.; They will only be inlined if they are being called on a pointer to the derived class that does not declare the method to be virtual anymore. CSolver knows what variables it creates and so in hot areas of the code it could do a static downcast to allow inlining (e.g. `static_cast<CEulerVariable*>(node[iNode])->DoStuff()`).; Where is this important? For example when computing gradients, where simple additions and subtractions are hidden behind virtual functions.; If you are worried about maintenance each solver can typedef its most safe downcast level or better yet (or just more modern), methods that could benefit from this can be templated for the type of downcast.; Those in favour say Yea those against say Nay.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-509273008
https://github.com/su2code/SU2/issues/716#issuecomment-513049255:243,Availability,avail,available,243,"Aok on inlines. Looking forward to the memory layout concept.. have you also thought about how we might combine this with vectorization (SIMD) across the edges in the residual / gradient / limiter routines? There's probably another 2x speedup available for those kernels. Lastly, I don't think we should throw out the possibility of removing the CVariable class entirely in favor of allocating memory directly in the solver classes. We have thought about this in the past, and it is not used deliberately in the DG solver, for example. Food for thought.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513049255
https://github.com/su2code/SU2/issues/716#issuecomment-513049255:197,Integrability,rout,routines,197,"Aok on inlines. Looking forward to the memory layout concept.. have you also thought about how we might combine this with vectorization (SIMD) across the edges in the residual / gradient / limiter routines? There's probably another 2x speedup available for those kernels. Lastly, I don't think we should throw out the possibility of removing the CVariable class entirely in favor of allocating memory directly in the solver classes. We have thought about this in the past, and it is not used deliberately in the DG solver, for example. Food for thought.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513049255
https://github.com/su2code/SU2/issues/716#issuecomment-513171591:601,Deployability,Integrat,Integration,601,"I've been doing some recreational reading on strategies that people have used for vectorization of fluxes but so far I have not thought of a way to reconcile them with the nice encapsulation we have of the numerics. For gradients (at least GG) and limiters on the other hand I do have ideas. By the way is there a branch on the repo for the work you, Francisco, Intel, and others did on this kind of stuff?. Yeah making solution variables members of the solver would avoid a lot of virtual calls but it would make it harder to eventually reach the solution for post processing, or in other areas like Integration/Iteration where the solution is manipulated directly by non-solver classes, we will see...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513171591
https://github.com/su2code/SU2/issues/716#issuecomment-513171591:601,Integrability,Integrat,Integration,601,"I've been doing some recreational reading on strategies that people have used for vectorization of fluxes but so far I have not thought of a way to reconcile them with the nice encapsulation we have of the numerics. For gradients (at least GG) and limiters on the other hand I do have ideas. By the way is there a branch on the repo for the work you, Francisco, Intel, and others did on this kind of stuff?. Yeah making solution variables members of the solver would avoid a lot of virtual calls but it would make it harder to eventually reach the solution for post processing, or in other areas like Integration/Iteration where the solution is manipulated directly by non-solver classes, we will see...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513171591
https://github.com/su2code/SU2/issues/716#issuecomment-513171591:429,Modifiability,variab,variables,429,"I've been doing some recreational reading on strategies that people have used for vectorization of fluxes but so far I have not thought of a way to reconcile them with the nice encapsulation we have of the numerics. For gradients (at least GG) and limiters on the other hand I do have ideas. By the way is there a branch on the repo for the work you, Francisco, Intel, and others did on this kind of stuff?. Yeah making solution variables members of the solver would avoid a lot of virtual calls but it would make it harder to eventually reach the solution for post processing, or in other areas like Integration/Iteration where the solution is manipulated directly by non-solver classes, we will see...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513171591
https://github.com/su2code/SU2/issues/716#issuecomment-513171591:467,Safety,avoid,avoid,467,"I've been doing some recreational reading on strategies that people have used for vectorization of fluxes but so far I have not thought of a way to reconcile them with the nice encapsulation we have of the numerics. For gradients (at least GG) and limiters on the other hand I do have ideas. By the way is there a branch on the repo for the work you, Francisco, Intel, and others did on this kind of stuff?. Yeah making solution variables members of the solver would avoid a lot of virtual calls but it would make it harder to eventually reach the solution for post processing, or in other areas like Integration/Iteration where the solution is manipulated directly by non-solver classes, we will see...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513171591
https://github.com/su2code/SU2/issues/716#issuecomment-513174037:44,Performance,perform,performance,44,"My experience is that nice looking code and performance are two conflicting items, unfortunately. Apart from being contiguous in memory, you only obtain good performance when the vector length is a multiple of 8 or 16. This typically leads to padding the array, which does not improve readability. Furthermore, the best optimization is obtained when the vector length is known at compile time, typically leading to even uglier looking constructions,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513174037
https://github.com/su2code/SU2/issues/716#issuecomment-513174037:158,Performance,perform,performance,158,"My experience is that nice looking code and performance are two conflicting items, unfortunately. Apart from being contiguous in memory, you only obtain good performance when the vector length is a multiple of 8 or 16. This typically leads to padding the array, which does not improve readability. Furthermore, the best optimization is obtained when the vector length is known at compile time, typically leading to even uglier looking constructions,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513174037
https://github.com/su2code/SU2/issues/716#issuecomment-513174037:320,Performance,optimiz,optimization,320,"My experience is that nice looking code and performance are two conflicting items, unfortunately. Apart from being contiguous in memory, you only obtain good performance when the vector length is a multiple of 8 or 16. This typically leads to padding the array, which does not improve readability. Furthermore, the best optimization is obtained when the vector length is known at compile time, typically leading to even uglier looking constructions,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513174037
https://github.com/su2code/SU2/issues/716#issuecomment-513292350:859,Energy Efficiency,efficient,efficient,859,"I can share that version of the code.. but beware, just as Edwin mentions, it is nasty looking and hard to compile (there are intrinsics and all sorts of architecture-specific changes). But, interesting to look at, of course. There you will see that we basically moved up all of the CVariable data (reordered contiguously) and methods to the solver to eliminate the extra layer of indirection, while still keeping access for outside classes, i.e. something like solver[FLOW_SOL]->node[iPoint]->GetPressure() becomes solver[FLOW_SOL]->GetPressure(iPoint). Since you mentioned it, another target is the CNumerics classes. The flexibility is nice, but does it really need an entire set of classes with getters/setters/virtual functions? I think that most of the ComputeResidual() functions could be moved up as methods in the solver classes as well to make more efficient residual kernel loops. In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility. While the former is still true (although certainly doable), the latter does not seem to me as high of a priority any longer. Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). In addition, the CVariable and CNumerics child classes all live almost entirely within their own solvers, so we aren't taking much advantage of code reuse to justify having them as separate classes. For instance, if we just copied the relevant ComputeResidual() routines up into their solvers from numerics, we would have very little code duplication in the end, which is an indicator that we may not really need the extra baggage.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513292350
https://github.com/su2code/SU2/issues/716#issuecomment-513292350:1583,Integrability,rout,routines,1583,"I can share that version of the code.. but beware, just as Edwin mentions, it is nasty looking and hard to compile (there are intrinsics and all sorts of architecture-specific changes). But, interesting to look at, of course. There you will see that we basically moved up all of the CVariable data (reordered contiguously) and methods to the solver to eliminate the extra layer of indirection, while still keeping access for outside classes, i.e. something like solver[FLOW_SOL]->node[iPoint]->GetPressure() becomes solver[FLOW_SOL]->GetPressure(iPoint). Since you mentioned it, another target is the CNumerics classes. The flexibility is nice, but does it really need an entire set of classes with getters/setters/virtual functions? I think that most of the ComputeResidual() functions could be moved up as methods in the solver classes as well to make more efficient residual kernel loops. In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility. While the former is still true (although certainly doable), the latter does not seem to me as high of a priority any longer. Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). In addition, the CVariable and CNumerics child classes all live almost entirely within their own solvers, so we aren't taking much advantage of code reuse to justify having them as separate classes. For instance, if we just copied the relevant ComputeResidual() routines up into their solvers from numerics, we would have very little code duplication in the end, which is an indicator that we may not really need the extra baggage.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513292350
https://github.com/su2code/SU2/issues/716#issuecomment-513292350:414,Security,access,access,414,"I can share that version of the code.. but beware, just as Edwin mentions, it is nasty looking and hard to compile (there are intrinsics and all sorts of architecture-specific changes). But, interesting to look at, of course. There you will see that we basically moved up all of the CVariable data (reordered contiguously) and methods to the solver to eliminate the extra layer of indirection, while still keeping access for outside classes, i.e. something like solver[FLOW_SOL]->node[iPoint]->GetPressure() becomes solver[FLOW_SOL]->GetPressure(iPoint). Since you mentioned it, another target is the CNumerics classes. The flexibility is nice, but does it really need an entire set of classes with getters/setters/virtual functions? I think that most of the ComputeResidual() functions could be moved up as methods in the solver classes as well to make more efficient residual kernel loops. In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility. While the former is still true (although certainly doable), the latter does not seem to me as high of a priority any longer. Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). In addition, the CVariable and CNumerics child classes all live almost entirely within their own solvers, so we aren't taking much advantage of code reuse to justify having them as separate classes. For instance, if we just copied the relevant ComputeResidual() routines up into their solvers from numerics, we would have very little code duplication in the end, which is an indicator that we may not really need the extra baggage.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-513292350
https://github.com/su2code/SU2/issues/716#issuecomment-514020687:907,Availability,failure,failure,907,"> In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility... Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). As someone who has worked with the CNumerics classes a lot, I can say that we really don't gain much by keeping them as separate classes. On the surface, it seems like a good use of the [strategy pattern](https://sourcemaking.com/design_patterns/strategy). But from a pragmatic approach, it's not as flexible as OO purists would like you to believe. First off, if you need a new variable in the CNumerics class, you need to change both the solver class and the numerics class, since the solver class calls Setters to set the numerics variables. If you don't call the right Setters, you get a silent failure (unless you're using valgrind). The passing of variables between solver and numerics also leads to a lot of code duplication. And for many solvers (e.g. the viscous NS numerics or the source terms in the SST model) you only end up with one numerics class anyways. I also imagine there's a strong performance hit from all the Setters and copying of variables. But I haven't taken the time to check for myself. In my opinion, you could keep 80% of the current flexibility by using different functions instead of different classes. But I also think we would have to work carefully, or else we'll make the code harder to maintain.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514020687
https://github.com/su2code/SU2/issues/716#issuecomment-514020687:608,Modifiability,flexible,flexible,608,"> In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility... Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). As someone who has worked with the CNumerics classes a lot, I can say that we really don't gain much by keeping them as separate classes. On the surface, it seems like a good use of the [strategy pattern](https://sourcemaking.com/design_patterns/strategy). But from a pragmatic approach, it's not as flexible as OO purists would like you to believe. First off, if you need a new variable in the CNumerics class, you need to change both the solver class and the numerics class, since the solver class calls Setters to set the numerics variables. If you don't call the right Setters, you get a silent failure (unless you're using valgrind). The passing of variables between solver and numerics also leads to a lot of code duplication. And for many solvers (e.g. the viscous NS numerics or the source terms in the SST model) you only end up with one numerics class anyways. I also imagine there's a strong performance hit from all the Setters and copying of variables. But I haven't taken the time to check for myself. In my opinion, you could keep 80% of the current flexibility by using different functions instead of different classes. But I also think we would have to work carefully, or else we'll make the code harder to maintain.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514020687
https://github.com/su2code/SU2/issues/716#issuecomment-514020687:687,Modifiability,variab,variable,687,"> In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility... Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). As someone who has worked with the CNumerics classes a lot, I can say that we really don't gain much by keeping them as separate classes. On the surface, it seems like a good use of the [strategy pattern](https://sourcemaking.com/design_patterns/strategy). But from a pragmatic approach, it's not as flexible as OO purists would like you to believe. First off, if you need a new variable in the CNumerics class, you need to change both the solver class and the numerics class, since the solver class calls Setters to set the numerics variables. If you don't call the right Setters, you get a silent failure (unless you're using valgrind). The passing of variables between solver and numerics also leads to a lot of code duplication. And for many solvers (e.g. the viscous NS numerics or the source terms in the SST model) you only end up with one numerics class anyways. I also imagine there's a strong performance hit from all the Setters and copying of variables. But I haven't taken the time to check for myself. In my opinion, you could keep 80% of the current flexibility by using different functions instead of different classes. But I also think we would have to work carefully, or else we'll make the code harder to maintain.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514020687
https://github.com/su2code/SU2/issues/716#issuecomment-514020687:842,Modifiability,variab,variables,842,"> In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility... Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). As someone who has worked with the CNumerics classes a lot, I can say that we really don't gain much by keeping them as separate classes. On the surface, it seems like a good use of the [strategy pattern](https://sourcemaking.com/design_patterns/strategy). But from a pragmatic approach, it's not as flexible as OO purists would like you to believe. First off, if you need a new variable in the CNumerics class, you need to change both the solver class and the numerics class, since the solver class calls Setters to set the numerics variables. If you don't call the right Setters, you get a silent failure (unless you're using valgrind). The passing of variables between solver and numerics also leads to a lot of code duplication. And for many solvers (e.g. the viscous NS numerics or the source terms in the SST model) you only end up with one numerics class anyways. I also imagine there's a strong performance hit from all the Setters and copying of variables. But I haven't taken the time to check for myself. In my opinion, you could keep 80% of the current flexibility by using different functions instead of different classes. But I also think we would have to work carefully, or else we'll make the code harder to maintain.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514020687
https://github.com/su2code/SU2/issues/716#issuecomment-514020687:962,Modifiability,variab,variables,962,"> In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility... Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). As someone who has worked with the CNumerics classes a lot, I can say that we really don't gain much by keeping them as separate classes. On the surface, it seems like a good use of the [strategy pattern](https://sourcemaking.com/design_patterns/strategy). But from a pragmatic approach, it's not as flexible as OO purists would like you to believe. First off, if you need a new variable in the CNumerics class, you need to change both the solver class and the numerics class, since the solver class calls Setters to set the numerics variables. If you don't call the right Setters, you get a silent failure (unless you're using valgrind). The passing of variables between solver and numerics also leads to a lot of code duplication. And for many solvers (e.g. the viscous NS numerics or the source terms in the SST model) you only end up with one numerics class anyways. I also imagine there's a strong performance hit from all the Setters and copying of variables. But I haven't taken the time to check for myself. In my opinion, you could keep 80% of the current flexibility by using different functions instead of different classes. But I also think we would have to work carefully, or else we'll make the code harder to maintain.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514020687
https://github.com/su2code/SU2/issues/716#issuecomment-514020687:1263,Modifiability,variab,variables,1263,"> In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility... Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). As someone who has worked with the CNumerics classes a lot, I can say that we really don't gain much by keeping them as separate classes. On the surface, it seems like a good use of the [strategy pattern](https://sourcemaking.com/design_patterns/strategy). But from a pragmatic approach, it's not as flexible as OO purists would like you to believe. First off, if you need a new variable in the CNumerics class, you need to change both the solver class and the numerics class, since the solver class calls Setters to set the numerics variables. If you don't call the right Setters, you get a silent failure (unless you're using valgrind). The passing of variables between solver and numerics also leads to a lot of code duplication. And for many solvers (e.g. the viscous NS numerics or the source terms in the SST model) you only end up with one numerics class anyways. I also imagine there's a strong performance hit from all the Setters and copying of variables. But I haven't taken the time to check for myself. In my opinion, you could keep 80% of the current flexibility by using different functions instead of different classes. But I also think we would have to work carefully, or else we'll make the code harder to maintain.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514020687
https://github.com/su2code/SU2/issues/716#issuecomment-514020687:1211,Performance,perform,performance,1211,"> In the early days, we thought completely removing CVariable and CNumerics would be very intrusive to change and would hurt flexibility... Over the years, I don't think that folks have really modified the CNumerics classes all that often (once you have implemented the Roe method, it is more or less done). As someone who has worked with the CNumerics classes a lot, I can say that we really don't gain much by keeping them as separate classes. On the surface, it seems like a good use of the [strategy pattern](https://sourcemaking.com/design_patterns/strategy). But from a pragmatic approach, it's not as flexible as OO purists would like you to believe. First off, if you need a new variable in the CNumerics class, you need to change both the solver class and the numerics class, since the solver class calls Setters to set the numerics variables. If you don't call the right Setters, you get a silent failure (unless you're using valgrind). The passing of variables between solver and numerics also leads to a lot of code duplication. And for many solvers (e.g. the viscous NS numerics or the source terms in the SST model) you only end up with one numerics class anyways. I also imagine there's a strong performance hit from all the Setters and copying of variables. But I haven't taken the time to check for myself. In my opinion, you could keep 80% of the current flexibility by using different functions instead of different classes. But I also think we would have to work carefully, or else we'll make the code harder to maintain.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514020687
https://github.com/su2code/SU2/issues/716#issuecomment-514334254:241,Safety,avoid,avoid,241,"I always thought of CSolver, CIteration, etc. as ""strategies"" and CNumerics as ""visitors"", but just because the numerics ""visit"" the edges. I like the separation between solver and numerics, but I think the implementation could be better to avoid the problems @clarkpede mentioned.; We will need the contiguous storage for vectorization, once we have that we should benchmark again to evaluate the overhead of the current numerics structure and the potential gains from vectorization and weight that against whatever loss of readibility we would need to incur.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514334254
https://github.com/su2code/SU2/issues/716#issuecomment-514334254:366,Testability,benchmark,benchmark,366,"I always thought of CSolver, CIteration, etc. as ""strategies"" and CNumerics as ""visitors"", but just because the numerics ""visit"" the edges. I like the separation between solver and numerics, but I think the implementation could be better to avoid the problems @clarkpede mentioned.; We will need the contiguous storage for vectorization, once we have that we should benchmark again to evaluate the overhead of the current numerics structure and the potential gains from vectorization and weight that against whatever loss of readibility we would need to incur.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-514334254
https://github.com/su2code/SU2/issues/716#issuecomment-518900363:741,Modifiability,polymorphi,polymorphism,741,"Thanks for sharing the progress on the container in #753 . You may already be going in this direction, but another idea to consider is making CVariable a pure data structure (basically a c-style struct with your new containers) with no methods. This could be interesting for 2 reasons: 1) we remove a level of indirection without the Getters/Setters and operate directly on the data, and 2) this breaks the current cycle we are stuck in where we need to add a new virtual function to the base class every time one of the child CVariable classes adds new data that it must access with Get()/Set(). . Adding new data to the child classes for each solver becomes trivial if it is just a data structure. A pure data structure and an object with polymorphism will always be at odds - we should choose the best for each situation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-518900363
https://github.com/su2code/SU2/issues/716#issuecomment-518900363:572,Security,access,access,572,"Thanks for sharing the progress on the container in #753 . You may already be going in this direction, but another idea to consider is making CVariable a pure data structure (basically a c-style struct with your new containers) with no methods. This could be interesting for 2 reasons: 1) we remove a level of indirection without the Getters/Setters and operate directly on the data, and 2) this breaks the current cycle we are stuck in where we need to add a new virtual function to the base class every time one of the child CVariable classes adds new data that it must access with Get()/Set(). . Adding new data to the child classes for each solver becomes trivial if it is just a data structure. A pure data structure and an object with polymorphism will always be at odds - we should choose the best for each situation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-518900363
https://github.com/su2code/SU2/issues/716#issuecomment-520226075:253,Deployability,release,release-quality,253,"@economon for prototyping, the changes proposed in #753 allow a container to be added to CVariable as a public member and thus directly accessible everywhere (one can even allocate only in some derived constructors, with no risk of leaking memory). For release-quality code I think encapsulation is desirable, that being said I'm not above declaring the client solver a friend of the specific CVariable it uses (also with the changes introduced, there would be a way to access member variables directly without moving them to base CVariable).; I like encapsulation not because of OOP principles but because of `GetVelocity(iDim)` instead of `GetPrimitive(iDim+1)`. As for overhead I think it is 0 as long as methods are inline: [example](https://gcc.godbolt.org/z/QXoExF); But in all honesty I also chose to change the CVariable interface as little as possible to make my life easier.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-520226075
https://github.com/su2code/SU2/issues/716#issuecomment-520226075:172,Energy Efficiency,allocate,allocate,172,"@economon for prototyping, the changes proposed in #753 allow a container to be added to CVariable as a public member and thus directly accessible everywhere (one can even allocate only in some derived constructors, with no risk of leaking memory). For release-quality code I think encapsulation is desirable, that being said I'm not above declaring the client solver a friend of the specific CVariable it uses (also with the changes introduced, there would be a way to access member variables directly without moving them to base CVariable).; I like encapsulation not because of OOP principles but because of `GetVelocity(iDim)` instead of `GetPrimitive(iDim+1)`. As for overhead I think it is 0 as long as methods are inline: [example](https://gcc.godbolt.org/z/QXoExF); But in all honesty I also chose to change the CVariable interface as little as possible to make my life easier.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-520226075
https://github.com/su2code/SU2/issues/716#issuecomment-520226075:829,Integrability,interface,interface,829,"@economon for prototyping, the changes proposed in #753 allow a container to be added to CVariable as a public member and thus directly accessible everywhere (one can even allocate only in some derived constructors, with no risk of leaking memory). For release-quality code I think encapsulation is desirable, that being said I'm not above declaring the client solver a friend of the specific CVariable it uses (also with the changes introduced, there would be a way to access member variables directly without moving them to base CVariable).; I like encapsulation not because of OOP principles but because of `GetVelocity(iDim)` instead of `GetPrimitive(iDim+1)`. As for overhead I think it is 0 as long as methods are inline: [example](https://gcc.godbolt.org/z/QXoExF); But in all honesty I also chose to change the CVariable interface as little as possible to make my life easier.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-520226075
https://github.com/su2code/SU2/issues/716#issuecomment-520226075:484,Modifiability,variab,variables,484,"@economon for prototyping, the changes proposed in #753 allow a container to be added to CVariable as a public member and thus directly accessible everywhere (one can even allocate only in some derived constructors, with no risk of leaking memory). For release-quality code I think encapsulation is desirable, that being said I'm not above declaring the client solver a friend of the specific CVariable it uses (also with the changes introduced, there would be a way to access member variables directly without moving them to base CVariable).; I like encapsulation not because of OOP principles but because of `GetVelocity(iDim)` instead of `GetPrimitive(iDim+1)`. As for overhead I think it is 0 as long as methods are inline: [example](https://gcc.godbolt.org/z/QXoExF); But in all honesty I also chose to change the CVariable interface as little as possible to make my life easier.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-520226075
https://github.com/su2code/SU2/issues/716#issuecomment-520226075:224,Safety,risk,risk,224,"@economon for prototyping, the changes proposed in #753 allow a container to be added to CVariable as a public member and thus directly accessible everywhere (one can even allocate only in some derived constructors, with no risk of leaking memory). For release-quality code I think encapsulation is desirable, that being said I'm not above declaring the client solver a friend of the specific CVariable it uses (also with the changes introduced, there would be a way to access member variables directly without moving them to base CVariable).; I like encapsulation not because of OOP principles but because of `GetVelocity(iDim)` instead of `GetPrimitive(iDim+1)`. As for overhead I think it is 0 as long as methods are inline: [example](https://gcc.godbolt.org/z/QXoExF); But in all honesty I also chose to change the CVariable interface as little as possible to make my life easier.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-520226075
https://github.com/su2code/SU2/issues/716#issuecomment-520226075:136,Security,access,accessible,136,"@economon for prototyping, the changes proposed in #753 allow a container to be added to CVariable as a public member and thus directly accessible everywhere (one can even allocate only in some derived constructors, with no risk of leaking memory). For release-quality code I think encapsulation is desirable, that being said I'm not above declaring the client solver a friend of the specific CVariable it uses (also with the changes introduced, there would be a way to access member variables directly without moving them to base CVariable).; I like encapsulation not because of OOP principles but because of `GetVelocity(iDim)` instead of `GetPrimitive(iDim+1)`. As for overhead I think it is 0 as long as methods are inline: [example](https://gcc.godbolt.org/z/QXoExF); But in all honesty I also chose to change the CVariable interface as little as possible to make my life easier.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-520226075
https://github.com/su2code/SU2/issues/716#issuecomment-520226075:470,Security,access,access,470,"@economon for prototyping, the changes proposed in #753 allow a container to be added to CVariable as a public member and thus directly accessible everywhere (one can even allocate only in some derived constructors, with no risk of leaking memory). For release-quality code I think encapsulation is desirable, that being said I'm not above declaring the client solver a friend of the specific CVariable it uses (also with the changes introduced, there would be a way to access member variables directly without moving them to base CVariable).; I like encapsulation not because of OOP principles but because of `GetVelocity(iDim)` instead of `GetPrimitive(iDim+1)`. As for overhead I think it is 0 as long as methods are inline: [example](https://gcc.godbolt.org/z/QXoExF); But in all honesty I also chose to change the CVariable interface as little as possible to make my life easier.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-520226075
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5076,Availability,mask,mask,5076,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5582,Availability,robust,robustness,5582,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:1400,Energy Efficiency,Green,Green-Gauss,1400,"ce is **""measure it before changing code""**, I broke that rule because as my first post illustrated non contiguous storage at the scale we had is a real killer. With that out of the way, to some extent at least (the layout may not be optimum still) measuring is essential to decide what to do next. This is the case I am using:; ![case](https://user-images.githubusercontent.com/38071223/63288257-27d9d580-c2b4-11e9-9899-8b44b230b8bb.png); It is a bad wing design (NACA0012) with some sweep and taper and a home-brew mesh whose quality rivals that of the design (it converges and the flow does not separate...).; The mesh is just over 500k vertices (so it ""fits"" comfortably in my pc) the y+ is not great (obvs) but the aspect ratios are 200 and 2000 in the chordwise and spanwise directions respectively, so not exactly linear solver friendly either. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case since the ratio of useful data to pointers and vtables is lower. After a celebratory dance I attempted to profile the code using [Perf](https://en.wikipedia.org/wiki/Perf_(Linux)) which I ""learned how to use"" from [a YouTube video](https://www.youtube.com/watch?v=nXaxk27zwlk&t=2052s).; In a nutshell compile the code as usual but with the `-fno-omit-frame",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:135,Integrability,wrap,wrapper,135,"Ok time to share some results after #753.; I deviated a bit from the original plan in that I skipped the contrived strategy of using a wrapper container with a special [] operator (as it had a slight whiff of hackery), and went straight to adding ""iNode"" to the methods of CVariable instead (me and a few lines of python...). The first rule of performance is **""measure it before changing code""**, I broke that rule because as my first post illustrated non contiguous storage at the scale we had is a real killer. With that out of the way, to some extent at least (the layout may not be optimum still) measuring is essential to decide what to do next. This is the case I am using:; ![case](https://user-images.githubusercontent.com/38071223/63288257-27d9d580-c2b4-11e9-9899-8b44b230b8bb.png); It is a bad wing design (NACA0012) with some sweep and taper and a home-brew mesh whose quality rivals that of the design (it converges and the flow does not separate...).; The mesh is just over 500k vertices (so it ""fits"" comfortably in my pc) the y+ is not great (obvs) but the aspect ratios are 200 and 2000 in the chordwise and spanwise directions respectively, so not exactly linear solver friendly either. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case sin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:3579,Integrability,rout,routine,3579,"orementioned flag), for 2-3 minutes for hundreds of MB of record (hence the 500k mesh...).; Run `perf report -g ""fractal,0.5,caller""`, this will show % of time spent in a function relative to its caller and you can expand each function to see what are its children, grandchildren, etc. Like so:; ![image](https://user-images.githubusercontent.com/38071223/63290949-725e5080-c2ba-11e9-90aa-ffc834e726db.png); How cool is that!! Pro-tip hit ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is probably not a good idea to draw conclusion about <1% variations. Moving on, I took the top level percentages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:3993,Integrability,rout,routines,3993,"it ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is probably not a good idea to draw conclusion about <1% variations. Moving on, I took the top level percentages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a tempor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:344,Performance,perform,performance,344,"Ok time to share some results after #753.; I deviated a bit from the original plan in that I skipped the contrived strategy of using a wrapper container with a special [] operator (as it had a slight whiff of hackery), and went straight to adding ""iNode"" to the methods of CVariable instead (me and a few lines of python...). The first rule of performance is **""measure it before changing code""**, I broke that rule because as my first post illustrated non contiguous storage at the scale we had is a real killer. With that out of the way, to some extent at least (the layout may not be optimum still) measuring is essential to decide what to do next. This is the case I am using:; ![case](https://user-images.githubusercontent.com/38071223/63288257-27d9d580-c2b4-11e9-9899-8b44b230b8bb.png); It is a bad wing design (NACA0012) with some sweep and taper and a home-brew mesh whose quality rivals that of the design (it converges and the flow does not separate...).; The mesh is just over 500k vertices (so it ""fits"" comfortably in my pc) the y+ is not great (obvs) but the aspect ratios are 200 and 2000 in the chordwise and spanwise directions respectively, so not exactly linear solver friendly either. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case sin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:4284,Performance,bottleneck,bottleneck,4284,"centages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about wi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5081,Performance,latency,latency,5081,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5597,Performance,perform,performance,5597,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:3946,Safety,predict,predicted,3946,"it ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is probably not a good idea to draw conclusion about <1% variations. Moving on, I took the top level percentages only, normalized by that of CFluidIteration::Iterate (to exclude pre-processing time) and multiplied the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a tempor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:4361,Testability,test,test,4361,"ed the results from the total ""iteration time"" from the history file. Doing that for before and after results allowed computing individual speedup factors for each important routine (in terms of time, otherwise they are all special and important in their own way) e.g. gradients, limiters, upwind/viscous residuals, etc.; ![image](https://user-images.githubusercontent.com/38071223/63292708-30cfa480-c2be-11e9-8d4a-5feb3dc61abf.png). Here is the data by the way: [results.xlsx](https://github.com/su2code/SU2/files/3517492/results.xlsx). As predicted the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:2187,Usability,learn,learned,2187,"ither. Some settings which are kinda optimal:; - Mach 0.6, AoA 2 degrees;; - SST (1st order);; - CFL 20 (higher and residuals would limit-cycle (regardless of linear solver settings); - Roe;; - MUSCL - Green-Gauss and Venkat-Wang;; - FGMRES + LU_SGS to 0.05 residual (about 3 iters on avg.);; - 2 levels of MG (1,1,2 iterations, all zeros for other stuff and 0.7 damping both ways);. The case is light on the linear solver and therefore stands to benefit the most from better data layout. Conversely, applications that can take higher CFL / or use central schemes will not benefit as much. **Running this from scratch to residual of 10^-8 on a couple of Xeon E5-2650v4 (24c total) shows a speedup of 1.4 and just over 10% lower memory usage.**; Those numbers will be better for an equivalent 2D case since the ratio of useful data to pointers and vtables is lower. After a celebratory dance I attempted to profile the code using [Perf](https://en.wikipedia.org/wiki/Perf_(Linux)) which I ""learned how to use"" from [a YouTube video](https://www.youtube.com/watch?v=nXaxk27zwlk&t=2052s).; In a nutshell compile the code as usual but with the `-fno-omit-frame-pointer` cxx flag (so perf can figure out the name of the functions, debug symbols are not required).; Run `perf record -g [command]` where command can be your usual `mpirun...` (I did not recompile my mpi with the aforementioned flag), for 2-3 minutes for hundreds of MB of record (hence the 500k mesh...).; Run `perf report -g ""fractal,0.5,caller""`, this will show % of time spent in a function relative to its caller and you can expand each function to see what are its children, grandchildren, etc. Like so:; ![image](https://user-images.githubusercontent.com/38071223/63290949-725e5080-c2ba-11e9-90aa-ffc834e726db.png); How cool is that!! Pro-tip hit ""a"" to look at some assembly, honestly sliced bread has nothing on perf. NOTE: By and large Perf is not an intrusive tool, as such the accuracy of the measurements is limited i.e. it is pr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-522730951:5345,Usability,clear,clear,5345,"ed the linear solvers stay the same and routines that are light see more speedup than their arithmetic-intensive friends.; What is surprising to me is how intensive the convective residuals appear to be with only a 7% improvement, so surprising in fact, I do not think the above paints the full picture. Maybe the outlet bandwidth bottleneck (into the Jacobian matrix) is more important.; To put that do the test I switched to Euler-explicit time marching and repeated the measurements:; ![image](https://user-images.githubusercontent.com/38071223/63293351-d8010b80-c2bf-11e9-8135-2502eac1128e.png); Better, but not by much, which means upwind and viscous residuals computations might gain a lot from vectorization (SIMD). And like @economon mentioned even more if they are somehow fused together.; It also means the writes to CSysMatrix are relatively expensive, I think there are two-three reasons for it.; - We do a linear search on each Add/SubtractBlock - This could be replaced by a map.; - The Jacobian contributions are first written into a temporary block - Interleaving the writes with the computation could help mask latency.; - That temporary is not stored contiguously - Which makes it hard to vectorize the writes to CSysMatrix. **So what do I think should be tackled next?**; Hybrid parallelism (wait what?!) from messing about with this case (and more refined versions) it is clear the MG puts some limits on how many cores can be used before it stops being able to produce coarse grids, both in number and quality. Going to an MPI+Threads strategy would move that limit by one order of magnitude, giving us some robustness and performance for folks hoping to rely on strong scaling. I think I'll break it off here and keep my thoughts about SIMD and hybrid parallel for a later occasion (I have to do some ""real"" PhD work for a while) but please, if anyone has ideias, comments, corrections, suggestions, similar ongoing developments (specially)... I am all ears/eyes. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-522730951
https://github.com/su2code/SU2/issues/716#issuecomment-523063269:72,Performance,perform,performance,72,"Thanks Pedro,. If you want I can run this test case also with the Intel performance tools. These usually give some more info what can be improved to obtain better performance. Cheers,. Edwin.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523063269
https://github.com/su2code/SU2/issues/716#issuecomment-523063269:163,Performance,perform,performance,163,"Thanks Pedro,. If you want I can run this test case also with the Intel performance tools. These usually give some more info what can be improved to obtain better performance. Cheers,. Edwin.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523063269
https://github.com/su2code/SU2/issues/716#issuecomment-523063269:42,Testability,test,test,42,"Thanks Pedro,. If you want I can run this test case also with the Intel performance tools. These usually give some more info what can be improved to obtain better performance. Cheers,. Edwin.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523063269
https://github.com/su2code/SU2/issues/716#issuecomment-523329065:512,Performance,perform,performance,512,"Pedro,. I did a single core analysis on a Xeon Gold @2.30 GHz for the implicit solver, see below; ![SU2_Profile](https://user-images.githubusercontent.com/15017924/63409877-5067e980-c3f2-11e9-8957-0fc3ba26d69d.png); I can give more details, if needed. This is not shown in the picture, but the good news is that your feature_contiguous_cvariable_PR branch is a factor 1.25 to 1.3 faster per iteration than the current develop version. The bad news is that the far majority is still spent in scalar loops and the performance of the vectorized loops is rather poor. However, that was to be expected with the current data structures. My experience is that if you can vectorize the loops appropriately you can gain a factor of 3 to 4 compared to scalar loops (theoretically 8, but you never get that). However, that means a complete redesign of the current data structures and most likely a loss in generality and readability. If people want, we can start a discussion on this. And indeed, the inviscid flux computations are very time consuming. In the DG code I created a more hard coded version of the Roe solver and that was significantly faster (factor of 3). So also that is something to think about. Cheers,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523329065
https://github.com/su2code/SU2/issues/716#issuecomment-523930905:564,Availability,down,down,564,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
https://github.com/su2code/SU2/issues/716#issuecomment-523930905:680,Modifiability,polymorphi,polymorphism,680,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
https://github.com/su2code/SU2/issues/716#issuecomment-523930905:509,Performance,cache,cache,509,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
https://github.com/su2code/SU2/issues/716#issuecomment-523930905:581,Performance,cache,cache,581,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
https://github.com/su2code/SU2/issues/716#issuecomment-523930905:669,Performance,optimiz,optimizing,669,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
https://github.com/su2code/SU2/issues/716#issuecomment-523930905:65,Usability,simpl,simple,65,"Thanks Edwin, the vectorized loops in the code are probably very simple array copies, hence the low efficiency? I would put money on not a single vector instruction being generated for the important stuff. I was surprised by the 1.25 to 1.3 factor you are seeing, for the exact same case I measured 1.39 (to be more precise). Initially I thought it had something to do with running single core, thus leaving vast amounts of L3 for only that core to use, so on the same 24c platform I ran 2 processes (30MB of cache for each) (very uncivilised) and the factor went down to 1.37, so cache was not the reason.; So then I thought maybe the Intel compilers are very good at optimizing polymorphism away, but the development branch compiled with icc 17 runs at exactly the same speed as when compiled with gcc 5.4. Then I compiled feature_contiguous_cvariable with icc 17 and it runs 9% slower than the gcc binaries, and so with icc 17 the speedup for this case was 1.27 errrrr... Anyone got a buddy at Intel?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523930905
https://github.com/su2code/SU2/issues/716#issuecomment-523952473:494,Modifiability,polymorphi,polymorphism,494,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
https://github.com/su2code/SU2/issues/716#issuecomment-523952473:517,Performance,optimiz,optimized,517,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
https://github.com/su2code/SU2/issues/716#issuecomment-523952473:1047,Performance,perform,performs,1047,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
https://github.com/su2code/SU2/issues/716#issuecomment-523952473:1061,Performance,optimiz,optimization,1061,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
https://github.com/su2code/SU2/issues/716#issuecomment-523952473:1203,Performance,optimiz,optimized,1203,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
https://github.com/su2code/SU2/issues/716#issuecomment-523952473:1092,Usability,simpl,simple,1092,"No need for Intel buddies, I know what's up. Take [this code:](https://gcc.godbolt.org/z/siQamn); ```; class Base {; public:; inline virtual double get() const {return 0.0;}; };. class Derived : public Base {; double val;; public:; Derived(double a) : val(a) {}. inline double get() const final {return val;}; };. double fun1(Base* obj) {; return obj->get();; }. double fun2(Base* obj) {; return static_cast<Derived*>(obj)->get();; }; ```. `get` of derived has been marked `final` so in `fun2` polymorphism should be optimized away. Here is the assembly for gcc 5.4:. ```; fun1(Base*):; mov rax, QWORD PTR [rdi]; jmp [QWORD PTR [rax]]; fun2(Base*):; movsd xmm0, QWORD PTR [rdi+8]; ret; ```; `fun1` needs a jump, `fun2` knows what to return right away. Here is the assembly for icc 17:; ```; fun1(Base*):; mov rax, QWORD PTR [rdi] #16.12; mov rdx, QWORD PTR [rax] #16.12; jmp rdx #16.12; fun2(Base*):; mov rax, QWORD PTR [rdi] #20.34; mov rdx, QWORD PTR [rax] #20.34; jmp rdx #20.34; ```. @vdweide please tell me you did not use icc 19, because it performs this optimization just fine on this simple example. By the way @talbring (since you asked in #753), take away the `final` keyword and nothing gets optimized by the `static_cast`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-523952473
https://github.com/su2code/SU2/issues/716#issuecomment-524038333:100,Integrability,depend,dependent,100,"@pcarruscag, my icpc version is 19.0.0.117 20180804....; The speed up is most likely also processor dependent. I ran this case on a Xeon(R) Gold 6140 CPU @ 2.30GHz with 24 Mb cache. Anyway, this is probably as fast as you can get the code to run with the current data structures. Maybe you can squeeze another 10 percent out of it, but that's most likely it. If we really want to speed things up, we need to change the data structures significantly (structure of arrays, a single array per variable, aligned memory allocation, padding arrays to a multiple of 8, no small loops over the number of dimensions, etc.) . As said before, I think we can get at least a factor of 4 in speed compared to the current version if we can use a significant number of SIMD loops, i.e. vectorization. However, I don't know how much support there is for a pretty much complete rewrite of the computational kernel. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524038333
https://github.com/su2code/SU2/issues/716#issuecomment-524038333:490,Modifiability,variab,variable,490,"@pcarruscag, my icpc version is 19.0.0.117 20180804....; The speed up is most likely also processor dependent. I ran this case on a Xeon(R) Gold 6140 CPU @ 2.30GHz with 24 Mb cache. Anyway, this is probably as fast as you can get the code to run with the current data structures. Maybe you can squeeze another 10 percent out of it, but that's most likely it. If we really want to speed things up, we need to change the data structures significantly (structure of arrays, a single array per variable, aligned memory allocation, padding arrays to a multiple of 8, no small loops over the number of dimensions, etc.) . As said before, I think we can get at least a factor of 4 in speed compared to the current version if we can use a significant number of SIMD loops, i.e. vectorization. However, I don't know how much support there is for a pretty much complete rewrite of the computational kernel. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524038333
https://github.com/su2code/SU2/issues/716#issuecomment-524038333:860,Modifiability,rewrite,rewrite,860,"@pcarruscag, my icpc version is 19.0.0.117 20180804....; The speed up is most likely also processor dependent. I ran this case on a Xeon(R) Gold 6140 CPU @ 2.30GHz with 24 Mb cache. Anyway, this is probably as fast as you can get the code to run with the current data structures. Maybe you can squeeze another 10 percent out of it, but that's most likely it. If we really want to speed things up, we need to change the data structures significantly (structure of arrays, a single array per variable, aligned memory allocation, padding arrays to a multiple of 8, no small loops over the number of dimensions, etc.) . As said before, I think we can get at least a factor of 4 in speed compared to the current version if we can use a significant number of SIMD loops, i.e. vectorization. However, I don't know how much support there is for a pretty much complete rewrite of the computational kernel. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524038333
https://github.com/su2code/SU2/issues/716#issuecomment-524038333:175,Performance,cache,cache,175,"@pcarruscag, my icpc version is 19.0.0.117 20180804....; The speed up is most likely also processor dependent. I ran this case on a Xeon(R) Gold 6140 CPU @ 2.30GHz with 24 Mb cache. Anyway, this is probably as fast as you can get the code to run with the current data structures. Maybe you can squeeze another 10 percent out of it, but that's most likely it. If we really want to speed things up, we need to change the data structures significantly (structure of arrays, a single array per variable, aligned memory allocation, padding arrays to a multiple of 8, no small loops over the number of dimensions, etc.) . As said before, I think we can get at least a factor of 4 in speed compared to the current version if we can use a significant number of SIMD loops, i.e. vectorization. However, I don't know how much support there is for a pretty much complete rewrite of the computational kernel. My two cents,. Edwin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524038333
https://github.com/su2code/SU2/issues/716#issuecomment-524215699:175,Performance,perform,performance,175,"Interesting. Well I managed to get icpc 19.04 to work last night (cluster IT problems...) and sure enough I got my 9% back. I think that is too large a difference in relative performance of a code that does not have any architecture specific tuning to attribute to 1 CPU generation. I have some ideas for vectorization + threads without complete re-writes and without readability concerns, I'll prototype them when I have time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524215699
https://github.com/su2code/SU2/issues/716#issuecomment-524534304:26,Performance,perform,performance,26,"@vdweide, of relevance to performance I used -O3 -march=native -DNDEBUG. That last one disables the assertions the container class performs to detect out of bounds accesses.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524534304
https://github.com/su2code/SU2/issues/716#issuecomment-524534304:131,Performance,perform,performs,131,"@vdweide, of relevance to performance I used -O3 -march=native -DNDEBUG. That last one disables the assertions the container class performs to detect out of bounds accesses.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524534304
https://github.com/su2code/SU2/issues/716#issuecomment-524534304:143,Safety,detect,detect,143,"@vdweide, of relevance to performance I used -O3 -march=native -DNDEBUG. That last one disables the assertions the container class performs to detect out of bounds accesses.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524534304
https://github.com/su2code/SU2/issues/716#issuecomment-524534304:164,Security,access,accesses,164,"@vdweide, of relevance to performance I used -O3 -march=native -DNDEBUG. That last one disables the assertions the container class performs to detect out of bounds accesses.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524534304
https://github.com/su2code/SU2/issues/716#issuecomment-524534304:100,Testability,assert,assertions,100,"@vdweide, of relevance to performance I used -O3 -march=native -DNDEBUG. That last one disables the assertions the container class performs to detect out of bounds accesses.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524534304
https://github.com/su2code/SU2/issues/716#issuecomment-524805261:33,Performance,perform,perform,33,"@pcarruscag, your compiler flags perform a lot better. Compared to what I used, it speeds up another 15 percent. Compared to the develop version I get a speed up of 1.5 now on my machine. As far as your earlier question about vectorization is concerned, yes these are all small loops. None of the bigger loops is vectorized.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524805261
https://github.com/su2code/SU2/issues/716#issuecomment-524806934:158,Security,access,access,158,"Awesome, close to 1.5 was what I saw on the skylake architecture too (albeit the consumer version).; Thanks for testing again, without the DNDEBUG flag every access to CVariable is an if statement basically. That flag is now set by default when building with meson.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524806934
https://github.com/su2code/SU2/issues/716#issuecomment-524806934:112,Testability,test,testing,112,"Awesome, close to 1.5 was what I saw on the skylake architecture too (albeit the consumer version).; Thanks for testing again, without the DNDEBUG flag every access to CVariable is an if statement basically. That flag is now set by default when building with meson.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/716#issuecomment-524806934
https://github.com/su2code/SU2/issues/717#issuecomment-513286450:212,Availability,error,error,212,Thank @stephansmit I agree since its a nozzle so I tried using the turbomachinery case. I tried the same earlier but it did not work out. Still tried exactly the same way you suggested. Below is the segmentation error I received. Attached updated .cfg and .su2 file for reference. Can you help me with this error? This restart and .su2 file was running perfectly fine so far with other Reimann and other BCs.. . [GILES_BC.zip](https://github.com/su2code/SU2/files/3411841/GILES_BC.zip). ---------------------- Turbomachinery Preprocessing ---------------------. Initialize Turbo Vertex Structure.; Number of span-wise sections in Zone 0: 1.; [nrlogin1:mpi_rank_0][error_sighandler] Caught error: Segmentation fault (signal 11); Segmentation fault,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/717#issuecomment-513286450
https://github.com/su2code/SU2/issues/717#issuecomment-513286450:307,Availability,error,error,307,Thank @stephansmit I agree since its a nozzle so I tried using the turbomachinery case. I tried the same earlier but it did not work out. Still tried exactly the same way you suggested. Below is the segmentation error I received. Attached updated .cfg and .su2 file for reference. Can you help me with this error? This restart and .su2 file was running perfectly fine so far with other Reimann and other BCs.. . [GILES_BC.zip](https://github.com/su2code/SU2/files/3411841/GILES_BC.zip). ---------------------- Turbomachinery Preprocessing ---------------------. Initialize Turbo Vertex Structure.; Number of span-wise sections in Zone 0: 1.; [nrlogin1:mpi_rank_0][error_sighandler] Caught error: Segmentation fault (signal 11); Segmentation fault,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/717#issuecomment-513286450
https://github.com/su2code/SU2/issues/717#issuecomment-513286450:689,Availability,error,error,689,Thank @stephansmit I agree since its a nozzle so I tried using the turbomachinery case. I tried the same earlier but it did not work out. Still tried exactly the same way you suggested. Below is the segmentation error I received. Attached updated .cfg and .su2 file for reference. Can you help me with this error? This restart and .su2 file was running perfectly fine so far with other Reimann and other BCs.. . [GILES_BC.zip](https://github.com/su2code/SU2/files/3411841/GILES_BC.zip). ---------------------- Turbomachinery Preprocessing ---------------------. Initialize Turbo Vertex Structure.; Number of span-wise sections in Zone 0: 1.; [nrlogin1:mpi_rank_0][error_sighandler] Caught error: Segmentation fault (signal 11); Segmentation fault,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/717#issuecomment-513286450
https://github.com/su2code/SU2/issues/717#issuecomment-513286450:709,Availability,fault,fault,709,Thank @stephansmit I agree since its a nozzle so I tried using the turbomachinery case. I tried the same earlier but it did not work out. Still tried exactly the same way you suggested. Below is the segmentation error I received. Attached updated .cfg and .su2 file for reference. Can you help me with this error? This restart and .su2 file was running perfectly fine so far with other Reimann and other BCs.. . [GILES_BC.zip](https://github.com/su2code/SU2/files/3411841/GILES_BC.zip). ---------------------- Turbomachinery Preprocessing ---------------------. Initialize Turbo Vertex Structure.; Number of span-wise sections in Zone 0: 1.; [nrlogin1:mpi_rank_0][error_sighandler] Caught error: Segmentation fault (signal 11); Segmentation fault,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/717#issuecomment-513286450
https://github.com/su2code/SU2/issues/717#issuecomment-513286450:741,Availability,fault,fault,741,Thank @stephansmit I agree since its a nozzle so I tried using the turbomachinery case. I tried the same earlier but it did not work out. Still tried exactly the same way you suggested. Below is the segmentation error I received. Attached updated .cfg and .su2 file for reference. Can you help me with this error? This restart and .su2 file was running perfectly fine so far with other Reimann and other BCs.. . [GILES_BC.zip](https://github.com/su2code/SU2/files/3411841/GILES_BC.zip). ---------------------- Turbomachinery Preprocessing ---------------------. Initialize Turbo Vertex Structure.; Number of span-wise sections in Zone 0: 1.; [nrlogin1:mpi_rank_0][error_sighandler] Caught error: Segmentation fault (signal 11); Segmentation fault,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/717#issuecomment-513286450
https://github.com/su2code/SU2/issues/717#issuecomment-513286450:239,Deployability,update,updated,239,Thank @stephansmit I agree since its a nozzle so I tried using the turbomachinery case. I tried the same earlier but it did not work out. Still tried exactly the same way you suggested. Below is the segmentation error I received. Attached updated .cfg and .su2 file for reference. Can you help me with this error? This restart and .su2 file was running perfectly fine so far with other Reimann and other BCs.. . [GILES_BC.zip](https://github.com/su2code/SU2/files/3411841/GILES_BC.zip). ---------------------- Turbomachinery Preprocessing ---------------------. Initialize Turbo Vertex Structure.; Number of span-wise sections in Zone 0: 1.; [nrlogin1:mpi_rank_0][error_sighandler] Caught error: Segmentation fault (signal 11); Segmentation fault,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/717#issuecomment-513286450
https://github.com/su2code/SU2/issues/719#issuecomment-508201120:186,Availability,error,error,186,I can't confirm that using Intel v19.0.4 worked (since I was unable to get that compiler version) but I am closing the issue nonetheless since @WallyMaier confirmed that he got the same error and fixed it by using v19.0.4,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/719#issuecomment-508201120
https://github.com/su2code/SU2/issues/721#issuecomment-515535554:693,Modifiability,coupling,coupling,693,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554
https://github.com/su2code/SU2/issues/721#issuecomment-515535554:1106,Modifiability,variab,variables,1106,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554
https://github.com/su2code/SU2/issues/721#issuecomment-515535554:5,Testability,test,tested,5,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554
https://github.com/su2code/SU2/issues/721#issuecomment-515535554:1266,Usability,simpl,simplicity,1266,"So I tested this on 4 mesh levels for a NACA0006 at 2.0 degrees AoA, at low (0.6) and high-ish (0.8) Mach number (Roe scheme).; These are the results for low Mach:; ![image](https://user-images.githubusercontent.com/38071223/61968547-3b08c680-afd0-11e9-8aae-9705a9441a00.png); Very small differences between recomputing a mass flux based on primitives (""Reconstructed"") or storing the flux computed during discretization of convection (""Consistent"").; However, the convergence rate for the latter approach is much worse:; ![image](https://user-images.githubusercontent.com/38071223/61968712-99ce4000-afd0-11e9-9c31-dafd7e26e3fb.png); Which makes sense because we are going from a Gauss-Seidel coupling of flow and turbulence to a half GS, half Jacobi (since the turbulence source terms were still computed with current velocity gradients).; After seeing this I only ran one mesh level (second to finest) at high Mach number and again differences were very small and convergence worse.; Some memory would indeed be saved in the discrete adjoint through the reduction of the number of pre-accumulation input variables, but only 30MB out of almost 9GB for a 2D case without MG. In summary the current approach seems to strike a good balance between accuracy, cost, and simplicity.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/721#issuecomment-515535554
https://github.com/su2code/SU2/issues/722#issuecomment-506407154:19,Deployability,install,installed,19,Do you have mpi4py installed in your machine?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506407154
https://github.com/su2code/SU2/issues/722#issuecomment-506457037:260,Deployability,install,installed,260,"I've run into a similar problem. We can check if you're having the same issue (and figure out more about the problem) by doing the following. Open a python terminal and enter the following commands:; ```; from mpi4py import MPI; MPI; ```; If you've got mpi4py installed on your system and it's on your python path, you'll see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```; What output do you get from that command?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506457037
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:469,Availability,error,errors,469,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:124,Deployability,install,install,124,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:153,Deployability,install,installed,153,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:214,Deployability,install,install,214,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:363,Deployability,install,install,363,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:394,Deployability,install,install,394,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:425,Deployability,install,install,425,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506576947:447,Integrability,Wrap,Wrapper,447,"Thank you. I have found my where my problem was. My default python environment is anaconda python. But when I use `sudo pip install mpi4py`, it actually installed mpi4py for python2.7 (system python). So I have to install mpi4py for python3 (system or anaconda python). Due to my network problem, I choose to intall mpi4py with following commands:; ```; sudo apt install python3-pip; sudo pip3 install mpi4py; ```; Now I can install SU2 by Python Wrapper Build without errors. Thank you. Closing now.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506576947
https://github.com/su2code/SU2/issues/722#issuecomment-506710295:122,Deployability,install,installed,122,"For people who came across this issue later, my previous issue was very similar. If you have multiple python environments installed on your machine (e.g. Python 2.7 and Python 3.6), then the build process for the python wrapper doesn't always select the one with mpi4py installed. In my case, I had to manually edit the Makefile in `SU2_PY/pySU2/Makefile` to point to the correct python installation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506710295
https://github.com/su2code/SU2/issues/722#issuecomment-506710295:270,Deployability,install,installed,270,"For people who came across this issue later, my previous issue was very similar. If you have multiple python environments installed on your machine (e.g. Python 2.7 and Python 3.6), then the build process for the python wrapper doesn't always select the one with mpi4py installed. In my case, I had to manually edit the Makefile in `SU2_PY/pySU2/Makefile` to point to the correct python installation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506710295
https://github.com/su2code/SU2/issues/722#issuecomment-506710295:387,Deployability,install,installation,387,"For people who came across this issue later, my previous issue was very similar. If you have multiple python environments installed on your machine (e.g. Python 2.7 and Python 3.6), then the build process for the python wrapper doesn't always select the one with mpi4py installed. In my case, I had to manually edit the Makefile in `SU2_PY/pySU2/Makefile` to point to the correct python installation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506710295
https://github.com/su2code/SU2/issues/722#issuecomment-506710295:220,Integrability,wrap,wrapper,220,"For people who came across this issue later, my previous issue was very similar. If you have multiple python environments installed on your machine (e.g. Python 2.7 and Python 3.6), then the build process for the python wrapper doesn't always select the one with mpi4py installed. In my case, I had to manually edit the Makefile in `SU2_PY/pySU2/Makefile` to point to the correct python installation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-506710295
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:746,Availability,error,error,746,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:829,Availability,Error,Error,829,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:2840,Availability,error,error,2840,"firmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modify the `MPI4PY_INCLUDE` line of `SU2_PY/pySU2/Makefile.am` to include the location of your mpi4py package.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:142,Deployability,install,installed,142,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:217,Deployability,install,installing,217,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:782,Deployability,install,install,782,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:896,Deployability,install,installed,896,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1112,Deployability,install,installing-using-pip-and-virtual-environments,1112,"when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1393,Deployability,install,installed,1393,"ally detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1591,Deployability,install,installed,1591,"es is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1868,Deployability,install,installed,1868,"'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:713,Integrability,wrap,wrapper,713,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:2286,Modifiability,config,configure,2286,"firmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modify the `MPI4PY_INCLUDE` line of `SU2_PY/pySU2/Makefile.am` to include the location of your mpi4py package.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:2718,Modifiability,config,configure,2718,"firmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, this prints out four lines. I don't care about the `Makefile.in` files, because those are generated automatically and will be overwritten every time I run ""configure"" or ""preconfigure.py."" The `NUMPY_INCLUDE` line is also commented out, so I ignore that too. That leaves me with one line, line 51 of `SU2_PY/pySU2/Makefile.am`:. ```; SU2_PY/pySU2/Makefile.am:51:MPI4PY_INCLUDE = ${HOME}/.local/lib/python2.7/site-packages/mpi4py/include \; ```. I now modify line 51 of Makefile.am to read:. ```; MPI4PY_INCLUDE = ${HOME}/.local/lib/python3.6/site-packages/mpi4py/include \; ```. Then run configure or preconfigure.py again, and then run make again. You should be good to go!. #### tl;dr. If you're having this error, modify the `MPI4PY_INCLUDE` line of `SU2_PY/pySU2/Makefile.am` to include the location of your mpi4py package.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:383,Safety,detect,detect,383,"It seems like your situation may have been resolved, but for archival purposes, I'll list my workaround here. This problem occurs when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-515693590:1105,Usability,guid,guides,1105,"when you've installed python packages in two different locations. This could be due to installing some python packages in a system directory (e.g. `/usr/lib/`) and some in a user directory (e.g. `~/.local/`). SU2's build process is set to automatically detect the default package location, but it's not equipped to handle multiple package locations. There are some hardcoded includes, but these only work for python 2.7. I don't consider this a bug *per se* because multiple python package directories is not a standard use case. #### The symptoms. When building SU2 with the python wrapper you'll see the following error during the swig build:; ```; <install directory>/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; ```; But mpi4py is indeed installed on your system and it's on your python path, as confirmed by opening a python terminal and running `import mpi4py`. #### The easiest workaround. Switch to a [virtualenv](https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/). This will ensure that all of your python packages are stored in single location. #### Alternate workaround. In this method, you change the hardcoded includes to match mpi4py's package location. First I figure out where my mpi4py is installed. I start a terminal session of python using the python environment I want to use (in this case, it's python 3.6), and then run:; ```; from mpi4py import MPI; MPI; ```. Since I have mpi4py installed on your system and it's on my python path, I see something like:; ```; <module 'mpi4py.MPI' from '/home/clarkpede/.local/lib/python3.6/site-packages/mpi4py/MPI.cpython-34m.so'>; ```. The `/home/clarkpede/.local/lib/python3.6/` directory is where my mpi4py package is installed. But the swig compile command includes `/home/clarkpede/.local/lib/python2.7/`. That's not the right directory! So first I find the hardcoded paths of the makefile by running (on a bash terminal):; ```; grep -rn python2\.7 SU2_PY/ ; ```; On my system, t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-515693590
https://github.com/su2code/SU2/issues/722#issuecomment-1073373429:87,Availability,error,error,87,"If anyone is encountering this issue in 2022, and you have a virtualenv set up and the error appears: Do a user-install of mpi4py and it will be able to find it. I.e. ```bash; pip3 install mpi4py --user; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-1073373429
https://github.com/su2code/SU2/issues/722#issuecomment-1073373429:112,Deployability,install,install,112,"If anyone is encountering this issue in 2022, and you have a virtualenv set up and the error appears: Do a user-install of mpi4py and it will be able to find it. I.e. ```bash; pip3 install mpi4py --user; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-1073373429
https://github.com/su2code/SU2/issues/722#issuecomment-1073373429:181,Deployability,install,install,181,"If anyone is encountering this issue in 2022, and you have a virtualenv set up and the error appears: Do a user-install of mpi4py and it will be able to find it. I.e. ```bash; pip3 install mpi4py --user; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/722#issuecomment-1073373429
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:464,Availability,avail,available,464,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:274,Energy Efficiency,energy,energy,274,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:187,Modifiability,variab,variable,187,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:407,Modifiability,config,config,407,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:474,Modifiability,config,config-file,474,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:615,Modifiability,variab,variable,615,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:705,Performance,Load,LoadVolumeData,705,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-514031723:639,Security,access,accessor,639,"First off, I love the changes. A cleanup of COuput and greater output flexibility were much needed. So let me see if I understand this code. Say that I, as a developer, want to add a new variable to the volume output. For example, I want the production of turbulent kinetic energy from the SST model during a compressible simulation. As a user, I can always add new outputs by adding new field names to the config file. But production isn't one of the (currently) available config-file options. So I would have to code it. First, I would obviously make sure that the production is properly stored in the turbulence variable class, with an accessor like `GetTurbProduction()`. Second, in `CFlowCompOutput::LoadVolumeData`, I would add to the appropriate place:. ```cpp; SetVolumeOutputValue(""PRODUCTION"", iPoint, Node_Turb->GetTurbProduction());; ```. Third, I would add `PRODUCTION` as a cfg input by adding the following line to `CFlowCompOutput::SetVolumeOutputFields`:. ```cpp; AddVolumeOutput(""PRODUCTION"", ""Turb_Production"", ""PRIMITVE""); ```. I could also split off production into its own output group by changing `PRIMITVE` to any other name. This name does not have to be registered anywhere else. In other words, I can change `PRIMITVE` to `SST_NUMERICS` and the only other place I need to put `SST_NUMERICS` is my cfg file. Finally, I could add either of the two following lines to my cfg file:; ```; VOLUME_OUTPUT= (COORDINATES, SOLUTION, PRODUCTION) ; VOLUME_OUTPUT= (COORDINATES, SOLUTION, SST_NUMERICS); ``` . Is this example correct? If not, what am I misunderstanding? What am I missing?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-514031723
https://github.com/su2code/SU2/pull/724#issuecomment-534095451:119,Usability,Guid,Guide-to-,119,I have created already a small document giving infos on how to prepare for version 7.0. https://su2code.github.io/docs/Guide-to-v7/,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534095451
https://github.com/su2code/SU2/pull/724#issuecomment-534522241:332,Energy Efficiency,adapt,adapt,332,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
https://github.com/su2code/SU2/pull/724#issuecomment-534522241:332,Modifiability,adapt,adapt,332,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
https://github.com/su2code/SU2/pull/724#issuecomment-534522241:343,Modifiability,config,config,343,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
https://github.com/su2code/SU2/pull/724#issuecomment-534522241:60,Testability,test,testing,60,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
https://github.com/su2code/SU2/pull/724#issuecomment-534522241:208,Usability,feedback,feedback,208,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
https://github.com/su2code/SU2/pull/724#issuecomment-534522241:224,Usability,usab,usability,224,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
https://github.com/su2code/SU2/pull/724#issuecomment-534522241:319,Usability,learn,learn,319,"We will merge this PR next in order to have enough time for testing and for you to solve conflicts (if you need any help to solve those, please contact me). Even if this PR is merged, please continue to give feedback on the usability. We will still continue to work on that. Refer to the user documentation in order to learn how to adapt your config files. Let me know if you have any questions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534522241
https://github.com/su2code/SU2/pull/724#issuecomment-534580926:128,Testability,test,test,128,"I am more than happy to get any reviews! However, I don't expect that anyone will go through all files and in order to properly test it, we have to slightly push it. . We will give it a couple of days though.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534580926
https://github.com/su2code/SU2/pull/724#issuecomment-534605572:285,Testability,test,tests,285,"I agree with @talbring. This one is a burden on both sides (to prepare and review), and it is easy for us to keep putting it off. I would recommend that everyone takes a look at this in the next day or two - at least take a look at the changes that will affect your own work. Once the tests pass, we can be confident that we are preserving what is in the regressions, but we will need a short period of conflict fixing and testing for those with active branches. The majority of the PR is for output features, which should not affect correctness of the solvers, but there are some important changes to the drivers and options that folks should be aware of. Please give these things a pass when you have a minute.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534605572
https://github.com/su2code/SU2/pull/724#issuecomment-534605572:423,Testability,test,testing,423,"I agree with @talbring. This one is a burden on both sides (to prepare and review), and it is easy for us to keep putting it off. I would recommend that everyone takes a look at this in the next day or two - at least take a look at the changes that will affect your own work. Once the tests pass, we can be confident that we are preserving what is in the regressions, but we will need a short period of conflict fixing and testing for those with active branches. The majority of the PR is for output features, which should not affect correctness of the solvers, but there are some important changes to the drivers and options that folks should be aware of. Please give these things a pass when you have a minute.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534605572
https://github.com/su2code/SU2/pull/724#issuecomment-534651933:530,Modifiability,refactor,refactoring,530,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
https://github.com/su2code/SU2/pull/724#issuecomment-534651933:130,Performance,perform,performance,130,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
https://github.com/su2code/SU2/pull/724#issuecomment-534651933:202,Testability,test,testing,202,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
https://github.com/su2code/SU2/pull/724#issuecomment-534651933:57,Usability,simpl,simpler,57,"This is obviously very good work and should make it much simpler to add new outputs etc. My main concern when first reviewing was performance (something no one seems to care about) but from the limited testing I did while merging this and CVariable there seems to be no big impact, I did not time anything though, if you have numbers to share please do.; Nevertheless if you can get away with using unordered_map instead of map it would be better. Possibly part of the reason everyone puts of reviewing this is that it is a major refactoring and yet there are no accompanying notes about the architecture the implementation choices etc. I absolutely guarantee you that is not how professional software is developed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534651933
https://github.com/su2code/SU2/pull/724#issuecomment-534682406:411,Availability,avail,available,411,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
https://github.com/su2code/SU2/pull/724#issuecomment-534682406:452,Availability,down,down,452,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
https://github.com/su2code/SU2/pull/724#issuecomment-534682406:175,Performance,perform,performance,175,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
https://github.com/su2code/SU2/pull/724#issuecomment-534682406:261,Performance,perform,performance,261,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
https://github.com/su2code/SU2/pull/724#issuecomment-534682406:535,Performance,perform,performance,535,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
https://github.com/su2code/SU2/pull/724#issuecomment-534682406:613,Performance,bottleneck,bottleneck,613,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
https://github.com/su2code/SU2/pull/724#issuecomment-534682406:725,Usability,clear,clearing,725,"I know that it can be frustrating sometimes operating within the constraints of an open-source project such as ours. However, I can assure you that folks do indeed care about performance, and sometimes I have the impression that we stress over relatively small performance issues (remember to keep the total pie chart of where the major work of the solver resides in mind). . The option WRT_PERFORMANCE= YES is available to get timings for runs broken down by preprocessing, compute, and output phases, and I think we should focus our performance concerns first on issues within the compute phase, unless a major bottleneck appears in the other two phases that completely prohibits us from running larger cases (we have been clearing many of those out lately). We do not have the resources of a professional software company, but what we do have is a great community of folks who are putting in lots of effort on a volunteer basis. @pcarruscag: your reviews have been very helpful for improving contributions - thank you for that effort. Let's keep supporting each other, but let's also make sure we stay positive and foster a welcoming environment to encourage more participation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534682406
https://github.com/su2code/SU2/pull/724#issuecomment-534720511:39,Usability,feedback,feedback,39,"I understand your frustration, and the feedback is helpful. Encouraging more participation in Issues and PRs is very important for us. We are still learning and improving our processes. A good metric for us to increase in the project is the total number of *different* people submitting/participating in PRs/Issues (not the total number of comments from just a handful). The best way to scale is to have the work evenly distributed among many folks, rather than just a handful processing the PRs. This will likely take some time & training, but I expect we can accomplish it while remaining positive. Open to good ideas there on how to better achieve it. . As for the other topic - I think that our recent move toward draft PRs may help with describing design decisions. This will also take some time to be adopted, and may or may not reach the depth necessary in the descriptions, but it is a good first step so that we can see things progress in real time. Using the project boards to list tasks and post comments is also helpful (but takes more effort). Open to ideas there too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534720511
https://github.com/su2code/SU2/pull/724#issuecomment-534720511:148,Usability,learn,learning,148,"I understand your frustration, and the feedback is helpful. Encouraging more participation in Issues and PRs is very important for us. We are still learning and improving our processes. A good metric for us to increase in the project is the total number of *different* people submitting/participating in PRs/Issues (not the total number of comments from just a handful). The best way to scale is to have the work evenly distributed among many folks, rather than just a handful processing the PRs. This will likely take some time & training, but I expect we can accomplish it while remaining positive. Open to good ideas there on how to better achieve it. . As for the other topic - I think that our recent move toward draft PRs may help with describing design decisions. This will also take some time to be adopted, and may or may not reach the depth necessary in the descriptions, but it is a good first step so that we can see things progress in real time. Using the project boards to list tasks and post comments is also helpful (but takes more effort). Open to ideas there too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-534720511
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:141,Integrability,rout,routines,141,"Here are some numbers regarding the performance. I used an unsteady 3D case with 83425 points. I took the extreme case of calling the output routines every time-step and only 5 inner iterations. For the first run I enabled the writing of restart and tecplot file:; ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6 ; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:1058,Integrability,rout,routine,1058,"mance. I used an unsteady 3D case with 83425 points. I took the extreme case of calling the output routines every time-step and only 5 inner iterations. For the first run I enabled the writing of restart and tecplot file:; ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6 ; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including gathering all data, partitioning and sor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:1165,Integrability,rout,routines,1165,"t routines every time-step and only 5 inner iterations. For the first run I enabled the writing of restart and tecplot file:; ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6 ; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including gathering all data, partitioning and sorting) just takes 0.7% of the overall time. Its not nothing, but roughly one order of magnitude sma",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:1982,Integrability,rout,routines,1982,"; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including gathering all data, partitioning and sorting) just takes 0.7% of the overall time. Its not nothing, but roughly one order of magnitude smaller than one iteration of the solver. . I also compared it to the current develop using callgrind on a similar case and for both versions the number of instructions in the output routines is roughly the same (~1.5% of the total number instructions).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:2320,Integrability,rout,routines,2320,"; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including gathering all data, partitioning and sorting) just takes 0.7% of the overall time. Its not nothing, but roughly one order of magnitude smaller than one iteration of the solver. . I also compared it to the current develop using callgrind on a similar case and for both versions the number of instructions in the output routines is roughly the same (~1.5% of the total number instructions).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:36,Performance,perform,performance,36,"Here are some numbers regarding the performance. I used an unsteady 3D case with 83425 points. I took the extreme case of calling the output routines every time-step and only 5 inner iterations. For the first run I enabled the writing of restart and tecplot file:; ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6 ; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:297,Performance,Perform,Performance,297,"Here are some numbers regarding the performance. I used an unsteady 3D case with 83425 points. I took the extreme case of calling the output routines every time-step and only 5 inner iterations. For the first run I enabled the writing of restart and tecplot file:; ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6 ; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535018704:1246,Performance,Perform,Performance,1246,"---------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6 ; Points/core: 10428.1 | Ghost points/core: 2045.25 ; Wall-clock time (hrs): 0.153299 | Core-hrs: 1.22639 . Preprocessing phase:; Preproc. Time (s): 2.69291 | Preproc. Time (%): 0.487956 . Compute phase:; Compute Time (s): 385.71 | Compute Time (%): 69.8909 ; Iteration count: 560 | Avg. s/iter: 0.688769 ; Core-s/iter/Mpoints: 55.2191 | Mpoints/s: 0.144877 . Output phase:; Output Time (s): 163.472 | Output Time (%): 29.6211 ; Output count: 112 | Avg. s/output: 1.45957 ; -------------------------------------------------------------------------; ```; Note that the iteration count is the total number of all inner iterations. 30% of the time is spend in the output routine. That may sound like a lot, but lets take a look at the second case, where I still call the output routines, but disabled the writing of any files. ```; -------------------------- Performance Summary --------------------------; Simulation totals:; Cores: 8 | DOFs/point: 6; Points/core: 10428.1 | Ghost points/core: 2045.25; Wall-clock time (hrs): 0.112822 | Core-hrs: 0.902578. Preprocessing phase:; Preproc. Time (s): 3.84826 | Preproc. Time (%): 0.947474. Compute phase:; Compute Time (s): 399.446 | Compute Time (%): 98.347; Iteration count: 560 | Avg. s/iter: 0.713297; Core-s/iter/Mpoints: 57.1855 | Mpoints/s: 0.139896. Output phase:; Output Time (s): 2.86557 | Output Time (%): 0.705527; Output count: 112 | Avg. s/output: 0.0255854; Restart Aggr. BW (MB/s): 0 | MB/s/core: 0; -------------------------------------------------------------------------; ``` ; You can see that now the time spend in the output routines (including gathering all data, partitioning and sorting) just takes 0.7% of the overall time. Its not nothing, but roughly one order of magnitude smaller than one iteration of the solver. . I also compared it to the current develop using callgrind on a similar case and for both versions the num",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535018704
https://github.com/su2code/SU2/pull/724#issuecomment-535044389:56,Energy Efficiency,allocate,allocated,56,And a comment on memory: buffers for the output are now allocated once at the beginning and the overall peak memory consumption has been reduced compared to develop.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535044389
https://github.com/su2code/SU2/pull/724#issuecomment-535044389:116,Energy Efficiency,consumption,consumption,116,And a comment on memory: buffers for the output are now allocated once at the beginning and the overall peak memory consumption has been reduced compared to develop.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535044389
https://github.com/su2code/SU2/pull/724#issuecomment-535044389:137,Energy Efficiency,reduce,reduced,137,And a comment on memory: buffers for the output are now allocated once at the beginning and the overall peak memory consumption has been reduced compared to develop.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535044389
https://github.com/su2code/SU2/pull/724#issuecomment-535429251:99,Modifiability,config,config,99,"Just as a hint: To print a list of all possible output fields, use the `-d` flag, i.e. `SU2_CFD -d config.cfg`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-535429251
https://github.com/su2code/SU2/pull/724#issuecomment-536735942:127,Performance,optimiz,optimizations,127,"There are a couple of small tweaks that need to be made to the python scripts to make sure the changes I pushed for multipoint optimizations work with this new output structure. There are also a few changes that need to be made to make sure that at the end of the fixed CL mode, the code outputs the flow state before the finite-differencing takes place. . It might be easiest if I make those changes and push them. Would that be a hassle? Should I just comment on the code and let you make the changes?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-536735942
https://github.com/su2code/SU2/pull/724#issuecomment-536924652:129,Performance,optimiz,optimizations,129,"> There are a couple of small tweaks that need to be made to the python scripts to make sure the changes I pushed for multipoint optimizations work with this new output structure. There are also a few changes that need to be made to make sure that at the end of the fixed CL mode, the code outputs the flow state before the finite-differencing takes place.; > ; > It might be easiest if I make those changes and push them. Would that be a hassle? Should I just comment on the code and let you make the changes?. Seems like you merged this one already in #780, then modify it there I would say.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-536924652
https://github.com/su2code/SU2/pull/724#issuecomment-537543417:81,Testability,Test,TestCases,81,"The .travis.yml file is currently cloning the feature_input_output branch of the TestCases and the Tutorials folders. Should those branches be merged with develop in their respective repos? And consequently, should the .travis.yml file be changed to point to the develop branches?. I ask because I am going to have to do something similar for #780 and I am not sure what the process for doing that would be.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-537543417
https://github.com/su2code/SU2/pull/724#issuecomment-537548522:220,Testability,Test,TestCases,220,"That is the process I followed so far. Jayant Mukhopadhaya <notifications@github.com> escreveu no dia quarta,; 2/10/2019 à(s) 16:20:. > The .travis.yml file is currently cloning the feature_input_output branch; > of the TestCases and the Tutorials folders. Should those branches be merged; > with develop in their respective repos? And consequently, should the; > .travis.yml file be changed to point to the develop branches?; >; > I ask because I am going to have to do something similar for #780; > <https://github.com/su2code/SU2/pull/780> and I am not sure what the; > process for doing that would be.; >; > —; > You are receiving this because you modified the open/close state.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/724?email_source=notifications&email_token=AJCOXN42AZJMAB5I3M7S5GDQMS33HA5CNFSM4H4D5RW2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEAFEF6I#issuecomment-537543417>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AJCOXN2S57FMOMAZNXV2ERTQMS33HANCNFSM4H4D5RWQ>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-537548522
https://github.com/su2code/SU2/pull/724#issuecomment-538361577:207,Modifiability,config,config,207,"@pcarruscag Yes, completely forgot about this. I can probably bring the functionality back in without using or waiting for #774 to make the regression test pass. I'll talk to @rsanfer next week to split the config files into the new multi-zone format.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-538361577
https://github.com/su2code/SU2/pull/724#issuecomment-538361577:151,Testability,test,test,151,"@pcarruscag Yes, completely forgot about this. I can probably bring the functionality back in without using or waiting for #774 to make the regression test pass. I'll talk to @rsanfer next week to split the config files into the new multi-zone format.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/724#issuecomment-538361577
https://github.com/su2code/SU2/pull/726#issuecomment-509334996:231,Availability,error,error,231,"Thanks @jayantmukho that would be great. If the meshes you have show grid convergence the results should converge to the same values, both ways of computing the fluxes are second order, but hopefully by using consistent fluxes the error constant is smaller.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/726#issuecomment-509334996
https://github.com/su2code/SU2/pull/728#issuecomment-511712751:198,Availability,avail,available,198,The externals/ directory changes are intentional. They correct some issues with CGNS library implementation. Those fixes are now being integrated in the develop branch of CGNS library and should be available in the next fix release around the end of the year.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-511712751
https://github.com/su2code/SU2/pull/728#issuecomment-511712751:135,Deployability,integrat,integrated,135,The externals/ directory changes are intentional. They correct some issues with CGNS library implementation. Those fixes are now being integrated in the develop branch of CGNS library and should be available in the next fix release around the end of the year.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-511712751
https://github.com/su2code/SU2/pull/728#issuecomment-511712751:224,Deployability,release,release,224,The externals/ directory changes are intentional. They correct some issues with CGNS library implementation. Those fixes are now being integrated in the develop branch of CGNS library and should be available in the next fix release around the end of the year.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-511712751
https://github.com/su2code/SU2/pull/728#issuecomment-511712751:135,Integrability,integrat,integrated,135,The externals/ directory changes are intentional. They correct some issues with CGNS library implementation. Those fixes are now being integrated in the develop branch of CGNS library and should be available in the next fix release around the end of the year.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-511712751
https://github.com/su2code/SU2/pull/728#issuecomment-513301555:55,Testability,test,tests,55,It would indeed be good to have better coverage in the tests. I have one or two small cases I will add. @MicK7 : do you have a small mixed-element section case (maybe just a small square and cube)? I only seem to have meshes with sections of a single element type.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-513301555
https://github.com/su2code/SU2/pull/728#issuecomment-514256159:6,Testability,test,testing,6,"Still testing this at scale and expect a couple small changes still, just fyi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-514256159
https://github.com/su2code/SU2/pull/728#issuecomment-515786563:19,Testability,test,testcase,19,Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-515786563
https://github.com/su2code/SU2/pull/728#issuecomment-515786563:120,Testability,test,test,120,Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-515786563
https://github.com/su2code/SU2/pull/728#issuecomment-520532998:126,Integrability,interface,interface,126,"I have started dividing the geometry classes. First, I created a new set of classes for the FVM mesh readers. There is a base interface that should never need to be modified, and the new CGNS reader is the first implementation. I will move the SU2 ASCII to this framework soon. The new class will make it easy to add new readers or even just implement analytic meshes like squares and cubes directly as child classes. I will break off a few more small classes in this PR, since they will be easy to handle, but I will likely wait for after this PR to completely divide CPhysicalGeometry just to be safe.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-520532998
https://github.com/su2code/SU2/pull/728#issuecomment-520532998:598,Safety,safe,safe,598,"I have started dividing the geometry classes. First, I created a new set of classes for the FVM mesh readers. There is a base interface that should never need to be modified, and the new CGNS reader is the first implementation. I will move the SU2 ASCII to this framework soon. The new class will make it easy to add new readers or even just implement analytic meshes like squares and cubes directly as child classes. I will break off a few more small classes in this PR, since they will be easy to handle, but I will likely wait for after this PR to completely divide CPhysicalGeometry just to be safe.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-520532998
https://github.com/su2code/SU2/pull/728#issuecomment-520774819:145,Testability,test,testing,145,@economon Thanks for separating the mesh reader! I think having the possibility to implement analytic meshes can be really beneficial for future testing.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-520774819
https://github.com/su2code/SU2/pull/728#issuecomment-520972324:243,Availability,down,down,243,"That's the idea! We should be aiming for many small classes with as few inputs as possible, so that we can easily unit test them. They should have a single responsibility. Many of our legacy classes are doing too many things and can be broken down into smaller classes, especially geometry, for instance. It will take us time to get there, but we're going in the right direction.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-520972324
https://github.com/su2code/SU2/pull/728#issuecomment-520972324:119,Testability,test,test,119,"That's the idea! We should be aiming for many small classes with as few inputs as possible, so that we can easily unit test them. They should have a single responsibility. Many of our legacy classes are doing too many things and can be broken down into smaller classes, especially geometry, for instance. It will take us time to get there, but we're going in the right direction.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-520972324
https://github.com/su2code/SU2/pull/728#issuecomment-521559088:233,Energy Efficiency,Green,Green,233,"I have added built-in support for 2D rectangular (quad) and 3D box (hexa) meshes, so no mesh file is required. Works in serial and parallel - all partitioning is taken care of for you. For example, if you wanted to run a 65^3 Taylor Green Vortex problem on a triply-periodic box, you could use the following new config options:. ```; MESH_FORMAT= BOX; MESH_BOX_SIZE= 65 65 65; MESH_BOX_LENGTH = 6.283185307179586 6.283185307179586 6.283185307179586; MESH_BOX_OFFSET = 0.0 0.0 0.0; ```. The marker names are ""x_minus"" ""x_plus"" ""y_minus"" ""y_plus"" ""z_minus"" and ""z_plus"" by default.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-521559088
https://github.com/su2code/SU2/pull/728#issuecomment-521559088:312,Modifiability,config,config,312,"I have added built-in support for 2D rectangular (quad) and 3D box (hexa) meshes, so no mesh file is required. Works in serial and parallel - all partitioning is taken care of for you. For example, if you wanted to run a 65^3 Taylor Green Vortex problem on a triply-periodic box, you could use the following new config options:. ```; MESH_FORMAT= BOX; MESH_BOX_SIZE= 65 65 65; MESH_BOX_LENGTH = 6.283185307179586 6.283185307179586 6.283185307179586; MESH_BOX_OFFSET = 0.0 0.0 0.0; ```. The marker names are ""x_minus"" ""x_plus"" ""y_minus"" ""y_plus"" ""z_minus"" and ""z_plus"" by default.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-521559088
https://github.com/su2code/SU2/pull/728#issuecomment-523804120:175,Testability,test,test,175,Happy to report that with this branch it is now possible to run a calculation with over 1 billion grid points. I ran freestream through a 1029^3 hexa CGNS grid of a cube as a test.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-523804120
https://github.com/su2code/SU2/pull/728#issuecomment-524179517:73,Integrability,rout,routines,73,"@Mick7: yep, I’ll look at that next. You may have noticed that the other routines for Loading and preparing adjacency are now general for any mesh reader, so all we need is to move the reader for the ASCII format into its own class. . @pcarruscag: there is at least one simple stretching function I have in some old code I can put in. Other elements would also be nice. It’s easy to cut the quads into tris (I have the same implementation for this in a python script) and hexas into tets. Might wait for a compelling need to add these features though, but I have no doubt we’ll add them",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-524179517
https://github.com/su2code/SU2/pull/728#issuecomment-524179517:86,Performance,Load,Loading,86,"@Mick7: yep, I’ll look at that next. You may have noticed that the other routines for Loading and preparing adjacency are now general for any mesh reader, so all we need is to move the reader for the ASCII format into its own class. . @pcarruscag: there is at least one simple stretching function I have in some old code I can put in. Other elements would also be nice. It’s easy to cut the quads into tris (I have the same implementation for this in a python script) and hexas into tets. Might wait for a compelling need to add these features though, but I have no doubt we’ll add them",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-524179517
https://github.com/su2code/SU2/pull/728#issuecomment-524179517:270,Usability,simpl,simple,270,"@Mick7: yep, I’ll look at that next. You may have noticed that the other routines for Loading and preparing adjacency are now general for any mesh reader, so all we need is to move the reader for the ASCII format into its own class. . @pcarruscag: there is at least one simple stretching function I have in some old code I can put in. Other elements would also be nice. It’s easy to cut the quads into tris (I have the same implementation for this in a python script) and hexas into tets. Might wait for a compelling need to add these features though, but I have no doubt we’ll add them",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-524179517
https://github.com/su2code/SU2/pull/728#issuecomment-526073407:294,Deployability,release,release,294,"The native SU2 ASCII mesh reader has been moved to a new class. If everything passes, I would consider this PR complete other than small clean up (like removing Read_SU2_Format_Parallel()). We can save the next pass at dividing the geometry classes, especially CPhysicalGeometry, for after the release.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526073407
https://github.com/su2code/SU2/pull/728#issuecomment-526380290:331,Availability,down,down,331,"> Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements. @MicK7 : does this test work for you? We could consider replacing the existing SU2 mesh with your CGNS mesh for that regression test (that way we keep overhead down by not adding a new test, but get more CGNS coverage).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526380290
https://github.com/su2code/SU2/pull/728#issuecomment-526380290:21,Testability,test,testcase,21,"> Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements. @MicK7 : does this test work for you? We could consider replacing the existing SU2 mesh with your CGNS mesh for that regression test (that way we keep overhead down by not adding a new test, but get more CGNS coverage).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526380290
https://github.com/su2code/SU2/pull/728#issuecomment-526380290:122,Testability,test,test,122,"> Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements. @MicK7 : does this test work for you? We could consider replacing the existing SU2 mesh with your CGNS mesh for that regression test (that way we keep overhead down by not adding a new test, but get more CGNS coverage).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526380290
https://github.com/su2code/SU2/pull/728#issuecomment-526380290:190,Testability,test,test,190,"> Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements. @MicK7 : does this test work for you? We could consider replacing the existing SU2 mesh with your CGNS mesh for that regression test (that way we keep overhead down by not adding a new test, but get more CGNS coverage).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526380290
https://github.com/su2code/SU2/pull/728#issuecomment-526380290:299,Testability,test,test,299,"> Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements. @MicK7 : does this test work for you? We could consider replacing the existing SU2 mesh with your CGNS mesh for that regression test (that way we keep overhead down by not adding a new test, but get more CGNS coverage).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526380290
https://github.com/su2code/SU2/pull/728#issuecomment-526380290:356,Testability,test,test,356,"> Here is a smaller [testcase](https://drive.google.com/open?id=1FK8ijEEh8vbtKEeoqX7Qd0h_yj3U6m7a). It is an existing SU2 test case converted while adding MIXED elements. @MicK7 : does this test work for you? We could consider replacing the existing SU2 mesh with your CGNS mesh for that regression test (that way we keep overhead down by not adding a new test, but get more CGNS coverage).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526380290
https://github.com/su2code/SU2/pull/728#issuecomment-526541234:153,Deployability,update,update,153,@economon can we merge this one soon? It would make reviewing the output changes easier (which already contain this branch).; You and @MicK7 could still update testcases before the release.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526541234
https://github.com/su2code/SU2/pull/728#issuecomment-526541234:181,Deployability,release,release,181,@economon can we merge this one soon? It would make reviewing the output changes easier (which already contain this branch).; You and @MicK7 could still update testcases before the release.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526541234
https://github.com/su2code/SU2/pull/728#issuecomment-526541234:160,Testability,test,testcases,160,@economon can we merge this one soon? It would make reviewing the output changes easier (which already contain this branch).; You and @MicK7 could still update testcases before the release.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526541234
https://github.com/su2code/SU2/pull/728#issuecomment-526586410:131,Availability,error,error,131,"@economon the rotating_cylinder case is running well with CGNS mesh input.; However when it reaches the File output part, I get an error :; *** Error in `/opt/SU2/SU2_CFD': munmap_chunk(): invalid pointer: 0x000000000b547cd0 ***; ======= Backtrace: =========; #0 0x00007ffff66841f7 in raise () from /lib64/libc.so.6; #1 0x00007ffff66858e8 in abort () from /lib64/libc.so.6; #2 0x00007ffff66c3f47 in __libc_message () from /lib64/libc.so.6; #3 0x00007ffff66c9b54 in malloc_printerr () from /lib64/libc.so.6; #4 0x000000000045c95e in COutput::DeallocateConnectivity_Parallel(CConfig*, CGeometry*, bool) (); #5 0x000000000045c41f in COutput::SetResult_Files_Parallel(CSolver*****, CGeometry****, CConfig**, unsigned long, unsigned short) (); #6 0x0000000002191a5f in CMultizoneDriver::Output(unsigned long) (); #7 0x00000000021918b1 in CMultizoneDriver::StartSolver() (); #8 0x0000000001620fe1 in main (). I haven't investigated much but I don't have the problem with the SU2 mesh.; Maybe there is a problem with the surface boundaries in CGNS.; It seems that the parsing of the ZoneBC node to get the FamilyName of the Boundary condition in CGNS is missing since moving to a class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526586410
https://github.com/su2code/SU2/pull/728#issuecomment-526586410:144,Availability,Error,Error,144,"@economon the rotating_cylinder case is running well with CGNS mesh input.; However when it reaches the File output part, I get an error :; *** Error in `/opt/SU2/SU2_CFD': munmap_chunk(): invalid pointer: 0x000000000b547cd0 ***; ======= Backtrace: =========; #0 0x00007ffff66841f7 in raise () from /lib64/libc.so.6; #1 0x00007ffff66858e8 in abort () from /lib64/libc.so.6; #2 0x00007ffff66c3f47 in __libc_message () from /lib64/libc.so.6; #3 0x00007ffff66c9b54 in malloc_printerr () from /lib64/libc.so.6; #4 0x000000000045c95e in COutput::DeallocateConnectivity_Parallel(CConfig*, CGeometry*, bool) (); #5 0x000000000045c41f in COutput::SetResult_Files_Parallel(CSolver*****, CGeometry****, CConfig**, unsigned long, unsigned short) (); #6 0x0000000002191a5f in CMultizoneDriver::Output(unsigned long) (); #7 0x00000000021918b1 in CMultizoneDriver::StartSolver() (); #8 0x0000000001620fe1 in main (). I haven't investigated much but I don't have the problem with the SU2 mesh.; Maybe there is a problem with the surface boundaries in CGNS.; It seems that the parsing of the ZoneBC node to get the FamilyName of the Boundary condition in CGNS is missing since moving to a class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526586410
https://github.com/su2code/SU2/pull/728#issuecomment-526586410:342,Safety,abort,abort,342,"@economon the rotating_cylinder case is running well with CGNS mesh input.; However when it reaches the File output part, I get an error :; *** Error in `/opt/SU2/SU2_CFD': munmap_chunk(): invalid pointer: 0x000000000b547cd0 ***; ======= Backtrace: =========; #0 0x00007ffff66841f7 in raise () from /lib64/libc.so.6; #1 0x00007ffff66858e8 in abort () from /lib64/libc.so.6; #2 0x00007ffff66c3f47 in __libc_message () from /lib64/libc.so.6; #3 0x00007ffff66c9b54 in malloc_printerr () from /lib64/libc.so.6; #4 0x000000000045c95e in COutput::DeallocateConnectivity_Parallel(CConfig*, CGeometry*, bool) (); #5 0x000000000045c41f in COutput::SetResult_Files_Parallel(CSolver*****, CGeometry****, CConfig**, unsigned long, unsigned short) (); #6 0x0000000002191a5f in CMultizoneDriver::Output(unsigned long) (); #7 0x00000000021918b1 in CMultizoneDriver::StartSolver() (); #8 0x0000000001620fe1 in main (). I haven't investigated much but I don't have the problem with the SU2 mesh.; Maybe there is a problem with the surface boundaries in CGNS.; It seems that the parsing of the ZoneBC node to get the FamilyName of the Boundary condition in CGNS is missing since moving to a class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526586410
https://github.com/su2code/SU2/pull/728#issuecomment-526775115:95,Availability,error,error,95,"This has the green light to be merged for me. Taking off the WIP tag. @MicK7 : I have added an error message if a user tries to use a multizone CGNS file for now. It is still possible to run multizone problems by using a separate CGNS single zone file for each zone. Reading multizone CGNS would be a new capability anyway, so I think we should take it out of the critical path and see if we can get it working separately together in the next couple of weeks. That way, we can proceed with merging this and other PRs in the backlog.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526775115
https://github.com/su2code/SU2/pull/728#issuecomment-526775115:13,Energy Efficiency,green,green,13,"This has the green light to be merged for me. Taking off the WIP tag. @MicK7 : I have added an error message if a user tries to use a multizone CGNS file for now. It is still possible to run multizone problems by using a separate CGNS single zone file for each zone. Reading multizone CGNS would be a new capability anyway, so I think we should take it out of the critical path and see if we can get it working separately together in the next couple of weeks. That way, we can proceed with merging this and other PRs in the backlog.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526775115
https://github.com/su2code/SU2/pull/728#issuecomment-526775115:101,Integrability,message,message,101,"This has the green light to be merged for me. Taking off the WIP tag. @MicK7 : I have added an error message if a user tries to use a multizone CGNS file for now. It is still possible to run multizone problems by using a separate CGNS single zone file for each zone. Reading multizone CGNS would be a new capability anyway, so I think we should take it out of the critical path and see if we can get it working separately together in the next couple of weeks. That way, we can proceed with merging this and other PRs in the backlog.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526775115
https://github.com/su2code/SU2/pull/728#issuecomment-526814716:43,Testability,test,testcase,43,"I solved the issue with the multizone cgns testcase. Even if Family of BC are not read (it is a feature that can be implemented later), the testcase works perfectly fine. It means that multizone CGNS reading works great but the issue is with the output of multizone case in WriteParaView_... . Indeed when writing multizone, the ParaView writing function did not behave well with the fact that the second zone of the case use MIXED elements and the last zone only use one type of elements and did not reset all the pointer to the previous zone when writing the last zone. SU2 ended up trying to free element that did not belong to the last zone but to the previous one thus a crash.; Since the output structure is under rewriting, this testcase may be a nice add-on to this branch to ensure that the new output structure work correctly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526814716
https://github.com/su2code/SU2/pull/728#issuecomment-526814716:140,Testability,test,testcase,140,"I solved the issue with the multizone cgns testcase. Even if Family of BC are not read (it is a feature that can be implemented later), the testcase works perfectly fine. It means that multizone CGNS reading works great but the issue is with the output of multizone case in WriteParaView_... . Indeed when writing multizone, the ParaView writing function did not behave well with the fact that the second zone of the case use MIXED elements and the last zone only use one type of elements and did not reset all the pointer to the previous zone when writing the last zone. SU2 ended up trying to free element that did not belong to the last zone but to the previous one thus a crash.; Since the output structure is under rewriting, this testcase may be a nice add-on to this branch to ensure that the new output structure work correctly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526814716
https://github.com/su2code/SU2/pull/728#issuecomment-526814716:736,Testability,test,testcase,736,"I solved the issue with the multizone cgns testcase. Even if Family of BC are not read (it is a feature that can be implemented later), the testcase works perfectly fine. It means that multizone CGNS reading works great but the issue is with the output of multizone case in WriteParaView_... . Indeed when writing multizone, the ParaView writing function did not behave well with the fact that the second zone of the case use MIXED elements and the last zone only use one type of elements and did not reset all the pointer to the previous zone when writing the last zone. SU2 ended up trying to free element that did not belong to the last zone but to the previous one thus a crash.; Since the output structure is under rewriting, this testcase may be a nice add-on to this branch to ensure that the new output structure work correctly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-526814716
https://github.com/su2code/SU2/pull/728#issuecomment-708041917:407,Modifiability,extend,extend,407,"@economon Is this multizone issue with .cgns files are resolved or still under progress? Because I am trying from last 1 week and having issues in running with. cgns file so just wondering is something wrong in code? ; Also as of now I am trying with FEM_LES (cgns) to FEM_LES (cgns) which didnt work, is it possible to run FEM_LES (cgns) with Unsteady RANS or NS (.su2) pair? It will work? My intent is to extend my LES simulation domain for far field analysis. Appreciate your advise!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-708041917
https://github.com/su2code/SU2/pull/728#issuecomment-710182402:41,Availability,error,errors,41,"Hi @monika1387 : at the moment, we throw errors if folks try to use a CGNS mesh that is multi-zone. SU2 currently accepts only single zone, unstructured CGNS files. It is possible to run a multi-zone calculation if you supply two separate single zone CGNS files though, I believe. Is there a particular error you are seeing that you can share? It is very common for vendors to implement CGNS differently, so depending on where you get the file, we may have compatibility issues. If so, feel free to open a new issue with the details.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-710182402
https://github.com/su2code/SU2/pull/728#issuecomment-710182402:303,Availability,error,error,303,"Hi @monika1387 : at the moment, we throw errors if folks try to use a CGNS mesh that is multi-zone. SU2 currently accepts only single zone, unstructured CGNS files. It is possible to run a multi-zone calculation if you supply two separate single zone CGNS files though, I believe. Is there a particular error you are seeing that you can share? It is very common for vendors to implement CGNS differently, so depending on where you get the file, we may have compatibility issues. If so, feel free to open a new issue with the details.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-710182402
https://github.com/su2code/SU2/pull/728#issuecomment-710182402:408,Integrability,depend,depending,408,"Hi @monika1387 : at the moment, we throw errors if folks try to use a CGNS mesh that is multi-zone. SU2 currently accepts only single zone, unstructured CGNS files. It is possible to run a multi-zone calculation if you supply two separate single zone CGNS files though, I believe. Is there a particular error you are seeing that you can share? It is very common for vendors to implement CGNS differently, so depending on where you get the file, we may have compatibility issues. If so, feel free to open a new issue with the details.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-710182402
https://github.com/su2code/SU2/pull/728#issuecomment-711099662:258,Availability,error,error,258,Thank you @economon for comment! Yes I am trying with 2 different cgns mesh in multi zone with FEM_LES solver. I think I will open the issue and you can look into it once. Also attached file here the code for the reference if you can tell me quickly is this error is due to some bug in SU2 or just my cfg specs. [FEL_LES_ERROR.docx](https://github.com/su2code/SU2/files/5396910/FEL_LES_ERROR.docx),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-711099662
https://github.com/su2code/SU2/pull/728#issuecomment-711119949:372,Energy Efficiency,efficient,efficient,372,"Hi @monika1387. Even if the reading of the CGNS file works with multiple zones, the FEM_LES solver does not support this at the moment. It will require significant changes in the data structures to allow for this, although I am also interested in it. However, this is going to be a long term effort, also because we are currently changing the FEM solver to allow for more efficient vectorization.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/728#issuecomment-711119949
https://github.com/su2code/SU2/issues/731#issuecomment-512577363:270,Availability,avail,available,270,"Hi @metuaee<https://github.com/metuaee>, further to @economon, I can add that we are presents working on a branch called NEMO (NonEquilibrium MOdels) that will deal with this type of aspects natively through a proper link with the library Mutation++. We plan to make it available soon through GitHub after some verification and validation steps are finalized.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/731#issuecomment-512577363
https://github.com/su2code/SU2/issues/731#issuecomment-512577363:328,Security,validat,validation,328,"Hi @metuaee<https://github.com/metuaee>, further to @economon, I can add that we are presents working on a branch called NEMO (NonEquilibrium MOdels) that will deal with this type of aspects natively through a proper link with the library Mutation++. We plan to make it available soon through GitHub after some verification and validation steps are finalized.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/731#issuecomment-512577363
https://github.com/su2code/SU2/issues/731#issuecomment-525189226:181,Integrability,rout,routine,181,"Hi all,. I guess the difficulty is about calling Config->GetGamma() function in everywhere in code (solver, numerics etc.). I have to change Gamma according to temperature in every routine and be sure ideal gas equation is consistent between Temperature and Pressure. I get stuck in this point. I am open to any help. Thanks in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/731#issuecomment-525189226
https://github.com/su2code/SU2/issues/731#issuecomment-525189226:49,Modifiability,Config,Config,49,"Hi all,. I guess the difficulty is about calling Config->GetGamma() function in everywhere in code (solver, numerics etc.). I have to change Gamma according to temperature in every routine and be sure ideal gas equation is consistent between Temperature and Pressure. I get stuck in this point. I am open to any help. Thanks in advance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/731#issuecomment-525189226
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:493,Availability,error,error,493,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:245,Integrability,interface,interface,245,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:841,Integrability,interface,interfaces,841,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:50,Performance,optimiz,optimization,50,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:406,Performance,optimiz,optimizer,406,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:596,Performance,optimiz,optimizer,596,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:826,Performance,optimiz,optimizer,826,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:859,Performance,optimiz,optimizers,859,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-520726069:1038,Performance,optimiz,optimizer,1038,"This is a very important topic, @jayantmukho. The optimization functionality is very difficult for folks to get working on their own. There are too many options, and it is not user friendly. We need to improve, and I am open to streamlining the interface if you have some ideas. In general, the bevy of options that you nicely describe above have been added over the years in order to coax the scipy SLSQP optimizer into converging, especially with constraints. It has mostly been a trial-and-error process during that time. Most of the tricks involve getting the scaling set such that the SLSQP optimizer does not take any massively errant steps during its line search that cause divergence. I think it would be great to see a standard normalization of the problem (say, make everything on the order of 1 going in/out of the optimizer) and interfaces to new optimizers (this exists already in part in feature_pyopt). In practice, I use **ONLY** the Scale value in OPT_OBJECTIVE and OPT_CONSTRAINT (set to a value that results in a first optimizer step roughly 10% the characteristic length of my geometry), and ignore the options OPT_GRADIENT_FACTOR, OPT_RELAX_FACTOR, and OPT_LINE_SEARCH_BOUND. I sometimes use the OPT_BOUND_UPPER and OPT_BOUND_LOWER options. But even this approach still requires some manual tuning.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-520726069
https://github.com/su2code/SU2/issues/733#issuecomment-616774814:116,Integrability,depend,dependent,116,"So I've got a more general question: Why do we want the gradient norm to be ~1E-6? Isn't this gradient norm problem dependent? it most definitely scales with the square root of the number of design variables. I would suspect that the relative scales of the design variables are also a factor. Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616774814
https://github.com/su2code/SU2/issues/733#issuecomment-616774814:198,Modifiability,variab,variables,198,"So I've got a more general question: Why do we want the gradient norm to be ~1E-6? Isn't this gradient norm problem dependent? it most definitely scales with the square root of the number of design variables. I would suspect that the relative scales of the design variables are also a factor. Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616774814
https://github.com/su2code/SU2/issues/733#issuecomment-616774814:264,Modifiability,variab,variables,264,"So I've got a more general question: Why do we want the gradient norm to be ~1E-6? Isn't this gradient norm problem dependent? it most definitely scales with the square root of the number of design variables. I would suspect that the relative scales of the design variables are also a factor. Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616774814
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:2007,Availability,robust,robust,2007,"p size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is having a robust solver. If it can handle flow simulations with odd geometries, you need to do less parameter tweaking. The reason you need good scaling is so that the optimizer doesn't explore difficult parts of the design space. If the simulation diverges, the optimization fails. Some intelligent handling of simulation divergences would also help the optimization framework.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:400,Integrability,depend,depending,400,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:506,Modifiability,variab,variables,506,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:73,Performance,optimiz,optimizations,73,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:133,Performance,optimiz,optimization,133,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:331,Performance,optimiz,optimizer,331,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:417,Performance,optimiz,optimization,417,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:770,Performance,optimiz,optimizations,770,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:979,Performance,optimiz,optimization,979,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:1333,Performance,optimiz,optimization,1333,"ne, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is having a robust solver. If it can handle flow simulations with odd geometries, you need to do less parameter tweaking. The reason you need good scaling is so that the optimizer doesn't explore difficult parts of the design space. If the simulation diverges, the optimization fails. Some intelligent handling of simulation divergences would also help the optimiz",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:2165,Performance,optimiz,optimizer,2165,"p size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is having a robust solver. If it can handle flow simulations with odd geometries, you need to do less parameter tweaking. The reason you need good scaling is so that the optimizer doesn't explore difficult parts of the design space. If the simulation diverges, the optimization fails. Some intelligent handling of simulation divergences would also help the optimization framework.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:2260,Performance,optimiz,optimization,2260,"p size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is having a robust solver. If it can handle flow simulations with odd geometries, you need to do less parameter tweaking. The reason you need good scaling is so that the optimizer doesn't explore difficult parts of the design space. If the simulation diverges, the optimization fails. Some intelligent handling of simulation divergences would also help the optimization framework.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:2352,Performance,optimiz,optimization,2352,"p size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is having a robust solver. If it can handle flow simulations with odd geometries, you need to do less parameter tweaking. The reason you need good scaling is so that the optimizer doesn't explore difficult parts of the design space. If the simulation diverges, the optimization fails. Some intelligent handling of simulation divergences would also help the optimization framework.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616810829:672,Testability,test,testing,672,"These are all fantastic questions. I have exclusively used SLSQP for any optimizations that I have run. So, I can only speak to that optimization algorithm. . > Why do we want the gradient norm to be ~1E-6?. Not sure why this is. I agree with what @economon said. These tuning parameters are to coax out an ideal step size for the optimizer. As you can imagine, the ideal step size is wildly varying depending on the optimization objectives/constraints, scales of the geometry, and types/numbers of design variables that are being used. You have to play this game of scaling the objectives and constraints in different ways to coax out the ideal first step. In my limited testing, the value of 1E-6 for the gradient norm seems to work well for 3D RANS aerodynamic shape optimizations of an aircraft wing when using FFD control points to change the shape of the wing. This is a specific use case that was the subject of a lot of the underlying research that resulted in the shape optimization framework. Which is likely why I have had good results using this rule of thumb. . > Is 1E-6 a good rule? Or is it just a decent starting point, and values very different from 1E-6 are used in practice? Also, if this is ""a good rule,"" then shouldn't we just automatically rescale the problem after the first design iteration?. Scaling in an optimization problem can be pretty frustrating and time consuming. Anecdotally, I have been using @economon 's suggestions of leaving everything else as default (value of 1) and only playing with the objective and constraint scalings to get a good first step size. As mentioned before, this step size is of different values for different problems, which is why it is difficult to come up with universal scalings that would work for most problems. But I am hoping to address some of these scaling issues in #923 . . I haven't really found much good literature on this problem, but I might be looking in the wrong places. Recommendations are welcome. . A big boon is hav",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616810829
https://github.com/su2code/SU2/issues/733#issuecomment-616825497:61,Energy Efficiency,efficient,efficiently,61,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
https://github.com/su2code/SU2/issues/733#issuecomment-616825497:41,Performance,optimiz,optimization,41,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
https://github.com/su2code/SU2/issues/733#issuecomment-616825497:390,Performance,optimiz,optimization,390,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
https://github.com/su2code/SU2/issues/733#issuecomment-616825497:592,Usability,clear,clear,592,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
https://github.com/su2code/SU2/issues/733#issuecomment-616825497:809,Usability,clear,clear,809,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
https://github.com/su2code/SU2/issues/733#issuecomment-616825497:902,Usability,clear,clear,902,"I've run into some headaches getting the optimization to run efficiently on my end, which is why I ask. Playing with a toy problem, SLSQP actually does a great job on its own (with all tuning parameters set to 1.0) if the following conditions are met:. + The constraints and bounds effectively bound ""reasonable"" solutions, so you don't have to worry about unrealistic deformations.; + The optimization function is (relatively) convex. If those conditions are met, then playing with any of the tuning parameters makes SLSQP converge more slowly, sometimes with 10x the iterations. So its not clear to me when the tuning parameters are necessary, and how those tuning parameters affect the convergence in those cases. I'm not arguing that the tuning parameters aren't necessary, just that their effects aren't clear. And I agree, the proper way to nondimensionalize and regularize these problems is not clear from a brief search of the literature.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616825497
https://github.com/su2code/SU2/issues/733#issuecomment-616830810:340,Modifiability,variab,variables,340,"Lately I've been playing with Ipopt, which has auto scaling, the documentation (https://coin-or.github.io/Ipopt/OPTIONS.html#OPT_NLP_Scaling) and implementation papers go into decent detail about the strategies they have.; That being said, in the optimizations I've run in the past using L-BFGS-B, I scaled the objectives, constraints, and variables to the [-1, 1] range, and things seemed to work ok, i.e. not excessively long line searches etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616830810
https://github.com/su2code/SU2/issues/733#issuecomment-616830810:247,Performance,optimiz,optimizations,247,"Lately I've been playing with Ipopt, which has auto scaling, the documentation (https://coin-or.github.io/Ipopt/OPTIONS.html#OPT_NLP_Scaling) and implementation papers go into decent detail about the strategies they have.; That being said, in the optimizations I've run in the past using L-BFGS-B, I scaled the objectives, constraints, and variables to the [-1, 1] range, and things seemed to work ok, i.e. not excessively long line searches etc.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616830810
https://github.com/su2code/SU2/issues/733#issuecomment-616833563:51,Modifiability,variab,variables,51,"@pcarruscag When you say that you rescaled all the variables, what do you mean? Using the built-in tuning parameters? Or in the python scripts? And for the deformations (which must have physical values when applied by SU2_DEF), how did you rescale those?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616833563
https://github.com/su2code/SU2/issues/733#issuecomment-616856147:47,Performance,optimiz,optimization,47,"Ah, I forgot to mention I do not use our shape optimization framework (should have started with that). The optimizer ""sees"" y = s_f * f(x'), SU2_** takes as input x, say ffd points, and computes f, say drag, (x' = s_x * x) then dy/dx' = s_f / s_x * df/dx, there is perhaps some equivalence with the tuning parameters we have.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616856147
https://github.com/su2code/SU2/issues/733#issuecomment-616856147:107,Performance,optimiz,optimizer,107,"Ah, I forgot to mention I do not use our shape optimization framework (should have started with that). The optimizer ""sees"" y = s_f * f(x'), SU2_** takes as input x, say ffd points, and computes f, say drag, (x' = s_x * x) then dy/dx' = s_f / s_x * df/dx, there is perhaps some equivalence with the tuning parameters we have.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-616856147
https://github.com/su2code/SU2/issues/733#issuecomment-655044357:35,Deployability,update,updates,35,WIP and I think there will be some updates on tomorrow's developers meeting.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/733#issuecomment-655044357
https://github.com/su2code/SU2/pull/734#issuecomment-516389102:94,Integrability,depend,dependent,94,The case is now also failing in #745. Tested it locally and found that the result is compiler dependent. GCC5.4 and GCC9 give different results.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/734#issuecomment-516389102
https://github.com/su2code/SU2/pull/734#issuecomment-516389102:38,Testability,Test,Tested,38,The case is now also failing in #745. Tested it locally and found that the result is compiler dependent. GCC5.4 and GCC9 give different results.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/734#issuecomment-516389102
https://github.com/su2code/SU2/pull/734#issuecomment-516404815:29,Integrability,message,message,29,Sorry I missed your previous message @talbring.; I imagine this is because of c++11 (which GCC9 might consider by default?); I will test this and come back to you.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/734#issuecomment-516404815
https://github.com/su2code/SU2/pull/734#issuecomment-516404815:132,Testability,test,test,132,Sorry I missed your previous message @talbring.; I imagine this is because of c++11 (which GCC9 might consider by default?); I will test this and come back to you.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/734#issuecomment-516404815
https://github.com/su2code/SU2/pull/734#issuecomment-516469929:14,Deployability,update,update,14,"Fine by me to update reference residuals, since:. - I turned the compiler warnings up to 11 and apart from a lot of name shadowing and ""float == float"" there is no standard-breaking code in those units.; - I've been compiling the code with the c++11 flag for a long time now and never had any issues.; - That is as low as the residuals get and they oscillate more between consecutive iterations than the change you are seeing. ; - The change is smaller than what one gets by using LAPACK instead of the naive matrix multiplication and factorization methods.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/734#issuecomment-516469929
https://github.com/su2code/SU2/issues/735#issuecomment-513311144:61,Availability,down,down,61,Any chance you could run on both branches with SST to narrow down where the bug might be?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513311144
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:740,Deployability,release,released,740,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:92,Testability,log,log,92,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:115,Testability,test,tests,115,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:193,Testability,test,test,193,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:261,Testability,test,tests,261,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:504,Testability,test,tests,504,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:539,Testability,test,test,539,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:684,Testability,test,test,684,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513324305:977,Testability,test,test,977,"I can provide some ideas as to where the change might have occurred. If you look at the git log for the regression tests, you can see every time that someone changed the expected results for a test. Specifically, we can see all the times that the SA regression tests have been changed, which is a necessary (but not sufficient) condition for a significant change in SA results. (It's possible a sneaky change slipped in with a small enough change in residuals so as to not be picked up by the regression tests.). I looked at the following test cases:; + `turb_SA_flatplate`; + `turb_SA_RAE2822`; + `turb_ONERAM6`; + `turb_NACA0012_sa`. I only found one commit where the SA regression test values changed since Feb 18, 2019 (when v6.2.0 was released): fa7ef0a6f0f6a32cd0512f738a1329bdc41ebe00 . That commit was part of PR #657, where a bug in the symmetry boundary condition was fixed. You do have symmetry boundary conditions in your cfg file. Why don't you try re-running the test case with the versions before and after PR #657 was merged?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513324305
https://github.com/su2code/SU2/issues/735#issuecomment-513330011:242,Usability,feedback,feedback,242,"@jayantmukho : The difference is also observed when using SST.; ![rans_cp_compare-branch_roe_SST](https://user-images.githubusercontent.com/9790985/61556955-d372da00-aa17-11e9-9351-5d3505cc85a1.png). @economon and @clarkpede : Thanks for the feedback. @clarkpede , I will re-run using the commit that you pointed and I will post the results here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513330011
https://github.com/su2code/SU2/issues/735#issuecomment-513442969:147,Integrability,rout,routine,147,Maybe this will help.. can you please try setting the viscosity and eddy viscosity inside V_reflected in the if (viscous) {} section of the BC_Sym routine with something like:. ```; /*--- Set laminar and eddy viscosity at the reflected state ---*/. V_reflected[nDim+5] = node[iPoint]->GetLaminarViscosity();; V_reflected[nDim+6] = node[iPoint]->GetEddyViscosity();; ```,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513442969
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:2867,Availability,fault,fault,2867,"t normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](https://github.com/su2code/SU2/files/3417354/SymAsInviscidSlipWall.diff.txt). The implementation of the Symmetry_BC could serve double as 'Inviscid (slip) wall' (which is prescribed in the NASA documents) for viscous flow if the 'Preprocessing' part gets recomputed for each boundary vertex. But how to integrate that best is s.th. to discuss. One could just pull it in at some higher computational cost, put a conditional together with a boolean (e.g. SYMMETRY_AS_SLIP_WALL= YES) or fixing and using MARKER_EULER for that case. I hope that clarifies what happens with that boundary. Please let me know if that works for you and fixes the issue. When I fixed the Regression Testcases for #657 i think that this one was not part of it, right? Maybe this validation case goes into the su2code/VandV repo :) . Cheers,Tobi. Edit: I think we can all agree, that it is Toms fault due to his requested changes in the PR 😉",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:1850,Deployability,patch,patch,1850,"putation/storage of the unit normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](https://github.com/su2code/SU2/files/3417354/SymAsInviscidSlipWall.diff.txt). The implementation of the Symmetry_BC could serve double as 'Inviscid (slip) wall' (which is prescribed in the NASA documents) for viscous flow if the 'Preprocessing' part gets recomputed for each boundary vertex. But how to integrate that best is s.th. to discuss. One could just pull it in at some higher computational cost, put a conditional together with a boolean (e.g. SYMMETRY_AS_SLIP_WALL= YES) or fixing and using MARKER_EULER for that case. I hope that clarifies what happens with that boundary. Please let me know if that works for you and fixes the issue. When I fixed the Regression Testcases for #657 i think that this one was not part of it, right? Maybe this validation case goes into the su2code/VandV repo :) . Cheers,Tobi. Edit: I think we can all agree, that it is Toms fault due to his req",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:1902,Deployability,patch,patch,1902,"putation/storage of the unit normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](https://github.com/su2code/SU2/files/3417354/SymAsInviscidSlipWall.diff.txt). The implementation of the Symmetry_BC could serve double as 'Inviscid (slip) wall' (which is prescribed in the NASA documents) for viscous flow if the 'Preprocessing' part gets recomputed for each boundary vertex. But how to integrate that best is s.th. to discuss. One could just pull it in at some higher computational cost, put a conditional together with a boolean (e.g. SYMMETRY_AS_SLIP_WALL= YES) or fixing and using MARKER_EULER for that case. I hope that clarifies what happens with that boundary. Please let me know if that works for you and fixes the issue. When I fixed the Regression Testcases for #657 i think that this one was not part of it, right? Maybe this validation case goes into the su2code/VandV repo :) . Cheers,Tobi. Edit: I think we can all agree, that it is Toms fault due to his req",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:2302,Deployability,integrat,integrate,2302,"t normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](https://github.com/su2code/SU2/files/3417354/SymAsInviscidSlipWall.diff.txt). The implementation of the Symmetry_BC could serve double as 'Inviscid (slip) wall' (which is prescribed in the NASA documents) for viscous flow if the 'Preprocessing' part gets recomputed for each boundary vertex. But how to integrate that best is s.th. to discuss. One could just pull it in at some higher computational cost, put a conditional together with a boolean (e.g. SYMMETRY_AS_SLIP_WALL= YES) or fixing and using MARKER_EULER for that case. I hope that clarifies what happens with that boundary. Please let me know if that works for you and fixes the issue. When I fixed the Regression Testcases for #657 i think that this one was not part of it, right? Maybe this validation case goes into the su2code/VandV repo :) . Cheers,Tobi. Edit: I think we can all agree, that it is Toms fault due to his requested changes in the PR 😉",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:338,Integrability,rout,routine,338,"Hi Eduardo,. As I wrote #657 here my bits (thanks @economon to notify me about this issue):; The top wall, which is the symmetry wall in your case, is not a straight line (i.e. line in 2D or plane in 3D) but has a bump in it. Therefore I would say the symmetry BC is inappropriate for that geometry/mesh. ; Implementation-wise the BC_sym routine in develop assumes (but not checks) a constant unit normal over all boundary elements in a symmetry marker and I would say that this a necessary condition for a symmetry-marker. . To cite a comment from @economon from that PR #657 . > As we should always have a plane for this BC type, is this [tangent vector computation to the unit normal, Editors note] something you can check outside the loop, or complete as a preprocessing and store? Looks a little expensive to perform at every vertex during runtime. Because of that preprocessed computation/storage of the unit normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](ht",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:2302,Integrability,integrat,integrate,2302,"t normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](https://github.com/su2code/SU2/files/3417354/SymAsInviscidSlipWall.diff.txt). The implementation of the Symmetry_BC could serve double as 'Inviscid (slip) wall' (which is prescribed in the NASA documents) for viscous flow if the 'Preprocessing' part gets recomputed for each boundary vertex. But how to integrate that best is s.th. to discuss. One could just pull it in at some higher computational cost, put a conditional together with a boolean (e.g. SYMMETRY_AS_SLIP_WALL= YES) or fixing and using MARKER_EULER for that case. I hope that clarifies what happens with that boundary. Please let me know if that works for you and fixes the issue. When I fixed the Regression Testcases for #657 i think that this one was not part of it, right? Maybe this validation case goes into the su2code/VandV repo :) . Cheers,Tobi. Edit: I think we can all agree, that it is Toms fault due to his requested changes in the PR 😉",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:814,Performance,perform,perform,814,"Hi Eduardo,. As I wrote #657 here my bits (thanks @economon to notify me about this issue):; The top wall, which is the symmetry wall in your case, is not a straight line (i.e. line in 2D or plane in 3D) but has a bump in it. Therefore I would say the symmetry BC is inappropriate for that geometry/mesh. ; Implementation-wise the BC_sym routine in develop assumes (but not checks) a constant unit normal over all boundary elements in a symmetry marker and I would say that this a necessary condition for a symmetry-marker. . To cite a comment from @economon from that PR #657 . > As we should always have a plane for this BC type, is this [tangent vector computation to the unit normal, Editors note] something you can check outside the loop, or complete as a preprocessing and store? Looks a little expensive to perform at every vertex during runtime. Because of that preprocessed computation/storage of the unit normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](ht",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:2752,Security,validat,validation,2752,"t normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](https://github.com/su2code/SU2/files/3417354/SymAsInviscidSlipWall.diff.txt). The implementation of the Symmetry_BC could serve double as 'Inviscid (slip) wall' (which is prescribed in the NASA documents) for viscous flow if the 'Preprocessing' part gets recomputed for each boundary vertex. But how to integrate that best is s.th. to discuss. One could just pull it in at some higher computational cost, put a conditional together with a boolean (e.g. SYMMETRY_AS_SLIP_WALL= YES) or fixing and using MARKER_EULER for that case. I hope that clarifies what happens with that boundary. Please let me know if that works for you and fixes the issue. When I fixed the Regression Testcases for #657 i think that this one was not part of it, right? Maybe this validation case goes into the su2code/VandV repo :) . Cheers,Tobi. Edit: I think we can all agree, that it is Toms fault due to his requested changes in the PR 😉",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513801538:2673,Testability,Test,Testcases,2673,"t normal (and a tangent to this normal) the current implementation of BC_Sym cannot be ""exploited"" to serve as an ""inviscid (slip) wall"" for non-straight markers. Using `MARKER_EULER= ( sym )` is not correct either as the gradients of the velocity components (used in the viscous stress tensor of the momentum equations) are not computed correctly for the reflected state. Although using MARKER_EULER in the current develop will give you the same results as the master (or older develop before #657 ) with MARKER_SYM (... as it uses the same implementation). If you pull the ""Preprocessing"" part from the develop Sym_BC into the loop over all vertices of the boundary marker, the unit normal (and tangential) gets recomputed for each vertex. That gives you results which should be a lot closer to what happens in the master. Plus handling the velocity gradient correctly. From my point of view this would be the correct way.; Apply this patch in the root of the latest develop code using `patch -p1 < SymAsInviscidSlipWall.diff` to get the code I mean. [SymAsInviscidSlipWall.diff.txt](https://github.com/su2code/SU2/files/3417354/SymAsInviscidSlipWall.diff.txt). The implementation of the Symmetry_BC could serve double as 'Inviscid (slip) wall' (which is prescribed in the NASA documents) for viscous flow if the 'Preprocessing' part gets recomputed for each boundary vertex. But how to integrate that best is s.th. to discuss. One could just pull it in at some higher computational cost, put a conditional together with a boolean (e.g. SYMMETRY_AS_SLIP_WALL= YES) or fixing and using MARKER_EULER for that case. I hope that clarifies what happens with that boundary. Please let me know if that works for you and fixes the issue. When I fixed the Regression Testcases for #657 i think that this one was not part of it, right? Maybe this validation case goes into the su2code/VandV repo :) . Cheers,Tobi. Edit: I think we can all agree, that it is Toms fault due to his requested changes in the PR 😉",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513801538
https://github.com/su2code/SU2/issues/735#issuecomment-513957018:547,Availability,down,downside,547,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
https://github.com/su2code/SU2/issues/735#issuecomment-513957018:285,Deployability,patch,patch,285,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
https://github.com/su2code/SU2/issues/735#issuecomment-513957018:749,Integrability,Depend,Depends,749,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
https://github.com/su2code/SU2/issues/735#issuecomment-513957018:681,Modifiability,extend,extend,681,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
https://github.com/su2code/SU2/issues/735#issuecomment-513957018:133,Usability,clear,clear,133,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
https://github.com/su2code/SU2/issues/735#issuecomment-513957018:251,Usability,simpl,simplest,251,"Hi Eduardo,. both, 'symmetry plane' and 'symmetry as the slip wall' should work in the code (upon fixing this) and it should be made clear (e.g. in the config_template.cfg) what the BC is suitable for, independent of how it is named in the end. ; The simplest solution is probably the patch I provided together with a short note in the config_template (maybe even a reference to this issue), as both 'options' will work as expected (using the very same code). It will basically 'restore' the behaviour of MARKER_SYM of before the fix in #657. The downside is some more computational cost (in case of a plane) which has to be done for each vertex on the marker. I cant say to which extend this takes more time but I would guess it is not too costly. Depends on the case as well. I can do a little check with your case here. . That's it for the diplomatic part :) (Please take the following with a grain). For me a symmetry has to be a line or plane. To cite Jiri Blazek's book 'Computational Fluid Dynamics'(...) 3rd edition using a screenshot:. ![blazekbook](https://user-images.githubusercontent.com/31306376/61662377-9ab05a80-acce-11e9-85bf-5998db204d92.png). The chapter is called 'symmetry plane' which already is kinda biased. But there is no 'slip wall for viscous flow' mentioned to my knowledge. In another book (from Ferziger&Peric, which I only have in german) symmetry is only used in the context of symmetry planes as well. ; To me, symmetry BC's are also linked to visualization using mirroring. And mirroring (as the word is commonly meant) is only possible along planes and its little brother, the straight line. I can be wrong or it might be a question of research background. So how to proceed? Trial by combat might have some unpleasant aftermath for the winner so we might go the democratic way and do a poll :) . Cheers, ; Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513957018
https://github.com/su2code/SU2/issues/735#issuecomment-513959331:68,Modifiability,config,config,68,Hi @TobiKattmann . I am OK if we clearly explain the changes in the config template as my main concern is with the users side.; Thanks!. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513959331
https://github.com/su2code/SU2/issues/735#issuecomment-513959331:33,Usability,clear,clearly,33,Hi @TobiKattmann . I am OK if we clearly explain the changes in the config template as my main concern is with the users side.; Thanks!. Eduardo,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-513959331
https://github.com/su2code/SU2/issues/735#issuecomment-514034313:49,Availability,error,error-prone,49,"I am also mostly concerned with making this less error-prone for the user, which means we should put in an error check or force a proper behavior. . Since the Euler bc does not have the viscous terms, maybe we can throw an error if folks try to use it with viscous problems for slip walls and require the Sym bc in that case (with the patch above). What do you both think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514034313
https://github.com/su2code/SU2/issues/735#issuecomment-514034313:107,Availability,error,error,107,"I am also mostly concerned with making this less error-prone for the user, which means we should put in an error check or force a proper behavior. . Since the Euler bc does not have the viscous terms, maybe we can throw an error if folks try to use it with viscous problems for slip walls and require the Sym bc in that case (with the patch above). What do you both think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514034313
https://github.com/su2code/SU2/issues/735#issuecomment-514034313:223,Availability,error,error,223,"I am also mostly concerned with making this less error-prone for the user, which means we should put in an error check or force a proper behavior. . Since the Euler bc does not have the viscous terms, maybe we can throw an error if folks try to use it with viscous problems for slip walls and require the Sym bc in that case (with the patch above). What do you both think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514034313
https://github.com/su2code/SU2/issues/735#issuecomment-514034313:335,Deployability,patch,patch,335,"I am also mostly concerned with making this less error-prone for the user, which means we should put in an error check or force a proper behavior. . Since the Euler bc does not have the viscous terms, maybe we can throw an error if folks try to use it with viscous problems for slip walls and require the Sym bc in that case (with the patch above). What do you both think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514034313
https://github.com/su2code/SU2/issues/735#issuecomment-514037801:34,Availability,fault,fault,34,"Oh, and this one is definitely my fault 😀",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514037801
https://github.com/su2code/SU2/issues/735#issuecomment-514969680:235,Availability,error,error,235,"Hello guys, I have a proposal to make some numerical tests automatically compared with standard analytical results, requiring the deviation of specific physical variables to be in an allowable range. So that such numerical result bias error could be detected in time accurately after every time the numerical algorithm changes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514969680
https://github.com/su2code/SU2/issues/735#issuecomment-514969680:161,Modifiability,variab,variables,161,"Hello guys, I have a proposal to make some numerical tests automatically compared with standard analytical results, requiring the deviation of specific physical variables to be in an allowable range. So that such numerical result bias error could be detected in time accurately after every time the numerical algorithm changes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514969680
https://github.com/su2code/SU2/issues/735#issuecomment-514969680:250,Safety,detect,detected,250,"Hello guys, I have a proposal to make some numerical tests automatically compared with standard analytical results, requiring the deviation of specific physical variables to be in an allowable range. So that such numerical result bias error could be detected in time accurately after every time the numerical algorithm changes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514969680
https://github.com/su2code/SU2/issues/735#issuecomment-514969680:53,Testability,test,tests,53,"Hello guys, I have a proposal to make some numerical tests automatically compared with standard analytical results, requiring the deviation of specific physical variables to be in an allowable range. So that such numerical result bias error could be detected in time accurately after every time the numerical algorithm changes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-514969680
https://github.com/su2code/SU2/issues/735#issuecomment-515070095:161,Testability,Test,Testcases,161,"Hi @WenyinWei ,; This is the idea behind https://github.com/su2code/vandv in the future (as far as I understand it) or now pretty much everything that is in the Testcases folder of SU2. . I am not sure if there is a Testcase currently which would catch the current issue. I think that not.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-515070095
https://github.com/su2code/SU2/issues/735#issuecomment-515070095:216,Testability,Test,Testcase,216,"Hi @WenyinWei ,; This is the idea behind https://github.com/su2code/vandv in the future (as far as I understand it) or now pretty much everything that is in the Testcases folder of SU2. . I am not sure if there is a Testcase currently which would catch the current issue. I think that not.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/735#issuecomment-515070095
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:527,Availability,error,errors,527,"GCC doesn’t necessarily come with g++. Does which g++ show anything? If not, try: sudo apt-get install g++. Dave. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1341,Availability,error,error,1341,"ables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1376,Availability,error,error,1376,"install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:95,Deployability,install,install,95,"GCC doesn’t necessarily come with g++. Does which g++ show anything? If not, try: sudo apt-get install g++. Dave. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:393,Deployability,install,install,393,"GCC doesn’t necessarily come with g++. Does which g++ show anything? If not, try: sudo apt-get install g++. Dave. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:879,Deployability,install,install,879,"GCC doesn’t necessarily come with g++. Does which g++ show anything? If not, try: sudo apt-get install g++. Dave. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:899,Deployability,install,install,899,"GCC doesn’t necessarily come with g++. Does which g++ show anything? If not, try: sudo apt-get install g++. Dave. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1480,Deployability,install,installed,1480," failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HFS5T4HH2MWIC4JR4TQAXH4ZANCNFS",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:574,Modifiability,config,configure,574,"GCC doesn’t necessarily come with g++. Does which g++ show anything? If not, try: sudo apt-get install g++. Dave. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1149,Modifiability,variab,variables,1149,"o:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1205,Modifiability,variab,variables,1205," 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on Gi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1330,Modifiability,config,configure,1330,"ables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG4",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1365,Modifiability,config,configure,1365,"install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1428,Modifiability,config,config,1428,"container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notificatio",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1947,Modifiability,config,config,1947,"compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HFS5T4HH2MWIC4JR4TQAXH4ZANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:2009,Modifiability,config,config,2009,"compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HFS5T4HH2MWIC4JR4TQAXH4ZANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:2065,Modifiability,config,config,2065,"compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HFS5T4HH2MWIC4JR4TQAXH4ZANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1219,Performance,cache,cached,1219,"eply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/S",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:984,Safety,safe,safe,984,"GCC doesn’t necessarily come with g++. Does which g++ show anything? If not, try: sudo apt-get install g++. Dave. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 8:38 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: [su2code/SU2] C++ compiler cannot create executables (#738). Dear developers,; I am trying to install SU2 in docker ubuntu 18.04 container so that I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1435,Testability,log,log,1435,"I can easily share with partner. But I failed to compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-au",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:1954,Testability,log,log,1954,"compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HFS5T4HH2MWIC4JR4TQAXH4ZANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:2016,Testability,log,log,2016,"compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HFS5T4HH2MWIC4JR4TQAXH4ZANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847308:2072,Testability,log,log,2072,"compile the code with following errors:. (base) root@a5502ebdff64:/home/SU2# ./configure --prefix=/home/SU2/SU2_Install CXXFLAGS=""-O3"" --enable-mpi --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx. checking build system type... x86_64-pc-linux-gnu. checking host system type... x86_64-pc-linux-gnu. checking target system type... x86_64-pc-linux-gnu. checking for a BSD-compatible install... /usr/bin/install -c. checking whether build environment is sane... yes. checking for a thread-safe mkdir -p... /bin/mkdir -p. checking for gawk... no. checking for mawk... mawk. checking whether make sets $(MAKE)... yes. checking whether make supports nested variables... yes. checking whether make supports nested variables... (cached) yes. checking for style of include used by make... GNU. checking whether the C++ compiler works... no. configure: error: in `/home/SU2':. configure: error: C++ compiler cannot create executables. See `config.log' for more details. I am sure that I have installed gcc/g++ successfully. You can see. (base) root@a5502ebdff64:/home# gcc --version. gcc (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0. Copyright (C) 2017 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO. warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. (base) root@a5502ebdff64:/home# g++ -o hello hello.cc. (base) root@a5502ebdff64:/home# ./hello. Hello, World!. I have uploaded the config.log file. Could you give me some suggestions, please?; config.log<https://github.com/su2code/SU2/files/3418183/config.log>. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HBFP42OXAJCIZGTH2DQAXH4ZA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFUVEXG43VMWVGG33NNVSW45C7NFSM4HAVNCNA>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HFS5T4HH2MWIC4JR4TQAXH4ZANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847308
https://github.com/su2code/SU2/issues/738#issuecomment-513847853:16,Deployability,install,installed,16,"Yes. I did have installed g++.; ```; (base) root@a5502ebdff64:/home# g++ --version; g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0; Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```; ```; (base) root@a5502ebdff64:/home/SU2# apt-get install gcc g++; Reading package lists... Done; Building dependency tree ; Reading state information... Done; g++ is already the newest version (4:7.4.0-1ubuntu2.3).; gcc is already the newest version (4:7.4.0-1ubuntu2.3).; 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847853
https://github.com/su2code/SU2/issues/738#issuecomment-513847853:384,Deployability,install,install,384,"Yes. I did have installed g++.; ```; (base) root@a5502ebdff64:/home# g++ --version; g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0; Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```; ```; (base) root@a5502ebdff64:/home/SU2# apt-get install gcc g++; Reading package lists... Done; Building dependency tree ; Reading state information... Done; g++ is already the newest version (4:7.4.0-1ubuntu2.3).; gcc is already the newest version (4:7.4.0-1ubuntu2.3).; 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847853
https://github.com/su2code/SU2/issues/738#issuecomment-513847853:610,Deployability,upgrade,upgraded,610,"Yes. I did have installed g++.; ```; (base) root@a5502ebdff64:/home# g++ --version; g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0; Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```; ```; (base) root@a5502ebdff64:/home/SU2# apt-get install gcc g++; Reading package lists... Done; Building dependency tree ; Reading state information... Done; g++ is already the newest version (4:7.4.0-1ubuntu2.3).; gcc is already the newest version (4:7.4.0-1ubuntu2.3).; 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847853
https://github.com/su2code/SU2/issues/738#issuecomment-513847853:628,Deployability,install,installed,628,"Yes. I did have installed g++.; ```; (base) root@a5502ebdff64:/home# g++ --version; g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0; Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```; ```; (base) root@a5502ebdff64:/home/SU2# apt-get install gcc g++; Reading package lists... Done; Building dependency tree ; Reading state information... Done; g++ is already the newest version (4:7.4.0-1ubuntu2.3).; gcc is already the newest version (4:7.4.0-1ubuntu2.3).; 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847853
https://github.com/su2code/SU2/issues/738#issuecomment-513847853:661,Deployability,upgrade,upgraded,661,"Yes. I did have installed g++.; ```; (base) root@a5502ebdff64:/home# g++ --version; g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0; Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```; ```; (base) root@a5502ebdff64:/home/SU2# apt-get install gcc g++; Reading package lists... Done; Building dependency tree ; Reading state information... Done; g++ is already the newest version (4:7.4.0-1ubuntu2.3).; gcc is already the newest version (4:7.4.0-1ubuntu2.3).; 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847853
https://github.com/su2code/SU2/issues/738#issuecomment-513847853:441,Integrability,depend,dependency,441,"Yes. I did have installed g++.; ```; (base) root@a5502ebdff64:/home# g++ --version; g++ (Ubuntu 7.4.0-1ubuntu1~18.04.1) 7.4.0; Copyright (C) 2017 Free Software Foundation, Inc.; This is free software; see the source for copying conditions. There is NO; warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.; ```; ```; (base) root@a5502ebdff64:/home/SU2# apt-get install gcc g++; Reading package lists... Done; Building dependency tree ; Reading state information... Done; g++ is already the newest version (4:7.4.0-1ubuntu2.3).; gcc is already the newest version (4:7.4.0-1ubuntu2.3).; 0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513847853
https://github.com/su2code/SU2/issues/738#issuecomment-513848082:86,Deployability,install,installed,86,"What about mpicc and mpicxx? You are trying to build a parallel executable, so is MPI installed?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513848082
https://github.com/su2code/SU2/issues/738#issuecomment-513848580:2,Deployability,install,install,2,I install OpenMPI following the [instructions](https://ubuntu.pkgs.org/18.04/ubuntu-universe-amd64/openmpi-bin_2.1.1-8_amd64.deb.html) with commands:; ```; root@d929b0ec33cb:/home# apt-get update; root@d929b0ec33cb:/home# apt-get install openmpi-bin; ```; and I can see the version; ```; root@d929b0ec33cb:/home# mpirun --version; mpirun (Open MPI) 2.1.1. Report bugs to http://www.open-mpi.org/community/help/; ```,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513848580
https://github.com/su2code/SU2/issues/738#issuecomment-513848580:189,Deployability,update,update,189,I install OpenMPI following the [instructions](https://ubuntu.pkgs.org/18.04/ubuntu-universe-amd64/openmpi-bin_2.1.1-8_amd64.deb.html) with commands:; ```; root@d929b0ec33cb:/home# apt-get update; root@d929b0ec33cb:/home# apt-get install openmpi-bin; ```; and I can see the version; ```; root@d929b0ec33cb:/home# mpirun --version; mpirun (Open MPI) 2.1.1. Report bugs to http://www.open-mpi.org/community/help/; ```,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513848580
https://github.com/su2code/SU2/issues/738#issuecomment-513848580:230,Deployability,install,install,230,I install OpenMPI following the [instructions](https://ubuntu.pkgs.org/18.04/ubuntu-universe-amd64/openmpi-bin_2.1.1-8_amd64.deb.html) with commands:; ```; root@d929b0ec33cb:/home# apt-get update; root@d929b0ec33cb:/home# apt-get install openmpi-bin; ```; and I can see the version; ```; root@d929b0ec33cb:/home# mpirun --version; mpirun (Open MPI) 2.1.1. Report bugs to http://www.open-mpi.org/community/help/; ```,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513848580
https://github.com/su2code/SU2/issues/738#issuecomment-513849210:50,Deployability,install,installed,50,"Are the compiler wrappers, mpicc and mpicxx, also installed? When I look in your log file it mentions ; ./configure: line 3362: /usr/bin/mpicxx: No such file or directory",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513849210
https://github.com/su2code/SU2/issues/738#issuecomment-513849210:17,Integrability,wrap,wrappers,17,"Are the compiler wrappers, mpicc and mpicxx, also installed? When I look in your log file it mentions ; ./configure: line 3362: /usr/bin/mpicxx: No such file or directory",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513849210
https://github.com/su2code/SU2/issues/738#issuecomment-513849210:106,Modifiability,config,configure,106,"Are the compiler wrappers, mpicc and mpicxx, also installed? When I look in your log file it mentions ; ./configure: line 3362: /usr/bin/mpicxx: No such file or directory",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513849210
https://github.com/su2code/SU2/issues/738#issuecomment-513849210:81,Testability,log,log,81,"Are the compiler wrappers, mpicc and mpicxx, also installed? When I look in your log file it mentions ; ./configure: line 3362: /usr/bin/mpicxx: No such file or directory",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513849210
https://github.com/su2code/SU2/issues/738#issuecomment-513849861:176,Deployability,update,update,176,"Below you can find the steps I used to build a singularity container using ubuntu 19.04. For pure docker and ubuntu 18.04 the steps should be the same I guess. ```; apt-get -y update; apt-get -y install python3 git build-essential autoconf python-dev libopenmpi3 openmpi-common; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python3 preconfigure.py --enable-mpi --prefix=$PWD; make install -j20; make clean; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513849861
https://github.com/su2code/SU2/issues/738#issuecomment-513849861:195,Deployability,install,install,195,"Below you can find the steps I used to build a singularity container using ubuntu 19.04. For pure docker and ubuntu 18.04 the steps should be the same I guess. ```; apt-get -y update; apt-get -y install python3 git build-essential autoconf python-dev libopenmpi3 openmpi-common; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python3 preconfigure.py --enable-mpi --prefix=$PWD; make install -j20; make clean; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513849861
https://github.com/su2code/SU2/issues/738#issuecomment-513849861:434,Deployability,install,install,434,"Below you can find the steps I used to build a singularity container using ubuntu 19.04. For pure docker and ubuntu 18.04 the steps should be the same I guess. ```; apt-get -y update; apt-get -y install python3 git build-essential autoconf python-dev libopenmpi3 openmpi-common; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python3 preconfigure.py --enable-mpi --prefix=$PWD; make install -j20; make clean; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513849861
https://github.com/su2code/SU2/issues/738#issuecomment-513850317:40,Deployability,install,installed,40,"Sorry. Do you mean that although I have installed OpenMPI, I still have to install mpicc and mpicxx ? I am not familiar with such problems. ; When I run `which mpicc` and `which mpicxx` in the container, there is no outputs. But on the host machine, I can see `/usr/bin/mpicc` and `/usr/bin/mpicxx`. Maybe this the reason.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513850317
https://github.com/su2code/SU2/issues/738#issuecomment-513850317:75,Deployability,install,install,75,"Sorry. Do you mean that although I have installed OpenMPI, I still have to install mpicc and mpicxx ? I am not familiar with such problems. ; When I run `which mpicc` and `which mpicxx` in the container, there is no outputs. But on the host machine, I can see `/usr/bin/mpicc` and `/usr/bin/mpicxx`. Maybe this the reason.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513850317
https://github.com/su2code/SU2/issues/738#issuecomment-513851975:363,Deployability,install,installed,363,"Those would come from package openmpi-dev. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 9:13 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Dave Taflin <d.taflin@tecplot.com>; Comment <comment@noreply.github.com>; Subject: Re: [su2code/SU2] C++ compiler cannot create executables (#738). Sorry. Do you mean that although I have installed OpenMPI, I still have to install mpicc and mpicxx ? I am not familiar with such problems.; When I run which mpicc and which mpicxx in the container, there is no outputs. But on the host machine, I can see /usr/bin/mpicc and /usr/bin/mpicxx. Maybe this the reason. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HHQUIUX3M4FOVSIWTTQAXL7JA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2QLXTI#issuecomment-513850317>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HGXH2W6SXJCN4OLCXLQAXL7JANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513851975
https://github.com/su2code/SU2/issues/738#issuecomment-513851975:398,Deployability,install,install,398,"Those would come from package openmpi-dev. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 9:13 AM; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Dave Taflin <d.taflin@tecplot.com>; Comment <comment@noreply.github.com>; Subject: Re: [su2code/SU2] C++ compiler cannot create executables (#738). Sorry. Do you mean that although I have installed OpenMPI, I still have to install mpicc and mpicxx ? I am not familiar with such problems.; When I run which mpicc and which mpicxx in the container, there is no outputs. But on the host machine, I can see /usr/bin/mpicc and /usr/bin/mpicxx. Maybe this the reason. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HHQUIUX3M4FOVSIWTTQAXL7JA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2QLXTI#issuecomment-513850317>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HGXH2W6SXJCN4OLCXLQAXL7JANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513851975
https://github.com/su2code/SU2/issues/738#issuecomment-513852685:736,Deployability,install,installed,736,"…or maybe libopenmpi-dev. From: Dave Taflin; Sent: Monday, July 22, 2019 9:18 AM; To: su2code/SU2 <reply@reply.github.com>; su2code/SU2 <SU2@noreply.github.com>; Cc: Comment <comment@noreply.github.com>; Subject: RE: [su2code/SU2] C++ compiler cannot create executables (#738). Those would come from package openmpi-dev. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 9:13 AM; To: su2code/SU2 <SU2@noreply.github.com<mailto:SU2@noreply.github.com>>; Cc: Dave Taflin <d.taflin@tecplot.com<mailto:d.taflin@tecplot.com>>; Comment <comment@noreply.github.com<mailto:comment@noreply.github.com>>; Subject: Re: [su2code/SU2] C++ compiler cannot create executables (#738). Sorry. Do you mean that although I have installed OpenMPI, I still have to install mpicc and mpicxx ? I am not familiar with such problems.; When I run which mpicc and which mpicxx in the container, there is no outputs. But on the host machine, I can see /usr/bin/mpicc and /usr/bin/mpicxx. Maybe this the reason. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HHQUIUX3M4FOVSIWTTQAXL7JA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2QLXTI#issuecomment-513850317>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HGXH2W6SXJCN4OLCXLQAXL7JANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513852685
https://github.com/su2code/SU2/issues/738#issuecomment-513852685:771,Deployability,install,install,771,"…or maybe libopenmpi-dev. From: Dave Taflin; Sent: Monday, July 22, 2019 9:18 AM; To: su2code/SU2 <reply@reply.github.com>; su2code/SU2 <SU2@noreply.github.com>; Cc: Comment <comment@noreply.github.com>; Subject: RE: [su2code/SU2] C++ compiler cannot create executables (#738). Those would come from package openmpi-dev. From: thw1021 [mailto:notifications@github.com]; Sent: Monday, July 22, 2019 9:13 AM; To: su2code/SU2 <SU2@noreply.github.com<mailto:SU2@noreply.github.com>>; Cc: Dave Taflin <d.taflin@tecplot.com<mailto:d.taflin@tecplot.com>>; Comment <comment@noreply.github.com<mailto:comment@noreply.github.com>>; Subject: Re: [su2code/SU2] C++ compiler cannot create executables (#738). Sorry. Do you mean that although I have installed OpenMPI, I still have to install mpicc and mpicxx ? I am not familiar with such problems.; When I run which mpicc and which mpicxx in the container, there is no outputs. But on the host machine, I can see /usr/bin/mpicc and /usr/bin/mpicxx. Maybe this the reason. —; You are receiving this because you commented.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/738?email_source=notifications&email_token=AADV2HHQUIUX3M4FOVSIWTTQAXL7JA5CNFSM4IFZ52EKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD2QLXTI#issuecomment-513850317>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AADV2HGXH2W6SXJCN4OLCXLQAXL7JANCNFSM4IFZ52EA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513852685
https://github.com/su2code/SU2/issues/738#issuecomment-513853762:22,Deployability,install,installed,22,Yes. Thank you all. I installed libopenmpi-dev and openmpi-common. I don't know which one is the key but I can see SU2_RUN and SU2_HOME environment variables displayed at the conclusion of configure.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513853762
https://github.com/su2code/SU2/issues/738#issuecomment-513853762:148,Modifiability,variab,variables,148,Yes. Thank you all. I installed libopenmpi-dev and openmpi-common. I don't know which one is the key but I can see SU2_RUN and SU2_HOME environment variables displayed at the conclusion of configure.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513853762
https://github.com/su2code/SU2/issues/738#issuecomment-513853762:189,Modifiability,config,configure,189,Yes. Thank you all. I installed libopenmpi-dev and openmpi-common. I don't know which one is the key but I can see SU2_RUN and SU2_HOME environment variables displayed at the conclusion of configure.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513853762
https://github.com/su2code/SU2/issues/738#issuecomment-513854558:65,Deployability,install,installed,65,Thank you. I will close this issue after I make sure that I have installed successfully.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513854558
https://github.com/su2code/SU2/issues/738#issuecomment-513868405:269,Safety,detect,detected,269,"Thank you all.; When I run the tutorial case with `mpirun`, there are some warnings:; ```; (base) root@a5502ebdff64:/home/SU2_RUN/QuickStart# mpirun -n 24 SU2_CFD inv_NACA0012.cfg ; --------------------------------------------------------------------------; mpirun has detected an attempt to run as root.; Running at root is *strongly* discouraged as any mistake (e.g., in; defining TMPDIR) or bug can result in catastrophic damage to the OS; file system, leaving your system in an unusable state. You can override this protection by adding the --allow-run-as-root; option to your cmd line. However, we reiterate our strong advice; against doing so - please do so at your own risk.; ```; Should I directly ignore such warnings ? Any suggestion would be grateful.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513868405
https://github.com/su2code/SU2/issues/738#issuecomment-513868405:676,Safety,risk,risk,676,"Thank you all.; When I run the tutorial case with `mpirun`, there are some warnings:; ```; (base) root@a5502ebdff64:/home/SU2_RUN/QuickStart# mpirun -n 24 SU2_CFD inv_NACA0012.cfg ; --------------------------------------------------------------------------; mpirun has detected an attempt to run as root.; Running at root is *strongly* discouraged as any mistake (e.g., in; defining TMPDIR) or bug can result in catastrophic damage to the OS; file system, leaving your system in an unusable state. You can override this protection by adding the --allow-run-as-root; option to your cmd line. However, we reiterate our strong advice; against doing so - please do so at your own risk.; ```; Should I directly ignore such warnings ? Any suggestion would be grateful.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513868405
https://github.com/su2code/SU2/issues/738#issuecomment-513871922:115,Deployability,update,update,115,"Here is the full definition file for singularity:. ```; Bootstrap: docker; From: ubuntu:19.04; ; %post; apt-get -y update; apt-get -y install python3 git build-essential autoconf python-dev libopenmpi3 openmpi-common; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python3 preconfigure.py --enable-mpi --prefix=$PWD; make install -j20; make clean; ; %runscript; exec /SU2/bin/$1 $2 ; ```. Store it in file called `su2.def`and run; ```; sudo singularity build su2.sif su2.def; ```. You can then run it like that:. ```; mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg; ```. The only thing to note is that the OpenMPI version you use inside the container and on the machine you want to run it should be similar. I tried it with OpenMPI v3 in the container and OpenMPI v4 outside and it worked.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513871922
https://github.com/su2code/SU2/issues/738#issuecomment-513871922:134,Deployability,install,install,134,"Here is the full definition file for singularity:. ```; Bootstrap: docker; From: ubuntu:19.04; ; %post; apt-get -y update; apt-get -y install python3 git build-essential autoconf python-dev libopenmpi3 openmpi-common; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python3 preconfigure.py --enable-mpi --prefix=$PWD; make install -j20; make clean; ; %runscript; exec /SU2/bin/$1 $2 ; ```. Store it in file called `su2.def`and run; ```; sudo singularity build su2.sif su2.def; ```. You can then run it like that:. ```; mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg; ```. The only thing to note is that the OpenMPI version you use inside the container and on the machine you want to run it should be similar. I tried it with OpenMPI v3 in the container and OpenMPI v4 outside and it worked.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513871922
https://github.com/su2code/SU2/issues/738#issuecomment-513871922:373,Deployability,install,install,373,"Here is the full definition file for singularity:. ```; Bootstrap: docker; From: ubuntu:19.04; ; %post; apt-get -y update; apt-get -y install python3 git build-essential autoconf python-dev libopenmpi3 openmpi-common; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python3 preconfigure.py --enable-mpi --prefix=$PWD; make install -j20; make clean; ; %runscript; exec /SU2/bin/$1 $2 ; ```. Store it in file called `su2.def`and run; ```; sudo singularity build su2.sif su2.def; ```. You can then run it like that:. ```; mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg; ```. The only thing to note is that the OpenMPI version you use inside the container and on the machine you want to run it should be similar. I tried it with OpenMPI v3 in the container and OpenMPI v4 outside and it worked.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/738#issuecomment-513871922
https://github.com/su2code/SU2/issues/739#issuecomment-514085935:336,Availability,down,download,336,"@thw1021 Like I already said in the comment in the other issue https://github.com/su2code/SU2/issues/738#issuecomment-513870126 : No one can give you support when running OpenMPI in a docker container since it is not officially supported. The only suggestion I have is to use singularity. If you want to test it, install it and you can download su2.sif I created here: https://drive.google.com/open?id=1SaZDloevjj8rFDG2x3Lh05nhTuKHakDK",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514085935
https://github.com/su2code/SU2/issues/739#issuecomment-514085935:313,Deployability,install,install,313,"@thw1021 Like I already said in the comment in the other issue https://github.com/su2code/SU2/issues/738#issuecomment-513870126 : No one can give you support when running OpenMPI in a docker container since it is not officially supported. The only suggestion I have is to use singularity. If you want to test it, install it and you can download su2.sif I created here: https://drive.google.com/open?id=1SaZDloevjj8rFDG2x3Lh05nhTuKHakDK",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514085935
https://github.com/su2code/SU2/issues/739#issuecomment-514085935:304,Testability,test,test,304,"@thw1021 Like I already said in the comment in the other issue https://github.com/su2code/SU2/issues/738#issuecomment-513870126 : No one can give you support when running OpenMPI in a docker container since it is not officially supported. The only suggestion I have is to use singularity. If you want to test it, install it and you can download su2.sif I created here: https://drive.google.com/open?id=1SaZDloevjj8rFDG2x3Lh05nhTuKHakDK",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514085935
https://github.com/su2code/SU2/issues/739#issuecomment-514460795:81,Deployability,install,install,81,"@talbring ; Really sorry for troubling you again. I followed your suggestions to install singularity (3.3.0) and use the su2.sif you shared with me. I run `mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg`. It failed to work. see the log file. ; [su2.sif.log](https://github.com/su2code/SU2/files/3424842/su2.sif.log). The reason should be the OpenMPI version. But I also have installed openmpi-4.0.1 and add ; ```; export PATH=$PATH:$HOME/openmpi/bin; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/openmpi/lib; ```; to my `.bashrc` file. But when I run `mpirun --version`, the output is; ```; mpirun (Open MPI) 1.10.2. Report bugs to http://www.open-mpi.org/community/help/; ```. The OS on my computer is ubuntu 16.04. Could you give me some suggestions to solve this problem ? I google for this but failed to find a good way. Best.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514460795
https://github.com/su2code/SU2/issues/739#issuecomment-514460795:374,Deployability,install,installed,374,"@talbring ; Really sorry for troubling you again. I followed your suggestions to install singularity (3.3.0) and use the su2.sif you shared with me. I run `mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg`. It failed to work. see the log file. ; [su2.sif.log](https://github.com/su2code/SU2/files/3424842/su2.sif.log). The reason should be the OpenMPI version. But I also have installed openmpi-4.0.1 and add ; ```; export PATH=$PATH:$HOME/openmpi/bin; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/openmpi/lib; ```; to my `.bashrc` file. But when I run `mpirun --version`, the output is; ```; mpirun (Open MPI) 1.10.2. Report bugs to http://www.open-mpi.org/community/help/; ```. The OS on my computer is ubuntu 16.04. Could you give me some suggestions to solve this problem ? I google for this but failed to find a good way. Best.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514460795
https://github.com/su2code/SU2/issues/739#issuecomment-514460795:231,Testability,log,log,231,"@talbring ; Really sorry for troubling you again. I followed your suggestions to install singularity (3.3.0) and use the su2.sif you shared with me. I run `mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg`. It failed to work. see the log file. ; [su2.sif.log](https://github.com/su2code/SU2/files/3424842/su2.sif.log). The reason should be the OpenMPI version. But I also have installed openmpi-4.0.1 and add ; ```; export PATH=$PATH:$HOME/openmpi/bin; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/openmpi/lib; ```; to my `.bashrc` file. But when I run `mpirun --version`, the output is; ```; mpirun (Open MPI) 1.10.2. Report bugs to http://www.open-mpi.org/community/help/; ```. The OS on my computer is ubuntu 16.04. Could you give me some suggestions to solve this problem ? I google for this but failed to find a good way. Best.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514460795
https://github.com/su2code/SU2/issues/739#issuecomment-514460795:252,Testability,log,log,252,"@talbring ; Really sorry for troubling you again. I followed your suggestions to install singularity (3.3.0) and use the su2.sif you shared with me. I run `mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg`. It failed to work. see the log file. ; [su2.sif.log](https://github.com/su2code/SU2/files/3424842/su2.sif.log). The reason should be the OpenMPI version. But I also have installed openmpi-4.0.1 and add ; ```; export PATH=$PATH:$HOME/openmpi/bin; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/openmpi/lib; ```; to my `.bashrc` file. But when I run `mpirun --version`, the output is; ```; mpirun (Open MPI) 1.10.2. Report bugs to http://www.open-mpi.org/community/help/; ```. The OS on my computer is ubuntu 16.04. Could you give me some suggestions to solve this problem ? I google for this but failed to find a good way. Best.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514460795
https://github.com/su2code/SU2/issues/739#issuecomment-514460795:310,Testability,log,log,310,"@talbring ; Really sorry for troubling you again. I followed your suggestions to install singularity (3.3.0) and use the su2.sif you shared with me. I run `mpirun -n 24 su2.sif SU2_CFD inv_NACA0012.cfg`. It failed to work. see the log file. ; [su2.sif.log](https://github.com/su2code/SU2/files/3424842/su2.sif.log). The reason should be the OpenMPI version. But I also have installed openmpi-4.0.1 and add ; ```; export PATH=$PATH:$HOME/openmpi/bin; export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HOME/openmpi/lib; ```; to my `.bashrc` file. But when I run `mpirun --version`, the output is; ```; mpirun (Open MPI) 1.10.2. Report bugs to http://www.open-mpi.org/community/help/; ```. The OS on my computer is ubuntu 16.04. Could you give me some suggestions to solve this problem ? I google for this but failed to find a good way. Best.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514460795
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:4137,Availability,Error,Error,4137,"e grid nodes.; 10216 interior elements before parallel partitioning.; Executing the partitioning functions.; Building the graph adjacency structure.; Distributing elements across all ranks.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; Calling ParMETIS... graph partitioning complete (1114 edge cuts).; Distributing ParMETIS coloring.; Rebalancing vertices.; Rebalancing volume element connectivity.; Rebalancing markers and surface elements.; 6403 vertices including ghost points. ; 11338 interior elements including halo cells. ; 11338 triangles.; Establishing MPI communication patterns.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERR",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:4371,Availability,Error,Error,4371,"tructure.; Distributing elements across all ranks.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; Calling ParMETIS... graph partitioning complete (1114 edge cuts).; Distributing ParMETIS coloring.; Rebalancing vertices.; Rebalancing volume element connectivity.; Rebalancing markers and surface elements.; 6403 vertices including ghost points. ; 11338 interior elements including halo cells. ; 11338 triangles.; Establishing MPI communication patterns.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:4561,Availability,error,errorcode,4561,"| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; Calling ParMETIS... graph partitioning complete (1114 edge cuts).; Distributing ParMETIS coloring.; Rebalancing vertices.; Rebalancing volume element connectivity.; Rebalancing markers and surface elements.; 6403 vertices including ghost points. ; 11338 interior elements including halo cells. ; 11338 triangles.; Establishing MPI communication patterns.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hong",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:4853,Availability,ERROR,ERROR,4853,"nd surface elements.; 6403 vertices including ghost points. ; 11338 interior elements including halo cells. ; 11338 triangles.; Establishing MPI communication patterns.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/Q",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:4948,Availability,ERROR,ERROR,4948,"; Establishing MPI communication patterns.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5043,Availability,ERROR,ERROR,5043," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5138,Availability,ERROR,ERROR,5138," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5233,Availability,ERROR,ERROR,5233," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5328,Availability,ERROR,ERROR,5328," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5585,Availability,error,error,5585," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:450,Deployability,Release,Release,450,"@talbring ; Yes, it worked. Thank you. However, no `flow.dat` file when it finished. And it seems that I cannot run `SU2_SOL` to get `flow.dat` file. I have tried with three ways, all failed. Could you give me some suggestions, please ?; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ mpirun -n 24 su2.sif SU2_SOL inv_NACA0012.cfg . -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 6.2.0 ""Falcon"" |; | \__ \ |_| |/ / |; | |___/\___//___| Suite (Solution Exporting Code) |; | |; -------------------------------------------------------------------------; | The current SU2 release has been coordinated by the |; | SU2 International Developers Society <www.su2devsociety.org> |; | with selected contributions from the open-source community. |; -------------------------------------------------------------------------; | The main research teams contributing to the current release are: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; | - Prof. Vincent Terrapon's group at the University of Liege. |; | - Prof. Edwin van der Weide's group at the University of Twente. |; | - Lab. of New Concepts in Aeronautics at Tech. Inst. of Aeronautics. |; -------------------------------------------------------------------------; | Copyright 2012-2019, Francisco D. Palacios, Thomas D. Economon, |; | Tim Albring, and the SU2 contributors. |; | |; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:647,Deployability,release,release,647,"@talbring ; Yes, it worked. Thank you. However, no `flow.dat` file when it finished. And it seems that I cannot run `SU2_SOL` to get `flow.dat` file. I have tried with three ways, all failed. Could you give me some suggestions, please ?; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ mpirun -n 24 su2.sif SU2_SOL inv_NACA0012.cfg . -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 6.2.0 ""Falcon"" |; | \__ \ |_| |/ / |; | |___/\___//___| Suite (Solution Exporting Code) |; | |; -------------------------------------------------------------------------; | The current SU2 release has been coordinated by the |; | SU2 International Developers Society <www.su2devsociety.org> |; | with selected contributions from the open-source community. |; -------------------------------------------------------------------------; | The main research teams contributing to the current release are: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; | - Prof. Vincent Terrapon's group at the University of Liege. |; | - Prof. Edwin van der Weide's group at the University of Twente. |; | - Lab. of New Concepts in Aeronautics at Tech. Inst. of Aeronautics. |; -------------------------------------------------------------------------; | Copyright 2012-2019, Francisco D. Palacios, Thomas D. Economon, |; | Tim Albring, and the SU2 contributors. |; | |; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:946,Deployability,release,release,946,"@talbring ; Yes, it worked. Thank you. However, no `flow.dat` file when it finished. And it seems that I cannot run `SU2_SOL` to get `flow.dat` file. I have tried with three ways, all failed. Could you give me some suggestions, please ?; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ mpirun -n 24 su2.sif SU2_SOL inv_NACA0012.cfg . -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 6.2.0 ""Falcon"" |; | \__ \ |_| |/ / |; | |___/\___//___| Suite (Solution Exporting Code) |; | |; -------------------------------------------------------------------------; | The current SU2 release has been coordinated by the |; | SU2 International Developers Society <www.su2devsociety.org> |; | with selected contributions from the open-source community. |; -------------------------------------------------------------------------; | The main research teams contributing to the current release are: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; | - Prof. Vincent Terrapon's group at the University of Liege. |; | - Prof. Edwin van der Weide's group at the University of Twente. |; | - Lab. of New Concepts in Aeronautics at Tech. Inst. of Aeronautics. |; -------------------------------------------------------------------------; | Copyright 2012-2019, Francisco D. Palacios, Thomas D. Economon, |; | Tim Albring, and the SU2 contributors. |; | |; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:4695,Integrability,depend,depending,4695,"e cuts).; Distributing ParMETIS coloring.; Rebalancing vertices.; Rebalancing volume element connectivity.; Rebalancing markers and surface elements.; 6403 vertices including ghost points. ; 11338 interior elements including halo cells. ; 11338 triangles.; Establishing MPI communication patterns.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SO",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5451,Integrability,message,message,5451," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5591,Integrability,message,messages,5591," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:2696,Modifiability,variab,variables,2696,"|; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the hope that it will be useful, |; | but WITHOUT ANY WARRANTY; without even the implied warranty of |; | MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU |; | Lesser General Public License for more details. |; | |; | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points before parallel partitioning.; Performing linear partitioning of the grid nodes.; 10216 interior elements before parallel partitioning.; Executing the partitioning functions.; Building the graph adjacency structure.; Distributing elements across all ranks.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; Calling ParMETIS... graph partitioning complete (1114 edge cuts).; Distr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:2743,Modifiability,Config,Config,2743,"ther |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the hope that it will be useful, |; | but WITHOUT ANY WARRANTY; without even the implied warranty of |; | MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU |; | Lesser General Public License for more details. |; | |; | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points before parallel partitioning.; Performing linear partitioning of the grid nodes.; 10216 interior elements before parallel partitioning.; Executing the partitioning functions.; Building the graph adjacency structure.; Distributing elements across all ranks.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; Calling ParMETIS... graph partitioning complete (1114 edge cuts).; Distributing ParMETIS coloring.; Rebalancing vertices.; Rebalancing volume element connectivity.; Rebalancing markers and surface elements.; 6403 vertices including ghost points. ; 11338 ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:3199,Performance,Perform,Performing,3199,"; | |; | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points before parallel partitioning.; Performing linear partitioning of the grid nodes.; 10216 interior elements before parallel partitioning.; Executing the partitioning functions.; Building the graph adjacency structure.; Distributing elements across all ranks.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; Calling ParMETIS... graph partitioning complete (1114 edge cuts).; Distributing ParMETIS coloring.; Rebalancing vertices.; Rebalancing volume element connectivity.; Rebalancing markers and surface elements.; 6403 vertices including ghost points. ; 11338 interior elements including halo cells. ; 11338 triangles.; Establishing MPI communication patterns.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; ---------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514630913:5482,Safety,abort,abort,5482," Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 17 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] PMIX ERROR: UNREACHABLE in file server/pmix_server.c at line 2079; [hongwei-Workstation:07803] 23 more processes have sent help message help-mpi-api.txt / mpi-abort; [hongwei-Workstation:07803] Set MCA parameter ""orte_base_help_aggregate"" to 0 to see all help / error messages; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif SU2_SOL inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: SU2_SOL: not found; ```; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity shell su2.sif ; Singularity su2.sif:~/SU2_RUN/QuickStart> SU2_SOL inv_NACA0012.cfg ; bash: SU2_SOL: command not found; Singularity su2.sif:~/SU2_RUN/QuickStart>; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514630913
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:3540,Availability,Error,Error,3540," | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; 10216 triangles.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:3774,Availability,Error,Error,3774," | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; 10216 triangles.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:3963,Availability,error,errorcode,3963," | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; 10216 triangles.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:447,Deployability,Release,Release,447,"I found your previous comments : ; ```; %runscript; exec /SU2/bin/$1 $2; ```; So I run `singularity exec su2.sif /SU2/bin/SU2_SOL inv_NACA0012.cfg `, but still failed. `SU2_CFD` can run successfully in this way. So why ？; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif /SU2/bin/SU2_SOL inv_NACA0012.cfg . -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 6.2.0 ""Falcon"" |; | \__ \ |_| |/ / |; | |___/\___//___| Suite (Solution Exporting Code) |; | |; -------------------------------------------------------------------------; | The current SU2 release has been coordinated by the |; | SU2 International Developers Society <www.su2devsociety.org> |; | with selected contributions from the open-source community. |; -------------------------------------------------------------------------; | The main research teams contributing to the current release are: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; | - Prof. Vincent Terrapon's group at the University of Liege. |; | - Prof. Edwin van der Weide's group at the University of Twente. |; | - Lab. of New Concepts in Aeronautics at Tech. Inst. of Aeronautics. |; -------------------------------------------------------------------------; | Copyright 2012-2019, Francisco D. Palacios, Thomas D. Economon, |; | Tim Albring, and the SU2 contributors. |; | |; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the hop",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:644,Deployability,release,release,644,"I found your previous comments : ; ```; %runscript; exec /SU2/bin/$1 $2; ```; So I run `singularity exec su2.sif /SU2/bin/SU2_SOL inv_NACA0012.cfg `, but still failed. `SU2_CFD` can run successfully in this way. So why ？; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif /SU2/bin/SU2_SOL inv_NACA0012.cfg . -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 6.2.0 ""Falcon"" |; | \__ \ |_| |/ / |; | |___/\___//___| Suite (Solution Exporting Code) |; | |; -------------------------------------------------------------------------; | The current SU2 release has been coordinated by the |; | SU2 International Developers Society <www.su2devsociety.org> |; | with selected contributions from the open-source community. |; -------------------------------------------------------------------------; | The main research teams contributing to the current release are: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; | - Prof. Vincent Terrapon's group at the University of Liege. |; | - Prof. Edwin van der Weide's group at the University of Twente. |; | - Lab. of New Concepts in Aeronautics at Tech. Inst. of Aeronautics. |; -------------------------------------------------------------------------; | Copyright 2012-2019, Francisco D. Palacios, Thomas D. Economon, |; | Tim Albring, and the SU2 contributors. |; | |; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the hop",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:943,Deployability,release,release,943,"I found your previous comments : ; ```; %runscript; exec /SU2/bin/$1 $2; ```; So I run `singularity exec su2.sif /SU2/bin/SU2_SOL inv_NACA0012.cfg `, but still failed. `SU2_CFD` can run successfully in this way. So why ？; ```; hongwei@hongwei-Workstation:~/SU2_RUN/QuickStart$ singularity exec su2.sif /SU2/bin/SU2_SOL inv_NACA0012.cfg . -------------------------------------------------------------------------; | ___ _ _ ___ |; | / __| | | |_ ) Release 6.2.0 ""Falcon"" |; | \__ \ |_| |/ / |; | |___/\___//___| Suite (Solution Exporting Code) |; | |; -------------------------------------------------------------------------; | The current SU2 release has been coordinated by the |; | SU2 International Developers Society <www.su2devsociety.org> |; | with selected contributions from the open-source community. |; -------------------------------------------------------------------------; | The main research teams contributing to the current release are: |; | - Prof. Juan J. Alonso's group at Stanford University. |; | - Prof. Piero Colonna's group at Delft University of Technology. |; | - Prof. Nicolas R. Gauger's group at Kaiserslautern U. of Technology. |; | - Prof. Alberto Guardone's group at Polytechnic University of Milan. |; | - Prof. Rafael Palacios' group at Imperial College London. |; | - Prof. Vincent Terrapon's group at the University of Liege. |; | - Prof. Edwin van der Weide's group at the University of Twente. |; | - Lab. of New Concepts in Aeronautics at Tech. Inst. of Aeronautics. |; -------------------------------------------------------------------------; | Copyright 2012-2019, Francisco D. Palacios, Thomas D. Economon, |; | Tim Albring, and the SU2 contributors. |; | |; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the hop",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:4097,Integrability,depend,depending,4097," | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; 10216 triangles.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. --------------------------------------------------------------------------; MPI_ABORT was invoked on rank 0 in communicator MPI_COMM_WORLD; with errorcode 1. NOTE: invoking MPI_ABORT causes Open MPI to kill all MPI processes.; You may or may not see output from other processes, depending on; exactly when Open MPI kills them.; --------------------------------------------------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:2693,Modifiability,variab,variables,2693,"|; | SU2 is free software; you can redistribute it and/or |; | modify it under the terms of the GNU Lesser General Public |; | License as published by the Free Software Foundation; either |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the hope that it will be useful, |; | but WITHOUT ANY WARRANTY; without even the implied warranty of |; | MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU |; | Lesser General Public License for more details. |; | |; | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; 10216 triangles.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to o",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-514653545:2740,Modifiability,Config,Config,2740,"ther |; | version 2.1 of the License, or (at your option) any later version. |; | |; | SU2 is distributed in the hope that it will be useful, |; | but WITHOUT ANY WARRANTY; without even the implied warranty of |; | MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU |; | Lesser General Public License for more details. |; | |; | You should have received a copy of the GNU Lesser General Public |; | License along with SU2. If not, see <http://www.gnu.org/licenses/>. |; -------------------------------------------------------------------------. ------------------------ Physical Case Definition -----------------------; Input mesh file name: mesh_NACA0012_inv.su2. -------------------------- Output Information ---------------------------; The output file format is Tecplot ASCII (.dat).; Flow variables file name: flow. ------------------- Config File Boundary Information --------------------; +-----------------------------------------+; | Marker Type| Marker Name|; +-----------------------------------------+; | Euler wall| airfoil|; +-----------------------------------------+; | Far-field| farfield|; +-----------------------------------------+. ---------------------- Read Grid File Information -----------------------; Two dimensional problem.; 5233 points.; 2 surface markers.; +------------------------------------+; | Index| Marker| Elements|; +------------------------------------+; | 0| airfoil| 200|; | 1| farfield| 50|; +------------------------------------+; 10216 triangles.; Identify vertices.; Storing a mapping from global to local point index. ------------------------- Solution Postprocessing -----------------------. Error in ""void CBaselineSolver::SetOutputVariables(CGeometry*, CConfig*)"": ; -------------------------------------------------------------------------; Unable to open SU2 restart file solution_flow.dat; ------------------------------ Error Exit -------------------------------. -------------------------------------------------------------------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-514653545
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:140,Availability,error,errors,140,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1106,Availability,error,error,1106,"reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %p",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1551,Availability,Error,Error,1551,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1695,Availability,Error,Error,1695,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1826,Availability,Error,Error,1826,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1985,Availability,Error,Error,1985,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:2125,Availability,Error,Error,2125,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:44,Deployability,install,install,44,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:370,Deployability,update,update,370,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:389,Deployability,upgrade,upgrade,389,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:409,Deployability,install,install,409,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:535,Deployability,install,install,535,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:874,Deployability,install,install,874,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:907,Deployability,install,install,907,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1047,Deployability,install,install,1047," your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1925,Deployability,install,install-recursive,1925,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:1966,Deployability,install,install-recursive,1966,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:2070,Deployability,install,install-,2070,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:2107,Deployability,install,install-,2107,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:66,Integrability,wrap,wrapper,66,"@talbring ; Thanks for your help. I want to install SU2 by python wrapper build. So I write a definition file based on yours. However, some errors happened. The reason seems to be python environment. Sorry for troubling you. Could you give me some suggestions, please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515298427:2199,Performance,perform,performing,2199,", please ?. Best. Here is my definition file.; ```; Bootstrap: docker; From: ubuntu:18.04; ; %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e .; ; %runscript; exec /SU2/bin/$1 $2 ; ```; The error is:; ```; make[3]: Entering directory '/SU2/SU2_BASE/SU2_PY/pySU2'; /bin/bash: python: command not found; swig -DHAVE_MPI -Wall -I/usr/include/python3.6m -I/usr/include/python3.6m -I/root/.local/lib/python2.7/site-packages/mpi4py/include -I/mpi4py/include -I/Library/Python/2.7/site-packages/mpi4py/include -outdir ./ -o SU2_APIPYTHON_wrap.cxx -c++ -python /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i ; /SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'; Makefile:532: recipe for target 'SU2_APIPYTHON_wrap.cxx' failed; make[3]: *** [SU2_APIPYTHON_wrap.cxx] Error 1; make[3]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:525: recipe for target 'all' failed; make[2]: *** [all] Error 2; make[2]: Leaving directory '/SU2/SU2_BASE/SU2_PY/pySU2'; Makefile:441: recipe for target 'install-recursive' failed; make[1]: *** [install-recursive] Error 1; make[1]: Leaving directory '/SU2/SU2_BASE'; Makefile:13: recipe for target 'install-SU2_BASE' failed; make: *** [install-SU2_BASE] Error 2; FATAL: failed to execute %post proc: exit status 2; FATAL: While performing build: while running engine: exit status 255; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515298427
https://github.com/su2code/SU2/issues/739#issuecomment-515360878:45,Availability,Error,Error,45,"```/SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'```. Use pip to install mpi4py. PS: just saw you already did that, sorry.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515360878
https://github.com/su2code/SU2/issues/739#issuecomment-515360878:100,Deployability,install,install,100,"```/SU2/SU2_BASE/../SU2_PY/pySU2/pySU2.i:64: Error: Unable to find 'mpi4py/mpi4py.i'```. Use pip to install mpi4py. PS: just saw you already did that, sorry.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515360878
https://github.com/su2code/SU2/issues/739#issuecomment-515362797:29,Deployability,install,install,29,"Thank you. But if use pip to install `mpi4py`, will it have some negative effects if I use python3 combining with SU2 for further research ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515362797
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:108,Deployability,update,update,108,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:127,Deployability,upgrade,upgrade,127,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:147,Deployability,install,install,147,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:295,Deployability,install,install,295,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:338,Deployability,install,install,338,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:677,Deployability,install,install,677,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:710,Deployability,install,install,710,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515364678:850,Deployability,install,install,850,"I build the image using following definition; ```; Bootstrap: docker; From: ubuntu:18.04. %post; apt-get -y update; apt-get -y upgrade; apt-get -y install python3 python3-pip python-dev python-pip git build-essential autoconf openmpi-bin openmpi-common libopenmpi-dev m4 gfortran swig vim; pip3 install mpi4py numpy scipy matplotlib; pip install mpi4py numpy scipy matplotlib; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; mkdir SU2_Install; autoreconf -i; ./bootstrap; export CXXFLAGS=""-O3 -Wall""; python3 preconfigure.py --enable-autodiff --enable-mpi --enable-PY_WRAPPER --with-cc=/usr/bin/mpicc --with-cxx=/usr/bin/mpicxx --prefix=$PWD/SU2_Install; make -j 4 install; make clean; cd ..; pip3 install tensorforce[tf]; git clone https://github.com/tensorforce/tensorforce.git; cd tensorforce/; git checkout major-revision-final; pip3 install -e . %runscript; exec /SU2/bin/$1 $2; ```; But it cannot run; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/QuickStart$ singularity exec su2_tensorforce.sif /SU2/bin/SU2_CFD inv_NACA0012.cfg ; /.singularity.d/actions/exec: 9: exec: /SU2/bin/SU2_CFD: not found; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515364678
https://github.com/su2code/SU2/issues/739#issuecomment-515372015:8,Deployability,install,installing,8,"You are installing it in the folder SU2_install/ according to ""--prefix=$PWD/SU2_Install""; So i think your last line should be:; exec /SU2_Install/bin/$1 $2. However I have no experience with this singularity so i could be wrong.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515372015
https://github.com/su2code/SU2/issues/739#issuecomment-515373129:65,Deployability,install,install,65,"But based on my own experience, I have to use `pip` (python2) to install `mpi4py` so that I can build the image successfully. I want to know if I use python3 for further development, will it be OK ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515373129
https://github.com/su2code/SU2/issues/739#issuecomment-515374119:17,Deployability,install,install,17,You will need to install it for python3 if you plan to use that. So use:; pip3 install mpi4py; or ; python3 -m pip install mpi4py,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515374119
https://github.com/su2code/SU2/issues/739#issuecomment-515374119:79,Deployability,install,install,79,You will need to install it for python3 if you plan to use that. So use:; pip3 install mpi4py; or ; python3 -m pip install mpi4py,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515374119
https://github.com/su2code/SU2/issues/739#issuecomment-515374119:115,Deployability,install,install,115,You will need to install it for python3 if you plan to use that. So use:; pip3 install mpi4py; or ; python3 -m pip install mpi4py,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515374119
https://github.com/su2code/SU2/issues/739#issuecomment-515376266:87,Deployability,update,update,87,"Made it work with this:. ```; Bootstrap: docker; From: ubuntu:19.04. %post; apt-get -y update; apt-get -y install python3 python3-pip git build-essential autoconf python3-dev libopenmpi3 openmpi-common swig; ln -s /usr/bin/python3 /usr/bin/python; python --version; pip3 install mpi4py numpy scipy; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python preconfigure.py --enable-mpi --enable-PY_WRAPPER --prefix=$PWD; make install -j20; make clean. %runscript; exec /SU2/bin/$1 $2; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515376266
https://github.com/su2code/SU2/issues/739#issuecomment-515376266:106,Deployability,install,install,106,"Made it work with this:. ```; Bootstrap: docker; From: ubuntu:19.04. %post; apt-get -y update; apt-get -y install python3 python3-pip git build-essential autoconf python3-dev libopenmpi3 openmpi-common swig; ln -s /usr/bin/python3 /usr/bin/python; python --version; pip3 install mpi4py numpy scipy; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python preconfigure.py --enable-mpi --enable-PY_WRAPPER --prefix=$PWD; make install -j20; make clean. %runscript; exec /SU2/bin/$1 $2; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515376266
https://github.com/su2code/SU2/issues/739#issuecomment-515376266:271,Deployability,install,install,271,"Made it work with this:. ```; Bootstrap: docker; From: ubuntu:19.04. %post; apt-get -y update; apt-get -y install python3 python3-pip git build-essential autoconf python3-dev libopenmpi3 openmpi-common swig; ln -s /usr/bin/python3 /usr/bin/python; python --version; pip3 install mpi4py numpy scipy; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python preconfigure.py --enable-mpi --enable-PY_WRAPPER --prefix=$PWD; make install -j20; make clean. %runscript; exec /SU2/bin/$1 $2; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515376266
https://github.com/su2code/SU2/issues/739#issuecomment-515376266:473,Deployability,install,install,473,"Made it work with this:. ```; Bootstrap: docker; From: ubuntu:19.04. %post; apt-get -y update; apt-get -y install python3 python3-pip git build-essential autoconf python3-dev libopenmpi3 openmpi-common swig; ln -s /usr/bin/python3 /usr/bin/python; python --version; pip3 install mpi4py numpy scipy; git clone --depth=1 https://github.com/su2code/SU2; cd SU2; autoreconf -i; export CXXFLAGS=""-O3""; python preconfigure.py --enable-mpi --enable-PY_WRAPPER --prefix=$PWD; make install -j20; make clean. %runscript; exec /SU2/bin/$1 $2; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515376266
https://github.com/su2code/SU2/issues/739#issuecomment-515383478:1060,Availability,error,error,1060,"It's running.; A small problem is that I have to change `ubuntu:19.04` to `ubuntu:18.04` and change `libopenmpi3` to `libopenmpi-dev openmpi-bin` in the definition, or it will fail.; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/builid_image$ sudo singularity build su2_tensorforce.sif su2_tensorforce.def ; INFO: Starting build...; Getting image source signatures; Skipping fetch of repeat blob sha256:1eecd0e4c2cd8c1f628b81c53a487aae6c8d4140248a8617313cd73079be09c4; Skipping fetch of repeat blob sha256:fac13afdf65bf403945c8d6bee654a26940c5527a9913bdf8daa54b69a49f550; Skipping fetch of repeat blob sha256:0c6dd534ddf18642a5af19c09c2d9744d0d1aa93680995d430b5257b6eed079d; Skipping fetch of repeat blob sha256:854703cff8700dce5b5ff70e54f5d612ab701405bc200a5b10a0213ca9025e50; Copying config sha256:993d5f573a24af19dd6006bc3e6e113bd0c709797dc48676f4f0b5ed456470cc; 2.42 KiB / 2.42 KiB [======================================================] 0s; Writing manifest to image destination; Storing signatures; singularity image-build: relocation error: /lib/x86_64-linux-gnu/libnss_files.so.2: symbol __libc_readline_unlocked version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference; FATAL: While performing build: while running engine: exit status 127; ```. My OS is ubuntu 18.04, and OpenMPI version is 2.1.1. I will take a test to see the reason. Once if finishes, I will let you know. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515383478
https://github.com/su2code/SU2/issues/739#issuecomment-515383478:804,Modifiability,config,config,804,"It's running.; A small problem is that I have to change `ubuntu:19.04` to `ubuntu:18.04` and change `libopenmpi3` to `libopenmpi-dev openmpi-bin` in the definition, or it will fail.; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/builid_image$ sudo singularity build su2_tensorforce.sif su2_tensorforce.def ; INFO: Starting build...; Getting image source signatures; Skipping fetch of repeat blob sha256:1eecd0e4c2cd8c1f628b81c53a487aae6c8d4140248a8617313cd73079be09c4; Skipping fetch of repeat blob sha256:fac13afdf65bf403945c8d6bee654a26940c5527a9913bdf8daa54b69a49f550; Skipping fetch of repeat blob sha256:0c6dd534ddf18642a5af19c09c2d9744d0d1aa93680995d430b5257b6eed079d; Skipping fetch of repeat blob sha256:854703cff8700dce5b5ff70e54f5d612ab701405bc200a5b10a0213ca9025e50; Copying config sha256:993d5f573a24af19dd6006bc3e6e113bd0c709797dc48676f4f0b5ed456470cc; 2.42 KiB / 2.42 KiB [======================================================] 0s; Writing manifest to image destination; Storing signatures; singularity image-build: relocation error: /lib/x86_64-linux-gnu/libnss_files.so.2: symbol __libc_readline_unlocked version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference; FATAL: While performing build: while running engine: exit status 127; ```. My OS is ubuntu 18.04, and OpenMPI version is 2.1.1. I will take a test to see the reason. Once if finishes, I will let you know. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515383478
https://github.com/su2code/SU2/issues/739#issuecomment-515383478:1231,Performance,perform,performing,1231,"It's running.; A small problem is that I have to change `ubuntu:19.04` to `ubuntu:18.04` and change `libopenmpi3` to `libopenmpi-dev openmpi-bin` in the definition, or it will fail.; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/builid_image$ sudo singularity build su2_tensorforce.sif su2_tensorforce.def ; INFO: Starting build...; Getting image source signatures; Skipping fetch of repeat blob sha256:1eecd0e4c2cd8c1f628b81c53a487aae6c8d4140248a8617313cd73079be09c4; Skipping fetch of repeat blob sha256:fac13afdf65bf403945c8d6bee654a26940c5527a9913bdf8daa54b69a49f550; Skipping fetch of repeat blob sha256:0c6dd534ddf18642a5af19c09c2d9744d0d1aa93680995d430b5257b6eed079d; Skipping fetch of repeat blob sha256:854703cff8700dce5b5ff70e54f5d612ab701405bc200a5b10a0213ca9025e50; Copying config sha256:993d5f573a24af19dd6006bc3e6e113bd0c709797dc48676f4f0b5ed456470cc; 2.42 KiB / 2.42 KiB [======================================================] 0s; Writing manifest to image destination; Storing signatures; singularity image-build: relocation error: /lib/x86_64-linux-gnu/libnss_files.so.2: symbol __libc_readline_unlocked version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference; FATAL: While performing build: while running engine: exit status 127; ```. My OS is ubuntu 18.04, and OpenMPI version is 2.1.1. I will take a test to see the reason. Once if finishes, I will let you know. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515383478
https://github.com/su2code/SU2/issues/739#issuecomment-515383478:1360,Testability,test,test,1360,"It's running.; A small problem is that I have to change `ubuntu:19.04` to `ubuntu:18.04` and change `libopenmpi3` to `libopenmpi-dev openmpi-bin` in the definition, or it will fail.; ```; ubuntu@main-3:~/main_shared_volume/build_singularity_image/builid_image$ sudo singularity build su2_tensorforce.sif su2_tensorforce.def ; INFO: Starting build...; Getting image source signatures; Skipping fetch of repeat blob sha256:1eecd0e4c2cd8c1f628b81c53a487aae6c8d4140248a8617313cd73079be09c4; Skipping fetch of repeat blob sha256:fac13afdf65bf403945c8d6bee654a26940c5527a9913bdf8daa54b69a49f550; Skipping fetch of repeat blob sha256:0c6dd534ddf18642a5af19c09c2d9744d0d1aa93680995d430b5257b6eed079d; Skipping fetch of repeat blob sha256:854703cff8700dce5b5ff70e54f5d612ab701405bc200a5b10a0213ca9025e50; Copying config sha256:993d5f573a24af19dd6006bc3e6e113bd0c709797dc48676f4f0b5ed456470cc; 2.42 KiB / 2.42 KiB [======================================================] 0s; Writing manifest to image destination; Storing signatures; singularity image-build: relocation error: /lib/x86_64-linux-gnu/libnss_files.so.2: symbol __libc_readline_unlocked version GLIBC_PRIVATE not defined in file libc.so.6 with link time reference; FATAL: While performing build: while running engine: exit status 127; ```. My OS is ubuntu 18.04, and OpenMPI version is 2.1.1. I will take a test to see the reason. Once if finishes, I will let you know. Thank you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/739#issuecomment-515383478
https://github.com/su2code/SU2/pull/740#issuecomment-515225353:96,Security,validat,validation,96,"Hey @EduardoMolina ,; Yes, I guess it would be good if you can test if this actually fixes your validation Testcase. Maybe also adding the case as regression/validation case could be an idea as there is currently none to my knowledge. ; MfG, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515225353
https://github.com/su2code/SU2/pull/740#issuecomment-515225353:158,Security,validat,validation,158,"Hey @EduardoMolina ,; Yes, I guess it would be good if you can test if this actually fixes your validation Testcase. Maybe also adding the case as regression/validation case could be an idea as there is currently none to my knowledge. ; MfG, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515225353
https://github.com/su2code/SU2/pull/740#issuecomment-515225353:63,Testability,test,test,63,"Hey @EduardoMolina ,; Yes, I guess it would be good if you can test if this actually fixes your validation Testcase. Maybe also adding the case as regression/validation case could be an idea as there is currently none to my knowledge. ; MfG, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515225353
https://github.com/su2code/SU2/pull/740#issuecomment-515225353:107,Testability,Test,Testcase,107,"Hey @EduardoMolina ,; Yes, I guess it would be good if you can test if this actually fixes your validation Testcase. Maybe also adding the case as regression/validation case could be an idea as there is currently none to my knowledge. ; MfG, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515225353
https://github.com/su2code/SU2/pull/740#issuecomment-515453841:155,Energy Efficiency,reduce,reduce,155,"Maybe instead of adding a new one, we can modify an existing one to check that feature. Or we add a new one and remove an existing one. We have to somehow reduce the number of tests ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515453841
https://github.com/su2code/SU2/pull/740#issuecomment-515453841:176,Testability,test,tests,176,"Maybe instead of adding a new one, we can modify an existing one to check that feature. Or we add a new one and remove an existing one. We have to somehow reduce the number of tests ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515453841
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:39,Testability,Test,Testcase,39,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:75,Testability,test,tests,75,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:123,Testability,Test,Testcase-files,123,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:240,Testability,test,test,240,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:373,Testability,Test,Testcase,373,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:563,Testability,Test,Testcases,563,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:650,Testability,test,test,650,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-515505274:739,Testability,Test,TestCases,739,"For clarification: you mean removing a Testcase from the active regression tests to get faster turnaround from travis, the Testcase-files can stay probably.; The person who put it in place most likely had some feature which (s)he wanted to test. The path can give the purpose of the case away, but not necessarily as it is purely the files. If you (or someone else) have a Testcase in mind which can go out or can be modified I would be thankful. Choosing myself is rather arbitrary. Just as an additional idea: I removed README.md from the gitignore list of the Testcases in a branch and my plan is to shortly explain what the cases are intended to test specifically [Link](https://github.com/su2code/SU2/tree/feature_periodic_streamwise/TestCases/incomp_navierstokes/streamwise_periodic) (Note: The Readme there is not done at all, but it shows the idea kinda)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-515505274
https://github.com/su2code/SU2/pull/740#issuecomment-517228836:406,Safety,avoid,avoid,406,"Hi @pcarruscag ,; compressible needs this as well. There is some NICF (`Chi_b`, `Kappa_b`,...) stuff in the Euler_Wall implementation which I need some help with to get it right (that's why it is not done yet ). That is also the only compressible-exclusive part that could be a reason to not have one single code for inc+comp. But of course one could do it anyway with an `if(compressible)` conditional to avoid code duplication :). Towards input boolean: I thought about that as well, but with that preprocessing step it is impossible to get it wrong imo. I personally agree with BC_Sym always being flat and Euler allowing to be curvy, but as seen in issue #735 this opinion is not undisputed. By paying the price of checking straightness once, one eliminates the use of Marker_Sym (assumes const normal after your proposal) on curvy slip walls (happened in #735 ), or the possibly correct use of Marker_Euler on flat boundaries which would be a lot more expensive than checking once, right.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-517228836
https://github.com/su2code/SU2/pull/740#issuecomment-518311244:145,Modifiability,config,config,145,> Question: What happens in moving mesh cases if the surface starts out flat and then gets deformed?. @pcarruscag I now explicitly stated that: `config->GetKind_GridMovement() != RIGID_MOTION` ->then recompute normals.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-518311244
https://github.com/su2code/SU2/pull/740#issuecomment-524639197:2890,Availability,error,error,2890,"ny delta. ## parallel_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medium delta; - [x] oneram6, big delta, restart; - [x] fixedcl_naca0012, tiny delta; - [x] polar_naca0012, tiny delta; - [x] bluntbody, medium delta; - [x] inc_euler_naca0012, tiny delta; - [x] inc_nozzle, medium delta; - [x] inc_lam_bend, tiny delta; - [x] contadj_naca0012, big delta, cont.Adj.; - [x] contadj_oneram6, big delta, cont.Adj.,, great diff to develop; - [x] contadj_wedge, big delta, cont.Adj.; - [x] contadj_fixedcl_naca0012, big delta (no computed vals), cont.Adj.; - [x] harmonic_balance, tiny delta; - [x] sine_gust, tiny delta; - [x] aeroelastic, tiny delta; - [x] edge_VW, tiny delta, NICFD; - [x] edge_PPR, tiny delta, NICFD; - [x] uniform_flow, tiny delta; - [x] channel_2D, tiny delta; - [x] channel_3D, tiny delta; - [x] pipe, tiny delta; - [x] rotating_cylinders, medium delta; - [x] supersonic_vortex_shedding, big delta; - [x] fsi2d, tiny delta (todo OUTPUT_FORMAT error in SU2_SOL); - [x] stat_fsi, no vals; - [x] dyn_fsi, medium delta; - [x] stat_fsi_restart, big delta; - [x] pywrapper_naca0012, big delta; - [x] pywrapper_aeroelastic, tiny delta; - [x] pywrapper_fsi2d, tiny delta; - [x] inviscid_bump_tutorial, medium delta; - [x] inviscid_wedge_tutorial, tiny delta; - [x] inviscid_onera_tutorial, tiny delta; - [x] design_inv_naca0012, tiny delta; - [x] design_multiobj, big delta. ## serial_regression_AD; - [x] discadj_naca0012, tiny delta; - [x] discadj_cylinder3D, medium delta; - [x] discadj_arina2k, tiny delta; - [x] discadj_incomp_NACA0012, tiny delta; - [x] discadj_euler_py, filediff; - [x] discadj_multiple_ffd_py, filediff; - [x] directdiff_euler_py, filediff; - [x] directdiff_multiple_ffd_py, filediff; - [x] discadj_multi_py, filediff; - [x] pywrapper_CFD_AD_MeshDisp, tiny delta. ## parallel_regression_AD; - [x] discadj_naca0012, tiny delta; - [x] discadj_cylinder3D, medium delta; - [x] discadj_arina2k, tiny delta; - [x] discadj_incomp_NACA0012,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524639197
https://github.com/su2code/SU2/pull/740#issuecomment-524639197:166,Energy Efficiency,adapt,adapted,166,"# Failing Regression tests (91 of'em); The Euler Wall BC (comp. & incomp. affected) is used in many Testcases. All failing tests are listed. ; Box checkked -> values adapted to newer ones. ; tiny delta = all delta_vals below 0.1; ; medium delta = one delta val larger than 0.1 but all below 1.0; ; big delta = one delta_val larger than 1.0. I use this post for me to keep track of what I already fixed on what is left to do. ## serial_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medium delta; - [x] oneram6, big delta, restart; - [x] fixedcl_naca0012, tiny delta; - [x] polar_naca0012, tiny delta; - [x] bluntbody, medium delta; - [x] inc_euler_naca0012, tiny delta; - [x] inc_nozzle, medium delta; - [x] inc_lam_bend, tiny delta; - [x] contadj_naca0012, big delta, cont.Adj. There is some issue with all the cont.adj. cases in the boundary formulation; - [x] contadj_oneram6, big delta, cont.Adj., great diff to develop; - [x] contadj_wedge, big delta, cont.Adj.; - [x] contadj_fixedcl_naca0012, big delta (no computed vals), cont.Adj.; - [x] harmonic_balance, tiny delta; - [x] sine_gust, tiny delta; - [x] aeroelastic, tiny delta; - [x] edge_VW, tiny delta, NICFD; - [x] edge_PPR, tiny delta, NICFD; - [x] uniform_flow, tiny delta; - [x] channel_2D, tiny delta; - [x] channel_3D, tiny delta; - [x] pipe, tiny delta; - [x] rotating_cylinders, medium delta; - [x] supersonic_vortex_shedding, big delta; - [x] fsi2d, tiny delta; - [x] stat_fsi; - [x] stat_fsi_restart; - [x] dyn_fsi; - [x] airfoil_fsi_rbf, big delta (no computed vals); - [x] contadj_euler_py; - [x] shape_opt_euler_py, big delta; - [x] opt_multiobj_py, medium delta; - [x] opt_multiobjcombo_py, medium delta; - [x] opt_multiobj1surf_py, medium delta; - [x] opt_2surf1obj_py, tiny delta; - [x] pywrapper_naca0012, tiny delta; - [x] pywrapper_aeroelastic, tiny delta; - [x] pywrapper_fsi2d, tiny delta. ## parallel_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524639197
https://github.com/su2code/SU2/pull/740#issuecomment-524639197:166,Modifiability,adapt,adapted,166,"# Failing Regression tests (91 of'em); The Euler Wall BC (comp. & incomp. affected) is used in many Testcases. All failing tests are listed. ; Box checkked -> values adapted to newer ones. ; tiny delta = all delta_vals below 0.1; ; medium delta = one delta val larger than 0.1 but all below 1.0; ; big delta = one delta_val larger than 1.0. I use this post for me to keep track of what I already fixed on what is left to do. ## serial_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medium delta; - [x] oneram6, big delta, restart; - [x] fixedcl_naca0012, tiny delta; - [x] polar_naca0012, tiny delta; - [x] bluntbody, medium delta; - [x] inc_euler_naca0012, tiny delta; - [x] inc_nozzle, medium delta; - [x] inc_lam_bend, tiny delta; - [x] contadj_naca0012, big delta, cont.Adj. There is some issue with all the cont.adj. cases in the boundary formulation; - [x] contadj_oneram6, big delta, cont.Adj., great diff to develop; - [x] contadj_wedge, big delta, cont.Adj.; - [x] contadj_fixedcl_naca0012, big delta (no computed vals), cont.Adj.; - [x] harmonic_balance, tiny delta; - [x] sine_gust, tiny delta; - [x] aeroelastic, tiny delta; - [x] edge_VW, tiny delta, NICFD; - [x] edge_PPR, tiny delta, NICFD; - [x] uniform_flow, tiny delta; - [x] channel_2D, tiny delta; - [x] channel_3D, tiny delta; - [x] pipe, tiny delta; - [x] rotating_cylinders, medium delta; - [x] supersonic_vortex_shedding, big delta; - [x] fsi2d, tiny delta; - [x] stat_fsi; - [x] stat_fsi_restart; - [x] dyn_fsi; - [x] airfoil_fsi_rbf, big delta (no computed vals); - [x] contadj_euler_py; - [x] shape_opt_euler_py, big delta; - [x] opt_multiobj_py, medium delta; - [x] opt_multiobjcombo_py, medium delta; - [x] opt_multiobj1surf_py, medium delta; - [x] opt_2surf1obj_py, tiny delta; - [x] pywrapper_naca0012, tiny delta; - [x] pywrapper_aeroelastic, tiny delta; - [x] pywrapper_fsi2d, tiny delta. ## parallel_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524639197
https://github.com/su2code/SU2/pull/740#issuecomment-524639197:21,Testability,test,tests,21,"# Failing Regression tests (91 of'em); The Euler Wall BC (comp. & incomp. affected) is used in many Testcases. All failing tests are listed. ; Box checkked -> values adapted to newer ones. ; tiny delta = all delta_vals below 0.1; ; medium delta = one delta val larger than 0.1 but all below 1.0; ; big delta = one delta_val larger than 1.0. I use this post for me to keep track of what I already fixed on what is left to do. ## serial_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medium delta; - [x] oneram6, big delta, restart; - [x] fixedcl_naca0012, tiny delta; - [x] polar_naca0012, tiny delta; - [x] bluntbody, medium delta; - [x] inc_euler_naca0012, tiny delta; - [x] inc_nozzle, medium delta; - [x] inc_lam_bend, tiny delta; - [x] contadj_naca0012, big delta, cont.Adj. There is some issue with all the cont.adj. cases in the boundary formulation; - [x] contadj_oneram6, big delta, cont.Adj., great diff to develop; - [x] contadj_wedge, big delta, cont.Adj.; - [x] contadj_fixedcl_naca0012, big delta (no computed vals), cont.Adj.; - [x] harmonic_balance, tiny delta; - [x] sine_gust, tiny delta; - [x] aeroelastic, tiny delta; - [x] edge_VW, tiny delta, NICFD; - [x] edge_PPR, tiny delta, NICFD; - [x] uniform_flow, tiny delta; - [x] channel_2D, tiny delta; - [x] channel_3D, tiny delta; - [x] pipe, tiny delta; - [x] rotating_cylinders, medium delta; - [x] supersonic_vortex_shedding, big delta; - [x] fsi2d, tiny delta; - [x] stat_fsi; - [x] stat_fsi_restart; - [x] dyn_fsi; - [x] airfoil_fsi_rbf, big delta (no computed vals); - [x] contadj_euler_py; - [x] shape_opt_euler_py, big delta; - [x] opt_multiobj_py, medium delta; - [x] opt_multiobjcombo_py, medium delta; - [x] opt_multiobj1surf_py, medium delta; - [x] opt_2surf1obj_py, tiny delta; - [x] pywrapper_naca0012, tiny delta; - [x] pywrapper_aeroelastic, tiny delta; - [x] pywrapper_fsi2d, tiny delta. ## parallel_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524639197
https://github.com/su2code/SU2/pull/740#issuecomment-524639197:100,Testability,Test,Testcases,100,"# Failing Regression tests (91 of'em); The Euler Wall BC (comp. & incomp. affected) is used in many Testcases. All failing tests are listed. ; Box checkked -> values adapted to newer ones. ; tiny delta = all delta_vals below 0.1; ; medium delta = one delta val larger than 0.1 but all below 1.0; ; big delta = one delta_val larger than 1.0. I use this post for me to keep track of what I already fixed on what is left to do. ## serial_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medium delta; - [x] oneram6, big delta, restart; - [x] fixedcl_naca0012, tiny delta; - [x] polar_naca0012, tiny delta; - [x] bluntbody, medium delta; - [x] inc_euler_naca0012, tiny delta; - [x] inc_nozzle, medium delta; - [x] inc_lam_bend, tiny delta; - [x] contadj_naca0012, big delta, cont.Adj. There is some issue with all the cont.adj. cases in the boundary formulation; - [x] contadj_oneram6, big delta, cont.Adj., great diff to develop; - [x] contadj_wedge, big delta, cont.Adj.; - [x] contadj_fixedcl_naca0012, big delta (no computed vals), cont.Adj.; - [x] harmonic_balance, tiny delta; - [x] sine_gust, tiny delta; - [x] aeroelastic, tiny delta; - [x] edge_VW, tiny delta, NICFD; - [x] edge_PPR, tiny delta, NICFD; - [x] uniform_flow, tiny delta; - [x] channel_2D, tiny delta; - [x] channel_3D, tiny delta; - [x] pipe, tiny delta; - [x] rotating_cylinders, medium delta; - [x] supersonic_vortex_shedding, big delta; - [x] fsi2d, tiny delta; - [x] stat_fsi; - [x] stat_fsi_restart; - [x] dyn_fsi; - [x] airfoil_fsi_rbf, big delta (no computed vals); - [x] contadj_euler_py; - [x] shape_opt_euler_py, big delta; - [x] opt_multiobj_py, medium delta; - [x] opt_multiobjcombo_py, medium delta; - [x] opt_multiobj1surf_py, medium delta; - [x] opt_2surf1obj_py, tiny delta; - [x] pywrapper_naca0012, tiny delta; - [x] pywrapper_aeroelastic, tiny delta; - [x] pywrapper_fsi2d, tiny delta. ## parallel_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524639197
https://github.com/su2code/SU2/pull/740#issuecomment-524639197:123,Testability,test,tests,123,"# Failing Regression tests (91 of'em); The Euler Wall BC (comp. & incomp. affected) is used in many Testcases. All failing tests are listed. ; Box checkked -> values adapted to newer ones. ; tiny delta = all delta_vals below 0.1; ; medium delta = one delta val larger than 0.1 but all below 1.0; ; big delta = one delta_val larger than 1.0. I use this post for me to keep track of what I already fixed on what is left to do. ## serial_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medium delta; - [x] oneram6, big delta, restart; - [x] fixedcl_naca0012, tiny delta; - [x] polar_naca0012, tiny delta; - [x] bluntbody, medium delta; - [x] inc_euler_naca0012, tiny delta; - [x] inc_nozzle, medium delta; - [x] inc_lam_bend, tiny delta; - [x] contadj_naca0012, big delta, cont.Adj. There is some issue with all the cont.adj. cases in the boundary formulation; - [x] contadj_oneram6, big delta, cont.Adj., great diff to develop; - [x] contadj_wedge, big delta, cont.Adj.; - [x] contadj_fixedcl_naca0012, big delta (no computed vals), cont.Adj.; - [x] harmonic_balance, tiny delta; - [x] sine_gust, tiny delta; - [x] aeroelastic, tiny delta; - [x] edge_VW, tiny delta, NICFD; - [x] edge_PPR, tiny delta, NICFD; - [x] uniform_flow, tiny delta; - [x] channel_2D, tiny delta; - [x] channel_3D, tiny delta; - [x] pipe, tiny delta; - [x] rotating_cylinders, medium delta; - [x] supersonic_vortex_shedding, big delta; - [x] fsi2d, tiny delta; - [x] stat_fsi; - [x] stat_fsi_restart; - [x] dyn_fsi; - [x] airfoil_fsi_rbf, big delta (no computed vals); - [x] contadj_euler_py; - [x] shape_opt_euler_py, big delta; - [x] opt_multiobj_py, medium delta; - [x] opt_multiobjcombo_py, medium delta; - [x] opt_multiobj1surf_py, medium delta; - [x] opt_2surf1obj_py, tiny delta; - [x] pywrapper_naca0012, tiny delta; - [x] pywrapper_aeroelastic, tiny delta; - [x] pywrapper_fsi2d, tiny delta. ## parallel_regression; - [x] channel, tiny delta; - [x] naca0012, tiny delta; - [x] wedge, medi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524639197
https://github.com/su2code/SU2/pull/740#issuecomment-524663117:437,Testability,test,tests,437,"@TobiKattmann please put at least a couple of the failing cases under the microscope, see if the convergence rate is the same starting from scratch, if the converged results are the same with wildly different number of cores and so on.; I know it is a pain but we have been tricked by small changes in the past, and for things related with parallelization 2 core regressions can easily give false positives.; I will run some independent tests myself and look into airfoil_fsi_rbf and discadj_fsi_airfoil for you.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524663117
https://github.com/su2code/SU2/pull/740#issuecomment-524819658:529,Testability,test,testing,529,@pcarruscag Of course! I already looked at `channel ` and `oneram6` case more detailed also with up to 28 cores. Computed from freestream conditions to convergence I found that the difference in convergence is only a handful of iterations. I will post some residual comparisons for one or two cases. I also want to look a bit more detailed at supersonic wedge and at least one incompressible case. ; And all the cases with big deltas and the filediff cases need special treatment (and a more in depth look) anyway...; Thanks for testing your cases as well! Helps a lot,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-524819658
https://github.com/su2code/SU2/pull/740#issuecomment-532401028:669,Performance,load,load,669,"Text always moves between the images for some reason ... euler oneram6 14cores; ![sloweuler_oneram6](https://user-images.githubusercontent.com/31306376/65078336-18c27200-d99d-11e9-9d5c-5e38df4f9803.gif). euler channel 14cores; ![sloweuler_channel](https://user-images.githubusercontent.com/31306376/65078374-2a0b7e80-d99d-11e9-8860-23e48399873b.gif); Hi @pcarruscag (and everyone else of course :) ), Here some selected convergence rate comparisons with of this PR with develop. I also compared results all of those case side by side and the differences (I used contour line positions for most of it) are pretty subtle. Most of the times I double checked that I didn't load the same flow.vtk. At shocks it was a bit more visible especially close the wall but one has to really zoom in for it. Concerning lift / drag coefficient which are written on screen the difference was below 1% throughout the cases I looked at. Some cases were tested with different amount of cores with no mentionable deviance in Residuals. inc ns bend 2cores; ![incns_bend](https://user-images.githubusercontent.com/31306376/65078454-50c9b500-d99d-11e9-8be2-4ea1cb397c14.gif). inc euler nozzle 4cores; ![inceuler_nozzle](https://user-images.githubusercontent.com/31306376/65078420-3ee81200-d99d-11e9-83b3-cd8d301a5771.gif). euler wedge 14cores; ![euler_wedge](https://user-images.githubusercontent.com/31306376/65078443-49a2a700-d99d-11e9-9110-03dd278d742f.gif)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532401028
https://github.com/su2code/SU2/pull/740#issuecomment-532401028:934,Testability,test,tested,934,"Text always moves between the images for some reason ... euler oneram6 14cores; ![sloweuler_oneram6](https://user-images.githubusercontent.com/31306376/65078336-18c27200-d99d-11e9-9d5c-5e38df4f9803.gif). euler channel 14cores; ![sloweuler_channel](https://user-images.githubusercontent.com/31306376/65078374-2a0b7e80-d99d-11e9-8860-23e48399873b.gif); Hi @pcarruscag (and everyone else of course :) ), Here some selected convergence rate comparisons with of this PR with develop. I also compared results all of those case side by side and the differences (I used contour line positions for most of it) are pretty subtle. Most of the times I double checked that I didn't load the same flow.vtk. At shocks it was a bit more visible especially close the wall but one has to really zoom in for it. Concerning lift / drag coefficient which are written on screen the difference was below 1% throughout the cases I looked at. Some cases were tested with different amount of cores with no mentionable deviance in Residuals. inc ns bend 2cores; ![incns_bend](https://user-images.githubusercontent.com/31306376/65078454-50c9b500-d99d-11e9-8be2-4ea1cb397c14.gif). inc euler nozzle 4cores; ![inceuler_nozzle](https://user-images.githubusercontent.com/31306376/65078420-3ee81200-d99d-11e9-83b3-cd8d301a5771.gif). euler wedge 14cores; ![euler_wedge](https://user-images.githubusercontent.com/31306376/65078443-49a2a700-d99d-11e9-9110-03dd278d742f.gif)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532401028
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:31,Deployability,continuous,continuous,31,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:154,Deployability,continuous,continuous,154,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:401,Deployability,continuous,continuous,401,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:513,Deployability,Update,Update,513,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:679,Deployability,continuous,continuous,679,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:726,Deployability,integrat,integration,726,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:726,Integrability,integrat,integration,726,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:856,Safety,avoid,avoid,856,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-532675551:50,Testability,Test,Testcases,50,"I do have some issues with the continuous adjoint Testcases. Taking for example the euler_wedge. In the primal, results/convergence are really close. The continuous adjoint case (contadj_wedge) however produces pretty different results especially along the Euler walls (will upload an image later). The cont.adj. case converges though. So I guess I am doing missing something which is specific to the continuous adjoint? ; Maybe someone with experience in that field can help me and take a look. @hlkline maybe?. Update: Fixed the problem -> I had to change the call signature of the base implementation of `BC_Euler_Wall `and I changed it for all the primal solvers but not the continuous adjoint solver. Therefore in during integration the empty method of the CSolver was called. I'll additionally add the `override `keyword to the method declaration to avoid that in the future. Thanks to @talbring for pointing me to that",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-532675551
https://github.com/su2code/SU2/pull/740#issuecomment-536618994:352,Deployability,integrat,integrated,352,"Alright everyone, this PR is now ready to get merged from my point of view. If there are further concerns regarding particular Testcases please let me know. @pcarruscag did you check airfoil_fsi_rbf and discadj_fsi_airfoil? If yes, your (dis-)approval for this PR would be appreciated (of course from everyone else as well). . I would like to get this integrated before #790 and I would recommend @economon not to start changing reg-test values before this is merged. The code still fixes the initial Issue #735",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536618994
https://github.com/su2code/SU2/pull/740#issuecomment-536618994:352,Integrability,integrat,integrated,352,"Alright everyone, this PR is now ready to get merged from my point of view. If there are further concerns regarding particular Testcases please let me know. @pcarruscag did you check airfoil_fsi_rbf and discadj_fsi_airfoil? If yes, your (dis-)approval for this PR would be appreciated (of course from everyone else as well). . I would like to get this integrated before #790 and I would recommend @economon not to start changing reg-test values before this is merged. The code still fixes the initial Issue #735",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536618994
https://github.com/su2code/SU2/pull/740#issuecomment-536618994:127,Testability,Test,Testcases,127,"Alright everyone, this PR is now ready to get merged from my point of view. If there are further concerns regarding particular Testcases please let me know. @pcarruscag did you check airfoil_fsi_rbf and discadj_fsi_airfoil? If yes, your (dis-)approval for this PR would be appreciated (of course from everyone else as well). . I would like to get this integrated before #790 and I would recommend @economon not to start changing reg-test values before this is merged. The code still fixes the initial Issue #735",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536618994
https://github.com/su2code/SU2/pull/740#issuecomment-536618994:433,Testability,test,test,433,"Alright everyone, this PR is now ready to get merged from my point of view. If there are further concerns regarding particular Testcases please let me know. @pcarruscag did you check airfoil_fsi_rbf and discadj_fsi_airfoil? If yes, your (dis-)approval for this PR would be appreciated (of course from everyone else as well). . I would like to get this integrated before #790 and I would recommend @economon not to start changing reg-test values before this is merged. The code still fixes the initial Issue #735",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536618994
https://github.com/su2code/SU2/pull/740#issuecomment-536752462:235,Availability,error,error,235,"LGTM. Thanks for the fix and updating all regressions, @TobiKattmann . Final question: in the end, the Euler and symmetry BCs are identical implementations, so do we have a practical guideline for when to use one or the other (or some error check), or will we just carry both and allow them to be used interchangeably?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536752462
https://github.com/su2code/SU2/pull/740#issuecomment-536752462:183,Usability,guid,guideline,183,"LGTM. Thanks for the fix and updating all regressions, @TobiKattmann . Final question: in the end, the Euler and symmetry BCs are identical implementations, so do we have a practical guideline for when to use one or the other (or some error check), or will we just carry both and allow them to be used interchangeably?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536752462
https://github.com/su2code/SU2/pull/740#issuecomment-536898493:106,Safety,safe,safely,106,"@economon Right now, Euler & Sym can be used interchangeably in both (incomp. & comp.) solvers. One could safely remove one but keeping both is reasonable I guess as both BC are expected by users and maybe the implementation deviates in the future.; Both will give the same results, independent of the 'curvyness' of the boundary (as that is checked in a preprocessing step). Bonus info: Comp & Incomp implementations are identical, so if a higher-level FlowSolver is implemented, EulerWall and SymBC could move up there.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-536898493
https://github.com/su2code/SU2/pull/740#issuecomment-537108499:88,Testability,test,test,88,Thanks @TobiKattmann for that fix and going through the hassle of changing all the reg. test values.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537108499
https://github.com/su2code/SU2/pull/740#issuecomment-537167522:92,Integrability,message,messages,92,"@TobiKattmann,; In the Airfoil_2D case, why are the surfaces detected as straight? Also the messages are a bit strange:; Boundary marker leading_edge is a single straight.; Boundary marker 0.0 is a single straight.; Boundary marker pressure_side is a single straight.; Boundary marker 0.0 is a single straight.; Boundary marker suction_side is a single straight.; Boundary marker 0.0 is a single straight.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537167522
https://github.com/su2code/SU2/pull/740#issuecomment-537167522:61,Safety,detect,detected,61,"@TobiKattmann,; In the Airfoil_2D case, why are the surfaces detected as straight? Also the messages are a bit strange:; Boundary marker leading_edge is a single straight.; Boundary marker 0.0 is a single straight.; Boundary marker pressure_side is a single straight.; Boundary marker 0.0 is a single straight.; Boundary marker suction_side is a single straight.; Boundary marker 0.0 is a single straight.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537167522
https://github.com/su2code/SU2/pull/740#issuecomment-537204246:589,Modifiability,config,configFlow,589,"Hi @pcarruscag ,; You probably mean `airfoil_fsi_rbf` from serial_regression (?); I get the written on screen:. Boundary marker leading_edge is NOT a single straight.; Boundary marker 0.0 is a single straight.; Boundary marker pressure_side is NOT a single straight.; Boundary marker 0.0 is a single straight.; Boundary marker suction_side is NOT a single straight.; Boundary marker 0.0 is a single straight. The diff of my local branch with (origin/)develop is empty, so can you double check for me if you are using the latest develop or fix_SlipWall branch?. For the 0.0 markers: In the configFlow.cfg you have ; `MARKER_EULER= ( leading_edge, 0.0, pressure_side, 0.0, suction_side, 0.0)`; I dont understand why there are zeros as nothing has to be prescribed on the Euler Wall. So the 0.0 is interpreted as a marker tag. Removing the 0.0 does not change anything for me in Residuals as well. In the mesh there are also no boundaries defined which are called `0.0` :) . Does that help or am I on the wrong track?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537204246
https://github.com/su2code/SU2/pull/740#issuecomment-537206528:261,Usability,simpl,simply,261,Maybe also an explanation why I specifically state `single straight`:; Take a case with two symmetry planes on either side of a channel -> it could be reasonable to put both in the same Marker in the su2 mesh -> both planes are straight for themselves but as I simply loop over all nodes in a marker I then have 2 different unit normals for the same marker -> thats why the specific `single` is used,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537206528
https://github.com/su2code/SU2/pull/740#issuecomment-537243630:57,Deployability,update,updated,57,"I mean the case in disc_adj_fsi/airfoil_2d for which you updated a filediff regression. You are probably right on the 0's, those were RANS cases...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537243630
https://github.com/su2code/SU2/pull/740#issuecomment-537377677:39,Safety,detect,detected,39,"For the fluid zone0 the boundaries are detected as NOT straight (captial letters because it is written on screen like that ;) ) and for the solid zone1 the fluid markers are still in the Global marker list but not in the local list... thats why they are written as straight on screen (explanation in next paragraph). In parallel cases this case (process knows the global marker but does not own any nodes of it i.e. it is also not in the local marker list) the process has to assume that the boundary is straight for the mpi communication otherwise we would never have straight boundary-straightness predictions in high process-count simulations. Here the situation is the same... except for it is a serial case. I have to admit I am not really sure how to best tackle that. Can you split the cfg files like in the Airfoil_RBF case (not sure if this is an old vs new driver thing)? I could exclude that structral solver from the surf_straightness check in CDriver::Geometrical_Preprocessing but I am not sure if that possible and if, what boolean to use.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537377677
https://github.com/su2code/SU2/pull/740#issuecomment-537377677:600,Safety,predict,predictions,600,"For the fluid zone0 the boundaries are detected as NOT straight (captial letters because it is written on screen like that ;) ) and for the solid zone1 the fluid markers are still in the Global marker list but not in the local list... thats why they are written as straight on screen (explanation in next paragraph). In parallel cases this case (process knows the global marker but does not own any nodes of it i.e. it is also not in the local marker list) the process has to assume that the boundary is straight for the mpi communication otherwise we would never have straight boundary-straightness predictions in high process-count simulations. Here the situation is the same... except for it is a serial case. I have to admit I am not really sure how to best tackle that. Can you split the cfg files like in the Airfoil_RBF case (not sure if this is an old vs new driver thing)? I could exclude that structral solver from the surf_straightness check in CDriver::Geometrical_Preprocessing but I am not sure if that possible and if, what boolean to use.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/740#issuecomment-537377677
https://github.com/su2code/SU2/issues/741#issuecomment-515010918:616,Deployability,integrat,integrated,616,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
https://github.com/su2code/SU2/issues/741#issuecomment-515010918:776,Deployability,integrat,integrated,776,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
https://github.com/su2code/SU2/issues/741#issuecomment-515010918:616,Integrability,integrat,integrated,616,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
https://github.com/su2code/SU2/issues/741#issuecomment-515010918:776,Integrability,integrat,integrated,776,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
https://github.com/su2code/SU2/issues/741#issuecomment-515010918:531,Usability,guid,guidance,531,"Surprisingly I have found the existing content related to plasma simulation in SU2. Really amazing. Could anyone give me any clues of the correspondent .cfg files? Or help me find the governing equations change which makes the plasma equations different from the neutral gas. ; ; ![image](https://user-images.githubusercontent.com/33152225/61871269-5fef3200-af1b-11e9-82c5-cd8418a6f83c.png). It already seems good enough at considering *E* field, but *B* is omitted. I can strive to supplement the equation. Could anyone give some guidance to me, a newcomer of SU2?. [Stanford University Unstructured An open-source integrated computational environment for multi-physics simula.pdf](https://github.com/su2code/SU2/files/3431264/Stanford.University.Unstructured.An.open-source.integrated.computational.environment.for.multi-physics.simula.pdf)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515010918
https://github.com/su2code/SU2/issues/741#issuecomment-515276512:160,Usability,learn,learn,160,"Thanks for your kindly reply, Clark. It is a good habit to have a search before asking, and I should keep it. . ""feature-AdjTNE2"" seems to be a good example to learn from how to edit the kernel of governing equations. I would try to deepen the utilities of electromagnetic computation. And I have found the commit that deleting all plasma computational relevant content. 45c2a63d1a0773dd2e9ca05b5a1798ea575d47f8 Anybody willing to tell me why we delete that part? Too complicated to handle?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515276512
https://github.com/su2code/SU2/issues/741#issuecomment-515552244:244,Modifiability,coupling,coupling,244,"Hi @WenyinWei : if they have some time, I think that @WallyMaier and @MarcoFossati could fill you in on their approach with the TNE2 branch and NEMO (the idea is for those branches to be merged). @MarcoFossati and one of his students have been coupling Mutation++ to SU2 and have been making nice progress. For the work you cite some time ago in our group at Stanford, Maxwell's equations were solved directly in SU2 (well perhaps just a subset, Gauss's law, if I remember correctly). That work should still be in the git history back in v1.0 or v2.0, I think. Should be able to find it with some searching.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515552244
https://github.com/su2code/SU2/issues/741#issuecomment-515662933:538,Security,validat,validation,538,"Dear @WenyinWei: presently Mutation is already fully linked to SU2 and is not only something that will allow to deal nicely with chemical reactions, but it presently also used to get all the species/mixture thermochemical properties (including ions and free electrons) and to address thermal non equilibrium (i.e. multiple-temperatures) by incorporating characteristic vibrational and electronic temperatures for various species. We still have not pushed the latest developments in NEMO-TNE2 since we are finalizing some verification and validation test cases and producing appropriate documentation to be added on the SU2 webpage. @srcopela already created a nice substrate for all these features now we are trying to put this up to speed with the latest SU2 versions and capabilities and go beyond that with additional capabilities. Introducing MHD is definitely something on our roadmap, but something that will come after we have completed our merging of TNE2+NEMO and we have one solid feature with thermochemical nonequilibrium.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515662933
https://github.com/su2code/SU2/issues/741#issuecomment-515662933:549,Testability,test,test,549,"Dear @WenyinWei: presently Mutation is already fully linked to SU2 and is not only something that will allow to deal nicely with chemical reactions, but it presently also used to get all the species/mixture thermochemical properties (including ions and free electrons) and to address thermal non equilibrium (i.e. multiple-temperatures) by incorporating characteristic vibrational and electronic temperatures for various species. We still have not pushed the latest developments in NEMO-TNE2 since we are finalizing some verification and validation test cases and producing appropriate documentation to be added on the SU2 webpage. @srcopela already created a nice substrate for all these features now we are trying to put this up to speed with the latest SU2 versions and capabilities and go beyond that with additional capabilities. Introducing MHD is definitely something on our roadmap, but something that will come after we have completed our merging of TNE2+NEMO and we have one solid feature with thermochemical nonequilibrium.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/741#issuecomment-515662933
https://github.com/su2code/SU2/pull/742#issuecomment-514566021:25,Testability,test,testing,25,Ignore this PR. Just for testing ...,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/742#issuecomment-514566021
https://github.com/su2code/SU2/issues/743#issuecomment-514651250:81,Energy Efficiency,adapt,adaptation,81,"Dear WenyinWei,; presently SU2 is interfaced with the INRIA AMG library for mesh adaptation. You can find all the necessary details and examples at https://pyamg.saclay.inria.fr. There are efforts going on in Stanford to connect it to goal-oriented adaptation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/743#issuecomment-514651250
https://github.com/su2code/SU2/issues/743#issuecomment-514651250:249,Energy Efficiency,adapt,adaptation,249,"Dear WenyinWei,; presently SU2 is interfaced with the INRIA AMG library for mesh adaptation. You can find all the necessary details and examples at https://pyamg.saclay.inria.fr. There are efforts going on in Stanford to connect it to goal-oriented adaptation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/743#issuecomment-514651250
https://github.com/su2code/SU2/issues/743#issuecomment-514651250:34,Integrability,interface,interfaced,34,"Dear WenyinWei,; presently SU2 is interfaced with the INRIA AMG library for mesh adaptation. You can find all the necessary details and examples at https://pyamg.saclay.inria.fr. There are efforts going on in Stanford to connect it to goal-oriented adaptation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/743#issuecomment-514651250
https://github.com/su2code/SU2/issues/743#issuecomment-514651250:81,Modifiability,adapt,adaptation,81,"Dear WenyinWei,; presently SU2 is interfaced with the INRIA AMG library for mesh adaptation. You can find all the necessary details and examples at https://pyamg.saclay.inria.fr. There are efforts going on in Stanford to connect it to goal-oriented adaptation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/743#issuecomment-514651250
https://github.com/su2code/SU2/issues/743#issuecomment-514651250:249,Modifiability,adapt,adaptation,249,"Dear WenyinWei,; presently SU2 is interfaced with the INRIA AMG library for mesh adaptation. You can find all the necessary details and examples at https://pyamg.saclay.inria.fr. There are efforts going on in Stanford to connect it to goal-oriented adaptation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/743#issuecomment-514651250
https://github.com/su2code/SU2/issues/743#issuecomment-514659919:58,Energy Efficiency,power,power,58,"Dear Marco,; That’s really an awesome website to show the power of SU2. Definitely make SU2 great. I have no problem now. If I have more relevant questions about AMR, I will reopen the issue. Thanks for your information, Macro!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/743#issuecomment-514659919
https://github.com/su2code/SU2/pull/745#issuecomment-516459774:13,Integrability,depend,depends,13,"That heavily depends on the filesystem as the linker copies and moves huge amounts of data. On my local machine linking is pretty fast, in the same order of compiling one file. However, on our cluster it is rather slow because its a (parallel) network filesystem. Anyway, in contrast to make, ninja builds ALL objects files in parallel without waiting for a specific static library to be linked. Linking is done as soon as all required object files are ready in parallel with the compilation of other object files. So yeah, for minor code modifications linking can still be the limiting factor, but there is no way around that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-516459774
https://github.com/su2code/SU2/pull/745#issuecomment-516687563:329,Deployability,update,update,329,"Very nice job, Tim. I can report that it works fine for me on Mac and a linux cluster. One suggestion to make our transition easier: if you agree, can you please add a 'bootstrap_meson' file in the root that will set up the build system like our current 'bootstrap' script? I am thinking just something like:; ```; git submodule update --init --recursive; cd externals/ninja; ./configure.py --bootstrap; cd ..; export PATH=$PWD/externals/ninja:$PWD/externals/meson:$PATH; ```; since I found that I usually need to get meson and ninja on my systems. This should also be familiar to folks given our current workflow.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-516687563
https://github.com/su2code/SU2/pull/745#issuecomment-516687563:378,Modifiability,config,configure,378,"Very nice job, Tim. I can report that it works fine for me on Mac and a linux cluster. One suggestion to make our transition easier: if you agree, can you please add a 'bootstrap_meson' file in the root that will set up the build system like our current 'bootstrap' script? I am thinking just something like:; ```; git submodule update --init --recursive; cd externals/ninja; ./configure.py --bootstrap; cd ..; export PATH=$PWD/externals/ninja:$PWD/externals/meson:$PATH; ```; since I found that I usually need to get meson and ninja on my systems. This should also be familiar to folks given our current workflow.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-516687563
https://github.com/su2code/SU2/pull/745#issuecomment-517243186:451,Integrability,depend,dependency,451,"> The documentation looks great! (Answered a couple of my questions); > Can you give an example of linking to external libraries? e.g. BLAS; > For example I currently need:; > ; > ```; > export CPPFLAGS=""-DHAVE_LAPACK""; > export LDFLAGS=""-L$OPENBLAS/haswell_omp/lib""; > export LIBS=""-lopenblas -lgfortran -fopenmp""; > ```. Well you have two options. First, if the libraries can be found with `pkg-config`, the easiest is to just use ; ```; openblas = dependency('openblas') ; su2_deps += openblas; ```; Otherwise you'll have to declare the dependency with; ```; openblas = declare_dependency(...); su2_deps += openblas; ```; where the arguments for that routine are explained [here](https://mesonbuild.com/Reference-manual.html#declare_dependency)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-517243186
https://github.com/su2code/SU2/pull/745#issuecomment-517243186:540,Integrability,depend,dependency,540,"> The documentation looks great! (Answered a couple of my questions); > Can you give an example of linking to external libraries? e.g. BLAS; > For example I currently need:; > ; > ```; > export CPPFLAGS=""-DHAVE_LAPACK""; > export LDFLAGS=""-L$OPENBLAS/haswell_omp/lib""; > export LIBS=""-lopenblas -lgfortran -fopenmp""; > ```. Well you have two options. First, if the libraries can be found with `pkg-config`, the easiest is to just use ; ```; openblas = dependency('openblas') ; su2_deps += openblas; ```; Otherwise you'll have to declare the dependency with; ```; openblas = declare_dependency(...); su2_deps += openblas; ```; where the arguments for that routine are explained [here](https://mesonbuild.com/Reference-manual.html#declare_dependency)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-517243186
https://github.com/su2code/SU2/pull/745#issuecomment-517243186:654,Integrability,rout,routine,654,"> The documentation looks great! (Answered a couple of my questions); > Can you give an example of linking to external libraries? e.g. BLAS; > For example I currently need:; > ; > ```; > export CPPFLAGS=""-DHAVE_LAPACK""; > export LDFLAGS=""-L$OPENBLAS/haswell_omp/lib""; > export LIBS=""-lopenblas -lgfortran -fopenmp""; > ```. Well you have two options. First, if the libraries can be found with `pkg-config`, the easiest is to just use ; ```; openblas = dependency('openblas') ; su2_deps += openblas; ```; Otherwise you'll have to declare the dependency with; ```; openblas = declare_dependency(...); su2_deps += openblas; ```; where the arguments for that routine are explained [here](https://mesonbuild.com/Reference-manual.html#declare_dependency)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-517243186
https://github.com/su2code/SU2/pull/745#issuecomment-517243186:397,Modifiability,config,config,397,"> The documentation looks great! (Answered a couple of my questions); > Can you give an example of linking to external libraries? e.g. BLAS; > For example I currently need:; > ; > ```; > export CPPFLAGS=""-DHAVE_LAPACK""; > export LDFLAGS=""-L$OPENBLAS/haswell_omp/lib""; > export LIBS=""-lopenblas -lgfortran -fopenmp""; > ```. Well you have two options. First, if the libraries can be found with `pkg-config`, the easiest is to just use ; ```; openblas = dependency('openblas') ; su2_deps += openblas; ```; Otherwise you'll have to declare the dependency with; ```; openblas = declare_dependency(...); su2_deps += openblas; ```; where the arguments for that routine are explained [here](https://mesonbuild.com/Reference-manual.html#declare_dependency)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-517243186
https://github.com/su2code/SU2/pull/745#issuecomment-519991805:88,Deployability,update,update,88,"I will try it right now (sorry I got absorbed by 753). If I make it work I volunteer to update the docs with the procedure. Edit: Actually I cannot get even the basic version to work.; I tried a fresh clone of this branch and running ./meson.py build -Dwith-mpi=enabled -Denable-autodiff; The script stops when it tries to build ninja as it cannot find the associated configure.py script.; If I supply a binary for ninja it stops because the submodules are not initialized properly (maybe it's the git version the cluster uses ? 1.8.3.1).; If I init the submodules manually, meson.py stops because the submodule folders are not empty.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-519991805
https://github.com/su2code/SU2/pull/745#issuecomment-519991805:368,Modifiability,config,configure,368,"I will try it right now (sorry I got absorbed by 753). If I make it work I volunteer to update the docs with the procedure. Edit: Actually I cannot get even the basic version to work.; I tried a fresh clone of this branch and running ./meson.py build -Dwith-mpi=enabled -Denable-autodiff; The script stops when it tries to build ninja as it cannot find the associated configure.py script.; If I supply a binary for ninja it stops because the submodules are not initialized properly (maybe it's the git version the cluster uses ? 1.8.3.1).; If I init the submodules manually, meson.py stops because the submodule folders are not empty.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-519991805
https://github.com/su2code/SU2/pull/745#issuecomment-520387997:11,Testability,test,testing,11,Thanks for testing :D Now it should work.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-520387997
https://github.com/su2code/SU2/pull/745#issuecomment-520856033:256,Integrability,depend,dependency,256,"Why do you think it is confusing ? . It is either:; ```; blas_dep = declare_dependency(include_directories: '/home/talbring/Projects/OpenBLAS-0.3.6/include',; link_args:'-L/home/talbring/Projects/OpenBLAS-0.3.6/lib/ -lopenblas'). ```. or . ```; blas_dep = dependency('openblas'); ```. if `pkgconfig` can find the `*.pc` file.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-520856033
https://github.com/su2code/SU2/pull/745#issuecomment-520973327:111,Integrability,depend,dependency,111,"I would always suggest adding the corresponding pkg config path to the `PKG_CONFIG_PATH` variable and use the `dependency` method. This way you get the correct version, additional dependencies, the include path and necessary flags.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-520973327
https://github.com/su2code/SU2/pull/745#issuecomment-520973327:180,Integrability,depend,dependencies,180,"I would always suggest adding the corresponding pkg config path to the `PKG_CONFIG_PATH` variable and use the `dependency` method. This way you get the correct version, additional dependencies, the include path and necessary flags.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-520973327
https://github.com/su2code/SU2/pull/745#issuecomment-520973327:52,Modifiability,config,config,52,"I would always suggest adding the corresponding pkg config path to the `PKG_CONFIG_PATH` variable and use the `dependency` method. This way you get the correct version, additional dependencies, the include path and necessary flags.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-520973327
https://github.com/su2code/SU2/pull/745#issuecomment-520973327:89,Modifiability,variab,variable,89,"I would always suggest adding the corresponding pkg config path to the `PKG_CONFIG_PATH` variable and use the `dependency` method. This way you get the correct version, additional dependencies, the include path and necessary flags.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-520973327
https://github.com/su2code/SU2/pull/745#issuecomment-521112696:195,Integrability,depend,dependencies,195,I am merging this in now. Please have a look at the documentation https://su2code.github.io/docs/Build-SU2-From-Source. Let me know if you have any problems with adding new files and/or external dependencies.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521112696
https://github.com/su2code/SU2/pull/745#issuecomment-521301556:196,Deployability,install,installed,196,"This works awesome. Except one thing.; I'm trying to build SU2 using Meson inside a Singularity container. However, the configuring of ninja doesn't work there. ; It looks for `python` but if not installed, this is not there, only python3 command is there. It works on my desktop because I have python2 installed there. However, from the documentation it seems I only need python3, in reality it uses both. Last part of the output of the Singularity build:; [meson_output.txt](https://github.com/su2code/SU2/files/3502142/meson_output.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521301556
https://github.com/su2code/SU2/pull/745#issuecomment-521301556:303,Deployability,install,installed,303,"This works awesome. Except one thing.; I'm trying to build SU2 using Meson inside a Singularity container. However, the configuring of ninja doesn't work there. ; It looks for `python` but if not installed, this is not there, only python3 command is there. It works on my desktop because I have python2 installed there. However, from the documentation it seems I only need python3, in reality it uses both. Last part of the output of the Singularity build:; [meson_output.txt](https://github.com/su2code/SU2/files/3502142/meson_output.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521301556
https://github.com/su2code/SU2/pull/745#issuecomment-521301556:120,Modifiability,config,configuring,120,"This works awesome. Except one thing.; I'm trying to build SU2 using Meson inside a Singularity container. However, the configuring of ninja doesn't work there. ; It looks for `python` but if not installed, this is not there, only python3 command is there. It works on my desktop because I have python2 installed there. However, from the documentation it seems I only need python3, in reality it uses both. Last part of the output of the Singularity build:; [meson_output.txt](https://github.com/su2code/SU2/files/3502142/meson_output.txt)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521301556
https://github.com/su2code/SU2/pull/745#issuecomment-521309234:51,Availability,avail,available,51,"@stephansmit For building ninja `python` has to be available. If its not, on ubuntu (which I assume you are using for the container) you can either use; `ln -s /usr/bin/python3 /usr/bin/python`; or ; `update-alternatives --install /usr/bin/python python /usr/bin/python3 10`; to set this up.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521309234
https://github.com/su2code/SU2/pull/745#issuecomment-521309234:201,Deployability,update,update-alternatives,201,"@stephansmit For building ninja `python` has to be available. If its not, on ubuntu (which I assume you are using for the container) you can either use; `ln -s /usr/bin/python3 /usr/bin/python`; or ; `update-alternatives --install /usr/bin/python python /usr/bin/python3 10`; to set this up.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521309234
https://github.com/su2code/SU2/pull/745#issuecomment-521309234:223,Deployability,install,install,223,"@stephansmit For building ninja `python` has to be available. If its not, on ubuntu (which I assume you are using for the container) you can either use; `ln -s /usr/bin/python3 /usr/bin/python`; or ; `update-alternatives --install /usr/bin/python python /usr/bin/python3 10`; to set this up.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521309234
https://github.com/su2code/SU2/pull/745#issuecomment-521545657:110,Usability,simpl,simpler,110,"@talbring Thanks! Works like a charm now! Thanks for implementing this, I think this building method is a lot simpler than the previous one.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-521545657
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:401,Availability,error,error,401,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:566,Availability,ERROR,ERROR,566,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:649,Deployability,install,installing,649,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:786,Deployability,install,install,786,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:826,Deployability,install,installation,826,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:415,Integrability,Message,Message,415,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:487,Integrability,depend,dependency,487,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:573,Integrability,Depend,Dependency,573,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/pull/745#issuecomment-525114027:930,Modifiability,config,configured,930,"Hey Tim, Sorry I couldn't try this while it was still in PR mode, but I just tried it on my ubuntu 16.04 and after some poking around, it worked! Compilation from scratch was very rapid. . Just a quick thing, the documentation didn't quite work for me but that is probably because my default python is 2.7. Which meant that I had to execute it as:. `python3 meson.py ...`. When I did that, I got this error: ; ```; Message: Looking for mpi4py in /usr/lib/python3/dist-packages; Run-time dependency python3 found: NO (tried pkgconfig). SU2_PY/pySU2/meson.build:29:0: ERROR: Dependency ""python3"" not found, tried pkgconfig; ```; This was not fixed by installing mpi4py the way it is suggested in the draft documentation. Stack overflow came to the rescue and I had to run . `sudo apt-get install python3-mpi4py`. After this the installation worked perfectly. I am not sure if this is an anomaly and that it won't happen in properly configured workstations. I also am not a 100% sure about why this worked (I am a linux noob). So I will leave it to your discretion whether this is something you want to add to the documentation.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/745#issuecomment-525114027
https://github.com/su2code/SU2/issues/747#issuecomment-516786129:282,Modifiability,config,configfile,282,"Well thats not really an issue. Its just a conceptual thing. Usually what you want to do with an container is to run something from the outside like; ```; ./container_binary <arguments>; ```; or to be more specific, like I did with the singularity container; ```; ./su2.sif SU2_CFD configfile; ```; This way you can also run the python scripts; ```; ./su2.sif parallel_computation.py -f configfile; ```; This works well in serial, however, if you want to run it in parallel you probably should use mpirun from the host system (actually I have no idea what happens if you run mpirun inside of the container, but I am pretty sure that it won't work properly on a cluster). But: at the moment the python scripts do exactly that at the moment, they call the binaries using mpirun in the container.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/747#issuecomment-516786129
https://github.com/su2code/SU2/issues/747#issuecomment-516786129:387,Modifiability,config,configfile,387,"Well thats not really an issue. Its just a conceptual thing. Usually what you want to do with an container is to run something from the outside like; ```; ./container_binary <arguments>; ```; or to be more specific, like I did with the singularity container; ```; ./su2.sif SU2_CFD configfile; ```; This way you can also run the python scripts; ```; ./su2.sif parallel_computation.py -f configfile; ```; This works well in serial, however, if you want to run it in parallel you probably should use mpirun from the host system (actually I have no idea what happens if you run mpirun inside of the container, but I am pretty sure that it won't work properly on a cluster). But: at the moment the python scripts do exactly that at the moment, they call the binaries using mpirun in the container.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/747#issuecomment-516786129
https://github.com/su2code/SU2/issues/747#issuecomment-519829012:303,Integrability,interface,interface,303,"While playing around with the singularity containers a little bit, what do you think about this solution?. Execute the python script inside the container with the python on the host; ~~~~; singularity exec su2_container.sif cat /SU2/bin/SU2_PY/parallel_computation.py | python3; ~~~~. Adjust the python interface (SU2_PY/SU2/run/interface.py) to execute the container:; ~~~~; # set mpi command; if user_defined:; mpi_Command = os.environ['SU2_MPI_COMMAND']; elif slurm_job:; mpi_Command = 'srun -n %i %s'; elif singularity_job:; mpi_Command = 'mpirun -n %i singularity exec su2_container.sif %s'; elif not which('mpirun') is None:; mpi_Command = 'mpirun -n %i %s'; elif not which('mpiexec') is None:; mpi_Command = 'mpiexec -n %i %s'; else:; mpi_Command = ''; ~~~~. Just need to make sure that the hostfile is also included in the mpirun command if run on multiple nodes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/747#issuecomment-519829012
https://github.com/su2code/SU2/issues/747#issuecomment-519829012:329,Integrability,interface,interface,329,"While playing around with the singularity containers a little bit, what do you think about this solution?. Execute the python script inside the container with the python on the host; ~~~~; singularity exec su2_container.sif cat /SU2/bin/SU2_PY/parallel_computation.py | python3; ~~~~. Adjust the python interface (SU2_PY/SU2/run/interface.py) to execute the container:; ~~~~; # set mpi command; if user_defined:; mpi_Command = os.environ['SU2_MPI_COMMAND']; elif slurm_job:; mpi_Command = 'srun -n %i %s'; elif singularity_job:; mpi_Command = 'mpirun -n %i singularity exec su2_container.sif %s'; elif not which('mpirun') is None:; mpi_Command = 'mpirun -n %i %s'; elif not which('mpiexec') is None:; mpi_Command = 'mpiexec -n %i %s'; else:; mpi_Command = ''; ~~~~. Just need to make sure that the hostfile is also included in the mpirun command if run on multiple nodes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/747#issuecomment-519829012
https://github.com/su2code/SU2/issues/748#issuecomment-526146883:116,Availability,error,error,116,"Hey @talbring, currently the 'Trigger build' function for non-PR branches seems to not work. @cvencro and I get the error message `Oh no! You tried to trigger a build for su2code/SU2 but the request was rejected. ` . Do you know more about it? Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/748#issuecomment-526146883
https://github.com/su2code/SU2/issues/748#issuecomment-526146883:122,Integrability,message,message,122,"Hey @talbring, currently the 'Trigger build' function for non-PR branches seems to not work. @cvencro and I get the error message `Oh no! You tried to trigger a build for su2code/SU2 but the request was rejected. ` . Do you know more about it? Thanks",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/748#issuecomment-526146883
https://github.com/su2code/SU2/issues/748#issuecomment-526150574:157,Deployability,configurat,configuration,157,"You have to add that particular branch to the .travis.yml file.; See https://travis-ci.org/su2code/SU2/requests (Branch ""feature_STLwriter"" not included per configuration.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/748#issuecomment-526150574
https://github.com/su2code/SU2/issues/748#issuecomment-526150574:157,Modifiability,config,configuration,157,"You have to add that particular branch to the .travis.yml file.; See https://travis-ci.org/su2code/SU2/requests (Branch ""feature_STLwriter"" not included per configuration.)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/748#issuecomment-526150574
https://github.com/su2code/SU2/pull/751#issuecomment-518274692:37,Safety,avoid,avoidable,37,@pcarruscag I would not call that an avoidable bug considering the fact that the regression test passed.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518274692
https://github.com/su2code/SU2/pull/751#issuecomment-518274692:92,Testability,test,test,92,@pcarruscag I would not call that an avoidable bug considering the fact that the regression test passed.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518274692
https://github.com/su2code/SU2/pull/751#issuecomment-518277470:46,Deployability,update,updated,46,It passed because the config options were not updated and so no mesh deformation was specified for any of the FSI cases.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518277470
https://github.com/su2code/SU2/pull/751#issuecomment-518277470:22,Modifiability,config,config,22,It passed because the config options were not updated and so no mesh deformation was specified for any of the FSI cases.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518277470
https://github.com/su2code/SU2/pull/751#issuecomment-518279551:32,Testability,test,test,32,If this has no influence on the test values then we should change these cases I would say.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518279551
https://github.com/su2code/SU2/pull/751#issuecomment-518454391:81,Testability,test,tests,81,Let’s try to keep it positive here.. @talbring has an interesting point that the tests should show some sensitivity to major changes like the grid deformation not being specified. Can they be made more sensitive to this?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518454391
https://github.com/su2code/SU2/pull/751#issuecomment-518536145:265,Availability,error,error,265,"I agree, but some do [pick up](https://github.com/su2code/SU2/commits/develop/TestCases/disc_adj_fsi/Airfoil_2d/config.cfg) those changes, just not all of them. Anyway, you'll notice I put an assert for the condition that was causing the problem instead of an ""mpi error"". That is inline with the philosophy that errors/exceptions are to deal with user errors and asserts to help debugging (they are ignored with -DNDEBUG). I can off-course change it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518536145
https://github.com/su2code/SU2/pull/751#issuecomment-518536145:313,Availability,error,errors,313,"I agree, but some do [pick up](https://github.com/su2code/SU2/commits/develop/TestCases/disc_adj_fsi/Airfoil_2d/config.cfg) those changes, just not all of them. Anyway, you'll notice I put an assert for the condition that was causing the problem instead of an ""mpi error"". That is inline with the philosophy that errors/exceptions are to deal with user errors and asserts to help debugging (they are ignored with -DNDEBUG). I can off-course change it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518536145
https://github.com/su2code/SU2/pull/751#issuecomment-518536145:353,Availability,error,errors,353,"I agree, but some do [pick up](https://github.com/su2code/SU2/commits/develop/TestCases/disc_adj_fsi/Airfoil_2d/config.cfg) those changes, just not all of them. Anyway, you'll notice I put an assert for the condition that was causing the problem instead of an ""mpi error"". That is inline with the philosophy that errors/exceptions are to deal with user errors and asserts to help debugging (they are ignored with -DNDEBUG). I can off-course change it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518536145
https://github.com/su2code/SU2/pull/751#issuecomment-518536145:112,Modifiability,config,config,112,"I agree, but some do [pick up](https://github.com/su2code/SU2/commits/develop/TestCases/disc_adj_fsi/Airfoil_2d/config.cfg) those changes, just not all of them. Anyway, you'll notice I put an assert for the condition that was causing the problem instead of an ""mpi error"". That is inline with the philosophy that errors/exceptions are to deal with user errors and asserts to help debugging (they are ignored with -DNDEBUG). I can off-course change it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518536145
https://github.com/su2code/SU2/pull/751#issuecomment-518536145:78,Testability,Test,TestCases,78,"I agree, but some do [pick up](https://github.com/su2code/SU2/commits/develop/TestCases/disc_adj_fsi/Airfoil_2d/config.cfg) those changes, just not all of them. Anyway, you'll notice I put an assert for the condition that was causing the problem instead of an ""mpi error"". That is inline with the philosophy that errors/exceptions are to deal with user errors and asserts to help debugging (they are ignored with -DNDEBUG). I can off-course change it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518536145
https://github.com/su2code/SU2/pull/751#issuecomment-518536145:192,Testability,assert,assert,192,"I agree, but some do [pick up](https://github.com/su2code/SU2/commits/develop/TestCases/disc_adj_fsi/Airfoil_2d/config.cfg) those changes, just not all of them. Anyway, you'll notice I put an assert for the condition that was causing the problem instead of an ""mpi error"". That is inline with the philosophy that errors/exceptions are to deal with user errors and asserts to help debugging (they are ignored with -DNDEBUG). I can off-course change it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518536145
https://github.com/su2code/SU2/pull/751#issuecomment-518536145:364,Testability,assert,asserts,364,"I agree, but some do [pick up](https://github.com/su2code/SU2/commits/develop/TestCases/disc_adj_fsi/Airfoil_2d/config.cfg) those changes, just not all of them. Anyway, you'll notice I put an assert for the condition that was causing the problem instead of an ""mpi error"". That is inline with the philosophy that errors/exceptions are to deal with user errors and asserts to help debugging (they are ignored with -DNDEBUG). I can off-course change it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/751#issuecomment-518536145
https://github.com/su2code/SU2/pull/752#issuecomment-524374294:100,Modifiability,variab,variables,100,"Thanks for the reviews guys. At the moment the optimization framework does not support the topology variables, there is a script in SU2_PY for this feature that runs a testcase with hardcoded parameters...; It is not an easy thing to run a tutorial for :/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/752#issuecomment-524374294
https://github.com/su2code/SU2/pull/752#issuecomment-524374294:47,Performance,optimiz,optimization,47,"Thanks for the reviews guys. At the moment the optimization framework does not support the topology variables, there is a script in SU2_PY for this feature that runs a testcase with hardcoded parameters...; It is not an easy thing to run a tutorial for :/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/752#issuecomment-524374294
https://github.com/su2code/SU2/pull/752#issuecomment-524374294:168,Testability,test,testcase,168,"Thanks for the reviews guys. At the moment the optimization framework does not support the topology variables, there is a script in SU2_PY for this feature that runs a testcase with hardcoded parameters...; It is not an easy thing to run a tutorial for :/",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/752#issuecomment-524374294
https://github.com/su2code/SU2/pull/753#issuecomment-526546118:200,Energy Efficiency,efficient,efficient,200,"@rsanfer , I deleted CFEAFSIBoundVariable and kept its data in CFEABoundVariable because:; - It would require two vertex maps to be build, one for vertices another for interfaces.; - It would be less efficient memory wise, the vertex map is size O(N) the number of vertices is O(N^(2/3)) in the worst case, which means eventually having two maps is worse.; - Most FSI cases have a large interface and small fixed boundaries, allocating FSI tractions for the latter is not so bad. I also removed CDiscAdjMeshVariable, as it was empty, and kept only its ""Bound"" counterpart. With this vertex allocation / mapping strategy we always need to instantiate the ""Bound"" version of the class so if the intermediates are empty they can be omitted. Please review the changes and if you have some more thorough tests run them or send them over to me.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-526546118
https://github.com/su2code/SU2/pull/753#issuecomment-526546118:168,Integrability,interface,interfaces,168,"@rsanfer , I deleted CFEAFSIBoundVariable and kept its data in CFEABoundVariable because:; - It would require two vertex maps to be build, one for vertices another for interfaces.; - It would be less efficient memory wise, the vertex map is size O(N) the number of vertices is O(N^(2/3)) in the worst case, which means eventually having two maps is worse.; - Most FSI cases have a large interface and small fixed boundaries, allocating FSI tractions for the latter is not so bad. I also removed CDiscAdjMeshVariable, as it was empty, and kept only its ""Bound"" counterpart. With this vertex allocation / mapping strategy we always need to instantiate the ""Bound"" version of the class so if the intermediates are empty they can be omitted. Please review the changes and if you have some more thorough tests run them or send them over to me.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-526546118
https://github.com/su2code/SU2/pull/753#issuecomment-526546118:387,Integrability,interface,interface,387,"@rsanfer , I deleted CFEAFSIBoundVariable and kept its data in CFEABoundVariable because:; - It would require two vertex maps to be build, one for vertices another for interfaces.; - It would be less efficient memory wise, the vertex map is size O(N) the number of vertices is O(N^(2/3)) in the worst case, which means eventually having two maps is worse.; - Most FSI cases have a large interface and small fixed boundaries, allocating FSI tractions for the latter is not so bad. I also removed CDiscAdjMeshVariable, as it was empty, and kept only its ""Bound"" counterpart. With this vertex allocation / mapping strategy we always need to instantiate the ""Bound"" version of the class so if the intermediates are empty they can be omitted. Please review the changes and if you have some more thorough tests run them or send them over to me.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-526546118
https://github.com/su2code/SU2/pull/753#issuecomment-526546118:799,Testability,test,tests,799,"@rsanfer , I deleted CFEAFSIBoundVariable and kept its data in CFEABoundVariable because:; - It would require two vertex maps to be build, one for vertices another for interfaces.; - It would be less efficient memory wise, the vertex map is size O(N) the number of vertices is O(N^(2/3)) in the worst case, which means eventually having two maps is worse.; - Most FSI cases have a large interface and small fixed boundaries, allocating FSI tractions for the latter is not so bad. I also removed CDiscAdjMeshVariable, as it was empty, and kept only its ""Bound"" counterpart. With this vertex allocation / mapping strategy we always need to instantiate the ""Bound"" version of the class so if the intermediates are empty they can be omitted. Please review the changes and if you have some more thorough tests run them or send them over to me.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-526546118
https://github.com/su2code/SU2/pull/753#issuecomment-538218606:940,Modifiability,refactor,refactoring,940,"> I want to be done with this PR folks... This is really tiring to maintain so if you don't want it please just tell me...; > Can we agree on:; > Instead of CSolver having the `node` field it will have a pure virtual function `CVariable* GetNodes()`, derived solvers need to implement this method and have a `nodes` field of the most appropriate type (e.g. CEulerVariable for CEulerSolver).; > ; > I know some of you do not like the name `nodes` but there is something to be said about consistency (that has always been the name) and I do not think changing a generic name for another generic name justifies breaking the formatting everywhere and having needlessly long calls to get some data. In the interest of keeping the PRs moving, I am ok with this. It will also be natural for folks in the short term to learn the new system, since everyone is already accustomed to using the solver->node* construct. We can always go for a targeted refactoring later separate from the changes in this PR if we would like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-538218606
https://github.com/su2code/SU2/pull/753#issuecomment-538218606:811,Usability,learn,learn,811,"> I want to be done with this PR folks... This is really tiring to maintain so if you don't want it please just tell me...; > Can we agree on:; > Instead of CSolver having the `node` field it will have a pure virtual function `CVariable* GetNodes()`, derived solvers need to implement this method and have a `nodes` field of the most appropriate type (e.g. CEulerVariable for CEulerSolver).; > ; > I know some of you do not like the name `nodes` but there is something to be said about consistency (that has always been the name) and I do not think changing a generic name for another generic name justifies breaking the formatting everywhere and having needlessly long calls to get some data. In the interest of keeping the PRs moving, I am ok with this. It will also be natural for folks in the short term to learn the new system, since everyone is already accustomed to using the solver->node* construct. We can always go for a targeted refactoring later separate from the changes in this PR if we would like.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-538218606
https://github.com/su2code/SU2/pull/753#issuecomment-541934596:265,Integrability,depend,depends,265,"Now that I am updating #790 to work with the new structure from this PR (#753), I am seeing that the aligned_alloc() function is not well defined on mac, so xcode/llvm builds are not working on mac at the moment. There are some issue related to C vs C++ with that (depends on the standard you choose for C or C++, 11 or 17, apparently). Might be some ways around it from reading comments by others on the issue: https://github.com/marian-nmt/marian-dev/issues/227. @pcarruscag : can you give this a quick look when you have some time? Thanks!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/753#issuecomment-541934596
https://github.com/su2code/SU2/issues/754#issuecomment-519503808:85,Performance,optimiz,optimization,85,I am not familiar with cygwin but maybe you compiling with debug options (-g) ? What optimization level are you using?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519503808
https://github.com/su2code/SU2/issues/754#issuecomment-519654913:29,Deployability,install,installation,29,"Hi,; I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that. For reference I attach my config.log file. [config.log](https://github.com/su2code/SU2/files/3483335/config.log)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519654913
https://github.com/su2code/SU2/issues/754#issuecomment-519654913:217,Modifiability,config,config,217,"Hi,; I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that. For reference I attach my config.log file. [config.log](https://github.com/su2code/SU2/files/3483335/config.log)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519654913
https://github.com/su2code/SU2/issues/754#issuecomment-519654913:235,Modifiability,config,config,235,"Hi,; I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that. For reference I attach my config.log file. [config.log](https://github.com/su2code/SU2/files/3483335/config.log)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519654913
https://github.com/su2code/SU2/issues/754#issuecomment-519654913:292,Modifiability,config,config,292,"Hi,; I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that. For reference I attach my config.log file. [config.log](https://github.com/su2code/SU2/files/3483335/config.log)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519654913
https://github.com/su2code/SU2/issues/754#issuecomment-519654913:224,Testability,log,log,224,"Hi,; I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that. For reference I attach my config.log file. [config.log](https://github.com/su2code/SU2/files/3483335/config.log)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519654913
https://github.com/su2code/SU2/issues/754#issuecomment-519654913:242,Testability,log,log,242,"Hi,; I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that. For reference I attach my config.log file. [config.log](https://github.com/su2code/SU2/files/3483335/config.log)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519654913
https://github.com/su2code/SU2/issues/754#issuecomment-519654913:299,Testability,log,log,299,"Hi,; I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that. For reference I attach my config.log file. [config.log](https://github.com/su2code/SU2/files/3483335/config.log)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519654913
https://github.com/su2code/SU2/issues/754#issuecomment-519737534:76,Performance,optimiz,optimization,76,> miliar with cygwin but maybe you compiling with debug options (-g) ? What optimization level are you using?. I don't use any build optimizations particularly at all. I'll check it and try to add some optimizations as your instruction. Thank you.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737534
https://github.com/su2code/SU2/issues/754#issuecomment-519737534:133,Performance,optimiz,optimizations,133,> miliar with cygwin but maybe you compiling with debug options (-g) ? What optimization level are you using?. I don't use any build optimizations particularly at all. I'll check it and try to add some optimizations as your instruction. Thank you.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737534
https://github.com/su2code/SU2/issues/754#issuecomment-519737534:202,Performance,optimiz,optimizations,202,> miliar with cygwin but maybe you compiling with debug options (-g) ? What optimization level are you using?. I don't use any build optimizations particularly at all. I'll check it and try to add some optimizations as your instruction. Thank you.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737534
https://github.com/su2code/SU2/issues/754#issuecomment-519737756:33,Deployability,install,installation,33,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). The fllowing link may help us; https://stackoverflow.com/questions/1042773/gcc-c-hello-world-program-exe-is-500kb-big-when-compiled-on-windows-how",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737756
https://github.com/su2code/SU2/issues/754#issuecomment-519737756:228,Modifiability,config,config,228,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). The fllowing link may help us; https://stackoverflow.com/questions/1042773/gcc-c-hello-world-program-exe-is-500kb-big-when-compiled-on-windows-how",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737756
https://github.com/su2code/SU2/issues/754#issuecomment-519737756:253,Modifiability,config,config,253,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). The fllowing link may help us; https://stackoverflow.com/questions/1042773/gcc-c-hello-world-program-exe-is-500kb-big-when-compiled-on-windows-how",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737756
https://github.com/su2code/SU2/issues/754#issuecomment-519737756:310,Modifiability,config,config,310,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). The fllowing link may help us; https://stackoverflow.com/questions/1042773/gcc-c-hello-world-program-exe-is-500kb-big-when-compiled-on-windows-how",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737756
https://github.com/su2code/SU2/issues/754#issuecomment-519737756:235,Testability,log,log,235,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). The fllowing link may help us; https://stackoverflow.com/questions/1042773/gcc-c-hello-world-program-exe-is-500kb-big-when-compiled-on-windows-how",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737756
https://github.com/su2code/SU2/issues/754#issuecomment-519737756:260,Testability,log,log,260,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). The fllowing link may help us; https://stackoverflow.com/questions/1042773/gcc-c-hello-world-program-exe-is-500kb-big-when-compiled-on-windows-how",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737756
https://github.com/su2code/SU2/issues/754#issuecomment-519737756:317,Testability,log,log,317,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). The fllowing link may help us; https://stackoverflow.com/questions/1042773/gcc-c-hello-world-program-exe-is-500kb-big-when-compiled-on-windows-how",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519737756
https://github.com/su2code/SU2/issues/754#issuecomment-519749680:80,Energy Efficiency,reduce,reduces,80,"> 2, g. I follow your instruction and try to rebuil it. The size of SU2_CFD.exe reduces to 596MB. Maybe I need more optimization options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519749680
https://github.com/su2code/SU2/issues/754#issuecomment-519749680:116,Performance,optimiz,optimization,116,"> 2, g. I follow your instruction and try to rebuil it. The size of SU2_CFD.exe reduces to 596MB. Maybe I need more optimization options.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519749680
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:33,Deployability,install,installation,33,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:377,Deployability,install,install-strip,377,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:228,Modifiability,config,config,228,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:253,Modifiability,config,config,253,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:310,Modifiability,config,config,310,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:340,Modifiability,config,configure,340,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:235,Testability,log,log,235,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:260,Testability,log,log,260,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-519762878:317,Testability,log,log,317,"> Hi,; > I made the Cygwin build installation instruction example. I just checked my SU2_CFD.exe and it is 625MB as well. Nevertheless, I have no clue why this is the case and how to solve that.; > ; > For reference I attach my config.log file.; > ; > [config.log](https://github.com/su2code/SU2/files/3483335/config.log). According to the configure file(line 2726), try 'make install-strip' after 'make'. ; The exe will be smaller than before after adding the strip option.; The following link may help. Just have a look at faq 6.3.; https://www.cygwin.com/faq.html; Good luck.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-519762878
https://github.com/su2code/SU2/issues/754#issuecomment-520468420:7,Deployability,install,install-strip,7,**make install-strip** did the job.; I'll add that to the documentation.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/754#issuecomment-520468420
https://github.com/su2code/SU2/pull/756#issuecomment-520705829:284,Modifiability,flexible,flexible,284,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829
https://github.com/su2code/SU2/pull/756#issuecomment-520705829:351,Modifiability,config,config,351,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829
https://github.com/su2code/SU2/pull/756#issuecomment-520705829:69,Safety,avoid,avoid,69,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829
https://github.com/su2code/SU2/pull/756#issuecomment-520705829:296,Usability,clear,clear,296,"I also like the idea of renaming to ""SOLVER"" but I would also say to avoid as much churn as possible in the conditionals throughout the code... looks like a wash when reading through the PR changes (almost as many +'s as -'s). Unless the changes are going to make something much more flexible or clear, I would say just keep Kind_Regime and set it in config postprocessing.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/756#issuecomment-520705829
https://github.com/su2code/SU2/issues/759#issuecomment-528426163:463,Availability,avail,available,463,"@WenyinWei : thanks for the proposal.. this idea has come up several times over the years and there have been a couple of implementations. You might want to see the old PR here, which proposed something similar (it is a pity that we were unable to merge that work). My comments there still apply: . https://github.com/su2code/SU2/pull/172. If it is to go into the main repo, the key is that it is easy to keep updated. It should automatically parse the currently available options in the C++, like the old python-based script did.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/759#issuecomment-528426163
https://github.com/su2code/SU2/issues/759#issuecomment-528426163:410,Deployability,update,updated,410,"@WenyinWei : thanks for the proposal.. this idea has come up several times over the years and there have been a couple of implementations. You might want to see the old PR here, which proposed something similar (it is a pity that we were unable to merge that work). My comments there still apply: . https://github.com/su2code/SU2/pull/172. If it is to go into the main repo, the key is that it is easy to keep updated. It should automatically parse the currently available options in the C++, like the old python-based script did.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/759#issuecomment-528426163
https://github.com/su2code/SU2/issues/759#issuecomment-529714022:301,Availability,reliab,reliable,301,"Hello Economon, here are some of my suggestions for the future convention of comments of the option structure:. 1. __Index__. To illustrate the relationship among so many options, we need to set some reliance relationship manually in the comment lines. Do you think using names of options as index is reliable? I think it will be helpful for code writers, but might not for code readers.; 2. __Relationship__. Here are some kinds of relationship between options. They are needed in comment for auto parsing.; - _Reliance_. Some options may rely on the precedent ones, otherwise they will not be triggered to be used. Furthermore, descendent options may be optional or compulsory. For the optional ones, users don’t have to set the values they need, while for the compulsory ones, users will automatically see the tips of what kinds of options are needed.; - _Mutual Exclusive_. Some options can not coexist together, or their precedent can not coexist together. Maybe option a has precedent A, option b has precedent B. If A and B can not coexist, a and b can’t , too. I wish that there is already such C++ package for our need, even when it just covers the functionality of structuring the relationship net. Do you have any idea of such code that can handle the option relationships easily?. Any supplement?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/759#issuecomment-529714022
https://github.com/su2code/SU2/issues/761#issuecomment-523415869:217,Modifiability,config,config,217,"Hello, @pcarruscag . Thank you for help. I try the examples and they run well. By the way, SU2 v6.2.0 doesn't have the option 'USE_ACCURATE_FLUX_JACOBIANS'. I'm not practised enough to know what it is for. Here is my config.; [cavity.zip](https://github.com/su2code/SU2/files/3525060/cavity.zip); It still diverges on lid-driven cavity flow case, at even a rather low CFL number, like 0.01. However, when I simulate laminar boundary layer case with 0.1 incoming mach number, it is OK, converging very slowly. Regards; Cao J. Z.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/761#issuecomment-523415869
https://github.com/su2code/SU2/issues/761#issuecomment-523511203:422,Safety,avoid,avoid,422,"Hi @cjz667,; I know, that is why I suggested using the current development version. You can read about what that option does in #691. AUSM+up and similar schemes need a reference Mach number, which comes from MACH_NUMBER, apparently if that is 0 they do not do so well.; These settings should get you started: [cavity.txt](https://github.com/su2code/SU2/files/3526060/cavity.txt). I will put a check in the code for v7 to avoid mysterious ""divergence on the first iteration"" problems, I'll leave this issue open to remind me. Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/761#issuecomment-523511203
https://github.com/su2code/SU2/issues/761#issuecomment-540509179:0,Availability,Error,Error,0,Error message for Minf = 0 has been included in #753,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/761#issuecomment-540509179
https://github.com/su2code/SU2/issues/761#issuecomment-540509179:6,Integrability,message,message,6,Error message for Minf = 0 has been included in #753,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/761#issuecomment-540509179
https://github.com/su2code/SU2/pull/762#issuecomment-525359274:120,Deployability,release,release,120,"The window to open additional PRs is going to end today. You can still open new ones, but they will be merged after the release (except bugfixes). . We have quite a bit of PRs open now. Everybody is encouraged to do reviews! Please take that chance.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/762#issuecomment-525359274
https://github.com/su2code/SU2/pull/762#issuecomment-525670354:243,Performance,concurren,concurrent,243,"PR opening window is closed now. Thanks to all the people contributing. . Since we only have a limited amount of time to deal with all the PRs we have to be a bit structured. That means the following:. - Since we only have a limited amount of concurrent Travis jobs we might **manually cancel some jobs** in order to give precedence to PRs which have reviews and are likely to be merged once Travis passes. Please check your branch once in a while to restart the job if necessary. - If you have comments on a PR that you think **should** be addressed before merging, please block the merge by **requesting changes**. - Make use of the **WIP** feature. Especially if you think that you are not able to work on your PR in any ways for a couple of days (including addressing comments). This makes it easier for us to find an order for reviewing/merging.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/762#issuecomment-525670354
https://github.com/su2code/SU2/pull/762#issuecomment-525853193:100,Testability,test,tests,100,"Since we're trying not to clog Travis, Is there a way to prevent Travis from running the regression tests on every push to a branch that is in the PR process?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/762#issuecomment-525853193
https://github.com/su2code/SU2/pull/762#issuecomment-526082617:157,Integrability,message,message,157,@jayantmukho There is no general setting. But you can change the branch in .travis.yml to something else than `develop` or you add `[ci skip]` to the commit message. That will prevent travis from running automatically.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/762#issuecomment-526082617
https://github.com/su2code/SU2/issues/763#issuecomment-524007345:614,Deployability,update,update,614,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
https://github.com/su2code/SU2/issues/763#issuecomment-524007345:744,Deployability,update,update,744,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
https://github.com/su2code/SU2/issues/763#issuecomment-524007345:1129,Integrability,rout,routine,1129,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
https://github.com/su2code/SU2/issues/763#issuecomment-524007345:106,Safety,avoid,avoid,106,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
https://github.com/su2code/SU2/issues/763#issuecomment-524007345:45,Usability,simpl,simplify,45,"Nice analysis @clarkpede. It is true that we simplify the Jacobians at the periodic boundaries, mostly to avoid issues with adding entries to the Jacobian from the neighbors that potentially do not live on our rank and to keep communication costs low (those neighbors are treated explicitly). This could be changed to communicate the full Jacobian.. but I am not sure it is worth the effort/cost. The approximation that is made should still be consistent though, because we only allow one of the repeated periodic nodes to participate in the linear solve with each nonlinear iteration, and then we communicate its update to its periodic pair. In short, the value of the solution should always be the same on periodic points with each iteration update, and if the problem converges to a steady-state (even in time stepping mode), the Jacobian should only affect convergence (the RHS should be the same). You could try the time stepping option with one of the RK methods to see if going fully explicit helps further isolate the issue. It could also be something related to the time step that is communicated. In the SetTime_Step() routine in the flow solver class, we do some special checks for time stepping mode to make sure that the minimum global time step is used in all cells. Might want to print out the dT communicated in the periodic comms or write the dT to the solution file to make sure everything is ok there too. Honestly, I don't think a ton of folks use the time stepping option in general with the FVM solver, so double-checking that it behaves well for a non-periodic problem could shed some light too, unless you have already done that.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-524007345
https://github.com/su2code/SU2/issues/763#issuecomment-548026394:10,Deployability,update,updates,10,"I have no updates here, but I also have done nothing to resolve this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-548026394
https://github.com/su2code/SU2/issues/763#issuecomment-770241115:637,Integrability,synchroniz,synchronize,637,"@clarkpede @economon In my never ending shuffling-code-around I noticed that we do this:; ```; for (unsigned short iPeriodic = 1; iPeriodic <= config->GetnMarker_Periodic()/2; iPeriodic++) {; InitiatePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; CompletePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; }; ```; ... for implicit iterations but not for explicit ones, the purpose of that comm is to:. /*--- Communicate the solution from our master set of periodic; nodes (from the linear solver perspective) to the passive; periodic nodes on the matching face. This is done at the; end of the iteration to synchronize the solution after the; linear solve. ---*/. I imagine the residual is constructed in a way that is consistent for the 2 periodic points, but... The explicit iteration implementation is now in CFVMFlowSolverBase.hpp::Explicit_Iteration_impl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-770241115
https://github.com/su2code/SU2/issues/763#issuecomment-770241115:143,Modifiability,config,config,143,"@clarkpede @economon In my never ending shuffling-code-around I noticed that we do this:; ```; for (unsigned short iPeriodic = 1; iPeriodic <= config->GetnMarker_Periodic()/2; iPeriodic++) {; InitiatePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; CompletePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; }; ```; ... for implicit iterations but not for explicit ones, the purpose of that comm is to:. /*--- Communicate the solution from our master set of periodic; nodes (from the linear solver perspective) to the passive; periodic nodes on the matching face. This is done at the; end of the iteration to synchronize the solution after the; linear solve. ---*/. I imagine the residual is constructed in a way that is consistent for the 2 periodic points, but... The explicit iteration implementation is now in CFVMFlowSolverBase.hpp::Explicit_Iteration_impl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-770241115
https://github.com/su2code/SU2/issues/763#issuecomment-770241115:224,Modifiability,config,config,224,"@clarkpede @economon In my never ending shuffling-code-around I noticed that we do this:; ```; for (unsigned short iPeriodic = 1; iPeriodic <= config->GetnMarker_Periodic()/2; iPeriodic++) {; InitiatePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; CompletePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; }; ```; ... for implicit iterations but not for explicit ones, the purpose of that comm is to:. /*--- Communicate the solution from our master set of periodic; nodes (from the linear solver perspective) to the passive; periodic nodes on the matching face. This is done at the; end of the iteration to synchronize the solution after the; linear solve. ---*/. I imagine the residual is constructed in a way that is consistent for the 2 periodic points, but... The explicit iteration implementation is now in CFVMFlowSolverBase.hpp::Explicit_Iteration_impl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-770241115
https://github.com/su2code/SU2/issues/763#issuecomment-770241115:296,Modifiability,config,config,296,"@clarkpede @economon In my never ending shuffling-code-around I noticed that we do this:; ```; for (unsigned short iPeriodic = 1; iPeriodic <= config->GetnMarker_Periodic()/2; iPeriodic++) {; InitiatePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; CompletePeriodicComms(geometry, config, iPeriodic, PERIODIC_IMPLICIT);; }; ```; ... for implicit iterations but not for explicit ones, the purpose of that comm is to:. /*--- Communicate the solution from our master set of periodic; nodes (from the linear solver perspective) to the passive; periodic nodes on the matching face. This is done at the; end of the iteration to synchronize the solution after the; linear solve. ---*/. I imagine the residual is constructed in a way that is consistent for the 2 periodic points, but... The explicit iteration implementation is now in CFVMFlowSolverBase.hpp::Explicit_Iteration_impl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/763#issuecomment-770241115
https://github.com/su2code/SU2/pull/765#issuecomment-523979583:293,Availability,down,download,293,"The PR looks good but more to @talbring 's point, do we want to conserve a vanilla SST implementation for validation purposes? . I thought about this when I was trying to incorporate some improvements to the SST model that were published in a [2003 paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.460.2814&rep=rep1&type=pdf) by Menter et al. These are small changes in the coefficients but I wasn't sure if I should make the changes to the base SST model or make a new one.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-523979583
https://github.com/su2code/SU2/pull/765#issuecomment-523979583:106,Security,validat,validation,106,"The PR looks good but more to @talbring 's point, do we want to conserve a vanilla SST implementation for validation purposes? . I thought about this when I was trying to incorporate some improvements to the SST model that were published in a [2003 paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.460.2814&rep=rep1&type=pdf) by Menter et al. These are small changes in the coefficients but I wasn't sure if I should make the changes to the base SST model or make a new one.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-523979583
https://github.com/su2code/SU2/pull/765#issuecomment-523996743:211,Modifiability,inherit,inherit,211,"Since most of the magic of turbulence models can be found in the source, you could adopt what we have done for the SA variants and make a new source term only in CNumerics for each new variant (or maybe have it inherit somehow from the existing one and add just an additional term without duplicating). That way, the bools can be left as SST everywhere and only one line is needed to instantiate the correct source term. The checks on SA and SST throughout are mostly because they have 1 and 2 equations, respectively, so all of their variants can still be lumped under checks for just SA and SST type, I think.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-523996743
https://github.com/su2code/SU2/pull/765#issuecomment-524053082:1158,Energy Efficiency,energy,energy,1158,"Guys,. Thanks for your feedback. @pcarruscag, the reason why I made a different enum rather than a boolean USE_SST_SUSTAINING_TERMS is that all different SA versions also have a different enum. So I thought this was more consistent. But if there is a strong preference for an additional boolean, I'm fine with that as well. What we can do is to keep the enum and set the boolean USE_SST_SUSTAINING_TERMS internally and overwrite SST_SUST to SST. @talbring, @jayantmukho, I am in favor of keeping the original version of SST. Although the difference between the models is rather small, basically the addition of one term, the difference in results can be quite significant, especially for relatively low Reynolds numbers and large value of the turbulent intensity. . @economon, you are right that a lot of the checks for SST are actually more general checks for a two equation model. So I think that most, if not all, checks for SST can be replaced be a check for the number of turbulent equations. That is more general as well, in case we want to add additional turbulence models in the future, assuming that an equation is present for the turbulent kinetic energy if the number of turbulence equations is two or bigger.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-524053082
https://github.com/su2code/SU2/pull/765#issuecomment-524053082:23,Usability,feedback,feedback,23,"Guys,. Thanks for your feedback. @pcarruscag, the reason why I made a different enum rather than a boolean USE_SST_SUSTAINING_TERMS is that all different SA versions also have a different enum. So I thought this was more consistent. But if there is a strong preference for an additional boolean, I'm fine with that as well. What we can do is to keep the enum and set the boolean USE_SST_SUSTAINING_TERMS internally and overwrite SST_SUST to SST. @talbring, @jayantmukho, I am in favor of keeping the original version of SST. Although the difference between the models is rather small, basically the addition of one term, the difference in results can be quite significant, especially for relatively low Reynolds numbers and large value of the turbulent intensity. . @economon, you are right that a lot of the checks for SST are actually more general checks for a two equation model. So I think that most, if not all, checks for SST can be replaced be a check for the number of turbulent equations. That is more general as well, in case we want to add additional turbulence models in the future, assuming that an equation is present for the turbulent kinetic energy if the number of turbulence equations is two or bigger.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/765#issuecomment-524053082
https://github.com/su2code/SU2/pull/766#issuecomment-524359236:253,Integrability,rout,routine,253,"> So, really, obtaining the GridVel vector would just be an additional FD computation both for rigid movement and dynamic grids, and a lot of memory savings are possible. Hey @rsanfer, I think that is ok for this PR. After a short search I guess such a routine does not exist yet. Or can you point me to the right direction? ; Otherwise `CVolumetricMovement::ComputeGridVel_from_Coord(..)` would be a naming suggestion. What do think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524359236
https://github.com/su2code/SU2/pull/766#issuecomment-524363232:4,Integrability,rout,routine,4,"The routine you are looking for is probably this one:. `void CPhysicalGeometry::SetGridVelocity(CConfig *config, unsigned long iter)` geometry_structure.cpp:14760 (cannot paste a link, the file is too big)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524363232
https://github.com/su2code/SU2/pull/766#issuecomment-524363232:105,Modifiability,config,config,105,"The routine you are looking for is probably this one:. `void CPhysicalGeometry::SetGridVelocity(CConfig *config, unsigned long iter)` geometry_structure.cpp:14760 (cannot paste a link, the file is too big)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524363232
https://github.com/su2code/SU2/pull/766#issuecomment-524565760:673,Energy Efficiency,adapt,adaptations,673,"Hi @rsanfer and @TobiKattmann , I agree with the more generalised solution for rigid and deforming meshes too and this is excellent timing of #760 to combine the new approach. ; I have FSI cases I can use, but thought it would be a good stepping stone to use fluid-only case to begin with to avoid the coupling terms for this verification. Using dynamic surface movement definitions for the single-zone pitching airfoil test which has previously been used for rigid motion, the primal solutions and gradients from finite differences for both are very similar as expected. Therefore this should be a good reference to check the discrete adjoints for deforming mesh when the adaptations for grid velocities are made using #760.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524565760
https://github.com/su2code/SU2/pull/766#issuecomment-524565760:302,Modifiability,coupling,coupling,302,"Hi @rsanfer and @TobiKattmann , I agree with the more generalised solution for rigid and deforming meshes too and this is excellent timing of #760 to combine the new approach. ; I have FSI cases I can use, but thought it would be a good stepping stone to use fluid-only case to begin with to avoid the coupling terms for this verification. Using dynamic surface movement definitions for the single-zone pitching airfoil test which has previously been used for rigid motion, the primal solutions and gradients from finite differences for both are very similar as expected. Therefore this should be a good reference to check the discrete adjoints for deforming mesh when the adaptations for grid velocities are made using #760.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524565760
https://github.com/su2code/SU2/pull/766#issuecomment-524565760:673,Modifiability,adapt,adaptations,673,"Hi @rsanfer and @TobiKattmann , I agree with the more generalised solution for rigid and deforming meshes too and this is excellent timing of #760 to combine the new approach. ; I have FSI cases I can use, but thought it would be a good stepping stone to use fluid-only case to begin with to avoid the coupling terms for this verification. Using dynamic surface movement definitions for the single-zone pitching airfoil test which has previously been used for rigid motion, the primal solutions and gradients from finite differences for both are very similar as expected. Therefore this should be a good reference to check the discrete adjoints for deforming mesh when the adaptations for grid velocities are made using #760.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524565760
https://github.com/su2code/SU2/pull/766#issuecomment-524565760:292,Safety,avoid,avoid,292,"Hi @rsanfer and @TobiKattmann , I agree with the more generalised solution for rigid and deforming meshes too and this is excellent timing of #760 to combine the new approach. ; I have FSI cases I can use, but thought it would be a good stepping stone to use fluid-only case to begin with to avoid the coupling terms for this verification. Using dynamic surface movement definitions for the single-zone pitching airfoil test which has previously been used for rigid motion, the primal solutions and gradients from finite differences for both are very similar as expected. Therefore this should be a good reference to check the discrete adjoints for deforming mesh when the adaptations for grid velocities are made using #760.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524565760
https://github.com/su2code/SU2/pull/766#issuecomment-524565760:420,Testability,test,test,420,"Hi @rsanfer and @TobiKattmann , I agree with the more generalised solution for rigid and deforming meshes too and this is excellent timing of #760 to combine the new approach. ; I have FSI cases I can use, but thought it would be a good stepping stone to use fluid-only case to begin with to avoid the coupling terms for this verification. Using dynamic surface movement definitions for the single-zone pitching airfoil test which has previously been used for rigid motion, the primal solutions and gradients from finite differences for both are very similar as expected. Therefore this should be a good reference to check the discrete adjoints for deforming mesh when the adaptations for grid velocities are made using #760.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-524565760
https://github.com/su2code/SU2/pull/766#issuecomment-525715240:661,Availability,reliab,reliable,661,"I haven't explicitly checked if they match but for the rigid motion cases the grid velocity is calculated from the transformation matrices and then imposed to update the grid. Therefore if the grid velocities are back calculated from the grid using FD then I would expect them to be close but not exact. For a pitching airfoil case with FFD design variables, the average difference in gradients for an objective function of L/D was within 1% between discrete adjoint and finite differences. This is very similar for both imposed grid velocities in the adjoint preprocessing and with the FD calculation for the grid velocities. So I think the results are pretty reliable for the rigid motion cases using the updated grid velocities calculation. . The deforming grid on the other hand is a different story. I still haven't been able to complete an adjoint run without diverging. More exploring to be done there...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-525715240
https://github.com/su2code/SU2/pull/766#issuecomment-525715240:159,Deployability,update,update,159,"I haven't explicitly checked if they match but for the rigid motion cases the grid velocity is calculated from the transformation matrices and then imposed to update the grid. Therefore if the grid velocities are back calculated from the grid using FD then I would expect them to be close but not exact. For a pitching airfoil case with FFD design variables, the average difference in gradients for an objective function of L/D was within 1% between discrete adjoint and finite differences. This is very similar for both imposed grid velocities in the adjoint preprocessing and with the FD calculation for the grid velocities. So I think the results are pretty reliable for the rigid motion cases using the updated grid velocities calculation. . The deforming grid on the other hand is a different story. I still haven't been able to complete an adjoint run without diverging. More exploring to be done there...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-525715240
https://github.com/su2code/SU2/pull/766#issuecomment-525715240:707,Deployability,update,updated,707,"I haven't explicitly checked if they match but for the rigid motion cases the grid velocity is calculated from the transformation matrices and then imposed to update the grid. Therefore if the grid velocities are back calculated from the grid using FD then I would expect them to be close but not exact. For a pitching airfoil case with FFD design variables, the average difference in gradients for an objective function of L/D was within 1% between discrete adjoint and finite differences. This is very similar for both imposed grid velocities in the adjoint preprocessing and with the FD calculation for the grid velocities. So I think the results are pretty reliable for the rigid motion cases using the updated grid velocities calculation. . The deforming grid on the other hand is a different story. I still haven't been able to complete an adjoint run without diverging. More exploring to be done there...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-525715240
https://github.com/su2code/SU2/pull/766#issuecomment-525715240:348,Modifiability,variab,variables,348,"I haven't explicitly checked if they match but for the rigid motion cases the grid velocity is calculated from the transformation matrices and then imposed to update the grid. Therefore if the grid velocities are back calculated from the grid using FD then I would expect them to be close but not exact. For a pitching airfoil case with FFD design variables, the average difference in gradients for an objective function of L/D was within 1% between discrete adjoint and finite differences. This is very similar for both imposed grid velocities in the adjoint preprocessing and with the FD calculation for the grid velocities. So I think the results are pretty reliable for the rigid motion cases using the updated grid velocities calculation. . The deforming grid on the other hand is a different story. I still haven't been able to complete an adjoint run without diverging. More exploring to be done there...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-525715240
https://github.com/su2code/SU2/pull/766#issuecomment-532394741:18,Security,validat,validation,18,"A little gradient validation using the added Testcase (comp euler, 150 timesteps, pitching airfoil, FFD points as DV, Efficiency obj function). . ![gradient](https://user-images.githubusercontent.com/31306376/65078088-96d24900-d99c-11e9-9fef-1fd1a73dd759.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-532394741
https://github.com/su2code/SU2/pull/766#issuecomment-532394741:45,Testability,Test,Testcase,45,"A little gradient validation using the added Testcase (comp euler, 150 timesteps, pitching airfoil, FFD points as DV, Efficiency obj function). . ![gradient](https://user-images.githubusercontent.com/31306376/65078088-96d24900-d99c-11e9-9fef-1fd1a73dd759.png)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-532394741
https://github.com/su2code/SU2/pull/766#issuecomment-533541630:18,Security,validat,validation,18,@TobiKattmann The validation looks perfect. Happy that it works now.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-533541630
https://github.com/su2code/SU2/pull/766#issuecomment-534026640:21,Testability,Test,Testcases,21,"Alright, the su2code/Testcases repo is already merged, .travis.yml is reverted. If there are no further request than this can be merged from my standpoint. ; Big thanks to @cvencro for the collaboration :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/766#issuecomment-534026640
https://github.com/su2code/SU2/pull/767#issuecomment-524348109:42,Testability,test,test,42,"@cvencro, @TobiKattmann You probably have test case ready to go. Would you mind writing a small tutorial? Because at the moment we have no unsteady cases there ...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-524348109
https://github.com/su2code/SU2/pull/767#issuecomment-526666570:117,Modifiability,config,config,117,"Thank you all for the review and comments. I've added a test case with this pull request for a pitching airfoil. The config is in the main repository and the mesh is added in the TestCases repository with the same branch name. Can both pleased be merged in together? Also about the tutorial request, I'll have a go at writing one in a feature branch of the website repository.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-526666570
https://github.com/su2code/SU2/pull/767#issuecomment-526666570:56,Testability,test,test,56,"Thank you all for the review and comments. I've added a test case with this pull request for a pitching airfoil. The config is in the main repository and the mesh is added in the TestCases repository with the same branch name. Can both pleased be merged in together? Also about the tutorial request, I'll have a go at writing one in a feature branch of the website repository.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-526666570
https://github.com/su2code/SU2/pull/767#issuecomment-526666570:179,Testability,Test,TestCases,179,"Thank you all for the review and comments. I've added a test case with this pull request for a pitching airfoil. The config is in the main repository and the mesh is added in the TestCases repository with the same branch name. Can both pleased be merged in together? Also about the tutorial request, I'll have a go at writing one in a feature branch of the website repository.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-526666570
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:905,Availability,error,error,905,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:259,Modifiability,variab,variable,259,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:201,Security,access,access,201,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:51,Testability,Test,Testcase,51,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:78,Testability,test,tests,78,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:282,Testability,Test,Testcase,282,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:442,Testability,test,tests,442,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:466,Testability,Test,Testcase,466,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:536,Testability,Test,Testcase,536,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:629,Testability,Test,Testcase,629,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527167827:489,Usability,simpl,simply,489,"Hi @cvencro , I think it would be good to add that Testcase to the regression tests to 'guard' the code. ; I actually wanted to do that real quick but it guess that with `SINGLEZONE_DRIVER` one cannot access `TIME_ITER`, only `EXT_ITER` with the` .test_iter` variable of the python Testcase class. Not sure if that is addressed in #724 , maybe @rsanfer or @talbring can give a quick info as this is probably affecting all unsteady regression tests. . Concerning the Testcase repo: You can simply open a PR for the develop branch of the Testcase repo, and refer to the corresponding PR here (and vice versa). As far as I know the Testcase repo is not protected, i.e. you can merge without any check. And as it is just one added mesh and no other change you could do it right now from my point of view. Another point: What about the rotating_frame for incompressible flow? If it is untested I would like an error catch in place that this feature can't be used out of the box.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527167827
https://github.com/su2code/SU2/pull/767#issuecomment-527185086:139,Energy Efficiency,adapt,adapt,139,@TobiKattmann Just test whether it works and gives the same results. The regression test should be added still with the old driver. I will adapt it accordingly.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527185086
https://github.com/su2code/SU2/pull/767#issuecomment-527185086:139,Modifiability,adapt,adapt,139,@TobiKattmann Just test whether it works and gives the same results. The regression test should be added still with the old driver. I will adapt it accordingly.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527185086
https://github.com/su2code/SU2/pull/767#issuecomment-527185086:19,Testability,test,test,19,@TobiKattmann Just test whether it works and gives the same results. The regression test should be added still with the old driver. I will adapt it accordingly.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527185086
https://github.com/su2code/SU2/pull/767#issuecomment-527185086:84,Testability,test,test,84,@TobiKattmann Just test whether it works and gives the same results. The regression test should be added still with the old driver. I will adapt it accordingly.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527185086
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:494,Deployability,Update,Update,494,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:25,Testability,Test,Testcase,25,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:210,Testability,Test,Testcase,210,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:344,Testability,Test,Testcase,344,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:385,Testability,Test,TestCases,385,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:425,Testability,test,tests,425,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:454,Testability,Test,Testcase,454,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527351447:510,Testability,Test,Testcases,510,"@cvencro & @talbring, Ok Testcase added using the old driver for serial and parallel regression. Residuals are identical for both drivers new & old (which should resolve your question @rsanfer, right?). In the Testcase .cfg the new driver options are commented out such that switching is a matter of (un)commenting lines. I put up a PR for the Testcase here https://github.com/su2code/TestCases/pull/36 and if the regression tests pass I would merge the Testcase PR and revert the .travis.yml. Update: su2code/Testcases is merged. So once my comment above concerning rotating frame is addressed this could be merged from my point of view.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527351447
https://github.com/su2code/SU2/pull/767#issuecomment-527542828:403,Availability,error,error,403,"@TobiKattmann , thanks for the regression test. The unsteady grid motion simulations work with the updates to the ALE formulation. The rotating frame is solved as a steady problem with an added source term, an initial implementation of which has been implemented for the incompressible solver but that is still a work in progress and probably outside the scope of this PR as it stands, so I've added an error catch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527542828
https://github.com/su2code/SU2/pull/767#issuecomment-527542828:99,Deployability,update,updates,99,"@TobiKattmann , thanks for the regression test. The unsteady grid motion simulations work with the updates to the ALE formulation. The rotating frame is solved as a steady problem with an added source term, an initial implementation of which has been implemented for the incompressible solver but that is still a work in progress and probably outside the scope of this PR as it stands, so I've added an error catch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527542828
https://github.com/su2code/SU2/pull/767#issuecomment-527542828:42,Testability,test,test,42,"@TobiKattmann , thanks for the regression test. The unsteady grid motion simulations work with the updates to the ALE formulation. The rotating frame is solved as a steady problem with an added source term, an initial implementation of which has been implemented for the incompressible solver but that is still a work in progress and probably outside the scope of this PR as it stands, so I've added an error catch.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/767#issuecomment-527542828
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:473,Energy Efficiency,adapt,adapts,473,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:148,Integrability,wrap,wrapper,148,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:309,Integrability,interface,interface,309,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:531,Integrability,interface,interface,531,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:583,Integrability,rout,routines,583,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:473,Modifiability,adapt,adapts,473,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:249,Performance,perform,performance,249,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524932838:215,Testability,test,testing,215,"Agreed that libraries are great as long as they are optional - sometimes we need them for highly specialized tasks. Btw, is it possible to use your wrapper for other external solvers? For example, it might be worth testing with PETSc again soon for performance reasons. I would encourage making a single base interface for external solvers that talks to the existing structure in SU2, which never needs to change, and then creating the implementations for each solver that adapts the particular solver data structures to the fixed interface (similar with the grid readers and output routines). Is this easy to do now?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524932838
https://github.com/su2code/SU2/pull/771#issuecomment-524942947:255,Integrability,wrap,wrapper,255,"Thanks for the comments guys.; I think for preconditioners CSysMatrix already gives default hooks to attach external solvers to, there is a build method and a compute method, and that was the logic I followed for this.; All the operations I do inside the wrapper are solver specific, the only thing that could eventually be abstracted from there is the conversion between our matrix format and the one PaStiX requires (which is a mere re-ordering so the column indices are ordered according to global index in linear partitioning, unfortunately this is enough to warrant a full copy).; My reason not to have gone with PETSc is [this table](https://www.mcs.anl.gov/petsc/documentation/linearsolvertable.html) that shows very little compatibility with the SU2 block sparse matrix format.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524942947
https://github.com/su2code/SU2/pull/771#issuecomment-524942947:192,Testability,log,logic,192,"Thanks for the comments guys.; I think for preconditioners CSysMatrix already gives default hooks to attach external solvers to, there is a build method and a compute method, and that was the logic I followed for this.; All the operations I do inside the wrapper are solver specific, the only thing that could eventually be abstracted from there is the conversion between our matrix format and the one PaStiX requires (which is a mere re-ordering so the column indices are ordered according to global index in linear partitioning, unfortunately this is enough to warrant a full copy).; My reason not to have gone with PETSc is [this table](https://www.mcs.anl.gov/petsc/documentation/linearsolvertable.html) that shows very little compatibility with the SU2 block sparse matrix format.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-524942947
https://github.com/su2code/SU2/pull/771#issuecomment-525350424:35,Integrability,depend,dependencies,35,@pcarruscag Do you want to add the dependencies to meson in this PR?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525350424
https://github.com/su2code/SU2/pull/771#issuecomment-525356822:155,Modifiability,variab,variables,155,Ah I just mean adding it to the meson.build file as an option and to provide the paths to headers/libraries. I am not in favor of doing it via environment variables ...,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525356822
https://github.com/su2code/SU2/pull/771#issuecomment-525370429:265,Modifiability,variab,variables,265,"Ok I'll see what I can do. On Tue, 27 Aug 2019, 16:33 Tim Albring, <notifications@github.com> wrote:. > Ah I just mean adding it to the meson.build file as an option and to; > provide the paths to headers/libraries. I am not in favor of doing it via; > environment variables ...; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/771?email_source=notifications&email_token=AJCOXN5NB6Z4366OSSPH373QGVCNPA5CNFSM4IPIUEI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5IE6FQ#issuecomment-525356822>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AJCOXNYGAQR35RW43NXLW3DQGVCNPANCNFSM4IPIUEIQ>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525370429
https://github.com/su2code/SU2/pull/771#issuecomment-525688282:202,Deployability,install,installation,202,"@talbring how do you want the ""interface"" to work for the user?; Do they modify meson.build?; Do they define environment variables for the root folder of each dependency? (I guess not); Do we force the installation directory? (not a good idea since some components can be installed with apt-get); Do we force them to link only statically / dynamically?; Also are you aware that linker flags for BLAS can be compiler dependent, especially for MKL?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525688282
https://github.com/su2code/SU2/pull/771#issuecomment-525688282:272,Deployability,install,installed,272,"@talbring how do you want the ""interface"" to work for the user?; Do they modify meson.build?; Do they define environment variables for the root folder of each dependency? (I guess not); Do we force the installation directory? (not a good idea since some components can be installed with apt-get); Do we force them to link only statically / dynamically?; Also are you aware that linker flags for BLAS can be compiler dependent, especially for MKL?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525688282
https://github.com/su2code/SU2/pull/771#issuecomment-525688282:31,Integrability,interface,interface,31,"@talbring how do you want the ""interface"" to work for the user?; Do they modify meson.build?; Do they define environment variables for the root folder of each dependency? (I guess not); Do we force the installation directory? (not a good idea since some components can be installed with apt-get); Do we force them to link only statically / dynamically?; Also are you aware that linker flags for BLAS can be compiler dependent, especially for MKL?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525688282
https://github.com/su2code/SU2/pull/771#issuecomment-525688282:159,Integrability,depend,dependency,159,"@talbring how do you want the ""interface"" to work for the user?; Do they modify meson.build?; Do they define environment variables for the root folder of each dependency? (I guess not); Do we force the installation directory? (not a good idea since some components can be installed with apt-get); Do we force them to link only statically / dynamically?; Also are you aware that linker flags for BLAS can be compiler dependent, especially for MKL?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525688282
https://github.com/su2code/SU2/pull/771#issuecomment-525688282:416,Integrability,depend,dependent,416,"@talbring how do you want the ""interface"" to work for the user?; Do they modify meson.build?; Do they define environment variables for the root folder of each dependency? (I guess not); Do we force the installation directory? (not a good idea since some components can be installed with apt-get); Do we force them to link only statically / dynamically?; Also are you aware that linker flags for BLAS can be compiler dependent, especially for MKL?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525688282
https://github.com/su2code/SU2/pull/771#issuecomment-525688282:121,Modifiability,variab,variables,121,"@talbring how do you want the ""interface"" to work for the user?; Do they modify meson.build?; Do they define environment variables for the root folder of each dependency? (I guess not); Do we force the installation directory? (not a good idea since some components can be installed with apt-get); Do we force them to link only statically / dynamically?; Also are you aware that linker flags for BLAS can be compiler dependent, especially for MKL?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525688282
https://github.com/su2code/SU2/pull/771#issuecomment-525694678:32,Modifiability,config,config,32,The standard way should use pkg-config. I see that pastix and BLAS both provide the required files. Should be quite easy actually to add them.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525694678
https://github.com/su2code/SU2/pull/771#issuecomment-525701307:131,Modifiability,config,config,131,"What about clusters?. On Wed, 28 Aug 2019, 12:02 Tim Albring, <notifications@github.com> wrote:. > The standard way should use pkg-config. I see that pastix and BLAS both; > provide the required files. Should be quite easy actually to add them.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/771?email_source=notifications&email_token=AJCOXN4ND46DXNDEFQ4OSW3QGZLLRA5CNFSM4IPIUEI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5KXNVQ#issuecomment-525694678>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AJCOXN67TTZLU5O6XIAYUHDQGZLLRANCNFSM4IPIUEIQ>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525701307
https://github.com/su2code/SU2/pull/771#issuecomment-525703583:34,Deployability,install,installed,34,"This approach also works for user installed libraries, by setting `PKG_CONFIG_PATH`",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-525703583
https://github.com/su2code/SU2/pull/771#issuecomment-526036812:97,Modifiability,config,configure,97,"@pcarruscag, I have not built the MKL executable with meson yet. What I typically did when using configure is to use environment variables for the compiler and linker flags.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-526036812
https://github.com/su2code/SU2/pull/771#issuecomment-526036812:129,Modifiability,variab,variables,129,"@pcarruscag, I have not built the MKL executable with meson yet. What I typically did when using configure is to use environment variables for the compiler and linker flags.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-526036812
https://github.com/su2code/SU2/pull/771#issuecomment-526052883:291,Modifiability,config,configure,291,"@vdweide, and what MKL flags do you use? The same you mentioned before?. On Thu, 29 Aug 2019, 07:00 Edwin van der Weide, <notifications@github.com>; wrote:. > @pcarruscag <https://github.com/pcarruscag>, I have not built the MKL; > executable with meson yet. What I typically did when using configure is to; > use environment variables for the compiler and linker flags.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/771?email_source=notifications&email_token=AJCOXN5M6NECJGMGJEGDHGTQG5QXLA5CNFSM4IPIUEI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5NK6TA#issuecomment-526036812>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AJCOXN23NPS4JJDU2VGK3NTQG5QXLANCNFSM4IPIUEIQ>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-526052883
https://github.com/su2code/SU2/pull/771#issuecomment-526052883:326,Modifiability,variab,variables,326,"@vdweide, and what MKL flags do you use? The same you mentioned before?. On Thu, 29 Aug 2019, 07:00 Edwin van der Weide, <notifications@github.com>; wrote:. > @pcarruscag <https://github.com/pcarruscag>, I have not built the MKL; > executable with meson yet. What I typically did when using configure is to; > use environment variables for the compiler and linker flags.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/771?email_source=notifications&email_token=AJCOXN5M6NECJGMGJEGDHGTQG5QXLA5CNFSM4IPIUEI2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD5NK6TA#issuecomment-526036812>,; > or mute the thread; > <https://github.com/notifications/unsubscribe-auth/AJCOXN23NPS4JJDU2VGK3NTQG5QXLANCNFSM4IPIUEIQ>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/771#issuecomment-526052883
https://github.com/su2code/SU2/issues/772#issuecomment-524737860:72,Deployability,release,release,72,Thanks for mentioning this. I will deal with this definitely before the release. Maybe I am gonna add a small test case which just reads the config_template.cfg to check whether it is up-to-date.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524737860
https://github.com/su2code/SU2/issues/772#issuecomment-524737860:110,Testability,test,test,110,Thanks for mentioning this. I will deal with this definitely before the release. Maybe I am gonna add a small test case which just reads the config_template.cfg to check whether it is up-to-date.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524737860
https://github.com/su2code/SU2/issues/772#issuecomment-524913164:129,Deployability,update,update,129,"I think along with this, the testcases/tutorials cfgs will have outdated configs. If we have a new template, I can help with the update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524913164
https://github.com/su2code/SU2/issues/772#issuecomment-524913164:73,Modifiability,config,configs,73,"I think along with this, the testcases/tutorials cfgs will have outdated configs. If we have a new template, I can help with the update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524913164
https://github.com/su2code/SU2/issues/772#issuecomment-524913164:29,Testability,test,testcases,29,"I think along with this, the testcases/tutorials cfgs will have outdated configs. If we have a new template, I can help with the update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524913164
https://github.com/su2code/SU2/issues/772#issuecomment-524917823:9,Deployability,release,release,9,"For next release, I think we have no choice but to just update the current template. In the future, we should go to a self-describing set of config options (add descriptive strings to each option in config_structure.cpp) so that we can automatically write a consistent config template. Better yet, the same strings can be used for an interactive help mode using the command line parser that @talbring has added. These things would go a long way to help users with the config - which is one of our major pain points.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524917823
https://github.com/su2code/SU2/issues/772#issuecomment-524917823:56,Deployability,update,update,56,"For next release, I think we have no choice but to just update the current template. In the future, we should go to a self-describing set of config options (add descriptive strings to each option in config_structure.cpp) so that we can automatically write a consistent config template. Better yet, the same strings can be used for an interactive help mode using the command line parser that @talbring has added. These things would go a long way to help users with the config - which is one of our major pain points.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524917823
https://github.com/su2code/SU2/issues/772#issuecomment-524917823:141,Modifiability,config,config,141,"For next release, I think we have no choice but to just update the current template. In the future, we should go to a self-describing set of config options (add descriptive strings to each option in config_structure.cpp) so that we can automatically write a consistent config template. Better yet, the same strings can be used for an interactive help mode using the command line parser that @talbring has added. These things would go a long way to help users with the config - which is one of our major pain points.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524917823
https://github.com/su2code/SU2/issues/772#issuecomment-524917823:269,Modifiability,config,config,269,"For next release, I think we have no choice but to just update the current template. In the future, we should go to a self-describing set of config options (add descriptive strings to each option in config_structure.cpp) so that we can automatically write a consistent config template. Better yet, the same strings can be used for an interactive help mode using the command line parser that @talbring has added. These things would go a long way to help users with the config - which is one of our major pain points.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524917823
https://github.com/su2code/SU2/issues/772#issuecomment-524917823:468,Modifiability,config,config,468,"For next release, I think we have no choice but to just update the current template. In the future, we should go to a self-describing set of config options (add descriptive strings to each option in config_structure.cpp) so that we can automatically write a consistent config template. Better yet, the same strings can be used for an interactive help mode using the command line parser that @talbring has added. These things would go a long way to help users with the config - which is one of our major pain points.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-524917823
https://github.com/su2code/SU2/issues/772#issuecomment-528298290:259,Availability,avail,available,259,"> One more thing to be added, please let the option authors also signature their email in comments in case of that nobody knows why the option exists and the community lost contact with the author. I don't think anyone wants to have their email that publicly available. When features go out of support they are taken out of the code.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-528298290
https://github.com/su2code/SU2/issues/772#issuecomment-562337816:12,Deployability,release,release,12,Solved with release of v7.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/772#issuecomment-562337816
https://github.com/su2code/SU2/pull/773#issuecomment-775245782:83,Deployability,release,releases,83,"I've put a ""WIP"" in the tittle just to make it easier to create the change log for releases (there is the manual step where we need to remove stuff that it not part of the release).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/773#issuecomment-775245782
https://github.com/su2code/SU2/pull/773#issuecomment-775245782:172,Deployability,release,release,172,"I've put a ""WIP"" in the tittle just to make it easier to create the change log for releases (there is the manual step where we need to remove stuff that it not part of the release).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/773#issuecomment-775245782
https://github.com/su2code/SU2/pull/773#issuecomment-775245782:75,Testability,log,log,75,"I've put a ""WIP"" in the tittle just to make it easier to create the change log for releases (there is the manual step where we need to remove stuff that it not part of the release).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/773#issuecomment-775245782
https://github.com/su2code/SU2/pull/773#issuecomment-786935589:129,Availability,error,error,129,I guess one can ignore the CodeFactor complaints here as it just gives a vague complex code without any further line information error for CIncEulerSolver.cpp (which I could understand to some degree) and CSolver.hpp (which I dont understand at all).,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/773#issuecomment-786935589
https://github.com/su2code/SU2/pull/773#issuecomment-787051080:23,Testability,test,testcases,23,"No need to squash, the testcases repo is actually a bit messed up ATM because of that (oooops)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/773#issuecomment-787051080
https://github.com/su2code/SU2/pull/773#issuecomment-788766954:313,Modifiability,config,config,313,"Thanks a lot on the comments so far @pcarruscag . Helps quite a bit 👍 ; I think I addressed all your comments by now (using AuxVarGrad, a bunch of openMP instructions, overhauling the FindUnique_RefNode func, making a struct for the streamwise periodic values and using that in Numerics and the solver, not using config as a solver var container, and some other things ); Feel encouraged to comment/request-changes on more things.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/773#issuecomment-788766954
https://github.com/su2code/SU2/pull/773#issuecomment-789009251:98,Deployability,release,release,98,"There we go :) ; The website stuff is no merged as well, so that can go live with the next master release.; Thanks again.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/773#issuecomment-789009251
https://github.com/su2code/SU2/pull/774#issuecomment-525944144:387,Deployability,update,updates,387,"> @oleburghardt can you create a branch with the open PR's you have already merged in so we can compare this branch against its true base? That would make the review easier. It's true base is feature_input_output from #724, so one can quickly get an overview [here](https://github.com/su2code/SU2/compare/feature_input_output...sc_develop). It's the only one and I am constantly merging updates from there.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-525944144
https://github.com/su2code/SU2/pull/774#issuecomment-537512518:181,Deployability,update,update,181,"Thanks for making the changes @oleburghardt , it is a bit easier to review and comment on this PR now that the output is merged, I will have another look by the end of the week and update my review.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-537512518
https://github.com/su2code/SU2/pull/774#issuecomment-537514345:183,Deployability,update,update,183,"> Thanks for making the changes @oleburghardt , it is a bit easier to review and comment on this PR now that the output is merged, I will have another look by the end of the week and update my review. Yeah, merging with develop was such a relief a couple of minutes ago :D Thanks for your effort! No hurry.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-537514345
https://github.com/su2code/SU2/pull/774#issuecomment-538411667:256,Energy Efficiency,adapt,adaptions,256,"@pcarruscag @WallyMaier ; I think I've adressed most of what you spotted in the latest commits. Thanks for taking so much care - you already helped me a lot getting everything ready to enter the main version, especially concerning the just-for-development adaptions that I had forgotten about. @TobiKattmann ; I sneaked in another commit for primal CHT that _might_ help with your issue. I'm still running tests that might confirm my guesswork. (Though you can already try it by setting `CHT_ROBIN= NO` which will then just directly apply heat fluxes.) I'm coming back to this once I'm sure about it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-538411667
https://github.com/su2code/SU2/pull/774#issuecomment-538411667:256,Modifiability,adapt,adaptions,256,"@pcarruscag @WallyMaier ; I think I've adressed most of what you spotted in the latest commits. Thanks for taking so much care - you already helped me a lot getting everything ready to enter the main version, especially concerning the just-for-development adaptions that I had forgotten about. @TobiKattmann ; I sneaked in another commit for primal CHT that _might_ help with your issue. I'm still running tests that might confirm my guesswork. (Though you can already try it by setting `CHT_ROBIN= NO` which will then just directly apply heat fluxes.) I'm coming back to this once I'm sure about it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-538411667
https://github.com/su2code/SU2/pull/774#issuecomment-538411667:406,Testability,test,tests,406,"@pcarruscag @WallyMaier ; I think I've adressed most of what you spotted in the latest commits. Thanks for taking so much care - you already helped me a lot getting everything ready to enter the main version, especially concerning the just-for-development adaptions that I had forgotten about. @TobiKattmann ; I sneaked in another commit for primal CHT that _might_ help with your issue. I'm still running tests that might confirm my guesswork. (Though you can already try it by setting `CHT_ROBIN= NO` which will then just directly apply heat fluxes.) I'm coming back to this once I'm sure about it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-538411667
https://github.com/su2code/SU2/pull/774#issuecomment-539440348:873,Availability,avail,available,873,"> Ok, I am ~halfway through and I have mostly nitpicking stuff. In general it is really tidy and I am looking forward to use everything you added. Rest will follow tomorrow. Thanks a lot Tobias! I think I made all the changes that you suggested, it's just the ouput that you and Pedro do not like. I'll think about what can be done .. (though part of it might be due to the fact that the `switch`-thing is more apparent now, same thing can be found in the solvers as well). > I already did the tutorial you uploaded but I'll redo everything as I couldn't reproduce the nice gradients you show in the tutorial. I'll report to you... maybe I somewhere wrong. Could be please try to run `SU2_DOT_AD` in serial? (If this doesn't help and if you've got the time, also `SU2_CFD_AD`?); That **really must work** .. it's quite important to me as I invested so much time so make it available for all. Could you send me your adjoint solution files?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-539440348
https://github.com/su2code/SU2/pull/774#issuecomment-539893223:220,Availability,avail,available,220,"> Could be please try to run `SU2_DOT_AD` in serial? (If this doesn't help and if you've got the time, also `SU2_CFD_AD`?); > That **really must work** .. it's quite important to me as I invested so much time so make it available for all. Could you send me your adjoint solution files?. @oleburghardt Yep, Single core for both did the trick and I now get the same gradient results. I will double check with 28 cores to see if it still produces differing results.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-539893223
https://github.com/su2code/SU2/pull/774#issuecomment-540513667:171,Integrability,depend,dependency,171,"@oleburghardt, looks like this is taking a turn to also address primal CHT topics, but all comments on the main dish have been addressed. Can we merge this to shorten the dependency chain between PR's while you continue working on ironing out minor kinks?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-540513667
https://github.com/su2code/SU2/pull/774#issuecomment-540531599:173,Integrability,depend,dependency,173,"> @oleburghardt, looks like this is taking a turn to also address primal CHT topics, but all comments on the main dish have been addressed. Can we merge this to shorten the dependency chain between PR's while you continue working on ironing out minor kinks?. True, but that was about it. They just have fit in so well. As for the main part, we just have to keep in mind the `CDiscAdjMultizoneDriver::SetObjFunction` that two of you didn't like. But as I said, it has much to do with other changes that should be done before.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/774#issuecomment-540531599
https://github.com/su2code/SU2/issues/775#issuecomment-536031012:218,Availability,avail,available,218,"I noticed the addition of the Guide to V7 page being introduced to the SU2 page. I think this would make a great starting point to beef up our documentation/tutorial pages. Using a similar format, we could discuss the available options in SU2. Speaking from experience, new SU2 users face an extremely high learning curve, often scaring them away. I believe this would help alleviate that problem. I understand this is no small task, and welcome others thoughts on the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-536031012
https://github.com/su2code/SU2/issues/775#issuecomment-536031012:30,Usability,Guid,Guide,30,"I noticed the addition of the Guide to V7 page being introduced to the SU2 page. I think this would make a great starting point to beef up our documentation/tutorial pages. Using a similar format, we could discuss the available options in SU2. Speaking from experience, new SU2 users face an extremely high learning curve, often scaring them away. I believe this would help alleviate that problem. I understand this is no small task, and welcome others thoughts on the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-536031012
https://github.com/su2code/SU2/issues/775#issuecomment-536031012:307,Usability,learn,learning,307,"I noticed the addition of the Guide to V7 page being introduced to the SU2 page. I think this would make a great starting point to beef up our documentation/tutorial pages. Using a similar format, we could discuss the available options in SU2. Speaking from experience, new SU2 users face an extremely high learning curve, often scaring them away. I believe this would help alleviate that problem. I understand this is no small task, and welcome others thoughts on the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-536031012
https://github.com/su2code/SU2/issues/775#issuecomment-540239931:579,Availability,avail,available,579,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
https://github.com/su2code/SU2/issues/775#issuecomment-540239931:637,Availability,avail,available,637,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
https://github.com/su2code/SU2/issues/775#issuecomment-540239931:615,Deployability,configurat,configuration,615,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
https://github.com/su2code/SU2/issues/775#issuecomment-540239931:615,Modifiability,config,configuration,615,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
https://github.com/su2code/SU2/issues/775#issuecomment-540239931:398,Security,expose,expose,398,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
https://github.com/su2code/SU2/issues/775#issuecomment-540239931:35,Usability,guid,guiding,35,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
https://github.com/su2code/SU2/issues/775#issuecomment-540239931:664,Usability,Guid,Guide,664,"From the SU2 paper, talking about ""guiding principles"":. <img width=""574"" alt=""Screen Shot 2019-10-09 at 3 26 46 PM"" src=""https://user-images.githubusercontent.com/19416354/66525312-edb5d480-eaa9-11e9-9c0f-158b3941b407.png"">. I particularly like. > Full documentation, including a comprehensive set of tutorials. (""including"" implying that the tutorials are a subset of the documentation), and . > expose the full set of options [...] to the practitioner. This conflicts with our ""operating principle"", laid out on the tutorials page:. > Rather than writing a long manual on all available (and constantly evolving) configuration options available in SU2[...]. The Guide to V7 is a good start, but I think at the bare minimum (since I agree that full documentation would be a huge task, though one that's apparently promised on a paper we link on our homepage), we should provide more information about the existing options beyond forcing the user to scroll through config_template.cfg or dig through the tutorials.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540239931
https://github.com/su2code/SU2/issues/775#issuecomment-540443125:404,Energy Efficiency,Monitor,Monitoring,404,There is no doubt in the fact that we need a better documentation. My idea was to have sections where we at least describe the basic settings (like the one I already started https://su2code.github.io/docs/Solver-Setup/) which are common to all solvers. Furthermore short paragraphs on each individual solver (including a brief theory). . Basic things could include:; - Markers and Boundary Conditions; - Monitoring Coefficients; - Defining the numerical methods. Please lets not start a big discussion on that. Lets rather invest that time in actually doing it.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-540443125
https://github.com/su2code/SU2/issues/775#issuecomment-543180614:58,Availability,error,errors,58,"@talbring are you ok with having best-practices or common errors interleaved with that documentation?; For example, careful when switching from Euler to RANS and not updating this or that boundary condition.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-543180614
https://github.com/su2code/SU2/issues/775#issuecomment-543255462:386,Modifiability,config,config,386,"All: we will need all the help we can get to make a big documentation push for v7. Please do take some time and contribute to the new structure that @talbring is setting up. Even if you only have some time to work through the new documentation and find/correct typos or issues you find. I will be adding some governing equations to the solver sections very soon. As for documenting the config options, the best policy is that it is automatic. As has been done with the output and the dry run mode (-d), we can also do the same for all config options. They can be made self-describing by adding their description/comment directly into the code that creates the option in the C++, which can then be printed on request with a -h flag (or something similar). This is no doubt the way to go in my mind. But, that will likely be for after v7, so for now, let's invest in the docs, since they are critically important.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-543255462
https://github.com/su2code/SU2/issues/775#issuecomment-543255462:535,Modifiability,config,config,535,"All: we will need all the help we can get to make a big documentation push for v7. Please do take some time and contribute to the new structure that @talbring is setting up. Even if you only have some time to work through the new documentation and find/correct typos or issues you find. I will be adding some governing equations to the solver sections very soon. As for documenting the config options, the best policy is that it is automatic. As has been done with the output and the dry run mode (-d), we can also do the same for all config options. They can be made self-describing by adding their description/comment directly into the code that creates the option in the C++, which can then be printed on request with a -h flag (or something similar). This is no doubt the way to go in my mind. But, that will likely be for after v7, so for now, let's invest in the docs, since they are critically important.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-543255462
https://github.com/su2code/SU2/issues/775#issuecomment-547996411:199,Modifiability,config,config,199,"We have created a new structure for the documentation for version 7:; https://su2code.github.io/docs_v7/ . We need some help from all of you. Please go through the files, check for typos, deprecated config options, add comments, and so on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/775#issuecomment-547996411
https://github.com/su2code/SU2/pull/778#issuecomment-525824799:93,Energy Efficiency,allocate,allocated,93,"About the FEA - that is a larger point. I expect that there are quite a few structures being allocated that you don't need for the finite element solver(s) based on the primal grid.. i.e., most of the dual grid structure (edges, dual CVs, etc.). Easy to adjust here for this PR, but we might want to have a larger pass later to selectively allocate only what is needed. Or, adjust the geometry classes slightly to better separate the primal and dual grids.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-525824799
https://github.com/su2code/SU2/pull/778#issuecomment-525824799:340,Energy Efficiency,allocate,allocate,340,"About the FEA - that is a larger point. I expect that there are quite a few structures being allocated that you don't need for the finite element solver(s) based on the primal grid.. i.e., most of the dual grid structure (edges, dual CVs, etc.). Easy to adjust here for this PR, but we might want to have a larger pass later to selectively allocate only what is needed. Or, adjust the geometry classes slightly to better separate the primal and dual grids.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-525824799
https://github.com/su2code/SU2/pull/778#issuecomment-525845039:135,Modifiability,evolve,evolves,135,"This is indeed important. Having some reference quality metric, while creating mesh (acceptable limits, specific to the solvers, which evolves with usage).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-525845039
https://github.com/su2code/SU2/pull/778#issuecomment-526456264:751,Deployability,release,released,751,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
https://github.com/su2code/SU2/pull/778#issuecomment-526456264:674,Integrability,rout,routines,674,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
https://github.com/su2code/SU2/pull/778#issuecomment-526456264:429,Performance,optimiz,optimization,429,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
https://github.com/su2code/SU2/pull/778#issuecomment-526456264:285,Usability,intuit,intuition,285,"Thanks for the quick review @pcarruscag. I have cleaned up a little bit. Also added a nicer table of the output. l prefer that we always compute the min/max values, at least for the FVM CFD solvers, for a few reasons. The most important reason is that we should start to build up some intuition about the correlation between mesh quality metrics and accuracy + convergence in the solvers. This can be especially important during optimization when the mesh is deforming. I think the metrics are valuable to print every time for this reason, which might help users diagnose problems eventually. Additionally, the cost is relatively small (on par with the other pre-processing routines, it is only executed once and it is parallelized, and the memory is released if we don't write).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526456264
https://github.com/su2code/SU2/pull/778#issuecomment-526476734:220,Deployability,update,update,220,"Hi @economon . Thanks for this PR. It is an essential feature that was missing. ; Also, I would like to see in the future acceptable min/max values for the metrics that SU2 can handle.; LGTM and ready to merge after you update from develop. Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/778#issuecomment-526476734
https://github.com/su2code/SU2/pull/780#issuecomment-534420006:204,Availability,robust,robust,204,"@talbring That was a good point about placement. I was able to move this implementation to a function called `FixedCL_Convergence()` in the euler solver class. It also allowed me to make it a little more robust. Since it still requires information about the convergence that is calculated in the integration container, the method has to be called `CFluidIteration::Iterate()`. I included the details of the implementation in the Constant CL tutorial on the website. That is in a pull request for the website. Consequently, that [pull request ](https://github.com/su2code/su2code.github.io/pull/16) needs to be approved first so that the regression test for this one can pass. This is because of a change in options in the Fixed CL mode.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-534420006
https://github.com/su2code/SU2/pull/780#issuecomment-534420006:296,Deployability,integrat,integration,296,"@talbring That was a good point about placement. I was able to move this implementation to a function called `FixedCL_Convergence()` in the euler solver class. It also allowed me to make it a little more robust. Since it still requires information about the convergence that is calculated in the integration container, the method has to be called `CFluidIteration::Iterate()`. I included the details of the implementation in the Constant CL tutorial on the website. That is in a pull request for the website. Consequently, that [pull request ](https://github.com/su2code/su2code.github.io/pull/16) needs to be approved first so that the regression test for this one can pass. This is because of a change in options in the Fixed CL mode.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-534420006
https://github.com/su2code/SU2/pull/780#issuecomment-534420006:296,Integrability,integrat,integration,296,"@talbring That was a good point about placement. I was able to move this implementation to a function called `FixedCL_Convergence()` in the euler solver class. It also allowed me to make it a little more robust. Since it still requires information about the convergence that is calculated in the integration container, the method has to be called `CFluidIteration::Iterate()`. I included the details of the implementation in the Constant CL tutorial on the website. That is in a pull request for the website. Consequently, that [pull request ](https://github.com/su2code/su2code.github.io/pull/16) needs to be approved first so that the regression test for this one can pass. This is because of a change in options in the Fixed CL mode.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-534420006
https://github.com/su2code/SU2/pull/780#issuecomment-534420006:648,Testability,test,test,648,"@talbring That was a good point about placement. I was able to move this implementation to a function called `FixedCL_Convergence()` in the euler solver class. It also allowed me to make it a little more robust. Since it still requires information about the convergence that is calculated in the integration container, the method has to be called `CFluidIteration::Iterate()`. I included the details of the implementation in the Constant CL tutorial on the website. That is in a pull request for the website. Consequently, that [pull request ](https://github.com/su2code/su2code.github.io/pull/16) needs to be approved first so that the regression test for this one can pass. This is because of a change in options in the Fixed CL mode.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-534420006
https://github.com/su2code/SU2/pull/780#issuecomment-539148332:273,Modifiability,config,config,273,"I am having some trouble in getting the Fixed CL mode to work properly with the new Output structure and SingleZoneDriver was wondering if anyone had some advice. . The way the fixed Cl mode works is that it first converges the solution to the target CL that is set in the config options. After that, it increases the `AOA` by 0.001 and runs for `ITER_DCL_DALPHA` iterations to determine the gradient `dCL_dAlpha`. This is essentially a finite differencing step to calculate gradients such as dCD_dCL so that it can be added to the objective function if the discrete adjoint is run in the fixed_cl mode. Currently, both the fixed cl convergence and the finite differencing occurs within the one call of `CFluidIteration::Solve` . This PR just changes how the fixed_CL mode converges to the `TARGET_CL` value and doesn't change anything about how the finite differencing step is performed. . My issue is to do with how to output the correct solution (the state before the finite differencing step) at the end of the simulation. Both the fixed cl convergence and the finite differencing occur within the one call of `CFluidIteration::Solve`. But the final solution output is controlled by the `CSinglezoneDriver::Output`. But by the time this is called the solution is at the state after the finite difference step has been taken and the CL is no longer matched. . The proper way to do it in this new output structure/SingleZoneDriver format would be to run the fixed CL mode to convergence using the SingleZoneDriver (including doing all the outputs from the `CSinglezoneDriver::Output` and then running the finite difference after that. But that wouldn't be possible without putting the if (fixed_cl) statement in either the SingleZoneDriver or in SU2_CFD, both of which are much higher level, and shouldn't have a problem specific if statement. The other way to do it would be to force the output structure to write the solution files before the finite differencing step (within the CFluidIteration) ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539148332
https://github.com/su2code/SU2/pull/780#issuecomment-539148332:878,Performance,perform,performed,878,"I am having some trouble in getting the Fixed CL mode to work properly with the new Output structure and SingleZoneDriver was wondering if anyone had some advice. . The way the fixed Cl mode works is that it first converges the solution to the target CL that is set in the config options. After that, it increases the `AOA` by 0.001 and runs for `ITER_DCL_DALPHA` iterations to determine the gradient `dCL_dAlpha`. This is essentially a finite differencing step to calculate gradients such as dCD_dCL so that it can be added to the objective function if the discrete adjoint is run in the fixed_cl mode. Currently, both the fixed cl convergence and the finite differencing occurs within the one call of `CFluidIteration::Solve` . This PR just changes how the fixed_CL mode converges to the `TARGET_CL` value and doesn't change anything about how the finite differencing step is performed. . My issue is to do with how to output the correct solution (the state before the finite differencing step) at the end of the simulation. Both the fixed cl convergence and the finite differencing occur within the one call of `CFluidIteration::Solve`. But the final solution output is controlled by the `CSinglezoneDriver::Output`. But by the time this is called the solution is at the state after the finite difference step has been taken and the CL is no longer matched. . The proper way to do it in this new output structure/SingleZoneDriver format would be to run the fixed CL mode to convergence using the SingleZoneDriver (including doing all the outputs from the `CSinglezoneDriver::Output` and then running the finite difference after that. But that wouldn't be possible without putting the if (fixed_cl) statement in either the SingleZoneDriver or in SU2_CFD, both of which are much higher level, and shouldn't have a problem specific if statement. The other way to do it would be to force the output structure to write the solution files before the finite differencing step (within the CFluidIteration) ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539148332
https://github.com/su2code/SU2/pull/780#issuecomment-539575775:436,Performance,perform,perform,436,"> What if you start with the ""perturbed value"" of AoA and then set it to the correct value for the FD step?. Mhmm, I am just thinking this through. At the end of the fixed_cl part, the flow is converged to the `TARGET_CL` and is at some angle of attack `alpha`. If I wanted to start from the perturbed value and set it to the final value of `alpha`, I would have to first, converge it to the perturbed value (`alpha + 0.001`), and then perform the finite difference step back to `alpha`. This would take approximately twice the number of `ITER_DCL_DALPHA` to perform. Which isn't the end of the world, but I would like to avoid if possible. Is there a cleverer way of doing this that I am not thinking off? The problem is that we don't know the final `alpha` until the fixed_cl simulation converges.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539575775
https://github.com/su2code/SU2/pull/780#issuecomment-539575775:559,Performance,perform,perform,559,"> What if you start with the ""perturbed value"" of AoA and then set it to the correct value for the FD step?. Mhmm, I am just thinking this through. At the end of the fixed_cl part, the flow is converged to the `TARGET_CL` and is at some angle of attack `alpha`. If I wanted to start from the perturbed value and set it to the final value of `alpha`, I would have to first, converge it to the perturbed value (`alpha + 0.001`), and then perform the finite difference step back to `alpha`. This would take approximately twice the number of `ITER_DCL_DALPHA` to perform. Which isn't the end of the world, but I would like to avoid if possible. Is there a cleverer way of doing this that I am not thinking off? The problem is that we don't know the final `alpha` until the fixed_cl simulation converges.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539575775
https://github.com/su2code/SU2/pull/780#issuecomment-539575775:622,Safety,avoid,avoid,622,"> What if you start with the ""perturbed value"" of AoA and then set it to the correct value for the FD step?. Mhmm, I am just thinking this through. At the end of the fixed_cl part, the flow is converged to the `TARGET_CL` and is at some angle of attack `alpha`. If I wanted to start from the perturbed value and set it to the final value of `alpha`, I would have to first, converge it to the perturbed value (`alpha + 0.001`), and then perform the finite difference step back to `alpha`. This would take approximately twice the number of `ITER_DCL_DALPHA` to perform. Which isn't the end of the world, but I would like to avoid if possible. Is there a cleverer way of doing this that I am not thinking off? The problem is that we don't know the final `alpha` until the fixed_cl simulation converges.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539575775
https://github.com/su2code/SU2/pull/780#issuecomment-539575775:246,Security,attack,attack,246,"> What if you start with the ""perturbed value"" of AoA and then set it to the correct value for the FD step?. Mhmm, I am just thinking this through. At the end of the fixed_cl part, the flow is converged to the `TARGET_CL` and is at some angle of attack `alpha`. If I wanted to start from the perturbed value and set it to the final value of `alpha`, I would have to first, converge it to the perturbed value (`alpha + 0.001`), and then perform the finite difference step back to `alpha`. This would take approximately twice the number of `ITER_DCL_DALPHA` to perform. Which isn't the end of the world, but I would like to avoid if possible. Is there a cleverer way of doing this that I am not thinking off? The problem is that we don't know the final `alpha` until the fixed_cl simulation converges.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539575775
https://github.com/su2code/SU2/pull/780#issuecomment-539587908:462,Deployability,update,update,462,"Probably not, it was a silly idea anyway. Maybe you could perturb the target value of CL instead and measure the variation of alpha for an imposed variation of CL but that is starting to sound quite strange. I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. Edit: Regardless of how the process works, you can always do one more update of alpha to refine CL and take those two points for the finite difference, i.e. you never do an explicit perturbation and the final state is guaranteed to be the best.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539587908
https://github.com/su2code/SU2/pull/780#issuecomment-539587908:364,Safety,avoid,avoid,364,"Probably not, it was a silly idea anyway. Maybe you could perturb the target value of CL instead and measure the variation of alpha for an imposed variation of CL but that is starting to sound quite strange. I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. Edit: Regardless of how the process works, you can always do one more update of alpha to refine CL and take those two points for the finite difference, i.e. you never do an explicit perturbation and the final state is guaranteed to be the best.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539587908
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:939,Availability,error,errors,939,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:495,Deployability,update,update,495,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:592,Deployability,update,update,592,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:705,Deployability,update,update,705,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:886,Deployability,update,update,886,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:291,Integrability,depend,depending,291,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:158,Safety,avoid,avoid,158,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:255,Security,attack,attack,255,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-539606698:194,Usability,simpl,simple,194,"> I don't known how the process to find the alpha that gives you a given CL works, but could the derivative not be obtained from this process? i.e. you could avoid the FD step entirely. It is a simple proportional controller that will change the angle of attack after a number of iterations depending on the difference between the current CL and the target CL. . So if the the option `ITER_DCL_DALPHA = 0` then it will do exactly what you suggest. It calculates the derivative based on the last update. The only problem with that is, there is no guarantee that the simulation at the previous update was converged, so the derivative might be incorrect. . But you are correct, I could just do a really tiny update (order of delta AoA ~10^-6) at the end and calculate the finite difference using that value. Let me try that and see if the gradients it calculates are reasonable, or if the update is too small and it gets clouded by numerical errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-539606698
https://github.com/su2code/SU2/pull/780#issuecomment-540421163:51,Deployability,update,update,51,"Unfortunately, there is an issue with doing a tiny update at the end of the simulation. To illustrate the numbers, lets assume that CL is converged to the `TARGET_CL` to within 10^-6. . In this case the finite-difference update is tiny: \alpha is changed by 10^-7 degrees (this is because `DCL_DALPHA` is usually between 0.5 and 0.05 and change in alpha = `(TARGET_CL-CL)/DCL_DALPHA`) . The change in CL resulting from this finite-difference step is small (10^-8) enough that if the solution isn't extremely converged (in this case, change in CL over two consecutive iterations is < 10^-9), the gradients calculated will be incorrect. . Anecdotally, the reduction in density residual in the simulation would have to be ~8 orders to get these gradients to be correct. This could add a large number of iterations and/or time to solution, especially for 3D RANS cases. Additionally, I am not sure what the best way to force this level of convergence would be. . Which brings me back to my original problem of trying to output the solution before the finite difference step. Well, I can definitely output the solution at the end of the fixed Cl mode, but it just gets overwritten when the solver finally exits after the finite difference step. The easiest way around this would be if there is a way to disable the output of the volume files after the solver exits. Something that could be changed from the CFluidIteration ideally. . I am sorry this feature is causing this issue. Unfortunately, even the way it is currently implemented in develop (without my changes, but after the new output structure) is plagued with the same problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-540421163
https://github.com/su2code/SU2/pull/780#issuecomment-540421163:221,Deployability,update,update,221,"Unfortunately, there is an issue with doing a tiny update at the end of the simulation. To illustrate the numbers, lets assume that CL is converged to the `TARGET_CL` to within 10^-6. . In this case the finite-difference update is tiny: \alpha is changed by 10^-7 degrees (this is because `DCL_DALPHA` is usually between 0.5 and 0.05 and change in alpha = `(TARGET_CL-CL)/DCL_DALPHA`) . The change in CL resulting from this finite-difference step is small (10^-8) enough that if the solution isn't extremely converged (in this case, change in CL over two consecutive iterations is < 10^-9), the gradients calculated will be incorrect. . Anecdotally, the reduction in density residual in the simulation would have to be ~8 orders to get these gradients to be correct. This could add a large number of iterations and/or time to solution, especially for 3D RANS cases. Additionally, I am not sure what the best way to force this level of convergence would be. . Which brings me back to my original problem of trying to output the solution before the finite difference step. Well, I can definitely output the solution at the end of the fixed Cl mode, but it just gets overwritten when the solver finally exits after the finite difference step. The easiest way around this would be if there is a way to disable the output of the volume files after the solver exits. Something that could be changed from the CFluidIteration ideally. . I am sorry this feature is causing this issue. Unfortunately, even the way it is currently implemented in develop (without my changes, but after the new output structure) is plagued with the same problem.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-540421163
https://github.com/su2code/SU2/pull/780#issuecomment-540470903:32,Integrability,rout,routine,32,@jayantmukho You can modify the routine CFlowOutput::WriteVolume_Output() in order to disable the writing of the files.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-540470903
https://github.com/su2code/SU2/pull/780#issuecomment-540650002:34,Integrability,rout,routine,34,"> @jayantmukho You can modify the routine CFlowOutput::WriteVolume_Output() in order to disable the writing of the files. Yes, I thought that would be the easiest place to make the change. But unfortunately, this gets ignored when the `CSingleZoneDriver` runs `SetResult_Files` and forces the output with the `force_writing` option. `StopCalc` passed into this function for `force_writing` and that is basically always true at this point in the case of steady RANS since the `CFluidIteration` has just finished running `Solve()`. An easy way to fix this would be to add `force_writing` to the input of `WriteVolume_Output`. I can preserve the behavior in the `COutput::WriteVolume_Output` but add some logic for the fixed CL mode in the `CFlowOutput::WriteVolume_Output`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-540650002
https://github.com/su2code/SU2/pull/780#issuecomment-540650002:702,Testability,log,logic,702,"> @jayantmukho You can modify the routine CFlowOutput::WriteVolume_Output() in order to disable the writing of the files. Yes, I thought that would be the easiest place to make the change. But unfortunately, this gets ignored when the `CSingleZoneDriver` runs `SetResult_Files` and forces the output with the `force_writing` option. `StopCalc` passed into this function for `force_writing` and that is basically always true at this point in the case of steady RANS since the `CFluidIteration` has just finished running `Solve()`. An easy way to fix this would be to add `force_writing` to the input of `WriteVolume_Output`. I can preserve the behavior in the `COutput::WriteVolume_Output` but add some logic for the fixed CL mode in the `CFlowOutput::WriteVolume_Output`.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-540650002
https://github.com/su2code/SU2/pull/780#issuecomment-545203243:71,Testability,Test,TestCase,71,In the process of the final merge which involves pulling corresponding TestCase and Tutorial branches into their develops as well. (and changing the travis.yml file),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/780#issuecomment-545203243
https://github.com/su2code/SU2/pull/781#issuecomment-525685943:234,Deployability,configurat,configurations,234,"@jayantmukho :; I think this is a very important addition. A typical optimization case (at least in the industry) deals with very different setups (say aircraft at cruise, take-off, and landing: different flight regimes and different configurations). That way it makes sense to allow also for different mesh files, each for every point.; Nimrod Cohen who works with me has been working on that line. I don't know how far he has gone.; I shall have him posted to this PR, he might be able to contribute.; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-525685943
https://github.com/su2code/SU2/pull/781#issuecomment-525685943:234,Modifiability,config,configurations,234,"@jayantmukho :; I think this is a very important addition. A typical optimization case (at least in the industry) deals with very different setups (say aircraft at cruise, take-off, and landing: different flight regimes and different configurations). That way it makes sense to allow also for different mesh files, each for every point.; Nimrod Cohen who works with me has been working on that line. I don't know how far he has gone.; I shall have him posted to this PR, he might be able to contribute.; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-525685943
https://github.com/su2code/SU2/pull/781#issuecomment-525685943:69,Performance,optimiz,optimization,69,"@jayantmukho :; I think this is a very important addition. A typical optimization case (at least in the industry) deals with very different setups (say aircraft at cruise, take-off, and landing: different flight regimes and different configurations). That way it makes sense to allow also for different mesh files, each for every point.; Nimrod Cohen who works with me has been working on that line. I don't know how far he has gone.; I shall have him posted to this PR, he might be able to contribute.; Best,; Eran",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-525685943
https://github.com/su2code/SU2/pull/781#issuecomment-532003485:30,Performance,optimiz,optimization,30,"@erangit I got the multipoint optimization to work with multiple mesh files. For a well posed optimization, the surfaces that can be deformed (for example the wing) should be same, and the FFD boxes have to be identical. Since the meshes are likely unstructured, you might not get the exact same discretization on the surface, which is fine. As long as the FFD box definition is the same, identical movements in the FFD control points should result in similar surface deformations. Just the marker definitions need to be consistent.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-532003485
https://github.com/su2code/SU2/pull/781#issuecomment-532003485:94,Performance,optimiz,optimization,94,"@erangit I got the multipoint optimization to work with multiple mesh files. For a well posed optimization, the surfaces that can be deformed (for example the wing) should be same, and the FFD boxes have to be identical. Since the meshes are likely unstructured, you might not get the exact same discretization on the surface, which is fine. As long as the FFD box definition is the same, identical movements in the FFD control points should result in similar surface deformations. Just the marker definitions need to be consistent.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-532003485
https://github.com/su2code/SU2/pull/781#issuecomment-532759515:41,Availability,failure,failure,41,"This PR is ready for merging. The Codacy failure is for a os.system() call that introduces a security vulnerability that I am not sure how to fix. There are a lot of os.system() calls in the code already, but since I introduced one more, it is failing. . Any help in fixing the issue would be fantastic. If this is not a big deal, I can merge the PR",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-532759515
https://github.com/su2code/SU2/pull/781#issuecomment-532759515:93,Security,secur,security,93,"This PR is ready for merging. The Codacy failure is for a os.system() call that introduces a security vulnerability that I am not sure how to fix. There are a lot of os.system() calls in the code already, but since I introduced one more, it is failing. . Any help in fixing the issue would be fantastic. If this is not a big deal, I can merge the PR",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-532759515
https://github.com/su2code/SU2/pull/781#issuecomment-533370188:38,Safety,risk,risk,38,Seems that 'shell=True' is a security risk. Any way to easily fix that by using different options with the system call? We could do a search and replace for the others already in the Python framework.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533370188
https://github.com/su2code/SU2/pull/781#issuecomment-533370188:29,Security,secur,security,29,Seems that 'shell=True' is a security risk. Any way to easily fix that by using different options with the system call? We could do a search and replace for the others already in the Python framework.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533370188
https://github.com/su2code/SU2/pull/781#issuecomment-533410018:118,Security,secur,secure,118,"shell = false doesn't seem to work in this particular case (symbolic linking) but it might in others. There seem more secure ways to run commands but they need case by case treatment. As in the solution for a `cp` command is different from a `ln -s` command. . We can also replace the `os.system` calls with other python functions (for example `os.symlink` for symbolic linking). . Either way, it wont be a simple search and replace. There seem to be about 25 `os.system` calls across the python scripts. Let me try and replace them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533410018
https://github.com/su2code/SU2/pull/781#issuecomment-533410018:407,Usability,simpl,simple,407,"shell = false doesn't seem to work in this particular case (symbolic linking) but it might in others. There seem more secure ways to run commands but they need case by case treatment. As in the solution for a `cp` command is different from a `ln -s` command. . We can also replace the `os.system` calls with other python functions (for example `os.symlink` for symbolic linking). . Either way, it wont be a simple search and replace. There seem to be about 25 `os.system` calls across the python scripts. Let me try and replace them.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533410018
https://github.com/su2code/SU2/pull/781#issuecomment-533469803:106,Modifiability,variab,variables,106,@jayantmukho Thanks for dealing with the python calls ... I think as soon as you deal with the two unused variables everything should be fine and we can merge that in!,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533469803
https://github.com/su2code/SU2/pull/781#issuecomment-533583473:32,Security,secur,security,32,"Agreed, thanks for fixing those security issues. I know it is more work, but it is important. Extra fixes added to PRs like this help improve the code quickly.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533583473
https://github.com/su2code/SU2/pull/781#issuecomment-533590086:332,Safety,risk,risk,332,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
https://github.com/su2code/SU2/pull/781#issuecomment-533590086:323,Security,secur,security,323,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
https://github.com/su2code/SU2/pull/781#issuecomment-533590086:831,Testability,test,tests,831,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
https://github.com/su2code/SU2/pull/781#issuecomment-533590086:291,Usability,simpl,simple,291,"Unfortunately, I wasn't able to get all of them. I fixed a majority of the calls but couldn't find workarounds all of them. There are 8 left in the following files: . `SU2_PY/change_version_number.py`: There's 2 in here. One is a complicated command with `grep` and pipes and the other is a simple `rm -rf`, but it isn't a security risk since there is no user input into that string. `SU2_PY/SU2/util/pyCppTap.py`: This is in the diff_routine and uses `tapenade`. I have no idea what this does so I didn't touch this one. `SU2/opt/server.py`: There are 4 `scp` calls that I didn't know how to replace. `SU2_PY/compute_polar.py`: There's one left in here which is a complicated `cat` call that I couldn't figure a workaround for. . If you have any suggestions for any of these, I can try and implement them. . Otherwise, once these tests pass, its good to merge.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533590086
https://github.com/su2code/SU2/pull/781#issuecomment-533595722:244,Integrability,rout,routines,244,We can remove pyCppTap.py. This is a holdover from early automatic differentiation work that is not functional any longer. Can you also please check whether the server.py is still necessary? That may only be needed for design space exploration routines (farming out jobs on a cluster) that are also not used regularly.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533595722
https://github.com/su2code/SU2/pull/781#issuecomment-533642749:263,Deployability,release,release,263,"Seems like `server.py` is only used by `patient_designspace.py` which is a python script I hadn't ever noticed. There really isn't much in the way of documentation, use cases, or comments for either of these files which makes me okay with scrapping them for this release. I will remove these three files (including `pyCppTap.py`) and take them out of the Makefiles as well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-533642749
https://github.com/su2code/SU2/pull/781#issuecomment-534162206:78,Integrability,wrap,wrappers,78,"Wing was one of the preferred IDEs for the development of the python IO-based wrappers early on in the project. I do not expect that folks are using it any longer, and unless anyone is against it (please speak up), I think it can also be removed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/781#issuecomment-534162206
https://github.com/su2code/SU2/issues/783#issuecomment-526940883:42,Deployability,update,updated,42,I believe the config_template.cfg will be updated for the 7.0 release as per #772. ; I think this would be a great opportunity to create proper documentation/tutorials for the solvers.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-526940883
https://github.com/su2code/SU2/issues/783#issuecomment-526940883:62,Deployability,release,release,62,I believe the config_template.cfg will be updated for the 7.0 release as per #772. ; I think this would be a great opportunity to create proper documentation/tutorials for the solvers.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-526940883
https://github.com/su2code/SU2/issues/783#issuecomment-526993716:47,Modifiability,config,config,47,"Hello Wally, do you know anyone has a TestCase config of HEAT_EQUATION_FVM? I have not found such one in the TestCases folder.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-526993716
https://github.com/su2code/SU2/issues/783#issuecomment-526993716:38,Testability,Test,TestCase,38,"Hello Wally, do you know anyone has a TestCase config of HEAT_EQUATION_FVM? I have not found such one in the TestCases folder.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-526993716
https://github.com/su2code/SU2/issues/783#issuecomment-526993716:109,Testability,Test,TestCases,109,"Hello Wally, do you know anyone has a TestCase config of HEAT_EQUATION_FVM? I have not found such one in the TestCases folder.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-526993716
https://github.com/su2code/SU2/issues/783#issuecomment-527331047:149,Modifiability,config,configSolid,149,"Hi @WenyinWei, ; using (on Linux) `grep -r HEAT_EQUATION_FVM .` in the `<SU2_root>/Testcases` folder will point you to `./coupled_cht/incompressible/configSolid.cfg:15:SOLVER= HEAT_EQUATION_FVM`. It is a CHT Testcase (i.e. coupled fluid and solid) but by changing `MARKER_CHT_INTERFACE ` in configSolid.cfg to `MARKER_ISOTHERMAL=(PINSD, 350)` for example you should be able to run the configSolid.cfg alone. ; Hope that helps, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527331047
https://github.com/su2code/SU2/issues/783#issuecomment-527331047:291,Modifiability,config,configSolid,291,"Hi @WenyinWei, ; using (on Linux) `grep -r HEAT_EQUATION_FVM .` in the `<SU2_root>/Testcases` folder will point you to `./coupled_cht/incompressible/configSolid.cfg:15:SOLVER= HEAT_EQUATION_FVM`. It is a CHT Testcase (i.e. coupled fluid and solid) but by changing `MARKER_CHT_INTERFACE ` in configSolid.cfg to `MARKER_ISOTHERMAL=(PINSD, 350)` for example you should be able to run the configSolid.cfg alone. ; Hope that helps, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527331047
https://github.com/su2code/SU2/issues/783#issuecomment-527331047:385,Modifiability,config,configSolid,385,"Hi @WenyinWei, ; using (on Linux) `grep -r HEAT_EQUATION_FVM .` in the `<SU2_root>/Testcases` folder will point you to `./coupled_cht/incompressible/configSolid.cfg:15:SOLVER= HEAT_EQUATION_FVM`. It is a CHT Testcase (i.e. coupled fluid and solid) but by changing `MARKER_CHT_INTERFACE ` in configSolid.cfg to `MARKER_ISOTHERMAL=(PINSD, 350)` for example you should be able to run the configSolid.cfg alone. ; Hope that helps, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527331047
https://github.com/su2code/SU2/issues/783#issuecomment-527331047:83,Testability,Test,Testcases,83,"Hi @WenyinWei, ; using (on Linux) `grep -r HEAT_EQUATION_FVM .` in the `<SU2_root>/Testcases` folder will point you to `./coupled_cht/incompressible/configSolid.cfg:15:SOLVER= HEAT_EQUATION_FVM`. It is a CHT Testcase (i.e. coupled fluid and solid) but by changing `MARKER_CHT_INTERFACE ` in configSolid.cfg to `MARKER_ISOTHERMAL=(PINSD, 350)` for example you should be able to run the configSolid.cfg alone. ; Hope that helps, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527331047
https://github.com/su2code/SU2/issues/783#issuecomment-527331047:208,Testability,Test,Testcase,208,"Hi @WenyinWei, ; using (on Linux) `grep -r HEAT_EQUATION_FVM .` in the `<SU2_root>/Testcases` folder will point you to `./coupled_cht/incompressible/configSolid.cfg:15:SOLVER= HEAT_EQUATION_FVM`. It is a CHT Testcase (i.e. coupled fluid and solid) but by changing `MARKER_CHT_INTERFACE ` in configSolid.cfg to `MARKER_ISOTHERMAL=(PINSD, 350)` for example you should be able to run the configSolid.cfg alone. ; Hope that helps, Tobi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527331047
https://github.com/su2code/SU2/issues/783#issuecomment-527392713:109,Availability,error,error,109,"Thanks a lot, Tobi! I did find the file which is the only one has SOLVER=HEAT_EQUATION_FVM before and got an error output in the boundary condition. Your answer told me how to settle the BC error. I will have a try and test it later.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527392713
https://github.com/su2code/SU2/issues/783#issuecomment-527392713:190,Availability,error,error,190,"Thanks a lot, Tobi! I did find the file which is the only one has SOLVER=HEAT_EQUATION_FVM before and got an error output in the boundary condition. Your answer told me how to settle the BC error. I will have a try and test it later.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527392713
https://github.com/su2code/SU2/issues/783#issuecomment-527392713:219,Testability,test,test,219,"Thanks a lot, Tobi! I did find the file which is the only one has SOLVER=HEAT_EQUATION_FVM before and got an error output in the boundary condition. Your answer told me how to settle the BC error. I will have a try and test it later.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527392713
https://github.com/su2code/SU2/issues/783#issuecomment-527789690:532,Availability,error,error,532,"Hey Tobi, I have tried and succeeded in testing the HEAT_EQUATION_FVM example. One more thing to mention, to run the configSolide.cfg alone, another line needs to be edited. . ```; %EXTRA_HEAT_ZONE_OUTPUT = 2-->; EXTRA_HEAT_ZONE_OUTPUT = 1; ```. And one can directly delete all things concerning iZone=1 in the mesh file and rename iZone=2 to be iZone=1. ![2019-09-04 15-56-09 的屏幕截图](https://user-images.githubusercontent.com/33152225/64236361-d163cc80-cf2c-11e9-9971-2d4e2c01955c.png). Except for that, is anyone familiar with the error: SU2 diverge? Every time when I want to add unsteady options to make an animation, the error tells me the solution diverges. ```; ------------------------------ Begin Solver -----------------------------. Error in ""void CSysSolve::ModGramSchmidt(int, std::vector<std::vector<double> >&, std::vector<CSysVector>&)"": ; -------------------------------------------------------------------------; SU2 has diverged.; ------------------------------ Error Exit -------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527789690
https://github.com/su2code/SU2/issues/783#issuecomment-527789690:625,Availability,error,error,625,"Hey Tobi, I have tried and succeeded in testing the HEAT_EQUATION_FVM example. One more thing to mention, to run the configSolide.cfg alone, another line needs to be edited. . ```; %EXTRA_HEAT_ZONE_OUTPUT = 2-->; EXTRA_HEAT_ZONE_OUTPUT = 1; ```. And one can directly delete all things concerning iZone=1 in the mesh file and rename iZone=2 to be iZone=1. ![2019-09-04 15-56-09 的屏幕截图](https://user-images.githubusercontent.com/33152225/64236361-d163cc80-cf2c-11e9-9971-2d4e2c01955c.png). Except for that, is anyone familiar with the error: SU2 diverge? Every time when I want to add unsteady options to make an animation, the error tells me the solution diverges. ```; ------------------------------ Begin Solver -----------------------------. Error in ""void CSysSolve::ModGramSchmidt(int, std::vector<std::vector<double> >&, std::vector<CSysVector>&)"": ; -------------------------------------------------------------------------; SU2 has diverged.; ------------------------------ Error Exit -------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527789690
https://github.com/su2code/SU2/issues/783#issuecomment-527789690:743,Availability,Error,Error,743,"Hey Tobi, I have tried and succeeded in testing the HEAT_EQUATION_FVM example. One more thing to mention, to run the configSolide.cfg alone, another line needs to be edited. . ```; %EXTRA_HEAT_ZONE_OUTPUT = 2-->; EXTRA_HEAT_ZONE_OUTPUT = 1; ```. And one can directly delete all things concerning iZone=1 in the mesh file and rename iZone=2 to be iZone=1. ![2019-09-04 15-56-09 的屏幕截图](https://user-images.githubusercontent.com/33152225/64236361-d163cc80-cf2c-11e9-9971-2d4e2c01955c.png). Except for that, is anyone familiar with the error: SU2 diverge? Every time when I want to add unsteady options to make an animation, the error tells me the solution diverges. ```; ------------------------------ Begin Solver -----------------------------. Error in ""void CSysSolve::ModGramSchmidt(int, std::vector<std::vector<double> >&, std::vector<CSysVector>&)"": ; -------------------------------------------------------------------------; SU2 has diverged.; ------------------------------ Error Exit -------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527789690
https://github.com/su2code/SU2/issues/783#issuecomment-527789690:980,Availability,Error,Error,980,"Hey Tobi, I have tried and succeeded in testing the HEAT_EQUATION_FVM example. One more thing to mention, to run the configSolide.cfg alone, another line needs to be edited. . ```; %EXTRA_HEAT_ZONE_OUTPUT = 2-->; EXTRA_HEAT_ZONE_OUTPUT = 1; ```. And one can directly delete all things concerning iZone=1 in the mesh file and rename iZone=2 to be iZone=1. ![2019-09-04 15-56-09 的屏幕截图](https://user-images.githubusercontent.com/33152225/64236361-d163cc80-cf2c-11e9-9971-2d4e2c01955c.png). Except for that, is anyone familiar with the error: SU2 diverge? Every time when I want to add unsteady options to make an animation, the error tells me the solution diverges. ```; ------------------------------ Begin Solver -----------------------------. Error in ""void CSysSolve::ModGramSchmidt(int, std::vector<std::vector<double> >&, std::vector<CSysVector>&)"": ; -------------------------------------------------------------------------; SU2 has diverged.; ------------------------------ Error Exit -------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527789690
https://github.com/su2code/SU2/issues/783#issuecomment-527789690:117,Modifiability,config,configSolide,117,"Hey Tobi, I have tried and succeeded in testing the HEAT_EQUATION_FVM example. One more thing to mention, to run the configSolide.cfg alone, another line needs to be edited. . ```; %EXTRA_HEAT_ZONE_OUTPUT = 2-->; EXTRA_HEAT_ZONE_OUTPUT = 1; ```. And one can directly delete all things concerning iZone=1 in the mesh file and rename iZone=2 to be iZone=1. ![2019-09-04 15-56-09 的屏幕截图](https://user-images.githubusercontent.com/33152225/64236361-d163cc80-cf2c-11e9-9971-2d4e2c01955c.png). Except for that, is anyone familiar with the error: SU2 diverge? Every time when I want to add unsteady options to make an animation, the error tells me the solution diverges. ```; ------------------------------ Begin Solver -----------------------------. Error in ""void CSysSolve::ModGramSchmidt(int, std::vector<std::vector<double> >&, std::vector<CSysVector>&)"": ; -------------------------------------------------------------------------; SU2 has diverged.; ------------------------------ Error Exit -------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527789690
https://github.com/su2code/SU2/issues/783#issuecomment-527789690:40,Testability,test,testing,40,"Hey Tobi, I have tried and succeeded in testing the HEAT_EQUATION_FVM example. One more thing to mention, to run the configSolide.cfg alone, another line needs to be edited. . ```; %EXTRA_HEAT_ZONE_OUTPUT = 2-->; EXTRA_HEAT_ZONE_OUTPUT = 1; ```. And one can directly delete all things concerning iZone=1 in the mesh file and rename iZone=2 to be iZone=1. ![2019-09-04 15-56-09 的屏幕截图](https://user-images.githubusercontent.com/33152225/64236361-d163cc80-cf2c-11e9-9971-2d4e2c01955c.png). Except for that, is anyone familiar with the error: SU2 diverge? Every time when I want to add unsteady options to make an animation, the error tells me the solution diverges. ```; ------------------------------ Begin Solver -----------------------------. Error in ""void CSysSolve::ModGramSchmidt(int, std::vector<std::vector<double> >&, std::vector<CSysVector>&)"": ; -------------------------------------------------------------------------; SU2 has diverged.; ------------------------------ Error Exit -------------------------------; ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-527789690
https://github.com/su2code/SU2/issues/783#issuecomment-528890515:566,Deployability,Update,Update,566,"I have tried many times to figure out why the HEAT_EQUATION_FVM does not support unsteady simulation, but failed. It seems that when one set the UNSTEADY_SIMULATION= NO, he can see the flow.dat rewritten as long as a new iteration stage passes just like time goes by. However, when the option is set to be TIME_STEPPING, outputs are in flow_000*.dat Tecplot data file but the data keeps the same without change no matter how much time passes by. . Dual time method seems to be totally unavailable in HEAT_EQUATION_FVM, because they cause the diverging problem.; —-; Update. I found the unsteady simulation is stagnant due to the zero returned by get delta time function, causing -Res*Delta=0. I will check why this function doesn’t work in unsteady case.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-528890515
https://github.com/su2code/SU2/issues/783#issuecomment-532154976:34,Deployability,release,release,34,"Hi there,; let's wait for the new release before proceeding with this issue. Many bugs had been removed along the road implementing a CHT capability and the fixes will be merged in by then. I'll also add a tutorial to make `HEAT_EQUATION_FVM` and CHT an official feature. There is no link to `HEAT_EQUATION` (a FEM implementation). I think `HEAT_EQUATION` is just not supported anymore.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/783#issuecomment-532154976
https://github.com/su2code/SU2/issues/787#issuecomment-528435629:769,Energy Efficiency,efficient,efficient,769,"You've got two options:. 1. Use the cfg option `WRT_BINARY_RESTART= NO` to dump the restart file(s) in human-readable ASCII.; 2. Use the cfg option `OUTPUT_FORMAT= TECPLOT` or `OUTPUT_FORMAT=PARAVIEW` with SU2_SOL to export the solution to an ASCII-formatted tecplot or paraview file. If you're not familiar with SU2_SOL, then check out [the documentation](https://su2code.github.io/docs/Post-processing/). You can find those cfg options in `config_template.cfg` in the root SU2 source code directory. In the end, using the tecplot or paraview option may be your best bet. Trying to manually parse the text files smells like an [XY Problem](https://en.wikipedia.org/wiki/XY_problem). Tecplot and Paraview both have scripting capabilities that make post-processing very efficient. Does that answer your question? Do you have any follow-up concerns?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528435629
https://github.com/su2code/SU2/issues/787#issuecomment-528450087:139,Usability,simpl,simply,139,I am using the binary of SU2_CFD on Mac Os X for a single core run. There are no restart files for SU2_SOL to work with. IS there a way to simply export in CSV format? config_template.cfg is missing in the folders.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528450087
https://github.com/su2code/SU2/issues/787#issuecomment-528453362:379,Energy Efficiency,efficient,efficiently,379,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
https://github.com/su2code/SU2/issues/787#issuecomment-528453362:453,Safety,Predict,Prediction,453,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
https://github.com/su2code/SU2/issues/787#issuecomment-528453362:149,Usability,Learn,Learning,149,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
https://github.com/su2code/SU2/issues/787#issuecomment-528453362:318,Usability,simpl,simple,318,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
https://github.com/su2code/SU2/issues/787#issuecomment-528453362:513,Usability,Learn,Learning,513,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
https://github.com/su2code/SU2/issues/787#issuecomment-528453362:687,Usability,Learn,Learning,687,"It does output the file, Paraview & Tecplot formats (binary & ASCII) both work. However, I need the raw data as I will be subjecting it to a Machine Learning Algorithm in Python. Manually deleting the lines for cell numbers in Tecplot format is an additional time consuming step, that hinders full automation. Hence a simple file as flow.csv (CSV format) may help me run it more efficiently. 1. Ganti, Himakar & Khare, Prashant. (2018). Spatio-Temporal Prediction of Gaseous and Liquid Spray Fields using Machine Learning. 10.2514/6.2018-4760. . 2. Ganti, Himakar & Kamin, Manu & Khare, Prashant. (2019). Design Space Exploration for Vaporizing Liquid Jet in Air Crossflow using Machine Learning. 10.2514/6.2019-2211.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528453362
https://github.com/su2code/SU2/issues/787#issuecomment-528461173:379,Energy Efficiency,efficient,efficient,379,"Hi Himakar,. If you are using python, you don't need to manually delete the connectivity table from the ASCII Tecplot as you can use numpy genfromtxt.(https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html). Another option is to use the following restart_flow binary reader/writer that I wrote in Python. # ----------; def read_restart_bin(filename):. 	# Not efficient way; 	infile = open(filename, 'rb'); 	data = infile.read(); 	infile.close(). 	print ""Size of the file: "", len(data). # The first is a magic number that we can use to check for binary files (it is the hex; # representation for ""SU2"").; 	if (struct.unpack('i',data[:4])[0] != 535532):; 		print ""Magic number 535532 not found in the solution file %s"" %filename; 		sys.exit(); 		#try:; 		#	data_file = read_restart_ascii(filename); 		#	return data_file; 		#except:; 			# Exit; 		#	sys.exit(). 	# The second two values are number of variables and number of points (DoFs). ; 	nvar = struct.unpack('i',data[4:8])[0]; 	ndof = struct.unpack('i',data[8:12])[0]. 	# Read the variable names of the file. Note that we are adopting a; # fixed length of 33 for the string length to match with CGNS.; 	variables_names = []; 	for i in range(nvar):; 		aux = (struct.unpack('33s',data[20+(i)*33:20+(i+1)*33])[0]); 		for j in range(len(aux)):; 			if aux[j] == ""\x00"":; 				break; 		variables_names.append(aux[:j]). 	# Read data in one shoot; 	start = 20 + nvar*33; 	end = start+nvar*ndof*8; 	array = np.asfarray(struct.unpack('%dd'%(nvar*ndof),data[start:end])); 	array = array.reshape(ndof,nvar). 	# The last two values are for metadata: one int for ExtIter and 8 su2doubles.; 	# Metadata: 1 int for ExtIter and 8 doubles; 	#ncount = len(data) - nvar*ndof*8 - 4 - 64; 	ExtIter = struct.unpack('i',data[end:end+4])[0]; 	metadata = struct.unpack('8d',data[end+4:end+4+8*8]). 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':ExtIter, 'MetaData':metadata}; 	return data_file. def read_restart_ascii(f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461173
https://github.com/su2code/SU2/issues/787#issuecomment-528461173:917,Modifiability,variab,variables,917,"Hi Himakar,. If you are using python, you don't need to manually delete the connectivity table from the ASCII Tecplot as you can use numpy genfromtxt.(https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html). Another option is to use the following restart_flow binary reader/writer that I wrote in Python. # ----------; def read_restart_bin(filename):. 	# Not efficient way; 	infile = open(filename, 'rb'); 	data = infile.read(); 	infile.close(). 	print ""Size of the file: "", len(data). # The first is a magic number that we can use to check for binary files (it is the hex; # representation for ""SU2"").; 	if (struct.unpack('i',data[:4])[0] != 535532):; 		print ""Magic number 535532 not found in the solution file %s"" %filename; 		sys.exit(); 		#try:; 		#	data_file = read_restart_ascii(filename); 		#	return data_file; 		#except:; 			# Exit; 		#	sys.exit(). 	# The second two values are number of variables and number of points (DoFs). ; 	nvar = struct.unpack('i',data[4:8])[0]; 	ndof = struct.unpack('i',data[8:12])[0]. 	# Read the variable names of the file. Note that we are adopting a; # fixed length of 33 for the string length to match with CGNS.; 	variables_names = []; 	for i in range(nvar):; 		aux = (struct.unpack('33s',data[20+(i)*33:20+(i+1)*33])[0]); 		for j in range(len(aux)):; 			if aux[j] == ""\x00"":; 				break; 		variables_names.append(aux[:j]). 	# Read data in one shoot; 	start = 20 + nvar*33; 	end = start+nvar*ndof*8; 	array = np.asfarray(struct.unpack('%dd'%(nvar*ndof),data[start:end])); 	array = array.reshape(ndof,nvar). 	# The last two values are for metadata: one int for ExtIter and 8 su2doubles.; 	# Metadata: 1 int for ExtIter and 8 doubles; 	#ncount = len(data) - nvar*ndof*8 - 4 - 64; 	ExtIter = struct.unpack('i',data[end:end+4])[0]; 	metadata = struct.unpack('8d',data[end+4:end+4+8*8]). 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':ExtIter, 'MetaData':metadata}; 	return data_file. def read_restart_ascii(f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461173
https://github.com/su2code/SU2/issues/787#issuecomment-528461173:1053,Modifiability,variab,variable,1053,"ally delete the connectivity table from the ASCII Tecplot as you can use numpy genfromtxt.(https://docs.scipy.org/doc/numpy/reference/generated/numpy.genfromtxt.html). Another option is to use the following restart_flow binary reader/writer that I wrote in Python. # ----------; def read_restart_bin(filename):. 	# Not efficient way; 	infile = open(filename, 'rb'); 	data = infile.read(); 	infile.close(). 	print ""Size of the file: "", len(data). # The first is a magic number that we can use to check for binary files (it is the hex; # representation for ""SU2"").; 	if (struct.unpack('i',data[:4])[0] != 535532):; 		print ""Magic number 535532 not found in the solution file %s"" %filename; 		sys.exit(); 		#try:; 		#	data_file = read_restart_ascii(filename); 		#	return data_file; 		#except:; 			# Exit; 		#	sys.exit(). 	# The second two values are number of variables and number of points (DoFs). ; 	nvar = struct.unpack('i',data[4:8])[0]; 	ndof = struct.unpack('i',data[8:12])[0]. 	# Read the variable names of the file. Note that we are adopting a; # fixed length of 33 for the string length to match with CGNS.; 	variables_names = []; 	for i in range(nvar):; 		aux = (struct.unpack('33s',data[20+(i)*33:20+(i+1)*33])[0]); 		for j in range(len(aux)):; 			if aux[j] == ""\x00"":; 				break; 		variables_names.append(aux[:j]). 	# Read data in one shoot; 	start = 20 + nvar*33; 	end = start+nvar*ndof*8; 	array = np.asfarray(struct.unpack('%dd'%(nvar*ndof),data[start:end])); 	array = array.reshape(ndof,nvar). 	# The last two values are for metadata: one int for ExtIter and 8 su2doubles.; 	# Metadata: 1 int for ExtIter and 8 doubles; 	#ncount = len(data) - nvar*ndof*8 - 4 - 64; 	ExtIter = struct.unpack('i',data[end:end+4])[0]; 	metadata = struct.unpack('8d',data[end+4:end+4+8*8]). 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':ExtIter, 'MetaData':metadata}; 	return data_file. def read_restart_ascii(filename):; 	""""""; 	; 	""""""; 	infile = open(filename, 'r'); 	h",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461173
https://github.com/su2code/SU2/issues/787#issuecomment-528461173:2694,Modifiability,variab,variables,2694,"('%dd'%(nvar*ndof),data[start:end])); 	array = array.reshape(ndof,nvar). 	# The last two values are for metadata: one int for ExtIter and 8 su2doubles.; 	# Metadata: 1 int for ExtIter and 8 doubles; 	#ncount = len(data) - nvar*ndof*8 - 4 - 64; 	ExtIter = struct.unpack('i',data[end:end+4])[0]; 	metadata = struct.unpack('8d',data[end+4:end+4+8*8]). 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':ExtIter, 'MetaData':metadata}; 	return data_file. def read_restart_ascii(filename):; 	""""""; 	; 	""""""; 	infile = open(filename, 'r'); 	header = infile.readline(); 	variables_names = header.replace(""\"""","" "").replace(""\t"", "" "").strip().split()[1:]; 	infile.close(); 	; 	array = np.loadtxt(filename, skiprows = 1). 	array = array[:,1:]; 	; 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':0, 'MetaData':[]}	; 	return data_file. def write_restart_binary(data_file,filename=""solution_flow_bin.dat""):; 	"""""". 	""""""; 	fout = open(filename,'wb'). 	# The first is a magic number that we can use to check for binary files (it is the hex; 	# representation for ""SU2"").; 	fout.write(struct.pack('i', 535532)). 	# The second two values are number of variables and number of points (DoFs).; 	nvar = data_file['data'].shape[1]; 	ndof = data_file['data'].shape[0]; 	fout.write(struct.pack('i', nvar)); 	fout.write(struct.pack('i', ndof)); 	fout.write(struct.pack('i', 1)); 	fout.write(struct.pack('i', 8)). 	# Write the variable names of the file. Note that we are adopting a; # fixed length of 33 for the string length to match with CGNS.; 	for variable_name in data_file['names']:; 		fout.write(struct.pack('33s', variable_name)); 	; 	# Write the entire data in one shoot; 	fout.write(struct.pack('%dd'%(nvar*ndof), *data_file['data'].flatten())). 	# Write ExtIter and Metadata; 	fout.write(struct.pack('i',data_file['ExtIter'])); 	for i in range(8):; 		fout.write(struct.pack('d', data_file['MetaData'][i])); 	fout.close(). 	return None; # ----------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461173
https://github.com/su2code/SU2/issues/787#issuecomment-528461173:2961,Modifiability,variab,variable,2961,"('%dd'%(nvar*ndof),data[start:end])); 	array = array.reshape(ndof,nvar). 	# The last two values are for metadata: one int for ExtIter and 8 su2doubles.; 	# Metadata: 1 int for ExtIter and 8 doubles; 	#ncount = len(data) - nvar*ndof*8 - 4 - 64; 	ExtIter = struct.unpack('i',data[end:end+4])[0]; 	metadata = struct.unpack('8d',data[end+4:end+4+8*8]). 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':ExtIter, 'MetaData':metadata}; 	return data_file. def read_restart_ascii(filename):; 	""""""; 	; 	""""""; 	infile = open(filename, 'r'); 	header = infile.readline(); 	variables_names = header.replace(""\"""","" "").replace(""\t"", "" "").strip().split()[1:]; 	infile.close(); 	; 	array = np.loadtxt(filename, skiprows = 1). 	array = array[:,1:]; 	; 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':0, 'MetaData':[]}	; 	return data_file. def write_restart_binary(data_file,filename=""solution_flow_bin.dat""):; 	"""""". 	""""""; 	fout = open(filename,'wb'). 	# The first is a magic number that we can use to check for binary files (it is the hex; 	# representation for ""SU2"").; 	fout.write(struct.pack('i', 535532)). 	# The second two values are number of variables and number of points (DoFs).; 	nvar = data_file['data'].shape[1]; 	ndof = data_file['data'].shape[0]; 	fout.write(struct.pack('i', nvar)); 	fout.write(struct.pack('i', ndof)); 	fout.write(struct.pack('i', 1)); 	fout.write(struct.pack('i', 8)). 	# Write the variable names of the file. Note that we are adopting a; # fixed length of 33 for the string length to match with CGNS.; 	for variable_name in data_file['names']:; 		fout.write(struct.pack('33s', variable_name)); 	; 	# Write the entire data in one shoot; 	fout.write(struct.pack('%dd'%(nvar*ndof), *data_file['data'].flatten())). 	# Write ExtIter and Metadata; 	fout.write(struct.pack('i',data_file['ExtIter'])); 	for i in range(8):; 		fout.write(struct.pack('d', data_file['MetaData'][i])); 	fout.close(). 	return None; # ----------",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461173
https://github.com/su2code/SU2/issues/787#issuecomment-528461173:2203,Performance,load,loadtxt,2203,"; 		aux = (struct.unpack('33s',data[20+(i)*33:20+(i+1)*33])[0]); 		for j in range(len(aux)):; 			if aux[j] == ""\x00"":; 				break; 		variables_names.append(aux[:j]). 	# Read data in one shoot; 	start = 20 + nvar*33; 	end = start+nvar*ndof*8; 	array = np.asfarray(struct.unpack('%dd'%(nvar*ndof),data[start:end])); 	array = array.reshape(ndof,nvar). 	# The last two values are for metadata: one int for ExtIter and 8 su2doubles.; 	# Metadata: 1 int for ExtIter and 8 doubles; 	#ncount = len(data) - nvar*ndof*8 - 4 - 64; 	ExtIter = struct.unpack('i',data[end:end+4])[0]; 	metadata = struct.unpack('8d',data[end+4:end+4+8*8]). 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':ExtIter, 'MetaData':metadata}; 	return data_file. def read_restart_ascii(filename):; 	""""""; 	; 	""""""; 	infile = open(filename, 'r'); 	header = infile.readline(); 	variables_names = header.replace(""\"""","" "").replace(""\t"", "" "").strip().split()[1:]; 	infile.close(); 	; 	array = np.loadtxt(filename, skiprows = 1). 	array = array[:,1:]; 	; 	# Create dictionary; 	data_file = {'names':variables_names,'data':array, 'ExtIter':0, 'MetaData':[]}	; 	return data_file. def write_restart_binary(data_file,filename=""solution_flow_bin.dat""):; 	"""""". 	""""""; 	fout = open(filename,'wb'). 	# The first is a magic number that we can use to check for binary files (it is the hex; 	# representation for ""SU2"").; 	fout.write(struct.pack('i', 535532)). 	# The second two values are number of variables and number of points (DoFs).; 	nvar = data_file['data'].shape[1]; 	ndof = data_file['data'].shape[0]; 	fout.write(struct.pack('i', nvar)); 	fout.write(struct.pack('i', ndof)); 	fout.write(struct.pack('i', 1)); 	fout.write(struct.pack('i', 8)). 	# Write the variable names of the file. Note that we are adopting a; # fixed length of 33 for the string length to match with CGNS.; 	for variable_name in data_file['names']:; 		fout.write(struct.pack('33s', variable_name)); 	; 	# Write the entire data in one shoot; 	fo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461173
https://github.com/su2code/SU2/issues/787#issuecomment-528461710:203,Energy Efficiency,Energy,Energy,203,"Run SU2_CFD with `WRT_BINARY_RESTART= NO`. That will give you an ASCII `restart_flow.dat`. It will look something like this:; ```; ""PointID""	""x""	""y""	""z""	""Density""	""X-Momentum""	""Y-Momentum""	""Z-Momentum""	""Energy""	""Pressure""	""Temperature""	""C<sub>p</sub>""	""Mach""; 0	6.931794337794450e-01	1.199410270705132e+00	3.552713678800501e-15	9.247274759558524e-01	6.998395924205978e-01	6.744390123118781e-01	2.033333591408758e-01	2.825647424000119e+00	9.170095708259952e-01	9.784295110379145e-01	-1.930126447908861e-01	9.113348070779481e-01	; 1	6.906841300000011e-01	1.196300000000000e+00	0.000000000000000e+00	1.118921803269151e+00	5.021166385546235e-01	7.896289876522433e-01	2.161057381347509e-01	3.352487832836354e+00	1.176133434271568e+00	1.037113520398247e+00	3.252350821002600e-01	7.075425651590469e-01	; 2	6.924294614497271e-01	1.202091611452504e+00	1.468890958566504e-03	9.758692057411605e-01	8.423040306657703e-01	5.135454779704676e-01	2.297213358745695e-01	2.971366201327637e+00	9.782771280113181e-01	9.890989089014984e-01	-7.047753042024051e-02	8.761491078578573e-01	; ```; This answers the original question, ""How do I get SU2 to output raw ASCII data?"". You can also use the python scripting capabilities of Tecplot or Paraview (technically, VTK). You can find documentation for Tecplot's python API [here](https://www.tecplot.com/docs/pytecplot/index.html) and for VTK's python API [here](https://lorensen.github.io/VTKExamples/site/). That will allow you to use the Paraview or Tecplot files directly in python. You would use the paraview or tecplot libraries to load the data into python, then post-process it however you want. There's no need for ""manually deleting the lines for cell numbers.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461710
https://github.com/su2code/SU2/issues/787#issuecomment-528461710:1564,Performance,load,load,1564,"Run SU2_CFD with `WRT_BINARY_RESTART= NO`. That will give you an ASCII `restart_flow.dat`. It will look something like this:; ```; ""PointID""	""x""	""y""	""z""	""Density""	""X-Momentum""	""Y-Momentum""	""Z-Momentum""	""Energy""	""Pressure""	""Temperature""	""C<sub>p</sub>""	""Mach""; 0	6.931794337794450e-01	1.199410270705132e+00	3.552713678800501e-15	9.247274759558524e-01	6.998395924205978e-01	6.744390123118781e-01	2.033333591408758e-01	2.825647424000119e+00	9.170095708259952e-01	9.784295110379145e-01	-1.930126447908861e-01	9.113348070779481e-01	; 1	6.906841300000011e-01	1.196300000000000e+00	0.000000000000000e+00	1.118921803269151e+00	5.021166385546235e-01	7.896289876522433e-01	2.161057381347509e-01	3.352487832836354e+00	1.176133434271568e+00	1.037113520398247e+00	3.252350821002600e-01	7.075425651590469e-01	; 2	6.924294614497271e-01	1.202091611452504e+00	1.468890958566504e-03	9.758692057411605e-01	8.423040306657703e-01	5.135454779704676e-01	2.297213358745695e-01	2.971366201327637e+00	9.782771280113181e-01	9.890989089014984e-01	-7.047753042024051e-02	8.761491078578573e-01	; ```; This answers the original question, ""How do I get SU2 to output raw ASCII data?"". You can also use the python scripting capabilities of Tecplot or Paraview (technically, VTK). You can find documentation for Tecplot's python API [here](https://www.tecplot.com/docs/pytecplot/index.html) and for VTK's python API [here](https://lorensen.github.io/VTKExamples/site/). That will allow you to use the Paraview or Tecplot files directly in python. You would use the paraview or tecplot libraries to load the data into python, then post-process it however you want. There's no need for ""manually deleting the lines for cell numbers.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528461710
https://github.com/su2code/SU2/issues/787#issuecomment-528484440:1128,Availability,error,errors,1128,"I am sorry, but neither of those 2 is helpful to me. I can obtain ASCII data with Tecplot format, and with the restart file. However, the end of the restart_flow file looks something like this, and it may change with conditions for simulation:; ```; 3748	2.000000000000002e-02	0.000000000000000e+00	1.161205517119654e+00	8.075360800285049e+02	-4.616675578067918e-14	5.307920350591170e+05	9.999999999999996e+04	2.999999999999997e+02	2.002826699082778e+00	-1.559133774467877e-16	; 3749	0.000000000000000e+00	0.000000000000000e+00	1.161205517119653e+00	8.075360800285049e+02	-1.451560808848285e-13	5.307920350591170e+05	9.999999999999988e+04	2.999999999999997e+02	2.002826699082779e+00	-4.157690065247673e-16	; EXT_ITER= 195; AOA= 0.000000000000000e+00; SIDESLIP_ANGLE= 0.000000000000000e+00; INITIAL_BCTHRUST= 4.000000000000000e+03; DCD_DCL_VALUE= 0.000000000000000e+00; DCMX_DCL_VALUE= 0.000000000000000e+00; DCMY_DCL_VALUE= 0.000000000000000e+00; DCMZ_DCL_VALUE= 0.000000000000000e+00; ```; It is the same case for the _flow.dat_ file with Tecplot format. When reading this data file back with Python, the last lines will cause errors (with skip_footer option in numpy.genfromtxt) if they are not consistent in number for the parameter sweep. I only need the array w/o the tail data and wanted to avoid additional scripting through Tecplot or Paraview for a faster turnaround for speedup. Hence I was requesting if we can have a CSV format, with just the raw grid data and headings.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528484440
https://github.com/su2code/SU2/issues/787#issuecomment-528484440:1297,Safety,avoid,avoid,1297,"I am sorry, but neither of those 2 is helpful to me. I can obtain ASCII data with Tecplot format, and with the restart file. However, the end of the restart_flow file looks something like this, and it may change with conditions for simulation:; ```; 3748	2.000000000000002e-02	0.000000000000000e+00	1.161205517119654e+00	8.075360800285049e+02	-4.616675578067918e-14	5.307920350591170e+05	9.999999999999996e+04	2.999999999999997e+02	2.002826699082778e+00	-1.559133774467877e-16	; 3749	0.000000000000000e+00	0.000000000000000e+00	1.161205517119653e+00	8.075360800285049e+02	-1.451560808848285e-13	5.307920350591170e+05	9.999999999999988e+04	2.999999999999997e+02	2.002826699082779e+00	-4.157690065247673e-16	; EXT_ITER= 195; AOA= 0.000000000000000e+00; SIDESLIP_ANGLE= 0.000000000000000e+00; INITIAL_BCTHRUST= 4.000000000000000e+03; DCD_DCL_VALUE= 0.000000000000000e+00; DCMX_DCL_VALUE= 0.000000000000000e+00; DCMY_DCL_VALUE= 0.000000000000000e+00; DCMZ_DCL_VALUE= 0.000000000000000e+00; ```; It is the same case for the _flow.dat_ file with Tecplot format. When reading this data file back with Python, the last lines will cause errors (with skip_footer option in numpy.genfromtxt) if they are not consistent in number for the parameter sweep. I only need the array w/o the tail data and wanted to avoid additional scripting through Tecplot or Paraview for a faster turnaround for speedup. Hence I was requesting if we can have a CSV format, with just the raw grid data and headings.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528484440
https://github.com/su2code/SU2/issues/787#issuecomment-528493781:106,Usability,simpl,simple,106,"If you _must_ use `restart_flow.dat`, then look at np.genfromtxt and the `invalid_raise` option. Here's a simple example:. ```python; import numpy as np; import matplotlib.pyplot as plt. data = np.genfromtxt(""solution_adj_combo.dat"", names=True, invalid_raise=False). plt.tricontourf(data[""x""], data[""y""], data[""Adjoint_Density""]); plt.show(); ```",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-528493781
https://github.com/su2code/SU2/issues/787#issuecomment-599629203:79,Availability,error,error,79,@clarkpede Can you please help how I can dump tecplot files? I am getting this error when it is trying to dump tecplot - YOUR APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7). ; Earlier I was using PARAVIEW and never see any issues in dumping them (both with FV and FEM solvers). But now files are so huge or some issues with Paraview to open dumped files from FEM solver for LES (DG scheme). So trying to switch back to Tecplot. But Can you suggest if I am missing something here in FEM solvers for dumping these files? Paraview should work or we have issues with FEM solvers with Paraview pr tecplot dumping files ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599629203
https://github.com/su2code/SU2/issues/787#issuecomment-599629203:175,Availability,error,error,175,@clarkpede Can you please help how I can dump tecplot files? I am getting this error when it is trying to dump tecplot - YOUR APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7). ; Earlier I was using PARAVIEW and never see any issues in dumping them (both with FV and FEM solvers). But now files are so huge or some issues with Paraview to open dumped files from FEM solver for LES (DG scheme). So trying to switch back to Tecplot. But Can you suggest if I am missing something here in FEM solvers for dumping these files? Paraview should work or we have issues with FEM solvers with Paraview pr tecplot dumping files ?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599629203
https://github.com/su2code/SU2/issues/787#issuecomment-599733674:217,Availability,error,error,217,"@monika1387 Can you describe what you mean by ""dumping"" the files? Are you talking about exporting the solution as a tecplot file? Or are you talking about post-processing the tecplot files themselves?. When does the error occur? Can you create a minimal working example?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599733674
https://github.com/su2code/SU2/issues/787#issuecomment-599774822:605,Availability,error,error,605,"> ﻿@clarkepede; > yes I mean exporting the solution as tecplot because paraview is not showing the result in visualisation when trying to open. Yes post processing but before post processing it needs to export solution in Tecplot format which is not happening . Monika Chauhan ; Sent from my iPhone. > On 16-Mar-2020, at 4:02 PM, Clark Pederson <notifications@github.com> wrote:; > ; > @monika1387 Can you describe what you mean by ""dumping"" the files? Are you talking about exporting the solution as a tecplot file? Or are you talking about post-processing the tecplot files themselves?; > When does the error occur? Can you create a minimal working example?; > ; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub, or unsubscribe.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599774822
https://github.com/su2code/SU2/issues/787#issuecomment-599781328:155,Availability,error,error,155,"@monika1387 I'm sorry, I still don't understand. Do you have a minimal working example, where you can reproduce the problem you're having?. Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In Tecplot? What's the specific error message? What's the context?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599781328
https://github.com/su2code/SU2/issues/787#issuecomment-599781328:237,Availability,error,error,237,"@monika1387 I'm sorry, I still don't understand. Do you have a minimal working example, where you can reproduce the problem you're having?. Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In Tecplot? What's the specific error message? What's the context?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599781328
https://github.com/su2code/SU2/issues/787#issuecomment-599781328:243,Integrability,message,message,243,"@monika1387 I'm sorry, I still don't understand. Do you have a minimal working example, where you can reproduce the problem you're having?. Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In Tecplot? What's the specific error message? What's the context?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599781328
https://github.com/su2code/SU2/issues/787#issuecomment-599793809:388,Availability,error,error,388,"@clarkepede Sure, I will try to make an example to show .; So my problem is CD nozzle and I am running FEM-LES solver and exported; data in .csv and PARAVIEW type. Everything seems good its just I was unable; to visualize exported .vtk files (open but does not show me the final; result- stuck in just opening it - I am not sure if its paraview issue or; its 4 GB file which causing this error). So I tried to export my file using; Tecplot type option but unable to do so and getting this Bus error which I; never encountered earlier in SU2 ever (what is that error - YOUR; APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; trying to dump my files in anyway to visualize them, since its FEM-LES; solver with DG scheme so files are pretty huge. Still let me know if I need; to send you an example. Attached .cfg file for reference. On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; wrote:. > @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; > understand. Do you have a minimal working example, where you can reproduce; > the problem you're having?; >; > Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; > Tecplot? What's the specific error message? What's the context?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599793809
https://github.com/su2code/SU2/issues/787#issuecomment-599793809:493,Availability,error,error,493,"@clarkepede Sure, I will try to make an example to show .; So my problem is CD nozzle and I am running FEM-LES solver and exported; data in .csv and PARAVIEW type. Everything seems good its just I was unable; to visualize exported .vtk files (open but does not show me the final; result- stuck in just opening it - I am not sure if its paraview issue or; its 4 GB file which causing this error). So I tried to export my file using; Tecplot type option but unable to do so and getting this Bus error which I; never encountered earlier in SU2 ever (what is that error - YOUR; APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; trying to dump my files in anyway to visualize them, since its FEM-LES; solver with DG scheme so files are pretty huge. Still let me know if I need; to send you an example. Attached .cfg file for reference. On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; wrote:. > @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; > understand. Do you have a minimal working example, where you can reproduce; > the problem you're having?; >; > Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; > Tecplot? What's the specific error message? What's the context?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599793809
https://github.com/su2code/SU2/issues/787#issuecomment-599793809:560,Availability,error,error,560,"@clarkepede Sure, I will try to make an example to show .; So my problem is CD nozzle and I am running FEM-LES solver and exported; data in .csv and PARAVIEW type. Everything seems good its just I was unable; to visualize exported .vtk files (open but does not show me the final; result- stuck in just opening it - I am not sure if its paraview issue or; its 4 GB file which causing this error). So I tried to export my file using; Tecplot type option but unable to do so and getting this Bus error which I; never encountered earlier in SU2 ever (what is that error - YOUR; APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; trying to dump my files in anyway to visualize them, since its FEM-LES; solver with DG scheme so files are pretty huge. Still let me know if I need; to send you an example. Attached .cfg file for reference. On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; wrote:. > @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; > understand. Do you have a minimal working example, where you can reproduce; > the problem you're having?; >; > Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; > Tecplot? What's the specific error message? What's the context?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599793809
https://github.com/su2code/SU2/issues/787#issuecomment-599793809:623,Availability,error,error,623,"@clarkepede Sure, I will try to make an example to show .; So my problem is CD nozzle and I am running FEM-LES solver and exported; data in .csv and PARAVIEW type. Everything seems good its just I was unable; to visualize exported .vtk files (open but does not show me the final; result- stuck in just opening it - I am not sure if its paraview issue or; its 4 GB file which causing this error). So I tried to export my file using; Tecplot type option but unable to do so and getting this Bus error which I; never encountered earlier in SU2 ever (what is that error - YOUR; APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; trying to dump my files in anyway to visualize them, since its FEM-LES; solver with DG scheme so files are pretty huge. Still let me know if I need; to send you an example. Attached .cfg file for reference. On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; wrote:. > @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; > understand. Do you have a minimal working example, where you can reproduce; > the problem you're having?; >; > Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; > Tecplot? What's the specific error message? What's the context?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599793809
https://github.com/su2code/SU2/issues/787#issuecomment-599793809:1136,Availability,error,error,1136,"@clarkepede Sure, I will try to make an example to show .; So my problem is CD nozzle and I am running FEM-LES solver and exported; data in .csv and PARAVIEW type. Everything seems good its just I was unable; to visualize exported .vtk files (open but does not show me the final; result- stuck in just opening it - I am not sure if its paraview issue or; its 4 GB file which causing this error). So I tried to export my file using; Tecplot type option but unable to do so and getting this Bus error which I; never encountered earlier in SU2 ever (what is that error - YOUR; APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; trying to dump my files in anyway to visualize them, since its FEM-LES; solver with DG scheme so files are pretty huge. Still let me know if I need; to send you an example. Attached .cfg file for reference. On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; wrote:. > @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; > understand. Do you have a minimal working example, where you can reproduce; > the problem you're having?; >; > Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; > Tecplot? What's the specific error message? What's the context?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599793809
https://github.com/su2code/SU2/issues/787#issuecomment-599793809:1221,Availability,error,error,1221,"@clarkepede Sure, I will try to make an example to show .; So my problem is CD nozzle and I am running FEM-LES solver and exported; data in .csv and PARAVIEW type. Everything seems good its just I was unable; to visualize exported .vtk files (open but does not show me the final; result- stuck in just opening it - I am not sure if its paraview issue or; its 4 GB file which causing this error). So I tried to export my file using; Tecplot type option but unable to do so and getting this Bus error which I; never encountered earlier in SU2 ever (what is that error - YOUR; APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; trying to dump my files in anyway to visualize them, since its FEM-LES; solver with DG scheme so files are pretty huge. Still let me know if I need; to send you an example. Attached .cfg file for reference. On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; wrote:. > @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; > understand. Do you have a minimal working example, where you can reproduce; > the problem you're having?; >; > Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; > Tecplot? What's the specific error message? What's the context?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599793809
https://github.com/su2code/SU2/issues/787#issuecomment-599793809:1227,Integrability,message,message,1227,"@clarkepede Sure, I will try to make an example to show .; So my problem is CD nozzle and I am running FEM-LES solver and exported; data in .csv and PARAVIEW type. Everything seems good its just I was unable; to visualize exported .vtk files (open but does not show me the final; result- stuck in just opening it - I am not sure if its paraview issue or; its 4 GB file which causing this error). So I tried to export my file using; Tecplot type option but unable to do so and getting this Bus error which I; never encountered earlier in SU2 ever (what is that error - YOUR; APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; trying to dump my files in anyway to visualize them, since its FEM-LES; solver with DG scheme so files are pretty huge. Still let me know if I need; to send you an example. Attached .cfg file for reference. On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; wrote:. > @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; > understand. Do you have a minimal working example, where you can reproduce; > the problem you're having?; >; > Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; > Tecplot? What's the specific error message? What's the context?; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599793809
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:250,Availability,redundant,redundant,250,"Also since this issue is getting resolved, is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:910,Availability,error,error,910,"Also since this issue is getting resolved, is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:1017,Availability,error,error,1017,"is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; >> unsubscribe; >> <https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:1086,Availability,error,error,1086,"is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; >> unsubscribe; >> <https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:1151,Availability,error,error,1151,"is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; >> unsubscribe; >> <https://github.co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:1692,Availability,error,error,1692,"I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; >> .; >>; >; >; > --; > *Thank you,*; >; > *Monika Chauhan *; >; > *Graduate Research Assistant, Doctoral Program*; >; > *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; > *Cell# 540-998-5012*; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:1778,Availability,error,error,1778,"I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; >> .; >>; >; >; > --; > *Thank you,*; >; > *Monika Chauhan *; >; > *Graduate Research Assistant, Doctoral Program*; >; > *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; > *Cell# 540-998-5012*; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:76,Energy Efficiency,reduce,reduced,76,"Also since this issue is getting resolved, is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:221,Energy Efficiency,reduce,reduce,221,"Also since this issue is getting resolved, is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:1784,Integrability,message,message,1784,"I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>, or; >> unsubscribe; >> <https://github.com/notifications/unsubscribe-auth/ALJ3OXFU367WBC2BSOGLCILRH2P7VANCNFSM4IT7MM2A>; >> .; >>; >; >; > --; > *Thank you,*; >; > *Monika Chauhan *; >; > *Graduate Research Assistant, Doctoral Program*; >; > *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; > *Cell# 540-998-5012*; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:94,Modifiability,variab,variables,94,"Also since this issue is getting resolved, is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599795725:250,Safety,redund,redundant,250,"Also since this issue is getting resolved, is there anyway or option I can; reduced number of variables in exported results? I tried using; VOLUME_OUTPUT= (COORDINATES, PRIMITIVE) deleted SOLUTIONS so that I can; able to reduce the size of file from redundant parameters which i don't; need as of now. But seems like that does not work either and exported .vtk; with same size. It supposed to work like that if I understand correctly. On Mon, Mar 16, 2020 at 6:53 PM Monika Chauhan <monika1387@vt.edu> wrote:. > @clarkepede Sure, I will try to make an example to show .; > So my problem is CD nozzle and I am running FEM-LES solver and exported; > data in .csv and PARAVIEW type. Everything seems good its just I was unable; > to visualize exported .vtk files (open but does not show me the final; > result- stuck in just opening it - I am not sure if its paraview issue or; > its 4 GB file which causing this error). So I tried to export my file using; > Tecplot type option but unable to do so and getting this Bus error which I; > never encountered earlier in SU2 ever (what is that error - YOUR; > APPLICATION TERMINATED WITH THE EXIT STRING: Bus error (signal 7)). So; > trying to dump my files in anyway to visualize them, since its FEM-LES; > solver with DG scheme so files are pretty huge. Still let me know if I need; > to send you an example. Attached .cfg file for reference.; >; >; >; > On Mon, Mar 16, 2020 at 6:13 PM Clark Pederson <notifications@github.com>; > wrote:; >; >> @monika1387 <https://github.com/monika1387> I'm sorry, I still don't; >> understand. Do you have a minimal working example, where you can reproduce; >> the problem you're having?; >>; >> Where does the error occur? In SU2_CFD? In SU2_SOL? In Paraview? In; >> Tecplot? What's the specific error message? What's the context?; >>; >> —; >> You are receiving this because you were mentioned.; >> Reply to this email directly, view it on GitHub; >> <https://github.com/su2code/SU2/issues/787#issuecomment-599781328>,",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599795725
https://github.com/su2code/SU2/issues/787#issuecomment-599805153:168,Availability,error,errors,168,"I can also confirm that there is an issue with the *binary* Paraview output for large files. The code appears to write out the .vtu file just fine, but Paraview throws errors when attempting to open it. This does not occur for ASCII format Paraview files or smaller binary Paraview files. The case I am working on consists of a 180 million cell mesh. Also, @monika1387 , please note that the DG-FEM LES capability is *not* currently fully validated, and may be unstable in certain circumstances. Use this at your own risk. We are working on fixes for the DG solver, but they are still a ways away from being finished.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599805153
https://github.com/su2code/SU2/issues/787#issuecomment-599805153:517,Safety,risk,risk,517,"I can also confirm that there is an issue with the *binary* Paraview output for large files. The code appears to write out the .vtu file just fine, but Paraview throws errors when attempting to open it. This does not occur for ASCII format Paraview files or smaller binary Paraview files. The case I am working on consists of a 180 million cell mesh. Also, @monika1387 , please note that the DG-FEM LES capability is *not* currently fully validated, and may be unstable in certain circumstances. Use this at your own risk. We are working on fixes for the DG solver, but they are still a ways away from being finished.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599805153
https://github.com/su2code/SU2/issues/787#issuecomment-599805153:439,Security,validat,validated,439,"I can also confirm that there is an issue with the *binary* Paraview output for large files. The code appears to write out the .vtu file just fine, but Paraview throws errors when attempting to open it. This does not occur for ASCII format Paraview files or smaller binary Paraview files. The case I am working on consists of a 180 million cell mesh. Also, @monika1387 , please note that the DG-FEM LES capability is *not* currently fully validated, and may be unstable in certain circumstances. Use this at your own risk. We are working on fixes for the DG solver, but they are still a ways away from being finished.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599805153
https://github.com/su2code/SU2/issues/787#issuecomment-599807771:500,Availability,error,errors,500,"@; *GomerOfDoom <https://github.com/GomerOfDoom>*. *Then it makes sense why I am having this trouble. Thank you for letting me; know. This helps a lot. I will try to figure this one out atleast for my; case, what I can do. Appreciate your response! *. On Mon, Mar 16, 2020 at 7:36 PM Paul <notifications@github.com> wrote:. > I can also confirm that there is an issue with the *binary* Paraview; > output for large files. The code appears to write out the .vtu file just; > fine, but Paraview throws errors when attempting to open it. This does not; > occur for ASCII format Paraview files or smaller binary Paraview files. The; > case I am working on consists of a 180 million cell mesh.; >; > Also, @monika1387 <https://github.com/monika1387> , please note that the; > DG-FEM LES capability is *not* currently fully validated, and may be; > unstable in certain circumstances. Use this at your own risk. We are; > working on fixes for the DG solver, but they are still a ways away from; > being finished.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599805153>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXCKD44SRSZPDWKSDM3RH2ZZFANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599807771
https://github.com/su2code/SU2/issues/787#issuecomment-599807771:899,Safety,risk,risk,899,"@; *GomerOfDoom <https://github.com/GomerOfDoom>*. *Then it makes sense why I am having this trouble. Thank you for letting me; know. This helps a lot. I will try to figure this one out atleast for my; case, what I can do. Appreciate your response! *. On Mon, Mar 16, 2020 at 7:36 PM Paul <notifications@github.com> wrote:. > I can also confirm that there is an issue with the *binary* Paraview; > output for large files. The code appears to write out the .vtu file just; > fine, but Paraview throws errors when attempting to open it. This does not; > occur for ASCII format Paraview files or smaller binary Paraview files. The; > case I am working on consists of a 180 million cell mesh.; >; > Also, @monika1387 <https://github.com/monika1387> , please note that the; > DG-FEM LES capability is *not* currently fully validated, and may be; > unstable in certain circumstances. Use this at your own risk. We are; > working on fixes for the DG solver, but they are still a ways away from; > being finished.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599805153>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXCKD44SRSZPDWKSDM3RH2ZZFANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599807771
https://github.com/su2code/SU2/issues/787#issuecomment-599807771:818,Security,validat,validated,818,"@; *GomerOfDoom <https://github.com/GomerOfDoom>*. *Then it makes sense why I am having this trouble. Thank you for letting me; know. This helps a lot. I will try to figure this one out atleast for my; case, what I can do. Appreciate your response! *. On Mon, Mar 16, 2020 at 7:36 PM Paul <notifications@github.com> wrote:. > I can also confirm that there is an issue with the *binary* Paraview; > output for large files. The code appears to write out the .vtu file just; > fine, but Paraview throws errors when attempting to open it. This does not; > occur for ASCII format Paraview files or smaller binary Paraview files. The; > case I am working on consists of a 180 million cell mesh.; >; > Also, @monika1387 <https://github.com/monika1387> , please note that the; > DG-FEM LES capability is *not* currently fully validated, and may be; > unstable in certain circumstances. Use this at your own risk. We are; > working on fixes for the DG solver, but they are still a ways away from; > being finished.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-599805153>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXCKD44SRSZPDWKSDM3RH2ZZFANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-599807771
https://github.com/su2code/SU2/issues/787#issuecomment-651252372:1215,Availability,error,error,1215,"> You've got two options:; > ; > 1. Use the cfg option `WRT_BINARY_RESTART= NO` to dump the restart file(s) in human-readable ASCII.; > 2. Use the cfg option `OUTPUT_FORMAT= TECPLOT` or `OUTPUT_FORMAT=PARAVIEW` with SU2_SOL to export the solution to an ASCII-formatted tecplot or paraview file. If you're not familiar with SU2_SOL, then check out [the documentation](https://su2code.github.io/docs/Post-processing/).; > ; > You can find those cfg options in `config_template.cfg` in the root SU2 source code directory.; > ; > In the end, using the tecplot or paraview option may be your best bet. Trying to manually parse the text files smells like an [XY Problem](https://en.wikipedia.org/wiki/XY_problem). Tecplot and Paraview both have scripting capabilities that make post-processing very efficient.; > ; > Does that answer your question? Do you have any follow-up concerns?. Hello @clarkpede can you please tell me how to convert the output flile format from vtu to vtk; I am facing a lots of trouble to open the file in Paraview but the output format is coming vtu everytime Can you please explain how to solve this problem; And whenever i tries to change the output format by editting in notepad it tells an error that check option in SU2 config_template.cfg ; Please Help",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-651252372
https://github.com/su2code/SU2/issues/787#issuecomment-651252372:793,Energy Efficiency,efficient,efficient,793,"> You've got two options:; > ; > 1. Use the cfg option `WRT_BINARY_RESTART= NO` to dump the restart file(s) in human-readable ASCII.; > 2. Use the cfg option `OUTPUT_FORMAT= TECPLOT` or `OUTPUT_FORMAT=PARAVIEW` with SU2_SOL to export the solution to an ASCII-formatted tecplot or paraview file. If you're not familiar with SU2_SOL, then check out [the documentation](https://su2code.github.io/docs/Post-processing/).; > ; > You can find those cfg options in `config_template.cfg` in the root SU2 source code directory.; > ; > In the end, using the tecplot or paraview option may be your best bet. Trying to manually parse the text files smells like an [XY Problem](https://en.wikipedia.org/wiki/XY_problem). Tecplot and Paraview both have scripting capabilities that make post-processing very efficient.; > ; > Does that answer your question? Do you have any follow-up concerns?. Hello @clarkpede can you please tell me how to convert the output flile format from vtu to vtk; I am facing a lots of trouble to open the file in Paraview but the output format is coming vtu everytime Can you please explain how to solve this problem; And whenever i tries to change the output format by editting in notepad it tells an error that check option in SU2 config_template.cfg ; Please Help",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-651252372
https://github.com/su2code/SU2/issues/787#issuecomment-651853049:1495,Availability,error,error,1495," too huge to open in; the system and crashes every time.; Thank you for the help!. On Mon, Jun 29, 2020 at 1:17 PM Karthik-ksd <notifications@github.com>; wrote:. > You've got two options:; >; > 1. Use the cfg option WRT_BINARY_RESTART= NO to dump the restart; > file(s) in human-readable ASCII.; > 2. Use the cfg option OUTPUT_FORMAT= TECPLOT or OUTPUT_FORMAT=PARAVIEW; > with SU2_SOL to export the solution to an ASCII-formatted tecplot or; > paraview file. If you're not familiar with SU2_SOL, then check out the; > documentation <https://su2code.github.io/docs/Post-processing/>.; >; > You can find those cfg options in config_template.cfg in the root SU2; > source code directory.; >; > In the end, using the tecplot or paraview option may be your best bet.; > Trying to manually parse the text files smells like an XY Problem; > <https://en.wikipedia.org/wiki/XY_problem>. Tecplot and Paraview both; > have scripting capabilities that make post-processing very efficient.; >; > Does that answer your question? Do you have any follow-up concerns?; >; > Hello @clarkpede <https://github.com/clarkpede> can you please tell me; > how to convert the output flile format from vtu to vtk; > I am facing a lots of trouble to open the file in Paraview but the output; > format is coming vtu everytime Can you please explain how to solve this; > problem; > And whenever i tries to change the output format by editting in notepad it; > tells an error that check option in SU2 config_template.cfg; > Please Help; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-651252372>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXHBNWF5UFMV7GZ4WDTRZDEC3ANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Virginia Tech,Blacksburg, VA 24061*; *Cell# 540-998-5012*",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-651853049
https://github.com/su2code/SU2/issues/787#issuecomment-651853049:1022,Energy Efficiency,efficient,efficient,1022,"I found the solution. It's just a VTU file that was way too huge to open in; the system and crashes every time.; Thank you for the help!. On Mon, Jun 29, 2020 at 1:17 PM Karthik-ksd <notifications@github.com>; wrote:. > You've got two options:; >; > 1. Use the cfg option WRT_BINARY_RESTART= NO to dump the restart; > file(s) in human-readable ASCII.; > 2. Use the cfg option OUTPUT_FORMAT= TECPLOT or OUTPUT_FORMAT=PARAVIEW; > with SU2_SOL to export the solution to an ASCII-formatted tecplot or; > paraview file. If you're not familiar with SU2_SOL, then check out the; > documentation <https://su2code.github.io/docs/Post-processing/>.; >; > You can find those cfg options in config_template.cfg in the root SU2; > source code directory.; >; > In the end, using the tecplot or paraview option may be your best bet.; > Trying to manually parse the text files smells like an XY Problem; > <https://en.wikipedia.org/wiki/XY_problem>. Tecplot and Paraview both; > have scripting capabilities that make post-processing very efficient.; >; > Does that answer your question? Do you have any follow-up concerns?; >; > Hello @clarkpede <https://github.com/clarkpede> can you please tell me; > how to convert the output flile format from vtu to vtk; > I am facing a lots of trouble to open the file in Paraview but the output; > format is coming vtu everytime Can you please explain how to solve this; > problem; > And whenever i tries to change the output format by editting in notepad it; > tells an error that check option in SU2 config_template.cfg; > Please Help; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/issues/787#issuecomment-651252372>, or; > unsubscribe; > <https://github.com/notifications/unsubscribe-auth/ALJ3OXHBNWF5UFMV7GZ4WDTRZDEC3ANCNFSM4IT7MM2A>; > .; >. -- ; *Thank you,*. *Monika Chauhan *. *Graduate Research Assistant, Doctoral Program*. *Aerospace and Ocean Engineering Dept, Vir",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-651853049
https://github.com/su2code/SU2/issues/787#issuecomment-652192691:110,Availability,error,error,110,@Karthik-ksd You said:; > And whenever i tries to change the output format by editting in notepad it tells an error that check option in SU2 config_template.cfg. What cfg setting are you changing? What are you changing it to? Can you supply the (non-working) cfg file? What is the error you're seeing?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-652192691
https://github.com/su2code/SU2/issues/787#issuecomment-652192691:281,Availability,error,error,281,@Karthik-ksd You said:; > And whenever i tries to change the output format by editting in notepad it tells an error that check option in SU2 config_template.cfg. What cfg setting are you changing? What are you changing it to? Can you supply the (non-working) cfg file? What is the error you're seeing?,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-652192691
https://github.com/su2code/SU2/issues/787#issuecomment-652292016:118,Availability,error,error,118,> @Karthik-ksd You said:; > ; > > And whenever i tries to change the output format by editting in notepad it tells an error that check option in SU2 config_template.cfg; > ; > What cfg setting are you changing? What are you changing it to? Can you supply the (non-working) cfg file? What is the error you're seeing?; Now I am able to open it in paraview after writing one extra code in cfg file in notepad after TABULAR_FORMAT = CSV ; OUTPUT_FILES = PARAVIEW_ASCII; due to which running the code in command prompt I am able to get vtk format instead of vtu format.; Thank you for responding .; If this is not the solution please respond. As in my case i tried every examples in tutorial everything is working fine.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-652292016
https://github.com/su2code/SU2/issues/787#issuecomment-652292016:295,Availability,error,error,295,> @Karthik-ksd You said:; > ; > > And whenever i tries to change the output format by editting in notepad it tells an error that check option in SU2 config_template.cfg; > ; > What cfg setting are you changing? What are you changing it to? Can you supply the (non-working) cfg file? What is the error you're seeing?; Now I am able to open it in paraview after writing one extra code in cfg file in notepad after TABULAR_FORMAT = CSV ; OUTPUT_FILES = PARAVIEW_ASCII; due to which running the code in command prompt I am able to get vtk format instead of vtu format.; Thank you for responding .; If this is not the solution please respond. As in my case i tried every examples in tutorial everything is working fine.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/787#issuecomment-652292016
https://github.com/su2code/SU2/issues/788#issuecomment-528745746:77,Energy Efficiency,monitor,monitored,77,"The forces_breakdown file gives you the \*cough\* breakdown per surface, the monitored value is just an indication of convergence.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/788#issuecomment-528745746
https://github.com/su2code/SU2/issues/788#issuecomment-531982235:543,Energy Efficiency,monitor,monitored,543,"@WallyMaier . I am able to get two forces since I have defined; `% Marker(s) of the surface where the functional (Cd, Cl, etc.) will be evaluated; MARKER_MONITORING= ( shell1, shell2 )`. For instance I see . `Surface name: shell1 ; Total CL... ; ... ; Surface name: shell2; Total CL...; ...`. But these coefficients are dependent on shape attributes like `REF_AREA= 0` and `REF_LENGTH= 0.5` (diameter of sphere being 1 unit). I was just curious if there's a way for the user to define `REF_LENGTH` or `REF_AREA` for two objects that are being monitored? At the moment these shapes are the same dimension but I was curious about what to do in the case they are not identical. Thanks a million!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/788#issuecomment-531982235
https://github.com/su2code/SU2/issues/788#issuecomment-531982235:320,Integrability,depend,dependent,320,"@WallyMaier . I am able to get two forces since I have defined; `% Marker(s) of the surface where the functional (Cd, Cl, etc.) will be evaluated; MARKER_MONITORING= ( shell1, shell2 )`. For instance I see . `Surface name: shell1 ; Total CL... ; ... ; Surface name: shell2; Total CL...; ...`. But these coefficients are dependent on shape attributes like `REF_AREA= 0` and `REF_LENGTH= 0.5` (diameter of sphere being 1 unit). I was just curious if there's a way for the user to define `REF_LENGTH` or `REF_AREA` for two objects that are being monitored? At the moment these shapes are the same dimension but I was curious about what to do in the case they are not identical. Thanks a million!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/788#issuecomment-531982235
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:402,Availability,avail,available,402,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1923,Availability,mask,mask,1923,"to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2033,Availability,avail,available,2033,"to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3586,Availability,avail,available,3586," would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3961,Deployability,update,update,3961,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1147,Energy Efficiency,efficient,efficient,1147,"ents. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3093,Energy Efficiency,Reduce,Reduce,3093,"metric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3247,Energy Efficiency,efficient,efficient,3247,"sible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4462,Energy Efficiency,reduce,reduce,4462,"GS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, perfor",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5069,Energy Efficiency,reduce,reduces,5069,"enced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit sche",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5157,Energy Efficiency,reduce,reduce,5157,"enced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit sche",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5733,Energy Efficiency,reduce,reduce,5733,"o so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is ea",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6875,Energy Efficiency,Green,Green-Gauss,6875,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3512,Integrability,rout,routines,3512," would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6844,Integrability,rout,routines,6844,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2204,Modifiability,variab,variables,2204,"There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead re",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2382,Modifiability,variab,variables,2382," of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2550,Modifiability,variab,variables,2550,"computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5878,Modifiability,variab,variables,5878,"erency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computin",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6096,Modifiability,variab,variables,6096,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:271,Performance,perform,performed,271,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:646,Performance,latency,latency,646,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:658,Performance,throughput,throughput,658,"### Intro to SIMD; The ALU of modern CPU are capable of processing multiple elements of built-in types simultaneously by applying one instruction (e.g. add) to a register of those elements. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1209,Performance,load,load,1209,"ents. Registers are at the very top of the memory hierarchy, for any computation to be performed data needs to be in registers.; An AVX register is 256 bits wide, that means 4 lanes of doubles or 8 of floats, AVX-512 (available in Xeon-Phi and SkylakeX processors) doubles the size. By GPU standards these are rookie numbers. **Why should we care about SIMD?**; Because it is the only way to use the whole silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1932,Performance,latency,latency,1932,"to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2588,Performance,perform,perform,2588,"computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3175,Performance,load,load,3175,"metric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3915,Performance,race condition,race conditions,3915,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4126,Performance,race condition,race conditions,4126,"we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4852,Performance,cache,cache,4852," the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5164,Performance,cache,cache,5164,"enced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit sche",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5423,Performance,perform,performance,5423,"ocations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes freque",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:5967,Performance,perform,performance,5967,"er thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performanc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6214,Performance,race condition,race conditions,6214,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6365,Performance,perform,performance,6365,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6596,Performance,race condition,race condition,6596,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:6971,Performance,perform,performance,6971,"orted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-fetcher.; This can be mitigated to some extent by coloring groups of edges, groups of edges of the same color can be processed simultaneously, but within each group edges need to be processed serially. However grouping will reduce how much parallelism can be exploited within each color.; - **Gather to scatter** will in general use more memory due to the intermediate variables and extra adjacency information needed. If the entire algorithm is transformed performance may suffer as some computations may have to be repeated.; However, some reductions are possible without intermediate variables, for example when assembling the system matrix for implicit schemes only the diagonal entries can result in race conditions, now it just so happens that each diagonal entry is equal to the negated corresponding column sum.; - **Atomics** are terrible for the performance of code that writes frequently to memory (i.e. bandwidth-bound code), they do not increase the memory footprint and so make sense for compute-bound code.; Bugs due to a missing atomic can be very hard to debug (but any race condition is). Coloring is what one sees most in the literature, and yet I lean towards gather-to-scatter. Fewer things can go wrong with it as it is easy to understand, one gets the maximum amount of parallelism. I will now take two familiar routines, computing gradients (Green-Gauss) and limiters, vectorize / parallelize them in different ways, and measure relative performance to illustrate some of these key points introduced here. There will be C++ snipets and there will be some x86 assembly too :)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2609,Safety,avoid,avoids,2609,"computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2848,Safety,avoid,avoided,2848,", which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4118,Safety,risk,risk,4118,"we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** r",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:3790,Security,access,access,3790,"tter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:4531,Security,access,access,4531,"r routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result in race conditions where multiple threads try to update the data of the same point.; There are 3 ways to address this:; - **Coloring**: Edges are colored (grouped) such that edges of the same color have no risk of race conditions, i.e. each endpoint is referenced only once per color (this definition gives you the basis of a greedy algorithm to color edges).; - **Scatter to gather transformations**: Edge quantities (e.g. fluxes) are computed and stored on one pass (i.e. we read from 2 locations and write to 1), on a second pass, over points, we reduce (e.g. sum) the edge quantities for each point, again a gather access pattern. It may also be possible to convert the entire algorithm to a loop over points instead of edges.; - **Atomic operations or locks**: Here when a thread wants to write to a memory location it either needs to do so atomically (this is essentially an operations that always goes through main memory and forces cache coherency) or it needs to acquire a *lock* for the point it is writing to, if it fails to acquire the *lock* (because another thread has it) it needs to wait. None of these is without drawbacks.; - **Coloring** reduces temporal locality, edges are sorted in increasing order of the point indices to reduce cache misses, this means small groups of contiguous edges will share the same ""iPoint"", coloring single edges destroys this. Furthermore coloring either requires edges to be re-sorted by color, or if the edge indices of each color are instead kept in arrays, performance will suffer due to increased indirection which confounds the hardware pre-f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:1617,Usability,simpl,simple,1617," silicon, by and large vector instructions have the same latency and throughput of their scalar versions, therefore speedups proportional to the number of SIMD lanes are possible in compute-bound code.; As we saw in #716 there is some of that in the numerics, do not expect 4x speed-ups though, low order unstructured FVM is known to be bandwidth-bound, vectorization helps a bit there too (instructions are also data that needs to travel to the CPU) (maybe for explicit schemes and 8 SIMD lanes, maybe). **Relation with data structures**; There is only one efficient way to move data between memory and registers, via `load` and `store` instructions (they do come in multiple flavors). That is, pointing to a memory location and reading or writing N elements of contiguous data.; It is not the only way, it is also possible to `gather` and `scatter` data. That is populating the register from non-contiguous locations and vice versa. This is about one order of magnitude slower, to the point where if the computations are very simple it may not pay-off to vectorize. **Relation with algorithms**; Some form of `gather` and `scatter` is required in unstructured CFD, which means SIMD has a price of admission. Some thought needs to go into designing algorithms that amortize that cost by maximizing the so called FLOP/Byte ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely pe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-529662724:2888,Usability,simpl,simpler,2888,"ratio, and mask the latency of those operations by being able to start computing as soon as the first element of data is available. **What elements should we try to process simultaneously?**; The choice is between multiple geometric primitives (edges/points) or multiple solution primitives (variables). The latter sounds like a sensible idea until we get to areas of the code where different primitives require different treatment, that and the fact that the number of variables might not fit evenly in the number of lanes can lead to very tricky and non-generic code. Nevertheless if the same code were to be applied to e.g. 4 solution variables, this strategy would likely perform better as it avoids the pesky gather/scatter operations.; Processing multiple geometric primitives can make full utilization of whatever register size (important on GPU's), the code is just as readable (as I hope to show), but gather/scatter cannot be avoided. ### Intro to SPMD; This one is simpler, in a nutshell multiple threads operate on the sub domain of an MPI rank.; The typical implementation has each thread executing a chunk of an edge or cell loop. **Why should we care about SPMD?**; Reduce the communication overhead resulting from domain decomposition and improve load balancing, important for strong scaling.; Some algorithms are more efficient that way, e.g. the ADT (as mentioned by Edwin), the current MG also seems to work better on fewer partitions, and additive versions of preconditioners like the ILU or LU-SGS lose effectiveness with number of partitions.; Optimum hardware utilization, for routines that are bandwidth-bound it may be beneficial to use all threads available, while for compute-bound or ""algorithm-bound"" ones this may not be the case. **Relation with algorithms**; A typical edge loop reads from 2 locations and writes to 2 locations (gather / scatter access pattern, not to be confused with the instructions) processing multiple edges at the same time can therefore result i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-529662724
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:4718,Availability,avail,available,4718,"ill be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; }; ```; The `Adjacency` class stores for each point: the surrounding neighbor points (this is available in SU2), the neighbor edges, and the direction (in or out, -1 or 1) of the area vector relative to the point.; The speedup is **0.83** (i.e. not a speedup), that is actually not that bad considering the same computation is repeated for each edge, the reason it is not that bad is the sequential access to the gradient. Note that this loop is one #pragma away from parallelization. The SIMD version of this code is:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& area,; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:14076,Availability,recover,recovers,14076,"irst;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:15713,Availability,recover,recover,15713,"formance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write to the gradient sequentially and they have a bit more compute due to the duplicated computations. **Conclusion**; Computing gradients via point-loops allows simpler and more generic SIMD and SPMD strategies, the resulting implementation seems to do better in the bandwidth-starved conditions typical of modern hardware (3 or more cores per memory channel). However, additional adjacency information is required to support point-based loops. Next I will talk about limiters, almost all concepts are introduced so it will be shorter (promise). As a little appetizer let me tell you we can recover the extra memory and we could be looking at a 2.7x speedup for gradients+limiters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:6280,Deployability,update,update,6280,",; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.getVec(iEdge,iDim));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,; grad.getVec(iPoint,iVar,iDim)/volume.getVec(iPoint));; }; }; ```; I think this is just as readable especially considering that in SU2 we always need to use some Set/Get/Add/Sub method to update a variable, the difference is that here those methods have overloads to operate on small fixed size vectors. The speedup is **1.35** (i.e. 35% faster than edge-based reference) note that the improvement relative to scalar-point-based is only 1.6, those pesky gathers... The loop advances `SIMDLEN` points on each iteration, yet there are no pragmas and small simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from whi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:489,Energy Efficiency,Green,Green-Gauss,489,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:12291,Energy Efficiency,schedul,schedule,12291,"iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core speedup (still relative to our reference) is **3.8** for the SIMD code and **2.8** for the scalar code. Parallelizing the edge loops is a bit more intricate, as this:; ```C++; for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Becomes:; ```C++; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:12910,Energy Efficiency,schedul,schedule,12910,"---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core speedup (still relative to our reference) is **3.8** for the SIMD code and **2.8** for the scalar code. Parallelizing the edge loops is a bit more intricate, as this:; ```C++; for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Becomes:; ```C++; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/6468680",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:13769,Energy Efficiency,reduce,reduces,13769,"size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3332,Integrability,rout,routine,3332,"{; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:9827,Integrability,interface,interface,9827,"ter types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly wast",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:1719,Modifiability,variab,variables,1719,"setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double phi_ave[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); phi_ave[iVar] = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a t",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:2817,Modifiability,variab,variables,2817,"ow with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double phi_ave[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); phi_ave[iVar] = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop loo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3124,Modifiability,variab,variables,3124," connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double phi_ave[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); phi_ave[iVar] = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:6289,Modifiability,variab,variable,6289,",; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.getVec(iEdge,iDim));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,; grad.getVec(iPoint,iVar,iDim)/volume.getVec(iPoint));; }; }; ```; I think this is just as readable especially considering that in SU2 we always need to use some Set/Get/Add/Sub method to update a variable, the difference is that here those methods have overloads to operate on small fixed size vectors. The speedup is **1.35** (i.e. 35% faster than edge-based reference) note that the improvement relative to scalar-point-based is only 1.6, those pesky gathers... The loop advances `SIMDLEN` points on each iteration, yet there are no pragmas and small simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from whi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:9050,Modifiability,portab,portable,9050,"erator= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] = rhs.vals_[k];; return *this;; }. STRONGINLINE Array& operator+= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] += rhs.vals_[k];; return *this;; }; STRONGINLINE Array operator+ (const Array& rhs) const { return Array(*this)+=rhs; }; ; /*; * Many other operators go here.; */; };. // Common math function overloads; template<class T>; STRONGINLINE T vmax(const T& a, const T& b); {; T res;; #pragma omp simd; for(size_t k=0; k<T::Size; ++k); res[k] = (a[k]>b[k])? a[k] : b[k];; return res;; }. #undef FOREACH; ```; There are other (better) ways to do this, for example using [x86 intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=2273,2273,2436,2943,2436,2943,610,1788,2942) (in header `<x86intrin.h>`), register types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:10178,Modifiability,variab,variable,10178,"ng type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each grou",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:20,Performance,perform,performance,20,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3498,Performance,race condition,race condition,3498,"{; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double flux = phi_ave[iVar]*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:7269,Performance,LOAD,LOAD,7269,"im; ++iDim); grad.setVec(iPoint,iVar,iDim,; grad.getVec(iPoint,iVar,iDim)/volume.getVec(iPoint));; }; }; ```; I think this is just as readable especially considering that in SU2 we always need to use some Set/Get/Add/Sub method to update a variable, the difference is that here those methods have overloads to operate on small fixed size vectors. The speedup is **1.35** (i.e. 35% faster than edge-based reference) note that the improvement relative to scalar-point-based is only 1.6, those pesky gathers... The loop advances `SIMDLEN` points on each iteration, yet there are no pragmas and small simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from which we LOAD data,; // or a memory location and some offsets from which we GATHER data.; // In addition to the ""normal"" constructors. // scalar broadcasting ctor; STRONGINLINE Array(T x) {bcast(x);}. // loading ctor; STRONGINLINE Array(const T* ptr); {; #pragma omp simd aligned(ptr:Align); FOREACH vals_[k] = ptr[k];; }; // gathering ctor; template<class U>; STRONGINLINE Array(const T* base_ptr, const U& offsets); {; #pragma omp simd; FOREACH vals_[k] = base_ptr[offsets[k]];; }; /*; * Other traditional constructors (default, copy-ctor, move-ctor, etc) go here; */. // **** ACCESSORS **** //; STRONGINLINE T& operator[] (size_t k) {return vals_[k];}; STRONGINLINE T operator[] (size_t k) const {return vals_[k];}. // **** MATH OPERATORS **** //; STRONGINLINE Array& operator= (const A",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:7464,Performance,load,loading,7464," simd-loops in sight, in good C++ fashion that trickery has been encapsulated in a ""simd-friendly"" class.; Such a class can look something like this:; ```C++; template<class T, size_t N>; class Array; {; #define FOREACH for(size_t k=0; k<N; ++k); public:; enum : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from which we LOAD data,; // or a memory location and some offsets from which we GATHER data.; // In addition to the ""normal"" constructors. // scalar broadcasting ctor; STRONGINLINE Array(T x) {bcast(x);}. // loading ctor; STRONGINLINE Array(const T* ptr); {; #pragma omp simd aligned(ptr:Align); FOREACH vals_[k] = ptr[k];; }; // gathering ctor; template<class U>; STRONGINLINE Array(const T* base_ptr, const U& offsets); {; #pragma omp simd; FOREACH vals_[k] = base_ptr[offsets[k]];; }; /*; * Other traditional constructors (default, copy-ctor, move-ctor, etc) go here; */. // **** ACCESSORS **** //; STRONGINLINE T& operator[] (size_t k) {return vals_[k];}; STRONGINLINE T operator[] (size_t k) const {return vals_[k];}. // **** MATH OPERATORS **** //; STRONGINLINE Array& operator= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] = rhs.vals_[k];; return *this;; }. STRONGINLINE Array& operator+= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] += rhs.vals_[k];; return *this;; }; STRONGINLINE Array operator+ (const Array& rhs) const { return Array(*this)+=rhs; }; ; /*; * Many other operators go here.; */; };. // Common math function overloads; template<class T>; STRONGINLINE T vmax(const T& a, const T& b); {; T res;; #pragma omp simd; for(size_t k=0; k<T::Size; ++k); res[k] = (a[k]>b[k])? a[k] : b[k];; return res;; }. #undef FOREACH; ```; There are other (bet",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:8890,Performance,load,load,8890,"k];}; STRONGINLINE T operator[] (size_t k) const {return vals_[k];}. // **** MATH OPERATORS **** //; STRONGINLINE Array& operator= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] = rhs.vals_[k];; return *this;; }. STRONGINLINE Array& operator+= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] += rhs.vals_[k];; return *this;; }; STRONGINLINE Array operator+ (const Array& rhs) const { return Array(*this)+=rhs; }; ; /*; * Many other operators go here.; */; };. // Common math function overloads; template<class T>; STRONGINLINE T vmax(const T& a, const T& b); {; T res;; #pragma omp simd; for(size_t k=0; k<T::Size; ++k); res[k] = (a[k]>b[k])? a[k] : b[k];; return res;; }. #undef FOREACH; ```; There are other (better) ways to do this, for example using [x86 intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=2273,2273,2436,2943,2436,2943,610,1788,2942) (in header `<x86intrin.h>`), register types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:9772,Performance,optimiz,optimized,9772,"ays to do this, for example using [x86 intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=2273,2273,2436,2943,2436,2943,610,1788,2942) (in header `<x86intrin.h>`), register types instead of arrays, and a boat load of template meta-programming (I'm guessing) there are professional libraries for this.; This quickly-hacked-together code is compatible with custom types, portable, and seems to do the trick. To pull this off we do not need to have `Vector` or `Matrix` of this class, the underlying type for those data structures is still `double`, only the `getVec` type methods need to convert on the fly to the SIMD type, for example:; ```C++; // use the ""pointer ctor"" to return an array starting at ""row0""; Array<double,4> Matrix<double>::getVec(size_t row0, size_t col) const {; return Array<double,4>(&data_[row0+col*rows_]);; }. // use the ""gather ctor"" to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all poi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:10484,Performance,load,load,10484,"to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:10623,Performance,perform,performance,10623,"to return an array with the indices in ""rows""; template<class U>; Array<double,4> Matrix<double>::getVec(const U& rows, size_t col) const {; return Array<double,4>(&data_[col*rows_], rows);; }; ```; After inlining those copies get optimized away.; Although the stored type, and ""scalar interface"" of the containers do not need to change, the storage order of the data does. Notice that in the above data is stored by columns instead of rows (something that @vdweide mentioned in #716) this has greater implications for gradients as instead of the familiar ""vector of matrices"" we would need a ""matrix of vectors"", i.e. the derivative of variable i w.r.t. coordinate j stored as a vector for all points. The `Adjacency` also needs to be stored in a funny way. For the scalar version of the code it was stored as a CSR sparse matrix (one array of indices into the arrays of data for each point, the rows).; For the vectorized version we want to load (small) arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:11828,Performance,perform,performance,11828,"y waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core speedup (still relative to our reference) is **3.8** for the SIMD code and **2.8** for the scalar code. Parallelizing the edge loops is a bit more intricate, as this:; ```C++; for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Becomes:; ```C++; for(size_t color=",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:13800,Performance,perform,performance,13800,"size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:14089,Performance,perform,performance,14089,"irst;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:3618,Safety,avoid,avoids,3618,"(size_t iDim=0; iDim<nDim; ++iDim); #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; Well it is not just a few pragmas, we need to make the number of variables known at compile time (via a template parameter) and we need to transpose how the gradient is stored, i.e. instead of {xyz, xyz, xyz, xyz} we need {xxxx, yyyy, zzzz}. This code gets a speed-up of **2.2**. This code is generic but the template needs to be instantiated for every possible number of variables and we need a `switch` to call the right version at runtime, not very friendly.; Processing multiple edges at the same time is not worth the effort, for one we need `gather/scatter` on a very light routine, and on top of that we need to sort the edges such that we do not attempt to `scatter` to the same point when updating the gradient (a problem similar to the race condition described for SPMD). We can switch to a point-based loop and process multiple points in a SIMD way, that avoids the `scatter` problem but `gathers` will still be required. Here is what the scalar version of the point-based loop looks like:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency& adj,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volum",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:11644,Safety,safe,safe,11644,") arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core sp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:14076,Safety,recover,recovers,14076,"irst;; size_t jPoint = connectivity[iEdge].second;; ```; Apologies for the macro but it is just to illustrate that if we re-sort edge data after coloring the edge index is the loop index, otherwise the edge indices for each color need to be stored in a separate array.; Note that for each edge loop we first loop over colors, then over same-color edges, it is this inner loop that can run in parallel in chunk sizes that are multiple of the group size considered during coloring. There is some runtime cost on entry to every #omp parallel section, with coloring we enter one such section once by color. I mentioned in the introduction coloring reduces locality and therefore performance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:15713,Safety,recover,recover,15713,"formance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write to the gradient sequentially and they have a bit more compute due to the duplicated computations. **Conclusion**; Computing gradients via point-loops allows simpler and more generic SIMD and SPMD strategies, the resulting implementation seems to do better in the bandwidth-starved conditions typical of modern hardware (3 or more cores per memory channel). However, additional adjacency information is required to support point-based loops. Next I will talk about limiters, almost all concepts are introduced so it will be shorter (promise). As a little appetizer let me tell you we can recover the extra memory and we could be looking at a 2.7x speedup for gradients+limiters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:5023,Security,access,access,5023,"_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) = 0.0;. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; size_t jPoint = adj.jPoint(iPoint,iNeigh);; size_t iEdge = adj.iEdge(iPoint,iNeigh);; double dir = adj.dir(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) += phi_ave*dir*area(iEdge,iDim);; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; }; ```; The `Adjacency` class stores for each point: the surrounding neighbor points (this is available in SU2), the neighbor edges, and the direction (in or out, -1 or 1) of the area vector relative to the point.; The speedup is **0.83** (i.e. not a speedup), that is actually not that bad considering the same computation is repeated for each edge, the reason it is not that bad is the sequential access to the gradient. Note that this loop is one #pragma away from parallelization. The SIMD version of this code is:; ```C++; void computeGradients(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& area,; const Vector& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; const size_t SIMDLEN = 4;. for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad.setVec(iPoint,iVar,iDim,Array<double,SIMDLEN>(0.0));. for(size_t iNeigh=0; iNeigh<adj.nNeighbor_vec(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);; auto iEdge = adj.iEdge_vec(iPoint,iNeigh);; auto dir = adj.dir_vec(iPoint,iNeigh);. for(size_t iVar=0; iVar<nVar; ++iVar); {; auto phi_ave = (phi.getVec(iPoint,iVar)+; phi.getVec(jPoint,iVar))*0.5;. for(size_t iDim=0; iDim<nDim; ++iDim); grad.addVec(iPoint,iVar,iDim,; phi_ave*dir*area.g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:7839,Security,ACCESS,ACCESSORS,7839,"m : size_t {Size = N};; enum : size_t {Align = N*sizeof(T)};; private:; // fixed size and aligned array of internal data, naturally maps to a SIMD register; alignas(Align) T vals_[N];; /*; * Some helper methods go here; */; public:; // **** CONSTRUCTORS **** //; // We want to be able to construct this type from single scalars,; // a memory location from which we LOAD data,; // or a memory location and some offsets from which we GATHER data.; // In addition to the ""normal"" constructors. // scalar broadcasting ctor; STRONGINLINE Array(T x) {bcast(x);}. // loading ctor; STRONGINLINE Array(const T* ptr); {; #pragma omp simd aligned(ptr:Align); FOREACH vals_[k] = ptr[k];; }; // gathering ctor; template<class U>; STRONGINLINE Array(const T* base_ptr, const U& offsets); {; #pragma omp simd; FOREACH vals_[k] = base_ptr[offsets[k]];; }; /*; * Other traditional constructors (default, copy-ctor, move-ctor, etc) go here; */. // **** ACCESSORS **** //; STRONGINLINE T& operator[] (size_t k) {return vals_[k];}; STRONGINLINE T operator[] (size_t k) const {return vals_[k];}. // **** MATH OPERATORS **** //; STRONGINLINE Array& operator= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] = rhs.vals_[k];; return *this;; }. STRONGINLINE Array& operator+= (const Array& rhs); {; #pragma omp simd; FOREACH vals_[k] += rhs.vals_[k];; return *this;; }; STRONGINLINE Array operator+ (const Array& rhs) const { return Array(*this)+=rhs; }; ; /*; * Many other operators go here.; */; };. // Common math function overloads; template<class T>; STRONGINLINE T vmax(const T& a, const T& b); {; T res;; #pragma omp simd; for(size_t k=0; k<T::Size; ++k); res[k] = (a[k]>b[k])? a[k] : b[k];; return res;; }. #undef FOREACH; ```; There are other (better) ways to do this, for example using [x86 intrinsics](https://software.intel.com/sites/landingpage/IntrinsicsGuide/#expand=2273,2273,2436,2943,2436,2943,610,1788,2942) (in header `<x86intrin.h>`), register types instead of arrays, and a boat load of templa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:11634,Security,access,access,11634,") arrays of jPoint's, arrays of iEdge's, and arrays of directions, and as we know either those are contiguous or we take a huge performance hit.; If all points had the same number of neighbors we could store the adjacency in LIL (list of lists) format, essentially a column-major matrix, but that is not true for hybrid meshes and so we would possibly waste a lot of memory.; The solution is to use a Block-CSR format (like in CSysMatrix) where the blocks are the vectors we want and instead of one row per point we have one row per SIMD group. But even within a SIMD-sized group points can have different number of neighbors...; The solution for that is padding, within each group the number of neighbors is rounded up, shorter rows are then padded with valid data, e.g. jPoint=iPoint, direction=0, and iEdge repeated. This concept of padding is important for something else, you may have noticed that the SIMD point-loops I showed make no provisions for values of nPoint that are not multiples of SIMDLEN, that is because the containers already took care of that by rounding up the number of columns, and so that seemingly out-of-bounds access is safe (ain't encapsulation great). Padding also aligns the start of each column, thus it is a generally good thing to have (on large dimensions) whether used or not. Here is a relative performance recap before we talk bout parallelization. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 1.0 | 2.2 | 0.83 | 1.35 |. **Parallel execution**. I will start at the end for this, all it takes to parallellize the points loops with OpenMP is to take this:; ```C++; for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; And add some pixie dust; ```C++; #pragma omp parallel for schedule(dynamic,128); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); ```; This means each thread gets chunks of 128 loop iterations (512 points) to work on, assigned in a dynamic way, the 4 core sp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:245,Testability,benchmark,benchmark,245,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:402,Testability,test,tests,402,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:65,Usability,simpl,simple,65,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:600,Usability,simpl,simplicity,600,"**Disclaimer**; The performance numbers that follow are based on simple implementations of the methods, I do not claim any of my implementations or choice of methods to be optimal. If you know better speak up.; The data is from the case used to benchmark #753 (see #716), it is by no means an extensive collection of different grid types. I will share code and data with anyone who wants to repeat the tests on the condition they post detailed results. With that out of the way :) ... ### Green-Gauss Gradients. This is the plain edge-loop version of the code with boundary contributions omitted for simplicity:; ```C++; void computeGradients(size_t nEdge,; size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; const Matrix& phi,; VectorOfMatrix& grad); {; grad.setZero();. for(size_t iEdge=0; iEdge<nEdge; ++iEdge); {; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phi_ave = 0.5*(phi(iPoint,iVar)+phi(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); {; double flux = phi_ave*area(iEdge,iDim);. grad(iPoint,iVar,iDim) += flux;; grad(jPoint,iVar,iDim) -= flux;; }; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); grad(iPoint,iVar,iDim) /= volume[iPoint];; }; ```; This is more or less what SU2 does with minor differences on how the edges (`connectivity`) and area are stored, there is no vectorization nor easy way to make the loop parallel, this will be the reference for execution times. Suppose now that due to a perfect storm the number of variables is 4, here is how with a few pragmas we get gcc to vectorize:; ```C++; template<size_t nVar>; void computeGradients_impl(size_t nEdge,; size_t nPoint,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& area,; const vector<double>& volume,; con",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530328194:15283,Usability,simpl,simpler,15283,"formance, here is the effect of color group size on the execution time of the scalar code on one thread:; ![image](https://user-images.githubusercontent.com/38071223/64686801-2e0d3d00-d481-11e9-82a0-c56e5554cd83.png); The hassle-free option of not sorting by color ""never"" recovers the performance of the base algorithm, things are even worse for the SIMD version where even at group size of 8192 with re-sorting the slowdown is 14%. Running the edge-loop version on 4 cores (8192 group + sorting) we get speedups (relative to reference) of **1.98** and **2.04** for the scalar and SIMD versions respectively (yes I quadruple checked).; If you are keeping track of the number two things should surprise you, the first is that there is no difference between scalar and SIMD now (the vector instruction are still there though), the second is that 4 cores give only a 2x speedup. The reason for both is: the implementation is very memory-bound, and so throwing more compute at it, either in the form of more cores or more lanes, does not help much. This is the 4 core summary:. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed** | 2.0 | 2.0 | 3.8 | 2.8 |. I think the point-based versions scale better because they are a bit less memory-bound as they write to the gradient sequentially and they have a bit more compute due to the duplicated computations. **Conclusion**; Computing gradients via point-loops allows simpler and more generic SIMD and SPMD strategies, the resulting implementation seems to do better in the bandwidth-starved conditions typical of modern hardware (3 or more cores per memory channel). However, additional adjacency information is required to support point-based loops. Next I will talk about limiters, almost all concepts are introduced so it will be shorter (promise). As a little appetizer let me tell you we can recover the extra memory and we could be looking at a 2.7x speedup for gradients+limiters.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530328194
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:547,Availability,avail,available,547,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:989,Availability,avail,available,989,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:1503,Energy Efficiency,reduce,reduce,1503,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:459,Integrability,depend,dependence,459,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:902,Integrability,interoperab,interoperable,902,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:1456,Integrability,rout,routines,1456,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:1830,Integrability,rout,routines,1830,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:660,Modifiability,portab,portability,660,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:1263,Performance,perform,performance,1263,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:1695,Performance,optimiz,optimization,1695,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:453,Safety,avoid,avoid,453,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530440072:342,Usability,simpl,simple,342,"Nice progress @pcarruscag!. I like the concept of your SIMD-friendly class that will take care of the data structure under the hood coupled with a standard type of loop statement (w/ +SIMDLEN). This should make it pretty easy for folks to still modify the kernels without having to worry about the data alignment, and they can reuse the same simple 'for' construct repeatedly. . Another reason to have our own lightweight class for this is that you can avoid dependence on OpenMP for SIMD (although that feature looks to have potential and wasn't available until somewhat recently) as well as the intrinsics. In my experience, the latter is especially bad for portability and readability (part of why we left the CaF work in a separate repo). It starts to become so specialized that compiling and modifying become difficult. W.r.t. OpenMP, another roadblock there a few years ago was making sure it is interoperable with CoDi for the adjoint, but I know this has been worked on and may be available by now. Might keep an open mind about point vs. edge. In some places, we may be able to pump up the compute in our loops by fusing kernels, as previously discussed (and I am guessing you are working on this already with gradients/limiters). Could change the final performance numbers significantly. Lastly, I know you are not there yet, but it is worth considering whether you can reuse anything you are developing in the kernels here for the linear solver routines. At some point, you will successfully reduce the cost of the residual kernels (RHS) to the bandwidth limit, and the majority of the iteration cost will be in the linear solver (it is already about 50% of the iteration cost before optimization, if I recall). Before making final decisions on strategy, you should consider if it will help in any of the linear solver routines too.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530440072
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:6436,Availability,mask,masked,6436,"ze_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:9835,Availability,recover,recovered,9835,");; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjMin[iVar]));. limiter.setVec(iPoint,iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 ti",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3892,Energy Efficiency,schedul,schedule,3892,"oj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // some hand-holding needed for simd min/max with gcc,; // one of the min/max operands needs to be on the stack; // (so the compiler knows the two do not overlap?); double phi_i[nVar], phi_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phi_i[iVar] = phi(iPoint,iVar);; phi_j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:4268,Energy Efficiency,schedul,schedule,4268,". Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // some hand-holding needed for simd min/max with gcc,; // one of the min/max operands needs to be on the stack; // (so the compiler knows the two do not overlap?); double phi_i[nVar], phi_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phi_i[iVar] = phi(iPoint,iVar);; phi_j[iVar] = phi(jPoint,iVar);; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = max(phiMax(iPoint,iVar), phi_j[iVar]);; phiMin(iPoint,iVar) = min(phiMin(iPoint,iVar), phi_j[iVar]);; phiMax(jPoint,iVar) = max(phiMax(jPoint,iVar), phi_i[iVar]);; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi_i[iVar]);; }; }. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:5259,Energy Efficiency,schedul,schedule,5259,"or]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // some hand-holding needed for simd min/max with gcc,; // one of the min/max operands needs to be on the stack; // (so the compiler knows the two do not overlap?); double phi_i[nVar], phi_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phi_i[iVar] = phi(iPoint,iVar);; phi_j[iVar] = phi(jPoint,iVar);; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = max(phiMax(iPoint,iVar), phi_j[iVar]);; phiMin(iPoint,iVar) = min(phiMin(iPoint,iVar), phi_j[iVar]);; phiMax(jPoint,iVar) = max(phiMax(jPoint,iVar), phi_i[iVar]);; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi_i[iVar]);; }; }. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:7069,Energy Efficiency,schedul,schedule,7069,"_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the scalar and sequential version).; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& limiter); {; const size_t SIMDLEN = 4;; using FltVec = Array<double,SIMDLEN>;. // working variables; FltVec phiMax[MAXNVAR], phiMin[MAXNVAR], prjMax[MAXNVAR], prjMin[MAXNVAR];. const double eps = numeric_limits<double>::epsilon();. #pragma omp parallel for schedule(dynamic,128) private(phiMax,phiMin,prjMax,prjMin); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMin[iVar] = phiMax[iVar] = phi.getVec(iPoint,iVar);; prjMax[iVar] = eps;; prjMin[iVar] = -eps;; }. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; auto jPoint = adj.jPoi",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:7910,Energy Efficiency,schedul,schedule,7910,") = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the scalar and sequential version).; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& limiter); {; const size_t SIMDLEN = 4;; using FltVec = Array<double,SIMDLEN>;. // working variables; FltVec phiMax[MAXNVAR], phiMin[MAXNVAR], prjMax[MAXNVAR], prjMin[MAXNVAR];. const double eps = numeric_limits<double>::epsilon();. #pragma omp parallel for schedule(dynamic,128) private(phiMax,phiMin,prjMax,prjMin); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMin[iVar] = phiMax[iVar] = phi.getVec(iPoint,iVar);; prjMax[iVar] = eps;; prjMin[iVar] = -eps;; }. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);. FltVec d_ij[3] = {FltVec(0.0), FltVec(0.0), FltVec(0.0)};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-; coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec prj = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); prj += d_ij[iDim]*grad.getVec(iPoint,iVar,iDim);. prjMax[iVar] = vmax(prjMax[iVar], prj);; prjMin[iVar] = vmin(prjMin[iVar], prj);. phiMax[iVar] = vmax(phiMax[iVar], phi.getVec(jPoint,iVar));; phiMin[iVar] = vmin(phiMin[iVar], phi.getVec(jPoint,iVar));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:11465,Energy Efficiency,efficient,efficient,11465,"nd max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.85 |; | **Speed 4 cores** | 2.3 | 5.35 | 6.1 |. Fusing point loops only gives a 14% improvement vs separate loops due to the difference in gathered data, only one gather is amortized and the remaining memory accesses are very efficient.; Nevertheless if it can be done nicely while accounting for boundaries (which may have to be handled outside the loop) it could allow some memory savings for the discrete adjoint.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3389,Modifiability,variab,variables,3389,"proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = ed",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3508,Modifiability,variab,variables,3508,"proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. // find min and max neighbor; for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = ed",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:7743,Modifiability,variab,variables,7743,"iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the scalar and sequential version).; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const Adjacency<4>& adj,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& limiter); {; const size_t SIMDLEN = 4;; using FltVec = Array<double,SIMDLEN>;. // working variables; FltVec phiMax[MAXNVAR], phiMin[MAXNVAR], prjMax[MAXNVAR], prjMin[MAXNVAR];. const double eps = numeric_limits<double>::epsilon();. #pragma omp parallel for schedule(dynamic,128) private(phiMax,phiMin,prjMax,prjMin); for(size_t iPoint=0; iPoint<nPoint; iPoint+=SIMDLEN); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMin[iVar] = phiMax[iVar] = phi.getVec(iPoint,iVar);; prjMax[iVar] = eps;; prjMin[iVar] = -eps;; }. for(size_t iNeigh=0; iNeigh<adj.nNeighbor(iPoint); ++iNeigh); {; auto jPoint = adj.jPoint_vec(iPoint,iNeigh);. FltVec d_ij[3] = {FltVec(0.0), FltVec(0.0), FltVec(0.0)};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-; coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec prj = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); prj += d_ij[iDim]*grad.getVec(iPoint,iVar,iDim);. prjMax[iVar] = vmax(prjMax[iVar], prj);; prjMin[iVar] = vmin(prjMin[iVar], prj);. phiMax[iVar] = vmax(phiMax[iVar], phi.getVec(jPoint,iVar));; phiMin[iVar] = vmin(phiMin[iVa",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:9687,Modifiability,variab,variables,9687,"[iVar] = vmax(phiMax[iVar], phi.getVec(jPoint,iVar));; phiMin[iVar] = vmin(phiMin[iVar], phi.getVec(jPoint,iVar));; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjMin[iVar]));. limiter.setVec(iPoint,iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:476,Performance,bottleneck,bottleneck,476,"Thanks @economon!; I don't know what is the current situation with OpenMP and CoDi but any eventual change will have to be compatible with CoDi. The worst case would be disabling OpenMP for the discrete adjoint, the parallel clause supports an ""if"" modifier so that would not be too hard. But I hope to at least be able to lower the memory footprint by fusing some loops or make pre-accumulation more effective by using point loops.; The linear solvers will indeed become the bottleneck, they already are for JST, the good thing is matrix multiplication is easier to vectorize, not sure the best strategy will be similar though. ### Limiters. Scalar (reference) version of the code:; ```C++; void computeLimiters(size_t nPoint,; size_t nVar,; size_t nDim,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = phi(iPoint,iVar);; phiMin(iPoint,iVar) = phi(iPoint,iVar);; limiter(iPoint,iVar) = 2.0;; }; }. for(auto edge : connectivity); {; size_t iPoint = edge.first;; size_t jPoint = edge.second;. for(size_t iVar=0; iVar<nVar; ++iVar); {; phiMax(iPoint,iVar) = max(phiMax(iPoint,iVar), phi(jPoint,iVar));; phiMin(iPoint,iVar) = min(phiMin(iPoint,iVar), phi(jPoint,iVar));. phiMax(jPoint,iVar) = max(phiMax(jPoint,iVar), phi(iPoint,iVar));; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi(iPoint,iVar));; }; }. for(auto edge : connectivity); {; size_t iPoint = edge.first;; size_t jPoint = edge.second;. double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double proj_i = 0.0, proj_j = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; proj_i += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }. doubl",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:10182,Performance,perform,performance,10182,"iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:10217,Performance,Perform,Performance,10217," then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3008,Safety,avoid,avoids,3008,"m_j = phiMax(jPoint,iVar);. const double eps = numeric_limits<double>::epsilon();. if(proj_i <= 0.0); {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }. if(proj_j <= 0.0); {; lim_j = phiMin(jPoint,iVar);; proj_j = min(proj_j, -eps);; }. lim_i = (lim_i-phi(iPoint,iVar))/proj_i;; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i);. lim_j = (lim_j-phi(jPoint,iVar))/proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:6100,Safety,avoid,avoid,6100,"i_i[iVar]);; phiMin(jPoint,iVar) = min(phiMin(jPoint,iVar), phi_i[iVar]);; }; }. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; #if SORT_BY_COLOR==1; size_t iEdge = k;; #else; size_t iEdge = edgeIdx[k];; #endif. size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHU",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:9835,Safety,recover,recovered,9835,");; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec lim = vmin(FltVec(2.0), vmin(; (phiMax[iVar]-phi.getVec(iPoint,iVar))/prjMax[iVar],; (phiMin[iVar]-phi.getVec(iPoint,iVar))/prjMin[iVar]));. limiter.setVec(iPoint,iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 ti",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:10609,Security,access,access,10609,"ive one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.85 |; | **Speed 4 cores** | 2.3 | 5.35 | 6.1 |. Fusing point loops only gives a 14% improvement vs separate loops due to the difference in gathered data, only one gather is amortized and the remaining memory accesses are very efficient.; Nevertheless if it can be done nicely while accounting for ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:11447,Security,access,accesses,11447,"nd max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and compare the scalar ""edge+edge"" with the SIMD ""point+point"" and ""fused point"" we get:. | G+L Approach | Edge+Edge | Point+Point | Fused Point |; | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.85 |; | **Speed 4 cores** | 2.3 | 5.35 | 6.1 |. Fusing point loops only gives a 14% improvement vs separate loops due to the difference in gathered data, only one gather is amortized and the remaining memory accesses are very efficient.; Nevertheless if it can be done nicely while accounting for boundaries (which may have to be handled outside the loop) it could allow some memory savings for the discrete adjoint.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:3108,Usability,simpl,simplifying,3108,"m_j = phiMax(jPoint,iVar);. const double eps = numeric_limits<double>::epsilon();. if(proj_i <= 0.0); {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }. if(proj_j <= 0.0); {; lim_j = phiMin(jPoint,iVar);; proj_j = min(proj_j, -eps);; }. lim_i = (lim_i-phi(iPoint,iVar))/proj_i;; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i);. lim_j = (lim_j-phi(jPoint,iVar))/proj_j;; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j);; }; }. for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Something in the code above is a bit different from the implementation in SU2, namely:; ```C++; double lim_i = phiMax(iPoint,iVar);; if(proj_i <= 0.0) {; lim_i = phiMin(iPoint,iVar);; proj_i = min(proj_i, -eps);; }; ```; This is the bit of code that selects the right delta based on the sign of the projection and avoids division by zero, this less readable version does the same with one branch instead of three, simplifying ""if"" statements is essential for vectorization, so to make the comparison fair I used the same strategy in the scalar code. To make this post shorter I will show the SIMD and parallel version of the code right away. Trying to process multiple edges instead of multiple variables has all the problems I mentioned for the gradients, so again we use the trick of templating on the number of variables.; ```C++; template<size_t nVar>; void computeLimiters_impl(size_t nPoint,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; Matrix& phiMax,; Matrix& phiMin,; Matrix& limiter); {; // initialize; #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; phiM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:6356,Usability,simpl,simple,6356,"ze_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. // i to j vector; double d_ij[3] = {0.0, 0.0, 0.0};. for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. // projections; double proj_i[nVar], proj_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); proj_i[iVar] = proj_j[iVar] = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; proj_i[iVar] += d_ij[iDim]*grad(iPoint,iVar,iDim);; proj_j[iVar] -= d_ij[iDim]*grad(jPoint,iVar,iDim);; }; }. // choose the ""right"" delta based on sign of projection; // and avoid division by zero; double lim_i[nVar], lim_j[nVar];. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = phiMax(iPoint,iVar);; lim_j[iVar] = phiMax(jPoint,iVar);; }. const double eps = numeric_limits<double>::epsilon();. // very simple if's are required to get vectorization; // trough vector comparisons and masked blends; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; if(proj_i[iVar] <= 0.0); {; lim_i[iVar] = phiMin(iPoint,iVar);; proj_i[iVar] = min(proj_i[iVar], -eps);; }. if(proj_j[iVar] <= 0.0); {; lim_j[iVar] = phiMin(jPoint,iVar);; proj_j[iVar] = min(proj_j[iVar], -eps);; }; }. #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; lim_i[iVar] = (lim_i[iVar]-phi(iPoint,iVar))/proj_i[iVar];; limiter(iPoint,iVar) = min(limiter(iPoint,iVar), lim_i[iVar]);. lim_j[iVar] = (lim_j[iVar]-phi(jPoint,iVar))/proj_j[iVar];; limiter(jPoint,iVar) = min(limiter(jPoint,iVar), lim_j[iVar]);; }; }. #pragma omp parallel for schedule(dynamic,TARGET_CHUNK_SIZE); for(size_t iPoint=0; iPoint<nPoint; ++iPoint); {; #pragma omp simd; for(size_t iVar=0; iVar<nVar; ++iVar); {; double lim = limiter(iPoint,iVar);; limiter(iPoint,iVar) = lim*(lim+2)/(lim*lim+lim+2);; }; }; }; ```; Again to keep things short here is the parallel and SIMD point-loop version (like for gradients it is very similar to the",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-530593912:10014,Usability,clear,clearly,10014,"iVar, lim*(lim+2.0)/(lim*lim+lim+2.0));; }; }; }; ```; In terms of algorithm, for each point we find the min and max neighbor values and the min (negative) and max (positive) projections, those are then combined in a final `min(2, max/max, min/min)` to which the limiter function is applied (this would also be applicable to Venkatakrishnan-[Wang] limiters).; This is equivalent to the edge-loop, if statements are not required as due to cells being closed, if the positive projection is not zero, the negative one will also not be zero, therefore it is correct to always evaluate both ratios.; This algorithm only needs min and max neighbors as small local variables instead of large global ones due to the way those values are determined. This is where the memory from the extra adjacency information is recovered. Like @economon said, fusing the gradient kernel with the limiter kernel is trivial with these point loops, and I do not think it affects readability much since one can clearly tell ""what is what"" (I will not put it here but it really is a matter of copy paste), including the boundaries could be a bit more challenging, but I will give performance number nevertheless. **Performance summary**. | Code | Edge | Edge, SIMD on vars | Point | Point, SIMD on points |; | ---- | ---- | ---- | ---- | ---- |; | **Speed 1 core** | 1.0 | 1.75 | 1.25 | 2.0 |; | **Speed 4 cores** | 2.45 | 2.7 | 4.5 | 7.0 |. The basic point version does not lose to edge based because, contrary to gradients, it does not require duplication of computations while benefiting from sequential access to gradients.; Again the point-based implementation does really well in parallel, limiters are more compute intensive and so the scaling is almost perfect.; For reference, limiters are 1.9 times more expensive to compute than gradients with the reference edge version. With point loops, SIMD, and in parallel, gradients and limiters cost the same. If we consider the combined cost of gradients and limiters, and co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-530593912
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5090,Availability,mask,mask,5090,";. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,si",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:435,Deployability,update,update,435,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1160,Deployability,update,update,1160," per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1269,Deployability,update,updates,1269," per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1288,Deployability,Update,Updates,1288,"went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1365,Deployability,update,update,1365,"went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:3830,Deployability,update,updateBlocks,3830," using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesse",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:3940,Deployability,update,updateBlocks,3940," using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesse",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:4710,Deployability,update,updates,4710,"ctivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5527,Deployability,update,updateBlocks,5527,"r a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[col",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8006,Deployability,update,update,8006,"lux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += flux;; residual(jPoint,iVar) -= flux;; }; }; }; ```; after vectorizing this to handle multiple edges simultaneously with the SIMD-friendly type the core of the loop becomes; ```c++; using FltVec = Array<double,SIMDLEN>;; ... FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (th",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:10097,Deployability,update,update,10097,"c` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored out of the inner loop so that the resulting assembly looks much simpler:; ```asm; .L15:; vmovsd xmm5, QWORD PTR [rsp-40+rax*8]; vfmadd231sd xmm0, xmm5, QWORD PTR [r15+rax*8]; add rax, 1; cmp rcx, rax; jne .L15; ```; I think the reason for this is that there are plenty of integer registers (64bit) to keep memory locations (rsp, rax, r15 in the above) but there are only 16 ymm registers (256bit). In any case we need to give the compiler a hand, the calculation we need is; `index = iPoint*nVar*nDim + iVar*nDim + iDim` where iPoint is an array of ints; Note that as we loop by nDim and then by nVar all we need is to compute `iPoint*nVar*nDim` outside the loops and then add 1 on each access (which is more or less what the compiler does for the scalar code), in other words we need an **iterator**, something silly like; ```c++; template<size_t VecLen, size_t Incr = VecLen>; class GatherIterator; {; private:; using IntVec = Array<size_t,VecLe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15145,Deployability,update,updates,15145,"N; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Arr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15777,Deployability,update,update,15777,"im);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be enc",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:16719,Deployability,update,updates,16719,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:16894,Deployability,update,updates,16894,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1827,Energy Efficiency,schedul,schedule,1827,"he residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the e",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:3612,Energy Efficiency,schedul,schedule,3612,"ntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had starte",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:6384,Energy Efficiency,schedul,schedule,6384,"a for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phiL = phi(iPoint,iVar);; double phiR = phi(jPoint,iVar);. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += limiter(iPoint,iVar)*grad(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= limiter(jPoint,iVar)*grad(jPoint,iVar,iDim)*d_ij[iDim];; }. double flux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += flux;; residual(jPoint,iVar) -= flux;; }; }; }; ```; after vectorizing this to handle multiple edges simultaneously with the SIMD-friendly type the core of the loop becomes; ```c++; using FltVec = Array<double,SIMDLEN>;; ... FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. for(size_t iVar=0; iV",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15153,Energy Efficiency,efficient,efficiently,15153,"N; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Arr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:235,Integrability,message,message,235,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12794,Integrability,rout,routines,12794,"j[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when s",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8395,Modifiability,variab,variables,8395,"<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12416,Modifiability,variab,variables,12416,"Vec(data_,offsets_); }. STRONGINLINE FltVec operator++(int) {; auto ret = (*this)(); offsets_ += Incr; return ret;; }; };; ```; so silly in fact, it only moves forward, we use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer a",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:13231,Modifiability,variab,variables,13231,"R [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when storing it, i.e.; ```c++; FltVec phiI[MAXNVAR], gradI[MAXNVAR][MAXNDIM];; ...; for(size_t iVar=0; iVar<nVar; ++iVar); {; auto flux = weight*(phiI[iVar]+phi.getVec(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); g",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:13804,Modifiability,variab,variable,13804,"using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when storing it, i.e.; ```c++; FltVec phiI[MAXNVAR], gradI[MAXNVAR][MAXNDIM];; ...; for(size_t iVar=0; iVar<nVar; ++iVar); {; auto flux = weight*(phiI[iVar]+phi.getVec(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and i",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15046,Modifiability,variab,variable,15046,"oint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:15136,Modifiability,variab,variable,15136,"N; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Arr",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:17193,Modifiability,variab,variables,17193,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:834,Performance,race condition,race conditions,834,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:971,Performance,perform,perform,971,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:1221,Performance,perform,performance,1221," per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:2432,Performance,bottleneck,bottleneck,2432,"nd off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeId",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5021,Performance,load,load,5021,";. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,si",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5099,Performance,latency,latency,5099,";. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,si",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5797,Performance,perform,performance,5797,"ix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8524,Performance,perform,perform,8524,"<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8727,Performance,cache,cache,8727,"; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8977,Performance,perform,performance,8977,"he end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:9248,Performance,optimiz,optimizable,9248,"r clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12332,Performance,perform,perform,12332,"Vec(data_,offsets_); }. STRONGINLINE FltVec operator++(int) {; auto ret = (*this)(); offsets_ += Incr; return ret;; }; };; ```; so silly in fact, it only moves forward, we use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer a",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12489,Performance,perform,performance,12489,"Vec(data_,offsets_); }. STRONGINLINE FltVec operator++(int) {; auto ret = (*this)(); offsets_ += Incr; return ret;; }; };; ```; so silly in fact, it only moves forward, we use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer a",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12582,Performance,optimiz,optimization,12582,"e use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12669,Performance,perform,performance,12669,"tColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:13605,Performance,perform,performance,13605,"use of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on gradients and limiters is the way the code is written, to vectorize the computation we need to compute the gradient into a local variable and then ""transpose"" it when storing it, i.e.; ```c++; FltVec phiI[MAXNVAR], gradI[MAXNVAR][MAXNDIM];; ...; for(size_t iVar=0; iVar<nVar; ++iVar); {; auto flux = weight*(phiI[iVar]+phi.getVec(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:14611,Performance,Perform,Performance,14611,"ed to compute the gradient into a local variable and then ""transpose"" it when storing it, i.e.; ```c++; FltVec phiI[MAXNVAR], gradI[MAXNVAR][MAXNDIM];; ...; for(size_t iVar=0; iVar<nVar; ++iVar); {; auto flux = weight*(phiI[iVar]+phi.getVec(jPoint,iVar));. for(size_t iDim=0; iDim<nDim; ++iDim); gradI[iVar][iDim] += a_ij[iDim]*flux;; }; }. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); grad(iPoint+k,iVar,iDim) = gradI[iVar][iDim][k];; ...; ```; Similarly when computing the gradient we need to first fetch/transpose it to be able to vectorize subsequent computations; ```c++; FltVec gradI[MAXNVAR][MAXNDIM];. for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t iDim=0; iDim<nDim; ++iDim); for(size_t k=0; k<SIMDLEN; ++k); gradI[iVar][iDim][k] = grad(iPoint+k,iVar,iDim);; ...; ```; Performance wise this is actually better than the SoA version (4% on gradients, 35% on limiters) as it also benefits from better locality, and it is only slightly (3%) worse than zig zag storage, especially when fusing limiters and gradients as the transposition of the gradient into storage is greatly amortised.; Regarding readability, the 3 nested loops can be moved to methods of the container, but we cannot get rid off the local variable (if we want vectorization that is). **We lose the ability to vectorize primitive variable updates efficiently with AoS** but currently that only accounts for 3% of the runtime and it is a memory bound operation therefore it would not gain much from vectorization anyway. On the subject of de-swizzling data remember I said the writes into CSysMatrix would be a bit weird, that is because each Jacobian contribution will be a ""matrix of short arrays"" that needs to be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpos",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:16548,Performance,perform,performance,16548," be transformed into a short array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""rea",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:17010,Performance,perform,performance,17010,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:17447,Performance,perform,performance,17447,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:824,Safety,avoid,avoid,824,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:12656,Safety,avoid,avoid,12656,"tColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; }; ...; ```; to get better assembly; ```asm; .L7:; vmovapd ymm3, ymm13; vmovapd ymm2, YMMWORD PTR [rbp-400]; add rax, 32; vgatherqpd ymm0, QWORD PTR [rcx+ymm1*8], ymm3; vpaddq ymm1, ymm1, ymm11; vmovapd YMMWORD PTR [rbp-272], ymm0; vmovapd YMMWORD PTR [rbp-240], ymm0; vfmadd132pd ymm0, ymm2, YMMWORD PTR [rax-32]; vmovdqa YMMWORD PTR [rbp-208], ymm1; vmovapd YMMWORD PTR [rbp-400], ymm0; cmp rax, rbx; jne .L7; ```; which makes the vectorized code perform just as well as the scalar code, iterators could also be used for the other variables but that would start to hurt readability without improving the performance much. _Note: There is also a chance the compiler (gcc) is not doing this kind of optimization because of the way I wrote the code..._. **So we need AoS to avoid losing performance in lightweight numerics classes.**. Before we look into the impact of not using SoA in the gradient and limiters routines let me tell you there is a way to have the best of both worlds, enter the *_array of structures of arrays_* or as I like to call it zig zag storage, aka a right mess.; Imagine an AoS of short arrays of SIMD length, e.g. `{ {u0 u1 u2 u3} {v0 ... v3} {w0 ... w3} {u4 u5 u6 u7} ... }` with that it is possible to fully vectorize point loops as the first index (iPoint) is contiguous in groups of SIMD length and when looping along variables and dimensions in edge loops the stride is small enough (equal to SIMD length) to trigger hardware prefetching.; The catch is that we need even more integer arithmetic and so we really need iterators to amortise that cost, there is also the drawback that scalar usage of such a container would be terrible. **For these reasons I think we should sacrifice ultimate performance and keep node data in AoS storage.**. The major impact on",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:16984,Safety,avoid,avoid,16984,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:2659,Security,access,access,2659,"double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.addBlock(iPoint, iPoint, blk_i);; matrix.addBlock(iPoint, jPoint, blk_j);. matrix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorSta",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:4950,Security,access,accesses,4950,"TRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeMap[edge].second;. #pragma omp simd; for(size_t k=0; k<blkSz; ++k); {; coeffs[bii+k] += blk_i[k]; coeffs[bij+k] = +blk_j[k];; coeffs[bji+k] = -blk_i[k]; coeffs[bjj+k] -= blk_j[k];; }; }; ```; This is **47% faster**, which for a memory bound task is massive!; Yes, this does increase the memory footprint a bit (makes CSysMatrix 4% larger for a 3D problem) but I can get that back by sharing sparsity patterns and maps across turbulence and bulk flow (I think @talbring was already working on this in the template linear solver branch he had started). We could also parallelize the matrix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the d",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8427,Security,access,accessing,8427,"<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= grad.getVec(jPoint,iVar,iDim)*d_ij[iDim];; }. phiL = phi.getVec(iPoint,iVar) + limiter.getVec(iPoint,iVar)*phiL;; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8678,Security,access,access,8678,"; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:8762,Security,access,accesses,8762,"; phiR = phi.getVec(jPoint,iVar) + limiter.getVec(jPoint,iVar)*phiR;. FltVec flux = (phiL+phiR)*0.5;. for(size_t k=0; k<SIMDLEN; ++k) {; residual(iPoint[k],iVar) += flux[k];; residual(jPoint[k],iVar) -= flux[k];; }; }; ```; Note that at the end of the loop we need to de-swizzle the flux to update the multiple indexes references by iPoint and jPoint, which are now short arrays of integers (this operation can be moved to the container, akin to `getVec` but I show it here for clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:9094,Security,access,accesses,9094,"r clarity). **With SoA (aka column major storage) this code is 1.5 times slower than the scalar version.**. The reason for that is poor locality (of the spacial variety), as we loop through the number of variables and dimensions we are accessing the data in strides of nPoint, as the contiguous index is the first one so that we can perform vector read/writes when computing gradients and limiters.; With the scalar version the data for each point is contiguous which means on the first access we get whatever extra data is on the same cache line for free and subsequent accesses will be hardware prefetched since the stride is small (1 in this case). We lose all this with SoA storage. If we go back to arrays of structures (AoS, aka row major storage, basically what we have in #753) performance is only 9% worse (the code is identical). Those 9% are mostly due to increased integer arithmetic in the accesses to the data, on each call to `getVec` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:10879,Security,access,access,10879,"R [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored out of the inner loop so that the resulting assembly looks much simpler:; ```asm; .L15:; vmovsd xmm5, QWORD PTR [rsp-40+rax*8]; vfmadd231sd xmm0, xmm5, QWORD PTR [r15+rax*8]; add rax, 1; cmp rcx, rax; jne .L15; ```; I think the reason for this is that there are plenty of integer registers (64bit) to keep memory locations (rsp, rax, r15 in the above) but there are only 16 ymm registers (256bit). In any case we need to give the compiler a hand, the calculation we need is; `index = iPoint*nVar*nDim + iVar*nDim + iDim` where iPoint is an array of ints; Note that as we loop by nDim and then by nVar all we need is to compute `iPoint*nVar*nDim` outside the loops and then add 1 on each access (which is more or less what the compiler does for the scalar code), in other words we need an **iterator**, something silly like; ```c++; template<size_t VecLen, size_t Incr = VecLen>; class GatherIterator; {; private:; using IntVec = Array<size_t,VecLen>;; using FltVec = Array<double,VecLen>;. IntVec offsets_;; const double* data_;; public:; GatherIterator() = delete;; GatherIterator(const double* data, IntVec offsets) : offsets_(offsets), data_(data) {}. STRONGINLINE FltVec operator()() const { return FltVec(data_,offsets_); }. STRONGINLINE FltVec operator++(int) {; auto ret = (*this)(); offsets_ += Incr; return ret;; }; };; ```; so silly in fact, it only moves forward, we use it in our loop like so; ```c++; ...; auto gradI = grad.getColIterator(iPoint);; auto gradJ = grad.getColIterator(jPoint);. for(size_t iVar=0; iVar<nVar; ++iVar); {; FltVec phiL = 0.0;; FltVec phiR = 0.0;. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += (gradI++)*d_ij[iDim];; phiR -= (gradJ++)*d_ij[iDim];; };",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:17372,Security,access,accessed,17372,"hort array of matrices, the result of that is code like the above that explicitly manipulates the lanes of our SIMD type, such code can be completely hidden inside CSysMatrix which is good because a 4x4 vectorized transpose and matrix update looks like this; ```c++; // block j, subs from jj and goes to ij; T0 = blk_j[ k ].unpackLo(blk_j[k+1]); T1 = blk_j[ k ].unpackHi(blk_j[k+1]);; T2 = blk_j[k+2].unpackLo(blk_j[k+3]); T3 = blk_j[k+2].unpackHi(blk_j[k+3]);. C0 = T0.widePermuteLo(T2); C1 = T1.widePermuteLo(T3);; C2 = T0.widePermuteHi(T2); C3 = T1.widePermuteHi(T3);. (Array4d(&bjj[0][k])-C0).store(&bjj[0][k]);; (Array4d(&bjj[1][k])-C1).store(&bjj[1][k]);; (Array4d(&bjj[2][k])-C2).store(&bjj[2][k]);; (Array4d(&bjj[3][k])-C3).store(&bjj[3][k]);. C0.store(&bij[0][k]); C1.store(&bij[1][k]);; C2.store(&bij[2][k]); C3.store(&bij[3][k]);; ```; I am showing this because it represents a readability worst case in terms of manipulating SIMD types, we might end up with one or two of these to get the best performance possible but they will always be encapsulated and deep in kernel-type areas of SU2 that are almost never touched. ## Conclusions; - Over 45% faster CSysMatrix updates by mapping off-diagonal blocks to edges and diagonal blocks to points.; - Colouring is the best strategy for hybrid parallelism of compute-heavy edge loops and matrix updates as it interleaves compute and memory operations.; - AoS storage should be kept to avoid significant loss of performance in compute-light edge loops due to poor locality of SoA storage.; - Major implication of AoS is on point loops where some data needs to be fetched (transposed) into local variables for effective vectorization.; - An intermediate storage scheme, AoSoA, can provide both good locality and vectorization of point loops, however it requires that data be accessed via special iterators and scalar code based on it would have poor performance. Next I will try to estimate how much we can gain for a ""realistic"" numerics class.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5934,Testability,benchmark,benchmark,5934,"ow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phiL = phi(iPoint,iVar);; double phiR = phi(jPoint,iVar);. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += limiter(iPoint,iVar)*grad(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= limiter(jPoint,iVar)*grad(jPoint,iVar,iDim)*d_ij[iDim];; }. double flux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5966,Testability,benchmark,benchmark,5966,"ow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint,iDim));. for(size_t iVar=0; iVar<nVar; ++iVar); {; double phiL = phi(iPoint,iVar);; double phiR = phi(jPoint,iVar);. for(size_t iDim=0; iDim<nDim; ++iDim); {; phiL += limiter(iPoint,iVar)*grad(iPoint,iVar,iDim)*d_ij[iDim];; phiR -= limiter(jPoint,iVar)*grad(jPoint,iVar,iDim)*d_ij[iDim];; }. double flux = 0.5*(phiL+phiR);. residual(iPoint,iVar) += f",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:67,Usability,simpl,simple,67,"Thanks @MicK7 I will have a look, my initial thought was to have a simple strategy where within each MPI rank parallelism is extracted via colouring or scatter-to-gather transformations and only one thread per rank participates in the message passing, I have no experience here though so this might be a bad strategy, idk. **Back to business:**; I went silent for a bit because in prototyping a typical residual computation and matrix update loop I made some realisations that made me go back to the drawing board regarding data structures, and eventually back to square 0. . ## Parallel strategy for flux computation; Because significant computation is required to obtain each edge's flux, it does not make sense to attempt a ""point-loop"" strategy (which would double the effort).; However, one can either use colouring to avoid the race conditions that would result from updating the residual of cells i and j, or store the edge fluxes and then, on a second point-loop perform the summation of fluxes for each cell, with the direction being accounted by the same adjacency information used in the point-loop GG gradient computation.; If we consider only the update of residuals the two strategies are fairly equivalent performance wise, the tie breaker is the matrix updates. ## Matrix Updates; By this I mean the `addBlock`, `subBlock` we do (two times each) to update diagonal and off-diagonal blocks for each edge.; Here is a dummy numerics loop that does nothing else but setting blocks in the matrix (with colouring).; ```c++; void testLoop1(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; double** blk_i, double** blk_j,; SparseMatrix& matrix); {; matrix.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t j",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:3122,Usability,clear,clear,3122,"trix.subBlock(jPoint, jPoint, blk_j);; matrix.subBlock(jPoint, iPoint, blk_i);; }; }; ```; This and a few more memory reads is why we can't have nice things, i.e. massive speedups with vectorization. Believe it or not this loop sets ~75% of the maximum speed at which the residual edge loop can run (bandwidth bottleneck).; Don't be sad though, we can make a few things about it better:; - We can store the blocks we insert contiguously so the writes can be vectorized (this would be done using a container so that we still have `(i,j)` access syntax);; - On each insertion we have to first look for the block by traversing the `colInd` (column index) array, we can instead map the diagonal blocks to the corresponding points and the off-diagonal blocks to the edge (remember we insert ""by the edge"").; - We can fuse numerics (possibly using the [decorator](https://en.wikipedia.org/wiki/Decorator_pattern) pattern) so that we write to the matrix only once per iteration, which means we only need to clear the diagonal blocks and not the entire matrix because we can **set** the off-diagonals instead of **updating** them. Assuming these modification our dummy loop becomes; ```c++; void testLoop2(const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const double* blk_i, const double* blk_j,; SparseMatrix& matrix); {; matrix.setDiagZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. matrix.updateBlocks(iEdge, iPoint, jPoint, blk_i, blk_j);; }; }; ```; where; ```c++; STRONGINLINE void SparseMatrix::updateBlocks(size_t edge,; size_t row, size_t col, const double* blk_i, const double* blk_j); {; size_t bii = diagMap[row], bij = edgeMap[edge].first,; bjj = diagMap[col], bji = edgeM",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:5680,Usability,simpl,simplest,5680,"ix updates without colouring by setting only the off-diagonal coefficients and then setting the diagonal entries to the column sum.; It turns out that this is worse (by about 10%), maybe if the matrix were symmetric (row sum) but a column sum accesses blocks very far apart. Also we want to interleave compute and load/stores as much as possible to allow the CPU pipelining magic to mask the latency of the latter (even if it looks like you can only write the block after it is computed, CPU's have all kinds of buffers that allow the next loop iteration to begin while data is in flight). **Therefore colouring is the way to go.**. _Note: With vectorized numerics we insert blocks for 4 or 8 edges into the matrix at a time, the data for those inserts will be in a slightly weird format, which will make `SparseMatrix::updateBlocks` a bit harder on the eye, more on that later._. ## MUSCL Reconstruction; The MUSCL reconstruction, characteristic of upwind schemes, is the simplest building block to show the (negative) implications of storing the data as structures of arrays (SoA) on the performance of some operations.; Here is the most basic numerics you can think of, reconstruct and average (the dummy matrix loop was to benchmark the writes this is to benchmark the reads); ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<size_t>& colorStart,; const vector<size_t>& edgeIdx,; const vector<pair<size_t,size_t> >& connectivity,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; Matrix& residual); {; residual.setZero();. for(size_t color=0; color<colorStart.size()-1; ++color); #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t k=colorStart[color]; k<colorStart[color+1]; ++k); {; size_t iEdge = edgeIdx[k];; size_t iPoint = connectivity[iEdge].first;; size_t jPoint = connectivity[iEdge].second;. double d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = 0.5*(coords(jPoint,iDim)-coords(iPoint",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-535977206:10256,Usability,simpl,simpler,10256,"c` we resolve 4/8 row/column pairs into 1D indexes, while this calculation is vectorized, it seems to be less optimizable by compilers, for example this; ```c++; for(size_t iDim=0; iDim<nDim; ++iDim); phiL += grad.getVec(iPoint,iVar,iDim)*d_ij[iDim];; ```; gets compiled into this monstrosity; ```asm; .L13:; vpmuludq ymm0, ymm4, ymm1; vmovq xmm15, rax; vmovapd ymm6, ymm11; mov rdx, rax; vpbroadcastq ymm15, xmm15; sal rdx, 5; add rax, 1; vpaddq ymm0, ymm0, ymm2; vpsllq ymm0, ymm0, 32; vpaddq ymm0, ymm5, ymm0; vmovdqa YMMWORD PTR [rbp-240], ymm0; vpaddq ymm0, ymm3, ymm0; vmovdqa YMMWORD PTR [rbp-208], ymm0; vpaddq ymm0, ymm15, ymm0; vmovdqa YMMWORD PTR [rbp-176], ymm0; vgatherqpd ymm15, QWORD PTR [rdi+ymm0*8], ymm6; vmovapd ymm0, YMMWORD PTR [rsi+rdx]; vfmadd213pd ymm0, ymm15, YMMWORD PTR [rbp-336]; vmovapd YMMWORD PTR [rbp-336], ymm0; cmp rbx, rax; jne .L13; ```; the meat of which is `vgatherqpd` (`getVec`) and `vfmadd213pd` fused-multiply-add to update `phiL`, everything else is integer arithmetic which in the scalar version gets factored out of the inner loop so that the resulting assembly looks much simpler:; ```asm; .L15:; vmovsd xmm5, QWORD PTR [rsp-40+rax*8]; vfmadd231sd xmm0, xmm5, QWORD PTR [r15+rax*8]; add rax, 1; cmp rcx, rax; jne .L15; ```; I think the reason for this is that there are plenty of integer registers (64bit) to keep memory locations (rsp, rax, r15 in the above) but there are only 16 ymm registers (256bit). In any case we need to give the compiler a hand, the calculation we need is; `index = iPoint*nVar*nDim + iVar*nDim + iDim` where iPoint is an array of ints; Note that as we loop by nDim and then by nVar all we need is to compute `iPoint*nVar*nDim` outside the loops and then add 1 on each access (which is more or less what the compiler does for the scalar code), in other words we need an **iterator**, something silly like; ```c++; template<size_t VecLen, size_t Incr = VecLen>; class GatherIterator; {; private:; using IntVec = Array<size_t,VecLe",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-535977206
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:470,Deployability,update,updates,470,"This has been a long long exposition (nerd joke) but bear with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:2242,Deployability,update,updated,2242,"nectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar=0; iVar<nVar; ++iVar) {; FltVec sum = flux[iVar];; for(size_t kVar=0; kVar<nVar; ++kVar); sum += blk_j[iVar*nVar+kVar]*(phiL[kVar]-phiR[kVar])*0.5;. // residuals for iPoint and jPoint updated here. matrix.updateBlocks_v(color, iEdge, iPoint, jPoint, blk_i, blk_j);; }; ++color;; }; }; ```; The more WORKITERS we have the better the vectorized code is going to look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furth",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:1070,Energy Efficiency,schedul,schedule,1070,"r with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:1657,Integrability,depend,depend,1657,"connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. // something akin to a dissipation term; for(size_t iVar=0; iVar<nVar; ++iVar) {; FltVec sum = flux[iVar];; for(size_t kVar=0; kVar<nVar; ++kVar); sum += blk_j[iVar*nVar+kVar]*(phiL[kVar]-phiR[kVar])*0.5;. // residuals for iPoint and jPoint updated here. matrix.updateBlocks_v(color, iEdge, iPoint, jPoint, blk_i, blk_j);; }; ++color;; }; }; ```; The more WORKITERS we have the better the vectorized code is going to look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matri",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:3924,Modifiability,variab,variable-specific,3924,"look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furthermore the scalar code I am considering is writing to CSysMatrix with all the mapping and vectorized writes I mentioned before, before you get all compound interest and take this 1.5 with the 1.47 from CSysMatrix, the speedup relative to code without mapping and vector writes is 1.85.; I restate that this does not require changes to the data layout, again for reasons previously mentioned. ## SpMv - Sparse matrix-vector multiplication; With all these speedups the linear solvers will start taking well over 50% of the time, and so it is desirable to make some improvements there too.; Sadly SpMv is as bandwidth bound as it gets, 1 FMA per 8 bytes, nonetheless I implemented some number-of-variable-specific kernels (for nVar=4 and nVar=5) and I can get about **1.12** speedup (same realistic core to channel conditions). I am not going to dump that code here because it is not too nice to look at (it uses intrinsics) but again that would be something hidden away in CSysMatrix that most people would not need to look at, and there would be a safe generic fall-back for arbitrary number of variables. I think I will do the estimated global speedup together with the summary/proposal.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:4325,Modifiability,variab,variables,4325,"look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furthermore the scalar code I am considering is writing to CSysMatrix with all the mapping and vectorized writes I mentioned before, before you get all compound interest and take this 1.5 with the 1.47 from CSysMatrix, the speedup relative to code without mapping and vector writes is 1.85.; I restate that this does not require changes to the data layout, again for reasons previously mentioned. ## SpMv - Sparse matrix-vector multiplication; With all these speedups the linear solvers will start taking well over 50% of the time, and so it is desirable to make some improvements there too.; Sadly SpMv is as bandwidth bound as it gets, 1 FMA per 8 bytes, nonetheless I implemented some number-of-variable-specific kernels (for nVar=4 and nVar=5) and I can get about **1.12** speedup (same realistic core to channel conditions). I am not going to dump that code here because it is not too nice to look at (it uses intrinsics) but again that would be something hidden away in CSysMatrix that most people would not need to look at, and there would be a safe generic fall-back for arbitrary number of variables. I think I will do the estimated global speedup together with the summary/proposal.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:4278,Safety,safe,safe,4278,"look, I used a conservative number based on:; For the Roe scheme 4 matrices are generated (Jacobian i, Jacobian j, P tensor, P^-1 tensor), each coefficient of those matrices requires a reasonable number of floating point ops, and two of those matrices are indeed multiplied by each other.; So lets say 5 matrix-matrix multiplications are representative, this should be a conservative estimate as I am not considering the eventual fusion of convective and diffusive discretizations. **The vectorized code is 1.5 times faster.**; This is a fair 1.5 as the code is running on 4 fast cores (parallel via colouring for the reasons I explained previously) and 2 memory channels (scalar code can eventually saturate the memory bandwidth too, but it would take an unreasonable ratio of cores to channels to do so).; Furthermore the scalar code I am considering is writing to CSysMatrix with all the mapping and vectorized writes I mentioned before, before you get all compound interest and take this 1.5 with the 1.47 from CSysMatrix, the speedup relative to code without mapping and vector writes is 1.85.; I restate that this does not require changes to the data layout, again for reasons previously mentioned. ## SpMv - Sparse matrix-vector multiplication; With all these speedups the linear solvers will start taking well over 50% of the time, and so it is desirable to make some improvements there too.; Sadly SpMv is as bandwidth bound as it gets, 1 FMA per 8 bytes, nonetheless I implemented some number-of-variable-specific kernels (for nVar=4 and nVar=5) and I can get about **1.12** speedup (same realistic core to channel conditions). I am not going to dump that code here because it is not too nice to look at (it uses intrinsics) but again that would be something hidden away in CSysMatrix that most people would not need to look at, and there would be a safe generic fall-back for arbitrary number of variables. I think I will do the estimated global speedup together with the summary/proposal.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539177957:374,Usability,simpl,simplest,374,"This has been a long long exposition (nerd joke) but bear with me I am almost done, and I will summarise the results in the form of a proposal (I'll probably put that at the top of the first post). ## ""Real"" numerics; Real in the sense that the flop to byte ratio (amount of computation per amount of data) is comparable to a real numerics scheme, say Roe for example.; The simplest way to do this is to combine the example code for MUSCL reconstruction with the matrix updates code and add something compute heavy between input and output, e.g. a number of matrix-matrix multiplications, here is some pseudo code for what I did:; ```c++; void computeResidual(size_t nVar,; size_t nDim,; const vector<Connectivity<SIMDLEN> >& connectivities,; const Matrix& coords,; const Matrix& phi,; const VectorOfMatrix& grad,; const Matrix& limiter,; RowMajorMatrix& residual,; SparseMatrix& matrix); {; using FltVec = Array<double,SIMDLEN>;. residual.setZero();; matrix.setDiagZero();. size_t color = 0;; for(const auto& connectivity : connectivities); {; #pragma omp parallel for schedule(dynamic,CHUNK_SIZE); for(size_t iEdge=0; iEdge<connectivity.size(); iEdge+=SIMDLEN); {; auto iPoint = connectivity.first_vec(iEdge);; auto jPoint = connectivity.second_vec(iEdge);. FltVec d_ij[MAXNDIM];; for(size_t iDim=0; iDim<nDim; ++iDim); d_ij[iDim] = (coords.getVec(jPoint,iDim)-coords.getVec(iPoint,iDim))*0.5;. FltVec phiL[MAXNVAR], phiR[MAXNVAR], flux[MAXNVAR],; blk_i[MAXNVAR*MAXNVAR],; blk_j[MAXNVAR*MAXNVAR];. for(size_t iVar=0; iVar<nVar; ++iVar); {; // Reconstruction goes here. flux[iVar] = (phiL[iVar]+phiR[iVar])*0.5;; }. // some silly way to make the Jacobians depend on the reconstruction; for(size_t iVar=0; iVar<nVar; ++iVar); for(size_t jVar=0; jVar<nVar; ++jVar); blk_j[iVar*nVar+jVar] = (phiL[iVar]*phiR[jVar]-phiL[jVar]*phiR[iVar])*0.5;. // the matrix-matrix multiplications; for(size_t i=0; i<WORKITERS; ++i) {; // blk_i = blk_j * blk_j; for(size_t k=0; k<nVar*nVar; ++k) blk_j[k] = blk_i[k];; }. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539177957
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:2900,Availability,mainten,maintenance,2900,"to preserve spatial locality (this aspect is absolutely fundamental).; - Matrix multiplication, BCSR format is also embarrassing parallel.; - Linear preconditioners, additive decomposition within each MPI rank over a number of threads that need not be the same as that used for other areas. **SIMD**; - For gradients, limiters, and numerics a SIMD-friendly type will be used, by and large the high level code will look the same (see my examples above) but multiple points/edges will be processed simultaneously.; - No changes will be required to the data layout of CVariable, which means there will be no penalty to scalar code, new overloads for accessor methods will be required to set/get SIMD-arrays of data instead of scalars.; - The geometric properties and graph information associated with CGeometry will require the same contiguous storage treatment received by CVariable.; - Linear algebra, dimension-specific multiplication kernels with manual low level optimisations (unrolling, vectorization through intrinsics, and software prefetching), complex code but encapsulated in a low maintenance area of the code. **General improvements**; - Fusing convective and viscous residual loops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved because it is responsible for fetching data, I may move that to CNumerics, which would let them fetch data as needed.; - Lookup accesses to CSysMatrix to avoid linear searches, the small increase in memory usage can be mitigated by sharing these lookup tables/arrays and the sparsity pattern between matrices associated with the same geometry (on the subject of these lookup tables, ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:542,Deployability,update,update,542,"I'll have the summary at the bottom, you guys read papers you know to look for the conclusions.; ## Global speedup (Conclusions); I took the expected speedups for each prototyped area of the code and applied them to the profile I measured for the benchmark case from #716 / #753 (which is not very linear solver intensive).; It is hard to estimate the effect of fusing the convective and viscous edge loops, I assumed the cheaper of the two becomes ""free"" and the other gets a speedup of 1.5 (speedup should be 1.85 accounting for the matrix update optimizations).; I assumed that gradients and limiters are not fused and that minor areas of the code get no speedup, which is not necessarily true as this work would require contiguous storage of geometric properties (geometry->node and geometry->edge) and so some speedup is expected due to that, but in the absence of evidence I prefer to be conservative.; Here are the numbers:; ![image](https://user-images.githubusercontent.com/38071223/66394872-15376f00-e9ce-11e9-80ed-193aea2aae6f.png); The take home number is **1.7**. Cumulative with the 1.4 from contiguous storage, so 2.4 total. Despite most of my posts being focused on SIMD my main motivation is the hybrid parallelization which will allow important algorithmic improvements when running on hundreds of cores, namely the multigrid and additive linear preconditioners will retain their effectiveness at much larger core counts.; I will not hazard an estimate for this. ## Proposed changes (Summary); **Hybrid parallel**; - Gradients (GG) and limiters converted to point loops (embarrassing parallel, no edge colouring needed).; - Residual loops parallelized with edge colouring, if anyone has suggestions regarding algorithms send them my way, so far I only tested greedy colouring on edge groups to preserve spatial locality (this aspect is absolutely fundamental).; - Matrix multiplication, BCSR format is also embarrassing parallel.; - Linear preconditioners, additive decomposition wit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:4964,Deployability,release,release,4964,"ops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved because it is responsible for fetching data, I may move that to CNumerics, which would let them fetch data as needed.; - Lookup accesses to CSysMatrix to avoid linear searches, the small increase in memory usage can be mitigated by sharing these lookup tables/arrays and the sparsity pattern between matrices associated with the same geometry (on the subject of these lookup tables, knowing where the diagonal of a row is should enable more efficient upper/lower multiplications). ## Work items; This is a lot of work and some changes will be significant, I will divide the work in steps, off the top of my head this order seems ok:; - CSysMatrix lookups and any required parallel pragmas put in place.; - Point-loop gradients and limiters, no SIMD (at which point I hope #777 to be finished so the next item does not disrupt it).; - Split CSolvers over multiple files, colour-based parallel residual loops (at this point we have hybrid parallel!).; - Contiguous storage of CGeometry members (to eventually enable vectorization).; - Split CNumerics over files, architecture for fusing convective and viscous loops (the most disruptive change).; - SIMD, of gradients, limiters, and numerics. SIMD in CSysMatrix can be started anywhere after item 1. If you foresee conflicts with your ongoing work let's start talking sooner rather than later, I tried to order items to delay major disruptions as much as possible.; Also I would prefer not to take the silence of the community as acceptance, when you have a minute to spare (after the 7.0 release) please leave your opinion.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:3270,Energy Efficiency,reduce,reduce,3270,"ariable, which means there will be no penalty to scalar code, new overloads for accessor methods will be required to set/get SIMD-arrays of data instead of scalars.; - The geometric properties and graph information associated with CGeometry will require the same contiguous storage treatment received by CVariable.; - Linear algebra, dimension-specific multiplication kernels with manual low level optimisations (unrolling, vectorization through intrinsics, and software prefetching), complex code but encapsulated in a low maintenance area of the code. **General improvements**; - Fusing convective and viscous residual loops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved because it is responsible for fetching data, I may move that to CNumerics, which would let them fetch data as needed.; - Lookup accesses to CSysMatrix to avoid linear searches, the small increase in memory usage can be mitigated by sharing these lookup tables/arrays and the sparsity pattern between matrices associated with the same geometry (on the subject of these lookup tables, knowing where the diagonal of a row is should enable more efficient upper/lower multiplications). ## Work items; This is a lot of work and some changes will be significant, I will divide the work in steps, off the top of my head this order seems ok:; - CSysMatrix lookups and any required parallel pragmas put in place.; - Point-loop gradients and limiters, no SIMD (at which point I hope #777 to be finished so the next item does not disrupt it).; - Split CSolvers over multiple files, colour-based parallel residual loops (at this point we have hybrid parallel!).;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:3868,Energy Efficiency,efficient,efficient,3868,"fic multiplication kernels with manual low level optimisations (unrolling, vectorization through intrinsics, and software prefetching), complex code but encapsulated in a low maintenance area of the code. **General improvements**; - Fusing convective and viscous residual loops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved because it is responsible for fetching data, I may move that to CNumerics, which would let them fetch data as needed.; - Lookup accesses to CSysMatrix to avoid linear searches, the small increase in memory usage can be mitigated by sharing these lookup tables/arrays and the sparsity pattern between matrices associated with the same geometry (on the subject of these lookup tables, knowing where the diagonal of a row is should enable more efficient upper/lower multiplications). ## Work items; This is a lot of work and some changes will be significant, I will divide the work in steps, off the top of my head this order seems ok:; - CSysMatrix lookups and any required parallel pragmas put in place.; - Point-loop gradients and limiters, no SIMD (at which point I hope #777 to be finished so the next item does not disrupt it).; - Split CSolvers over multiple files, colour-based parallel residual loops (at this point we have hybrid parallel!).; - Contiguous storage of CGeometry members (to eventually enable vectorization).; - Split CNumerics over files, architecture for fusing convective and viscous loops (the most disruptive change).; - SIMD, of gradients, limiters, and numerics. SIMD in CSysMatrix can be started anywhere after item 1. If you foresee conflicts with your ongoing work let",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:3289,Integrability,depend,dependencies,3289,"ariable, which means there will be no penalty to scalar code, new overloads for accessor methods will be required to set/get SIMD-arrays of data instead of scalars.; - The geometric properties and graph information associated with CGeometry will require the same contiguous storage treatment received by CVariable.; - Linear algebra, dimension-specific multiplication kernels with manual low level optimisations (unrolling, vectorization through intrinsics, and software prefetching), complex code but encapsulated in a low maintenance area of the code. **General improvements**; - Fusing convective and viscous residual loops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved because it is responsible for fetching data, I may move that to CNumerics, which would let them fetch data as needed.; - Lookup accesses to CSysMatrix to avoid linear searches, the small increase in memory usage can be mitigated by sharing these lookup tables/arrays and the sparsity pattern between matrices associated with the same geometry (on the subject of these lookup tables, knowing where the diagonal of a row is should enable more efficient upper/lower multiplications). ## Work items; This is a lot of work and some changes will be significant, I will divide the work in steps, off the top of my head this order seems ok:; - CSysMatrix lookups and any required parallel pragmas put in place.; - Point-loop gradients and limiters, no SIMD (at which point I hope #777 to be finished so the next item does not disrupt it).; - Split CSolvers over multiple files, colour-based parallel residual loops (at this point we have hybrid parallel!).;",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:549,Performance,optimiz,optimizations,549,"I'll have the summary at the bottom, you guys read papers you know to look for the conclusions.; ## Global speedup (Conclusions); I took the expected speedups for each prototyped area of the code and applied them to the profile I measured for the benchmark case from #716 / #753 (which is not very linear solver intensive).; It is hard to estimate the effect of fusing the convective and viscous edge loops, I assumed the cheaper of the two becomes ""free"" and the other gets a speedup of 1.5 (speedup should be 1.85 accounting for the matrix update optimizations).; I assumed that gradients and limiters are not fused and that minor areas of the code get no speedup, which is not necessarily true as this work would require contiguous storage of geometric properties (geometry->node and geometry->edge) and so some speedup is expected due to that, but in the absence of evidence I prefer to be conservative.; Here are the numbers:; ![image](https://user-images.githubusercontent.com/38071223/66394872-15376f00-e9ce-11e9-80ed-193aea2aae6f.png); The take home number is **1.7**. Cumulative with the 1.4 from contiguous storage, so 2.4 total. Despite most of my posts being focused on SIMD my main motivation is the hybrid parallelization which will allow important algorithmic improvements when running on hundreds of cores, namely the multigrid and additive linear preconditioners will retain their effectiveness at much larger core counts.; I will not hazard an estimate for this. ## Proposed changes (Summary); **Hybrid parallel**; - Gradients (GG) and limiters converted to point loops (embarrassing parallel, no edge colouring needed).; - Residual loops parallelized with edge colouring, if anyone has suggestions regarding algorithms send them my way, so far I only tested greedy colouring on edge groups to preserve spatial locality (this aspect is absolutely fundamental).; - Matrix multiplication, BCSR format is also embarrassing parallel.; - Linear preconditioners, additive decomposition wit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:1452,Safety,hazard,hazard,1452," the other gets a speedup of 1.5 (speedup should be 1.85 accounting for the matrix update optimizations).; I assumed that gradients and limiters are not fused and that minor areas of the code get no speedup, which is not necessarily true as this work would require contiguous storage of geometric properties (geometry->node and geometry->edge) and so some speedup is expected due to that, but in the absence of evidence I prefer to be conservative.; Here are the numbers:; ![image](https://user-images.githubusercontent.com/38071223/66394872-15376f00-e9ce-11e9-80ed-193aea2aae6f.png); The take home number is **1.7**. Cumulative with the 1.4 from contiguous storage, so 2.4 total. Despite most of my posts being focused on SIMD my main motivation is the hybrid parallelization which will allow important algorithmic improvements when running on hundreds of cores, namely the multigrid and additive linear preconditioners will retain their effectiveness at much larger core counts.; I will not hazard an estimate for this. ## Proposed changes (Summary); **Hybrid parallel**; - Gradients (GG) and limiters converted to point loops (embarrassing parallel, no edge colouring needed).; - Residual loops parallelized with edge colouring, if anyone has suggestions regarding algorithms send them my way, so far I only tested greedy colouring on edge groups to preserve spatial locality (this aspect is absolutely fundamental).; - Matrix multiplication, BCSR format is also embarrassing parallel.; - Linear preconditioners, additive decomposition within each MPI rank over a number of threads that need not be the same as that used for other areas. **SIMD**; - For gradients, limiters, and numerics a SIMD-friendly type will be used, by and large the high level code will look the same (see my examples above) but multiple points/edges will be processed simultaneously.; - No changes will be required to the data layout of CVariable, which means there will be no penalty to scalar code, new overloads for acce",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:3581,Safety,avoid,avoid,3581,"fic multiplication kernels with manual low level optimisations (unrolling, vectorization through intrinsics, and software prefetching), complex code but encapsulated in a low maintenance area of the code. **General improvements**; - Fusing convective and viscous residual loops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved because it is responsible for fetching data, I may move that to CNumerics, which would let them fetch data as needed.; - Lookup accesses to CSysMatrix to avoid linear searches, the small increase in memory usage can be mitigated by sharing these lookup tables/arrays and the sparsity pattern between matrices associated with the same geometry (on the subject of these lookup tables, knowing where the diagonal of a row is should enable more efficient upper/lower multiplications). ## Work items; This is a lot of work and some changes will be significant, I will divide the work in steps, off the top of my head this order seems ok:; - CSysMatrix lookups and any required parallel pragmas put in place.; - Point-loop gradients and limiters, no SIMD (at which point I hope #777 to be finished so the next item does not disrupt it).; - Split CSolvers over multiple files, colour-based parallel residual loops (at this point we have hybrid parallel!).; - Contiguous storage of CGeometry members (to eventually enable vectorization).; - Split CNumerics over files, architecture for fusing convective and viscous loops (the most disruptive change).; - SIMD, of gradients, limiters, and numerics. SIMD in CSysMatrix can be started anywhere after item 1. If you foresee conflicts with your ongoing work let",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:2456,Security,access,accessor,2456,"e counts.; I will not hazard an estimate for this. ## Proposed changes (Summary); **Hybrid parallel**; - Gradients (GG) and limiters converted to point loops (embarrassing parallel, no edge colouring needed).; - Residual loops parallelized with edge colouring, if anyone has suggestions regarding algorithms send them my way, so far I only tested greedy colouring on edge groups to preserve spatial locality (this aspect is absolutely fundamental).; - Matrix multiplication, BCSR format is also embarrassing parallel.; - Linear preconditioners, additive decomposition within each MPI rank over a number of threads that need not be the same as that used for other areas. **SIMD**; - For gradients, limiters, and numerics a SIMD-friendly type will be used, by and large the high level code will look the same (see my examples above) but multiple points/edges will be processed simultaneously.; - No changes will be required to the data layout of CVariable, which means there will be no penalty to scalar code, new overloads for accessor methods will be required to set/get SIMD-arrays of data instead of scalars.; - The geometric properties and graph information associated with CGeometry will require the same contiguous storage treatment received by CVariable.; - Linear algebra, dimension-specific multiplication kernels with manual low level optimisations (unrolling, vectorization through intrinsics, and software prefetching), complex code but encapsulated in a low maintenance area of the code. **General improvements**; - Fusing convective and viscous residual loops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved bec",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:3555,Security,access,accesses,3555,"fic multiplication kernels with manual low level optimisations (unrolling, vectorization through intrinsics, and software prefetching), complex code but encapsulated in a low maintenance area of the code. **General improvements**; - Fusing convective and viscous residual loops, this will NOT be done by super gluing convective and viscous numerics. I do not have a concrete design in mind yet but I hope to be able to do something akin to the *decorator* pattern I mentioned before. I also plan to make the numerics a full-fledged *visitor* to reduce compilation dependencies, currently a change to numerics may affect CVariable CSolver and CNumerics (as mentioned by @clarkpede), CSolver is involved because it is responsible for fetching data, I may move that to CNumerics, which would let them fetch data as needed.; - Lookup accesses to CSysMatrix to avoid linear searches, the small increase in memory usage can be mitigated by sharing these lookup tables/arrays and the sparsity pattern between matrices associated with the same geometry (on the subject of these lookup tables, knowing where the diagonal of a row is should enable more efficient upper/lower multiplications). ## Work items; This is a lot of work and some changes will be significant, I will divide the work in steps, off the top of my head this order seems ok:; - CSysMatrix lookups and any required parallel pragmas put in place.; - Point-loop gradients and limiters, no SIMD (at which point I hope #777 to be finished so the next item does not disrupt it).; - Split CSolvers over multiple files, colour-based parallel residual loops (at this point we have hybrid parallel!).; - Contiguous storage of CGeometry members (to eventually enable vectorization).; - Split CNumerics over files, architecture for fusing convective and viscous loops (the most disruptive change).; - SIMD, of gradients, limiters, and numerics. SIMD in CSysMatrix can be started anywhere after item 1. If you foresee conflicts with your ongoing work let",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:247,Testability,benchmark,benchmark,247,"I'll have the summary at the bottom, you guys read papers you know to look for the conclusions.; ## Global speedup (Conclusions); I took the expected speedups for each prototyped area of the code and applied them to the profile I measured for the benchmark case from #716 / #753 (which is not very linear solver intensive).; It is hard to estimate the effect of fusing the convective and viscous edge loops, I assumed the cheaper of the two becomes ""free"" and the other gets a speedup of 1.5 (speedup should be 1.85 accounting for the matrix update optimizations).; I assumed that gradients and limiters are not fused and that minor areas of the code get no speedup, which is not necessarily true as this work would require contiguous storage of geometric properties (geometry->node and geometry->edge) and so some speedup is expected due to that, but in the absence of evidence I prefer to be conservative.; Here are the numbers:; ![image](https://user-images.githubusercontent.com/38071223/66394872-15376f00-e9ce-11e9-80ed-193aea2aae6f.png); The take home number is **1.7**. Cumulative with the 1.4 from contiguous storage, so 2.4 total. Despite most of my posts being focused on SIMD my main motivation is the hybrid parallelization which will allow important algorithmic improvements when running on hundreds of cores, namely the multigrid and additive linear preconditioners will retain their effectiveness at much larger core counts.; I will not hazard an estimate for this. ## Proposed changes (Summary); **Hybrid parallel**; - Gradients (GG) and limiters converted to point loops (embarrassing parallel, no edge colouring needed).; - Residual loops parallelized with edge colouring, if anyone has suggestions regarding algorithms send them my way, so far I only tested greedy colouring on edge groups to preserve spatial locality (this aspect is absolutely fundamental).; - Matrix multiplication, BCSR format is also embarrassing parallel.; - Linear preconditioners, additive decomposition wit",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-539523312:1770,Testability,test,tested,1770,"operties (geometry->node and geometry->edge) and so some speedup is expected due to that, but in the absence of evidence I prefer to be conservative.; Here are the numbers:; ![image](https://user-images.githubusercontent.com/38071223/66394872-15376f00-e9ce-11e9-80ed-193aea2aae6f.png); The take home number is **1.7**. Cumulative with the 1.4 from contiguous storage, so 2.4 total. Despite most of my posts being focused on SIMD my main motivation is the hybrid parallelization which will allow important algorithmic improvements when running on hundreds of cores, namely the multigrid and additive linear preconditioners will retain their effectiveness at much larger core counts.; I will not hazard an estimate for this. ## Proposed changes (Summary); **Hybrid parallel**; - Gradients (GG) and limiters converted to point loops (embarrassing parallel, no edge colouring needed).; - Residual loops parallelized with edge colouring, if anyone has suggestions regarding algorithms send them my way, so far I only tested greedy colouring on edge groups to preserve spatial locality (this aspect is absolutely fundamental).; - Matrix multiplication, BCSR format is also embarrassing parallel.; - Linear preconditioners, additive decomposition within each MPI rank over a number of threads that need not be the same as that used for other areas. **SIMD**; - For gradients, limiters, and numerics a SIMD-friendly type will be used, by and large the high level code will look the same (see my examples above) but multiple points/edges will be processed simultaneously.; - No changes will be required to the data layout of CVariable, which means there will be no penalty to scalar code, new overloads for accessor methods will be required to set/get SIMD-arrays of data instead of scalars.; - The geometric properties and graph information associated with CGeometry will require the same contiguous storage treatment received by CVariable.; - Linear algebra, dimension-specific multiplication kernels with m",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-539523312
https://github.com/su2code/SU2/issues/789#issuecomment-549037701:114,Availability,avail,available,114,"### Easter Egg - Mixed Precision; The work proposed above should have the solver run at the speed dictated by the available memory bandwidth (for implicit applications).; Keeping CSysMatrix in single precision, and solving the linear systems also in single precision, should therefore provide a good speedup (probably around 1.5 extra speedup).; Since all the flux computations would still be done in double precision no loss of accuracy would be incurred. However some stability can be lost on meshes with very high aspect ratios, therefore there would be a compile-time switch for this mode and the default would be all doubles (hence the Easter egg designation). This should be relatively easy to do cleanly since the relevant classes are already templated and have ""mixing-type logic"" for when they are used with AD. Except for central schemes, currently we would not gain much by doing it as residual loops are compute-bound and the linear solvers do not use that much time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-549037701
https://github.com/su2code/SU2/issues/789#issuecomment-549037701:782,Testability,log,logic,782,"### Easter Egg - Mixed Precision; The work proposed above should have the solver run at the speed dictated by the available memory bandwidth (for implicit applications).; Keeping CSysMatrix in single precision, and solving the linear systems also in single precision, should therefore provide a good speedup (probably around 1.5 extra speedup).; Since all the flux computations would still be done in double precision no loss of accuracy would be incurred. However some stability can be lost on meshes with very high aspect ratios, therefore there would be a compile-time switch for this mode and the default would be all doubles (hence the Easter egg designation). This should be relatively easy to do cleanly since the relevant classes are already templated and have ""mixing-type logic"" for when they are used with AD. Except for central schemes, currently we would not gain much by doing it as residual loops are compute-bound and the linear solvers do not use that much time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-549037701
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3056,Availability,down,down,3056,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3267,Availability,down,down,3267,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:5184,Availability,down,down,5184,"Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // instantiated here and we can force them to be inlined.; ComputeFlux::Compute(wv, sol);. // Do some additional work if needed and return result.; return wv.flux / wv.area;; }; ```; [Care for some assembly?](https://gcc.godbolt.org/z/os-gNg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:9,Deployability,update,update,9,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:556,Energy Efficiency,reduce,reduced,556,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:2393,Integrability,interface,interface,2393," for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the me",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:4383,Integrability,interface,interface,4383,"mplate the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:4722,Integrability,depend,depending,4722,"Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // instantiated here and we can force them to be inlined.; ComputeFlux::Compute(wv, sol);. // Do some additional work if needed and return result.; return wv.flux / wv.area;; }; ```; [Care for some assembly?](https://gcc.godbolt.org/z/os-gNg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:527,Modifiability,polymorphi,polymorphic,527,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1486,Modifiability,inherit,inheriting,1486,"ion, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1871,Modifiability,polymorphi,polymorphic,1871,"ive loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class Com",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:2557,Modifiability,inherit,inheritance,2557,"o allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:2623,Modifiability,inherit,inherit,2623,"o allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. ",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:2712,Modifiability,variab,variables,2712," means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our sp",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3005,Modifiability,variab,variables,3005,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3096,Modifiability,inherit,inheritance,3096,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3188,Modifiability,variab,variables,3188,"h>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Compute method is to be composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3564,Modifiability,polymorphi,polymorphism,3564,"composed via an inheritance chain, to do this; // we allow each building block to inherit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:3590,Modifiability,variab,variables,3590,"erit from any class. These classes should; // be function objects that have no member variables, all data used in the; // resulting Compute method will be on the stack.; template<typename Base>; class ComputeArea : Base; {; protected:; // Different template instantiations will be made for; // 2D/3D to allow perfect loop unrolling.; enum : int {nDim = Base::nDim};. // To share variables between building blocks we will pass; // down a struct which is also composed by inheritance; struct WorkVarsType : Base::WorkVarsType; {; double area; // add ""area"" to the variables of Base; };; ; // The final implementation of Compute will be a call down the chain.; // The final constructed WorkVarsType is not known at this stage,; // hence we also template the method.; template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // Boilerplate, call base first. This is akin to the decorator design pattern; // without polymorphism. The working variables resemble Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; }",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:5120,Modifiability,variab,variables,5120,"Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // instantiated here and we can force them to be inlined.; ComputeFlux::Compute(wv, sol);. // Do some additional work if needed and return result.; return wv.flux / wv.area;; }; ```; [Care for some assembly?](https://gcc.godbolt.org/z/os-gNg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:5201,Modifiability,variab,variables,5201,"Python's ""self"" which; // makes this solution reasonably idiomatic.; Base::Compute(wv, sol);. // Then do our specific job.; wv.area = 0.0;; for(int i=0; i<nDim; ++i); wv.area += pow(sol.areaVector[i],2);; wv.area = sqrt(wv.area);; }; };. // Same mechanics as above; template<typename Base>; class ComputeFlux : Base; {; protected:; enum : int {nDim = Base::nDim};. struct WorkVarsType : Base::WorkVarsType ; {; double flux; // ...add new member; };. template<typename WV>; void Compute(WV& wv, const SolutionContainer& sol) const; {; // ...call base; Base::Compute(wv,sol);. // ...do aditional work; wv.flux = 0.0;; for(int i=0; i<nDim; ++i); wv.flux += sol.velocity[i]*sol.areaVector[i];; }; };. // This class is used to terminate the chain, it makes the link; // with the interface and it is used to specify any fixed sizes.; template<int NDIM>; class Terminator : private VirtualInterface; {; protected:; enum : int {nDim = NDIM};. struct WorkVarsType {};. template<typename... Ts>; void Compute(Ts&...) const {}; };. // Finally we use the building blocks to implement Compute.; // The blocks can be reordered depending on application to; // help the compiler fuse loops or minimize register spillage,; // the resulting WorkVarsType definition will be equivalent.; class ComposedClass: public; ComputeFlux< ComputeArea< Terminator<3> > >; {; public:; ResultType Compute(const SolutionContainer& sol) const;; };. ResultType ComposedClass::Compute(const SolutionContainer& sol) const; {; // Create the working variables on the stack.; ComputeFlux::WorkVarsType wv;. // Pass down the working variables and whatever other arguments.; // If the convention was followed, all building blocks will run.; // Recall that all Compute's were templates, they will be; // instantiated here and we can force them to be inlined.; ComputeFlux::Compute(wv, sol);. // Do some additional work if needed and return result.; return wv.flux / wv.area;; }; ```; [Care for some assembly?](https://gcc.godbolt.org/z/os-gNg)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:407,Safety,safe,safe,407,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:466,Safety,safe,safe,466,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:790,Safety,avoid,avoid,790,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:165,Security,access,accessor,165,"Ok, SIMD update, with #753, #959, and #966 we now have a unified storage type for the data we need in CNumerics. This means that we (I) only need to implement ""SIMD accessor methods"" (i.e. that return a SIMD type instead of a su2double) for one class (C2DContainer and co.). I think to do SIMD right we need a new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not por",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1295,Security,access,access,1295," new way of going about CNumerics, these are my design requirements for ""CNewNumerics"":; - Thread-safe (consequently const-correct), a single object must be safe to use by multiple threads.; - Minimal indirection, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/issues/789#issuecomment-622941617:1476,Usability,simpl,simply,1476,"ion, the polymorphic overhead will be reduced to a single call (ComputeResidual), all auxiliary functions (like the ones that live in CNumerics) will be forcefully inlined, no useless copies of data (no more numerics->SetBlaBla).; - Compile time nDim/nVar, which will: a) avoid heap allocations; b) allow effective loop-unrolling (also during the writes to CSysMatrix).; - Allow low-overhead composition, e.g. have one CRoe for Euler and one CRoeVisc for NS to fuse convective and viscous residuals (without copy pasting code).; - A lot more readable, those cryptic V_i[iDim+1] need to go (somehow...). To achieve all this, the ""CNewNumerics"" will work as a template (obvs) decorator/visitor.; A visitor in the sense that the solver calls the numerics and gives it (read-only) access to all its data, the object pulls whatever it needs directly and there is no need for numerics->SetBlaBla.; A template decorator in the sense that the class can be augmented simply by inheriting from another, along the lines of `class CRoeVisc : public CRoe, public CVisc` (to allow fusing residual and Jacobian contributions).; All this needs to be done with templates for the ""minimal indirection"" requirement. Which means for each numerical method we will have 4 explicit template instantiations (Euler2D, Euler3D, (RA)NS2D, (RA)NS3D) but in the end these are still polymorphic objects that will be instantiated by some factory function (i.e. it will look clean, especially because I will not port all methods in one go xD). The template machinery to support this is actually not too crazy:; ```c++; #include <array>; #include <cmath>. // An example type to use instead of the container that stores solution data for all vertices.; struct SolutionContainer; {; std::array<double,3> velocity;; std::array<double,3> areaVector;; };. using ResultType = double;. // We want classes with this interface.; class VirtualInterface; {; public:; virtual ResultType Compute(const SolutionContainer&) const = 0;; };. // The Co",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/789#issuecomment-622941617
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:259,Energy Efficiency,adapt,adaptive,259,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:311,Energy Efficiency,adapt,adaptive,311,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:531,Energy Efficiency,adapt,adaptive,531,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:544,Integrability,rout,routine,544,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:259,Modifiability,adapt,adaptive,259,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:311,Modifiability,adapt,adaptive,311,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:531,Modifiability,adapt,adaptive,531,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:229,Performance,perform,performing,229,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:240,Performance,optimiz,optimizations,240,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:411,Performance,perform,performs,411,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:50,Testability,test,test,50,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531520526:818,Usability,simpl,simple,818,"YES! I am excited to try this out. I can probably test it on some of the other TMR cases (airfoils, flatplates). Will post the results when I get those done. . Side note, there was one issue that @bmunguia and I encountered when performing optimizations with adaptive CFL. Say the DIRECT simulation is run with adaptive CFL and is well converged (6 to 8 orders of residual reduction). When the discrete adjoint performs the one direct iteration to store the computational graph, it uses the initial CFL value, not the CFL that the adaptive CFL routine ended at. This results in the residuals being very high for that one iteration, which then affects the convergence of the discrete adjoint. . I will try to run an adjoint on one of these cases as well to see if the problem persists. Perhaps could be overcome with a simple additional field for CFL in the restart meta-data",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531520526
https://github.com/su2code/SU2/pull/790#issuecomment-531890295:98,Availability,down,downside,98,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
https://github.com/su2code/SU2/pull/790#issuecomment-531890295:676,Availability,robust,robust,676,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
https://github.com/su2code/SU2/pull/790#issuecomment-531890295:782,Availability,robust,robustness,782,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
https://github.com/su2code/SU2/pull/790#issuecomment-531890295:1008,Energy Efficiency,reduce,reduce,1008,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
https://github.com/su2code/SU2/pull/790#issuecomment-531890295:1495,Performance,tune,tune,1495,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
https://github.com/su2code/SU2/pull/790#issuecomment-531890295:1300,Usability,feedback,feedback,1300,"> Do I understand correctly that two gradients are always computed per iteration?; > Is there any downside to using the unweighted LS for viscous flux correction? Is the statement that this type of gradient is better for reconstruction based on your observations or is it one of those well known things?. Yes - the gradient for now is computed twice and stored separately for viscous flows with 2nd-order upwind. Could be combined into one loop eventually. It is known that weighted LSQ / GG is more accurate (see Mavriplis, ""Revisiting the Least-Squares Procedure for Gradient Reconstruction on Unstructured Meshes"" for instance). However, unweighted LSQ is known to be more robust.. so a good compromise is to use it only for the reconstruction step (which is more susceptible to robustness issues than the viscous term) and then use WLSQ or GG for all other gradients in the viscous flux/sources for accuracy. > Sometimes high CFL leads to limit-cycle oscillations of the residuals and the solution is to reduce it, is this something this controller can pick up?; > High CFL also makes the linear systems harder to solve and as Edwin pointed out _somewhere_ there is not much point going above reasonable values with weakly coupled turbulence. Do you think it would be reasonable to build in some feedback from the linear solver (e.g. it is taking too much time or did not converge -> drop the CFL)?. Yes, I would also like to couple it to the linear solver so that we can remove the need to tune that as well. Ideally the user will not need to adjust parameters. There are some things I am going to try for that..",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-531890295
https://github.com/su2code/SU2/pull/790#issuecomment-532883592:425,Availability,robust,robust,425,"@pcarruscag: the approach to use different gradient methods for the convective and viscous terms is relatively common across codes. If it is a computational cost concern, this can be addressed by fusing the kernels. . However, the bigger issue at hand is the other comment that is made in the article about the choice between LSQ and WLSQ/GG for 2nd-order upwind reconstructions: while less accurate, the former is much more robust, while the latter two usually require limiters just to obtain a stable solution on stretched RANS-type meshes, even for flows where we do not expect shocks/discontinuities. The problem with always requiring a limiter is that they stall convergence due to chatter, which apart from the obvious problems, also causes issues for the adjoint. I think everyone has experienced this. Hence the compromise to use both gradients as I note above, which is also stated on p. 9 of Anderson and Bonhaus ""An Implicit Upwind Algorithm for Computing Turbulent Flows on Unstructured Grids."" In that paper they mention an additional interesting point that, in their numerical tests, LSQ outperforms WLSQ/GG for reconstructing nonlinear data at interfaces on highly-stretched meshes. Note the WLSQ/GG gradients are used for the viscous terms, which is important for accuracy. This type of approach is still applied in FUN3D. . If there are any accuracy concerns, we can also address those via our typical verification tools. I agree that we should continue along the path of looking at grid quality issues and how they impact the numerics (potentially adding some grid-based corrections / limiting), but I think the proposed approach in this PR will serve us well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-532883592
https://github.com/su2code/SU2/pull/790#issuecomment-532883592:1159,Integrability,interface,interfaces,1159,"@pcarruscag: the approach to use different gradient methods for the convective and viscous terms is relatively common across codes. If it is a computational cost concern, this can be addressed by fusing the kernels. . However, the bigger issue at hand is the other comment that is made in the article about the choice between LSQ and WLSQ/GG for 2nd-order upwind reconstructions: while less accurate, the former is much more robust, while the latter two usually require limiters just to obtain a stable solution on stretched RANS-type meshes, even for flows where we do not expect shocks/discontinuities. The problem with always requiring a limiter is that they stall convergence due to chatter, which apart from the obvious problems, also causes issues for the adjoint. I think everyone has experienced this. Hence the compromise to use both gradients as I note above, which is also stated on p. 9 of Anderson and Bonhaus ""An Implicit Upwind Algorithm for Computing Turbulent Flows on Unstructured Grids."" In that paper they mention an additional interesting point that, in their numerical tests, LSQ outperforms WLSQ/GG for reconstructing nonlinear data at interfaces on highly-stretched meshes. Note the WLSQ/GG gradients are used for the viscous terms, which is important for accuracy. This type of approach is still applied in FUN3D. . If there are any accuracy concerns, we can also address those via our typical verification tools. I agree that we should continue along the path of looking at grid quality issues and how they impact the numerics (potentially adding some grid-based corrections / limiting), but I think the proposed approach in this PR will serve us well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-532883592
https://github.com/su2code/SU2/pull/790#issuecomment-532883592:1091,Testability,test,tests,1091,"@pcarruscag: the approach to use different gradient methods for the convective and viscous terms is relatively common across codes. If it is a computational cost concern, this can be addressed by fusing the kernels. . However, the bigger issue at hand is the other comment that is made in the article about the choice between LSQ and WLSQ/GG for 2nd-order upwind reconstructions: while less accurate, the former is much more robust, while the latter two usually require limiters just to obtain a stable solution on stretched RANS-type meshes, even for flows where we do not expect shocks/discontinuities. The problem with always requiring a limiter is that they stall convergence due to chatter, which apart from the obvious problems, also causes issues for the adjoint. I think everyone has experienced this. Hence the compromise to use both gradients as I note above, which is also stated on p. 9 of Anderson and Bonhaus ""An Implicit Upwind Algorithm for Computing Turbulent Flows on Unstructured Grids."" In that paper they mention an additional interesting point that, in their numerical tests, LSQ outperforms WLSQ/GG for reconstructing nonlinear data at interfaces on highly-stretched meshes. Note the WLSQ/GG gradients are used for the viscous terms, which is important for accuracy. This type of approach is still applied in FUN3D. . If there are any accuracy concerns, we can also address those via our typical verification tools. I agree that we should continue along the path of looking at grid quality issues and how they impact the numerics (potentially adding some grid-based corrections / limiting), but I think the proposed approach in this PR will serve us well.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-532883592
https://github.com/su2code/SU2/pull/790#issuecomment-532893719:21,Integrability,rout,routines,21,"Regardless of fusing routines computing two is more expensive than computing one, and the method is full of drawbacks, so I do not think it should be a forceful default.; Can this be implemented as a USE_ROBUST_GRADIENT option that if set to NO uses whatever gradient method is chosen for both convection and diffusion, computing and allocating only once? I do not care what the default is I just want to be able to turn it off.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-532893719
https://github.com/su2code/SU2/pull/790#issuecomment-532903950:79,Availability,robust,robustness,79,"Hi @economon ,. Thanks for the effort in implementing this PR that is focus in robustness and convergence. . However, I agree with @pcarruscag that we need to give to the user the ability to choose the gradient method that he/she thinks is appropriate. Although, this PR sounds promising we didn't test in complex geometries, i.e. High Lift PW or Drag PW (please correct me if I am wrong). Moreover, it may well be that in some cases the use of the more robust gradient method is not necessary since the CFL number is small for accuracy reasons, i.e. hybrid RANS/LES simulations like DDES. Thanks again,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-532903950
https://github.com/su2code/SU2/pull/790#issuecomment-532903950:454,Availability,robust,robust,454,"Hi @economon ,. Thanks for the effort in implementing this PR that is focus in robustness and convergence. . However, I agree with @pcarruscag that we need to give to the user the ability to choose the gradient method that he/she thinks is appropriate. Although, this PR sounds promising we didn't test in complex geometries, i.e. High Lift PW or Drag PW (please correct me if I am wrong). Moreover, it may well be that in some cases the use of the more robust gradient method is not necessary since the CFL number is small for accuracy reasons, i.e. hybrid RANS/LES simulations like DDES. Thanks again,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-532903950
https://github.com/su2code/SU2/pull/790#issuecomment-532903950:298,Testability,test,test,298,"Hi @economon ,. Thanks for the effort in implementing this PR that is focus in robustness and convergence. . However, I agree with @pcarruscag that we need to give to the user the ability to choose the gradient method that he/she thinks is appropriate. Although, this PR sounds promising we didn't test in complex geometries, i.e. High Lift PW or Drag PW (please correct me if I am wrong). Moreover, it may well be that in some cases the use of the more robust gradient method is not necessary since the CFL number is small for accuracy reasons, i.e. hybrid RANS/LES simulations like DDES. Thanks again,; Eduardo",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-532903950
https://github.com/su2code/SU2/pull/790#issuecomment-533259202:678,Availability,error,error,678,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
https://github.com/su2code/SU2/pull/790#issuecomment-533259202:121,Modifiability,config,config,121,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
https://github.com/su2code/SU2/pull/790#issuecomment-533259202:745,Safety,avoid,avoid,745,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
https://github.com/su2code/SU2/pull/790#issuecomment-533259202:106,Security,expose,exposed,106,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
https://github.com/su2code/SU2/pull/790#issuecomment-533259202:67,Usability,user-friendly,user-friendly,67,"The motivation of having it as the default was to make the code as user-friendly as possible (fewer knobs exposed in the config), but options are good of course. I would propose then that we add an option for the reconstruction gradient, something like:; ```; NUM_METHOD_GRAD_RECON= LEAST_SQUARES; ```; to let users decide if they want a separate option for the reconstruction gradients. If it does not appear, then the default is to use the same method as defined by NUM_METHOD_GRAD without a second gradient computation (basically what we have now). The nice thing about that is we can even try out other combos such as WLS+GG for the two different gradients. I will throw an error if users try to use LSQ for the viscous/source gradients, to avoid accuracy issues. What do you think?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533259202
https://github.com/su2code/SU2/pull/790#issuecomment-533266438:57,Availability,robust,robust,57,"I agree with having suitable defaults that make the code robust, but ""expert"" options should still be available.; Having separate controls also sounds good, I would not throw an error though, maybe just a warning. If you detect the two gradient options to be the same the associated CVariable classes make the reconstruction gradient point to the primitive gradient instead of allocating, and the call to compute the reconstruction gradient is skipped. If this is what you have in mind I support 100%.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533266438
https://github.com/su2code/SU2/pull/790#issuecomment-533266438:102,Availability,avail,available,102,"I agree with having suitable defaults that make the code robust, but ""expert"" options should still be available.; Having separate controls also sounds good, I would not throw an error though, maybe just a warning. If you detect the two gradient options to be the same the associated CVariable classes make the reconstruction gradient point to the primitive gradient instead of allocating, and the call to compute the reconstruction gradient is skipped. If this is what you have in mind I support 100%.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533266438
https://github.com/su2code/SU2/pull/790#issuecomment-533266438:178,Availability,error,error,178,"I agree with having suitable defaults that make the code robust, but ""expert"" options should still be available.; Having separate controls also sounds good, I would not throw an error though, maybe just a warning. If you detect the two gradient options to be the same the associated CVariable classes make the reconstruction gradient point to the primitive gradient instead of allocating, and the call to compute the reconstruction gradient is skipped. If this is what you have in mind I support 100%.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533266438
https://github.com/su2code/SU2/pull/790#issuecomment-533266438:221,Safety,detect,detect,221,"I agree with having suitable defaults that make the code robust, but ""expert"" options should still be available.; Having separate controls also sounds good, I would not throw an error though, maybe just a warning. If you detect the two gradient options to be the same the associated CVariable classes make the reconstruction gradient point to the primitive gradient instead of allocating, and the call to compute the reconstruction gradient is skipped. If this is what you have in mind I support 100%.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-533266438
https://github.com/su2code/SU2/pull/790#issuecomment-535683971:130,Modifiability,enhance,enhanced,130,"Hi @economon ,. I tested a couple of cases - laminar flow over a cylinder and turbulent flat plate and the convergence is greatly enhanced. I have attached a plot of convergence history for the flat plate case. I didn't have much luck with the laminar backward facing step case though. The residuals tends to oscillate around -5.5. I was planning to run the NACA 0012 test case soon. Do you have any cases specifically that you wanted to test? I can run some of them soon.; ![Convergence](https://user-images.githubusercontent.com/28007882/65721666-b9eeae00-e0aa-11e9-97c6-727d743e923b.png). Cheers,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-535683971
https://github.com/su2code/SU2/pull/790#issuecomment-535683971:18,Testability,test,tested,18,"Hi @economon ,. I tested a couple of cases - laminar flow over a cylinder and turbulent flat plate and the convergence is greatly enhanced. I have attached a plot of convergence history for the flat plate case. I didn't have much luck with the laminar backward facing step case though. The residuals tends to oscillate around -5.5. I was planning to run the NACA 0012 test case soon. Do you have any cases specifically that you wanted to test? I can run some of them soon.; ![Convergence](https://user-images.githubusercontent.com/28007882/65721666-b9eeae00-e0aa-11e9-97c6-727d743e923b.png). Cheers,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-535683971
https://github.com/su2code/SU2/pull/790#issuecomment-535683971:368,Testability,test,test,368,"Hi @economon ,. I tested a couple of cases - laminar flow over a cylinder and turbulent flat plate and the convergence is greatly enhanced. I have attached a plot of convergence history for the flat plate case. I didn't have much luck with the laminar backward facing step case though. The residuals tends to oscillate around -5.5. I was planning to run the NACA 0012 test case soon. Do you have any cases specifically that you wanted to test? I can run some of them soon.; ![Convergence](https://user-images.githubusercontent.com/28007882/65721666-b9eeae00-e0aa-11e9-97c6-727d743e923b.png). Cheers,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-535683971
https://github.com/su2code/SU2/pull/790#issuecomment-535683971:438,Testability,test,test,438,"Hi @economon ,. I tested a couple of cases - laminar flow over a cylinder and turbulent flat plate and the convergence is greatly enhanced. I have attached a plot of convergence history for the flat plate case. I didn't have much luck with the laminar backward facing step case though. The residuals tends to oscillate around -5.5. I was planning to run the NACA 0012 test case soon. Do you have any cases specifically that you wanted to test? I can run some of them soon.; ![Convergence](https://user-images.githubusercontent.com/28007882/65721666-b9eeae00-e0aa-11e9-97c6-727d743e923b.png). Cheers,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-535683971
https://github.com/su2code/SU2/pull/790#issuecomment-536145232:182,Energy Efficiency,allocate,allocated,182,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
https://github.com/su2code/SU2/pull/790#issuecomment-536145232:645,Testability,test,tests,645,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
https://github.com/su2code/SU2/pull/790#issuecomment-536145232:697,Testability,test,testing,697,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
https://github.com/su2code/SU2/pull/790#issuecomment-536145232:984,Testability,Test,TestCases,984,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
https://github.com/su2code/SU2/pull/790#issuecomment-536145232:253,Usability,simpl,simple,253,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
https://github.com/su2code/SU2/pull/790#issuecomment-536145232:260,Usability,feedback,feedback,260,"I have added the new option NUM_METHOD_GRAD_RECON to specify a separate method for computing the reconstruction gradient. If that option is not present, then no additional memory is allocated and no extra gradient computation occurs. I have also put in simple feedback from the linear solver residual and the nonlinear residual to the nonlinear controller. If the linear system converges less than a half an order of magnitude, then the CFL is lowered. A Cauchy-like criteria checks for stall in the nonlinear residuals and drops the CFL to the minimum floor to kick the solver out of a rut. Both of these use factors that are empirical from my tests. Will probably be improved with time and more testing, but they do seem to improve behavior. @koodlyakshay : I had success with the inc. laminar backward facing step after adding extra iterations to the linear solve. For some cases, this is necessary to get a large speedup. I am seeing good speedup for most of the cases within our TestCases repo. If you have some tough cases not covered by the repo, please give those a try.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-536145232
https://github.com/su2code/SU2/pull/790#issuecomment-537630224:104,Deployability,integrat,integrate,104,Adding some additional residual convergence plots sampled from our test cases. Still some work to do to integrate #724 and clean up regressions. ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072901-fa737f00-e523-11e9-9369-92bbea23f1bb.png); ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072920-03645080-e524-11e9-858a-dc7c310a673b.png); ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072950-1414c680-e524-11e9-80eb-0c4b4a5c0aa7.png),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-537630224
https://github.com/su2code/SU2/pull/790#issuecomment-537630224:104,Integrability,integrat,integrate,104,Adding some additional residual convergence plots sampled from our test cases. Still some work to do to integrate #724 and clean up regressions. ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072901-fa737f00-e523-11e9-9369-92bbea23f1bb.png); ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072920-03645080-e524-11e9-858a-dc7c310a673b.png); ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072950-1414c680-e524-11e9-80eb-0c4b4a5c0aa7.png),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-537630224
https://github.com/su2code/SU2/pull/790#issuecomment-537630224:67,Testability,test,test,67,Adding some additional residual convergence plots sampled from our test cases. Still some work to do to integrate #724 and clean up regressions. ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072901-fa737f00-e523-11e9-9369-92bbea23f1bb.png); ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072920-03645080-e524-11e9-858a-dc7c310a673b.png); ![residual_convergence](https://user-images.githubusercontent.com/4896083/66072950-1414c680-e524-11e9-80eb-0c4b4a5c0aa7.png),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-537630224
https://github.com/su2code/SU2/pull/790#issuecomment-539278925:123,Energy Efficiency,adapt,adaption,123,"I have run some test to verify that the changes here also work ok for unsteady flows with dual time-stepping (even the CFL adaption seems to work pretty well for pseudo time). I also added some checks to make sure CFL adaption is disabled for TIME_STEPPING mode. @EduardoMolina @clarkpede @cvencro: if you have some time, can you please test this branch out with some of your unsteady cases to verify that everything is ok for you as well? Let me know if you see any issues",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-539278925
https://github.com/su2code/SU2/pull/790#issuecomment-539278925:218,Energy Efficiency,adapt,adaption,218,"I have run some test to verify that the changes here also work ok for unsteady flows with dual time-stepping (even the CFL adaption seems to work pretty well for pseudo time). I also added some checks to make sure CFL adaption is disabled for TIME_STEPPING mode. @EduardoMolina @clarkpede @cvencro: if you have some time, can you please test this branch out with some of your unsteady cases to verify that everything is ok for you as well? Let me know if you see any issues",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-539278925
https://github.com/su2code/SU2/pull/790#issuecomment-539278925:123,Modifiability,adapt,adaption,123,"I have run some test to verify that the changes here also work ok for unsteady flows with dual time-stepping (even the CFL adaption seems to work pretty well for pseudo time). I also added some checks to make sure CFL adaption is disabled for TIME_STEPPING mode. @EduardoMolina @clarkpede @cvencro: if you have some time, can you please test this branch out with some of your unsteady cases to verify that everything is ok for you as well? Let me know if you see any issues",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-539278925
https://github.com/su2code/SU2/pull/790#issuecomment-539278925:218,Modifiability,adapt,adaption,218,"I have run some test to verify that the changes here also work ok for unsteady flows with dual time-stepping (even the CFL adaption seems to work pretty well for pseudo time). I also added some checks to make sure CFL adaption is disabled for TIME_STEPPING mode. @EduardoMolina @clarkpede @cvencro: if you have some time, can you please test this branch out with some of your unsteady cases to verify that everything is ok for you as well? Let me know if you see any issues",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-539278925
https://github.com/su2code/SU2/pull/790#issuecomment-539278925:16,Testability,test,test,16,"I have run some test to verify that the changes here also work ok for unsteady flows with dual time-stepping (even the CFL adaption seems to work pretty well for pseudo time). I also added some checks to make sure CFL adaption is disabled for TIME_STEPPING mode. @EduardoMolina @clarkpede @cvencro: if you have some time, can you please test this branch out with some of your unsteady cases to verify that everything is ok for you as well? Let me know if you see any issues",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-539278925
https://github.com/su2code/SU2/pull/790#issuecomment-539278925:337,Testability,test,test,337,"I have run some test to verify that the changes here also work ok for unsteady flows with dual time-stepping (even the CFL adaption seems to work pretty well for pseudo time). I also added some checks to make sure CFL adaption is disabled for TIME_STEPPING mode. @EduardoMolina @clarkpede @cvencro: if you have some time, can you please test this branch out with some of your unsteady cases to verify that everything is ok for you as well? Let me know if you see any issues",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-539278925
https://github.com/su2code/SU2/pull/790#issuecomment-540057251:188,Performance,perform,performance,188,I think it would be super useful to change some (or all) of the TestCases to include the suggested settings that you have outlined in this PR. Most users wouldn't know how to get the best performance out of the code otherwise.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-540057251
https://github.com/su2code/SU2/pull/790#issuecomment-540057251:64,Testability,Test,TestCases,64,I think it would be super useful to change some (or all) of the TestCases to include the suggested settings that you have outlined in this PR. Most users wouldn't know how to get the best performance out of the code otherwise.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-540057251
https://github.com/su2code/SU2/pull/790#issuecomment-541376224:116,Deployability,update,update,116,"> * From the history output it seems that the maximum CFL value is not being reached, even for small CFL values the update seems to stop one step before max. There was a small factor applied to keep it above and below the CFL min and max (1.001, 0.999), respectively. But I have removed that, since it is not necessary. Btw, I have added the ability to print the min/max time step, and min/max/avg CFL to the screen by adding MIN_DELTA_TIME, MAX_DELTA_TIME, MIN_CFL, MAX_CFL, AVG_CFL to the SCREEN_OUTPUT. > * I still see some residual oscillations with high CFL values (100-1000), I think the issue is that despite the oscillations the linear solver still converges fine, and so the reduction never kicks in. There are reduction checks for both the linear and nonlinear residuals, but they likely still need some tuning (the factors were just empirical from my tests). I am also finding in my tests that if I am having trouble with a particular RANS case, sometimes it is most effective to turn off the adaption and go for a fixed CFL of 250, 500, or even 1000, if stable (don't forget you may need NUM_METHOD_GRAD_RECON= LEAST_SQUARES for that to be stable).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-541376224
https://github.com/su2code/SU2/pull/790#issuecomment-541376224:1004,Energy Efficiency,adapt,adaption,1004,"> * From the history output it seems that the maximum CFL value is not being reached, even for small CFL values the update seems to stop one step before max. There was a small factor applied to keep it above and below the CFL min and max (1.001, 0.999), respectively. But I have removed that, since it is not necessary. Btw, I have added the ability to print the min/max time step, and min/max/avg CFL to the screen by adding MIN_DELTA_TIME, MAX_DELTA_TIME, MIN_CFL, MAX_CFL, AVG_CFL to the SCREEN_OUTPUT. > * I still see some residual oscillations with high CFL values (100-1000), I think the issue is that despite the oscillations the linear solver still converges fine, and so the reduction never kicks in. There are reduction checks for both the linear and nonlinear residuals, but they likely still need some tuning (the factors were just empirical from my tests). I am also finding in my tests that if I am having trouble with a particular RANS case, sometimes it is most effective to turn off the adaption and go for a fixed CFL of 250, 500, or even 1000, if stable (don't forget you may need NUM_METHOD_GRAD_RECON= LEAST_SQUARES for that to be stable).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-541376224
https://github.com/su2code/SU2/pull/790#issuecomment-541376224:1004,Modifiability,adapt,adaption,1004,"> * From the history output it seems that the maximum CFL value is not being reached, even for small CFL values the update seems to stop one step before max. There was a small factor applied to keep it above and below the CFL min and max (1.001, 0.999), respectively. But I have removed that, since it is not necessary. Btw, I have added the ability to print the min/max time step, and min/max/avg CFL to the screen by adding MIN_DELTA_TIME, MAX_DELTA_TIME, MIN_CFL, MAX_CFL, AVG_CFL to the SCREEN_OUTPUT. > * I still see some residual oscillations with high CFL values (100-1000), I think the issue is that despite the oscillations the linear solver still converges fine, and so the reduction never kicks in. There are reduction checks for both the linear and nonlinear residuals, but they likely still need some tuning (the factors were just empirical from my tests). I am also finding in my tests that if I am having trouble with a particular RANS case, sometimes it is most effective to turn off the adaption and go for a fixed CFL of 250, 500, or even 1000, if stable (don't forget you may need NUM_METHOD_GRAD_RECON= LEAST_SQUARES for that to be stable).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-541376224
https://github.com/su2code/SU2/pull/790#issuecomment-541376224:862,Testability,test,tests,862,"> * From the history output it seems that the maximum CFL value is not being reached, even for small CFL values the update seems to stop one step before max. There was a small factor applied to keep it above and below the CFL min and max (1.001, 0.999), respectively. But I have removed that, since it is not necessary. Btw, I have added the ability to print the min/max time step, and min/max/avg CFL to the screen by adding MIN_DELTA_TIME, MAX_DELTA_TIME, MIN_CFL, MAX_CFL, AVG_CFL to the SCREEN_OUTPUT. > * I still see some residual oscillations with high CFL values (100-1000), I think the issue is that despite the oscillations the linear solver still converges fine, and so the reduction never kicks in. There are reduction checks for both the linear and nonlinear residuals, but they likely still need some tuning (the factors were just empirical from my tests). I am also finding in my tests that if I am having trouble with a particular RANS case, sometimes it is most effective to turn off the adaption and go for a fixed CFL of 250, 500, or even 1000, if stable (don't forget you may need NUM_METHOD_GRAD_RECON= LEAST_SQUARES for that to be stable).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-541376224
https://github.com/su2code/SU2/pull/790#issuecomment-541376224:894,Testability,test,tests,894,"> * From the history output it seems that the maximum CFL value is not being reached, even for small CFL values the update seems to stop one step before max. There was a small factor applied to keep it above and below the CFL min and max (1.001, 0.999), respectively. But I have removed that, since it is not necessary. Btw, I have added the ability to print the min/max time step, and min/max/avg CFL to the screen by adding MIN_DELTA_TIME, MAX_DELTA_TIME, MIN_CFL, MAX_CFL, AVG_CFL to the SCREEN_OUTPUT. > * I still see some residual oscillations with high CFL values (100-1000), I think the issue is that despite the oscillations the linear solver still converges fine, and so the reduction never kicks in. There are reduction checks for both the linear and nonlinear residuals, but they likely still need some tuning (the factors were just empirical from my tests). I am also finding in my tests that if I am having trouble with a particular RANS case, sometimes it is most effective to turn off the adaption and go for a fixed CFL of 250, 500, or even 1000, if stable (don't forget you may need NUM_METHOD_GRAD_RECON= LEAST_SQUARES for that to be stable).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-541376224
https://github.com/su2code/SU2/pull/790#issuecomment-543913900:108,Deployability,configurat,configuration,108,Will it be a good idea to provide the optional control of these under-relaxation parameters to the users in configuration (.cfg) file? (ANSYS-Fluent does have such controls). It may be useful sometimes.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-543913900
https://github.com/su2code/SU2/pull/790#issuecomment-543913900:108,Modifiability,config,configuration,108,Will it be a good idea to provide the optional control of these under-relaxation parameters to the users in configuration (.cfg) file? (ANSYS-Fluent does have such controls). It may be useful sometimes.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-543913900
https://github.com/su2code/SU2/pull/790#issuecomment-551323531:417,Usability,clear,clear,417,"> @jayantmukho : I am finding that the clipping limits for the SST model are very important for the UQ cases. If you adjust them slightly, the UQ regression cases tend to diverge immediately. Don't think any immediate action is needed, just wanted to bring it to your attention. Mhmmm, that's a little odd. I wouldn't think that the UQ methodology would be affected by the clipping. I will look into this. Just to be clear, you are changing the lowerlimit and upperlimit in CTurbSSTSolver constructor? What are you changing them too? Just want to reproduce the issue",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-551323531
https://github.com/su2code/SU2/pull/790#issuecomment-551351016:426,Usability,clear,clear,426,"> > @jayantmukho : I am finding that the clipping limits for the SST model are very important for the UQ cases. If you adjust them slightly, the UQ regression cases tend to diverge immediately. Don't think any immediate action is needed, just wanted to bring it to your attention.; > ; > Mhmmm, that's a little odd. I wouldn't think that the UQ methodology would be affected by the clipping. I will look into this. Just to be clear, you are changing the lowerlimit and upperlimit in CTurbSSTSolver constructor? What are you changing them too? Just want to reproduce the issue. If you revert my last commit, you will see the issue. It diverges right away for me, so perhaps it is just something with the initial transient that is caught by the clipping",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-551351016
https://github.com/su2code/SU2/pull/790#issuecomment-552012110:252,Deployability,update,updated,252,"@salvovitale @talbring : I have run the turbomachinery cases to convergence, and everything seems to be working fine. There are some non-negligible differences in the solution due to the changes to the SST model, the this is to be expected. So, I have updated all of the regression values. . However, due to the legacy output, the turbo cases do not currently write restart files, which means a couple of the cases should be updated with proper restarts (and SU2_SOL is complaining that it can't find the restarts). Can you please give it a look when you have a moment?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552012110
https://github.com/su2code/SU2/pull/790#issuecomment-552012110:425,Deployability,update,updated,425,"@salvovitale @talbring : I have run the turbomachinery cases to convergence, and everything seems to be working fine. There are some non-negligible differences in the solution due to the changes to the SST model, the this is to be expected. So, I have updated all of the regression values. . However, due to the legacy output, the turbo cases do not currently write restart files, which means a couple of the cases should be updated with proper restarts (and SU2_SOL is complaining that it can't find the restarts). Can you please give it a look when you have a moment?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552012110
https://github.com/su2code/SU2/pull/790#issuecomment-552402092:221,Deployability,release,release,221,"@economon Output should be fixed for now. Volume output uses the new structure. History output still the legacy one. I am working with @salvovitale to also move that to the new structure, but that won't happen before the release of v7.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552402092
https://github.com/su2code/SU2/pull/790#issuecomment-552706095:223,Deployability,release,release,223,"> @economon Output should be fixed for now. Volume output uses the new structure. History output still the legacy one. I am working with @salvovitale to also move that to the new structure, but that won't happen before the release of v7. Aok. Thanks for the fix and the update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552706095
https://github.com/su2code/SU2/pull/790#issuecomment-552706095:270,Deployability,update,update,270,"> @economon Output should be fixed for now. Volume output uses the new structure. History output still the legacy one. I am working with @salvovitale to also move that to the new structure, but that won't happen before the release of v7. Aok. Thanks for the fix and the update.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552706095
https://github.com/su2code/SU2/pull/790#issuecomment-552707156:7,Deployability,update,updated,7,"I have updated the sliding mesh cases now, but I have found two cases that had odd behavior. The rotating cylinders case seems to give different results for values such as lift and drag depending on the core count, even in the develop branch. Also, the supersonic vortex shedding problem reports that hundreds of points are non-physical at the end of the run, both with this PR and in develop. Anyone have any insight on these? I am going to keep moving through the final cases that need updated for this PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552707156
https://github.com/su2code/SU2/pull/790#issuecomment-552707156:488,Deployability,update,updated,488,"I have updated the sliding mesh cases now, but I have found two cases that had odd behavior. The rotating cylinders case seems to give different results for values such as lift and drag depending on the core count, even in the develop branch. Also, the supersonic vortex shedding problem reports that hundreds of points are non-physical at the end of the run, both with this PR and in develop. Anyone have any insight on these? I am going to keep moving through the final cases that need updated for this PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552707156
https://github.com/su2code/SU2/pull/790#issuecomment-552707156:186,Integrability,depend,depending,186,"I have updated the sliding mesh cases now, but I have found two cases that had odd behavior. The rotating cylinders case seems to give different results for values such as lift and drag depending on the core count, even in the develop branch. Also, the supersonic vortex shedding problem reports that hundreds of points are non-physical at the end of the run, both with this PR and in develop. Anyone have any insight on these? I am going to keep moving through the final cases that need updated for this PR.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-552707156
https://github.com/su2code/SU2/pull/790#issuecomment-553099621:287,Integrability,interface,interface,287,"Oddly enough, I changed the number of inner iterations to a high value so that it would converge each physical time step, and I still see non-deterministic output for the rotating cylinders case. . Perhaps these cases need to be flagged for checking if some folks using the sliding mesh interface have some time.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553099621
https://github.com/su2code/SU2/pull/790#issuecomment-553494652:609,Availability,down,down,609,"Hey everyone! Just posting the results from one of the NASA TMR verification test cases I have been running: [the DSMA661](https://turbmodels.larc.nasa.gov/airfoilwakeverif500c.html). Using Least Squares (LSQ) for the gradient reconstruction does affect the results and can be seen from this force convergence plot. Using the same gradient reconstruction (GG) gives more accurate results. The two SU2 runs were done using identical linear solver parameters. The only difference is that for the GG+LSQ case, I specified : `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` and for the GG case, I had to reduce the max CFL down to ~20 for it to get stable. . ![cfl_adap_force_convergence_dsma661_SA](https://user-images.githubusercontent.com/30271435/68785755-7ec12380-05f3-11ea-89e3-4b93edeb9d64.png). But due to the much lower maximum CFL, the GG run takes 40-50x longer to reach the same level of convergence. I'm not sure what else can be done to make adaptive CFL better for the GG or WLSQ cases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553494652
https://github.com/su2code/SU2/pull/790#issuecomment-553494652:590,Energy Efficiency,reduce,reduce,590,"Hey everyone! Just posting the results from one of the NASA TMR verification test cases I have been running: [the DSMA661](https://turbmodels.larc.nasa.gov/airfoilwakeverif500c.html). Using Least Squares (LSQ) for the gradient reconstruction does affect the results and can be seen from this force convergence plot. Using the same gradient reconstruction (GG) gives more accurate results. The two SU2 runs were done using identical linear solver parameters. The only difference is that for the GG+LSQ case, I specified : `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` and for the GG case, I had to reduce the max CFL down to ~20 for it to get stable. . ![cfl_adap_force_convergence_dsma661_SA](https://user-images.githubusercontent.com/30271435/68785755-7ec12380-05f3-11ea-89e3-4b93edeb9d64.png). But due to the much lower maximum CFL, the GG run takes 40-50x longer to reach the same level of convergence. I'm not sure what else can be done to make adaptive CFL better for the GG or WLSQ cases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553494652
https://github.com/su2code/SU2/pull/790#issuecomment-553494652:942,Energy Efficiency,adapt,adaptive,942,"Hey everyone! Just posting the results from one of the NASA TMR verification test cases I have been running: [the DSMA661](https://turbmodels.larc.nasa.gov/airfoilwakeverif500c.html). Using Least Squares (LSQ) for the gradient reconstruction does affect the results and can be seen from this force convergence plot. Using the same gradient reconstruction (GG) gives more accurate results. The two SU2 runs were done using identical linear solver parameters. The only difference is that for the GG+LSQ case, I specified : `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` and for the GG case, I had to reduce the max CFL down to ~20 for it to get stable. . ![cfl_adap_force_convergence_dsma661_SA](https://user-images.githubusercontent.com/30271435/68785755-7ec12380-05f3-11ea-89e3-4b93edeb9d64.png). But due to the much lower maximum CFL, the GG run takes 40-50x longer to reach the same level of convergence. I'm not sure what else can be done to make adaptive CFL better for the GG or WLSQ cases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553494652
https://github.com/su2code/SU2/pull/790#issuecomment-553494652:942,Modifiability,adapt,adaptive,942,"Hey everyone! Just posting the results from one of the NASA TMR verification test cases I have been running: [the DSMA661](https://turbmodels.larc.nasa.gov/airfoilwakeverif500c.html). Using Least Squares (LSQ) for the gradient reconstruction does affect the results and can be seen from this force convergence plot. Using the same gradient reconstruction (GG) gives more accurate results. The two SU2 runs were done using identical linear solver parameters. The only difference is that for the GG+LSQ case, I specified : `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` and for the GG case, I had to reduce the max CFL down to ~20 for it to get stable. . ![cfl_adap_force_convergence_dsma661_SA](https://user-images.githubusercontent.com/30271435/68785755-7ec12380-05f3-11ea-89e3-4b93edeb9d64.png). But due to the much lower maximum CFL, the GG run takes 40-50x longer to reach the same level of convergence. I'm not sure what else can be done to make adaptive CFL better for the GG or WLSQ cases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553494652
https://github.com/su2code/SU2/pull/790#issuecomment-553494652:77,Testability,test,test,77,"Hey everyone! Just posting the results from one of the NASA TMR verification test cases I have been running: [the DSMA661](https://turbmodels.larc.nasa.gov/airfoilwakeverif500c.html). Using Least Squares (LSQ) for the gradient reconstruction does affect the results and can be seen from this force convergence plot. Using the same gradient reconstruction (GG) gives more accurate results. The two SU2 runs were done using identical linear solver parameters. The only difference is that for the GG+LSQ case, I specified : `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` and for the GG case, I had to reduce the max CFL down to ~20 for it to get stable. . ![cfl_adap_force_convergence_dsma661_SA](https://user-images.githubusercontent.com/30271435/68785755-7ec12380-05f3-11ea-89e3-4b93edeb9d64.png). But due to the much lower maximum CFL, the GG run takes 40-50x longer to reach the same level of convergence. I'm not sure what else can be done to make adaptive CFL better for the GG or WLSQ cases.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553494652
https://github.com/su2code/SU2/pull/790#issuecomment-553517069:163,Availability,avail,available,163,"Cool results @jayantmukho, few questions (which maybe you have answered somewhere already); - If someone wants to play around with the same case, are your configs available somewhere? (asking for a friend); - The grid levels in the plots correspond to the meshes available through that link right?; - Did you run the other solvers yourself? If so how does the runtime compare?; - The non monotonic variation with LSQ+GG is a bit weird, did the case converge to the same level? (I had some cases that at very high CFL would stagnate and not converge properly)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553517069
https://github.com/su2code/SU2/pull/790#issuecomment-553517069:263,Availability,avail,available,263,"Cool results @jayantmukho, few questions (which maybe you have answered somewhere already); - If someone wants to play around with the same case, are your configs available somewhere? (asking for a friend); - The grid levels in the plots correspond to the meshes available through that link right?; - Did you run the other solvers yourself? If so how does the runtime compare?; - The non monotonic variation with LSQ+GG is a bit weird, did the case converge to the same level? (I had some cases that at very high CFL would stagnate and not converge properly)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553517069
https://github.com/su2code/SU2/pull/790#issuecomment-553517069:155,Modifiability,config,configs,155,"Cool results @jayantmukho, few questions (which maybe you have answered somewhere already); - If someone wants to play around with the same case, are your configs available somewhere? (asking for a friend); - The grid levels in the plots correspond to the meshes available through that link right?; - Did you run the other solvers yourself? If so how does the runtime compare?; - The non monotonic variation with LSQ+GG is a bit weird, did the case converge to the same level? (I had some cases that at very high CFL would stagnate and not converge properly)",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553517069
https://github.com/su2code/SU2/pull/790#issuecomment-553521522:937,Energy Efficiency,adapt,adaptive,937,"Nice work, and thanks for sharing, @jayantmukho. I expect you'll add everything to the V&V repo and eventually the V&V tab once we understand what is happening?. The GG results look great, potentially even better than the previous set of results we had for the DSMA case. I am also surprised to see the behavior of the GG+LSQ.. the finest mesh seems to be especially errant. I have been running the NACA 0012 case, and I also see that the results with pure GG or WLSQ are slightly better there, but not this drastic. I think we still need to dial in the LSQ and make sure we do not have any bugs. Although, the flat plate and bump-in-channel cases were run with LSQ and gave very good results. It could be that too much curvature in the grid, especially near walls (which is known to be a potential problem), is causing these issues for the LSQ accuracy, but I'm surprised it would be that significant. Still looking into this... As for adaptive CFL, sometimes I find that just turning it off for some rans cases and using a fixed 250, 500, or 1000 works best. Does that work for you with these cases with GG or WLSQ, @jayantmukho ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553521522
https://github.com/su2code/SU2/pull/790#issuecomment-553521522:937,Modifiability,adapt,adaptive,937,"Nice work, and thanks for sharing, @jayantmukho. I expect you'll add everything to the V&V repo and eventually the V&V tab once we understand what is happening?. The GG results look great, potentially even better than the previous set of results we had for the DSMA case. I am also surprised to see the behavior of the GG+LSQ.. the finest mesh seems to be especially errant. I have been running the NACA 0012 case, and I also see that the results with pure GG or WLSQ are slightly better there, but not this drastic. I think we still need to dial in the LSQ and make sure we do not have any bugs. Although, the flat plate and bump-in-channel cases were run with LSQ and gave very good results. It could be that too much curvature in the grid, especially near walls (which is known to be a potential problem), is causing these issues for the LSQ accuracy, but I'm surprised it would be that significant. Still looking into this... As for adaptive CFL, sometimes I find that just turning it off for some rans cases and using a fixed 250, 500, or 1000 works best. Does that work for you with these cases with GG or WLSQ, @jayantmukho ?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553521522
https://github.com/su2code/SU2/pull/790#issuecomment-553524258:17,Availability,avail,available,17,"- The meshes are available here: https://github.com/su2code/VandV/tree/master/rans/dsma661; - The config files for the GG + LSQ results are here: [dsma661_configs.zip](https://github.com/su2code/SU2/files/3842634/dsma661_configs.zip). - I did not run the other solvers myself. Those are results from the NASA TMR website. I don't have access to those solvers unfortunately. . - Yeah the non-monotonic variation worried me as well. But all the simulations were converged to a density residual of -13. (all of them have over 6 orders of residual reduction). The residuals for the GG+LSQ results shown here:; ![res_SA](https://user-images.githubusercontent.com/30271435/68789548-8a641880-05fa-11ea-8885-4e024fe84eda.png); I tried a few re-runs of that finest mesh with a couple of different options. I reduced the maximum CFL to ~30 from 1000 and it still gave the same result. I reduced the number of cores I was running on from 80 to 20 and that had no effect either. As soon as I ran without the `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` option, it got a C_L of about 0.159402 which would be more in line with the other solvers. @economon I haven't tried a high fixed CFL. Let me check that behavior and report back.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553524258
https://github.com/su2code/SU2/pull/790#issuecomment-553524258:799,Energy Efficiency,reduce,reduced,799,"- The meshes are available here: https://github.com/su2code/VandV/tree/master/rans/dsma661; - The config files for the GG + LSQ results are here: [dsma661_configs.zip](https://github.com/su2code/SU2/files/3842634/dsma661_configs.zip). - I did not run the other solvers myself. Those are results from the NASA TMR website. I don't have access to those solvers unfortunately. . - Yeah the non-monotonic variation worried me as well. But all the simulations were converged to a density residual of -13. (all of them have over 6 orders of residual reduction). The residuals for the GG+LSQ results shown here:; ![res_SA](https://user-images.githubusercontent.com/30271435/68789548-8a641880-05fa-11ea-8885-4e024fe84eda.png); I tried a few re-runs of that finest mesh with a couple of different options. I reduced the maximum CFL to ~30 from 1000 and it still gave the same result. I reduced the number of cores I was running on from 80 to 20 and that had no effect either. As soon as I ran without the `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` option, it got a C_L of about 0.159402 which would be more in line with the other solvers. @economon I haven't tried a high fixed CFL. Let me check that behavior and report back.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553524258
https://github.com/su2code/SU2/pull/790#issuecomment-553524258:877,Energy Efficiency,reduce,reduced,877,"- The meshes are available here: https://github.com/su2code/VandV/tree/master/rans/dsma661; - The config files for the GG + LSQ results are here: [dsma661_configs.zip](https://github.com/su2code/SU2/files/3842634/dsma661_configs.zip). - I did not run the other solvers myself. Those are results from the NASA TMR website. I don't have access to those solvers unfortunately. . - Yeah the non-monotonic variation worried me as well. But all the simulations were converged to a density residual of -13. (all of them have over 6 orders of residual reduction). The residuals for the GG+LSQ results shown here:; ![res_SA](https://user-images.githubusercontent.com/30271435/68789548-8a641880-05fa-11ea-8885-4e024fe84eda.png); I tried a few re-runs of that finest mesh with a couple of different options. I reduced the maximum CFL to ~30 from 1000 and it still gave the same result. I reduced the number of cores I was running on from 80 to 20 and that had no effect either. As soon as I ran without the `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` option, it got a C_L of about 0.159402 which would be more in line with the other solvers. @economon I haven't tried a high fixed CFL. Let me check that behavior and report back.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553524258
https://github.com/su2code/SU2/pull/790#issuecomment-553524258:98,Modifiability,config,config,98,"- The meshes are available here: https://github.com/su2code/VandV/tree/master/rans/dsma661; - The config files for the GG + LSQ results are here: [dsma661_configs.zip](https://github.com/su2code/SU2/files/3842634/dsma661_configs.zip). - I did not run the other solvers myself. Those are results from the NASA TMR website. I don't have access to those solvers unfortunately. . - Yeah the non-monotonic variation worried me as well. But all the simulations were converged to a density residual of -13. (all of them have over 6 orders of residual reduction). The residuals for the GG+LSQ results shown here:; ![res_SA](https://user-images.githubusercontent.com/30271435/68789548-8a641880-05fa-11ea-8885-4e024fe84eda.png); I tried a few re-runs of that finest mesh with a couple of different options. I reduced the maximum CFL to ~30 from 1000 and it still gave the same result. I reduced the number of cores I was running on from 80 to 20 and that had no effect either. As soon as I ran without the `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` option, it got a C_L of about 0.159402 which would be more in line with the other solvers. @economon I haven't tried a high fixed CFL. Let me check that behavior and report back.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553524258
https://github.com/su2code/SU2/pull/790#issuecomment-553524258:335,Security,access,access,335,"- The meshes are available here: https://github.com/su2code/VandV/tree/master/rans/dsma661; - The config files for the GG + LSQ results are here: [dsma661_configs.zip](https://github.com/su2code/SU2/files/3842634/dsma661_configs.zip). - I did not run the other solvers myself. Those are results from the NASA TMR website. I don't have access to those solvers unfortunately. . - Yeah the non-monotonic variation worried me as well. But all the simulations were converged to a density residual of -13. (all of them have over 6 orders of residual reduction). The residuals for the GG+LSQ results shown here:; ![res_SA](https://user-images.githubusercontent.com/30271435/68789548-8a641880-05fa-11ea-8885-4e024fe84eda.png); I tried a few re-runs of that finest mesh with a couple of different options. I reduced the maximum CFL to ~30 from 1000 and it still gave the same result. I reduced the number of cores I was running on from 80 to 20 and that had no effect either. As soon as I ran without the `NUM_METHOD_GRAD_RECON= LEAST_SQUARES` option, it got a C_L of about 0.159402 which would be more in line with the other solvers. @economon I haven't tried a high fixed CFL. Let me check that behavior and report back.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-553524258
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:31,Energy Efficiency,adapt,adaptive,31,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:66,Energy Efficiency,adapt,adaptive,66,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:286,Energy Efficiency,adapt,adaptive,286,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:464,Energy Efficiency,adapt,adaptive,464,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:31,Modifiability,adapt,adaptive,31,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:66,Modifiability,adapt,adaptive,66,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:286,Modifiability,adapt,adaptive,286,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-554101997:464,Modifiability,adapt,adaptive,464,"@economon The behavior without adaptive CFL is similar to its non-adaptive behavior. I cannot increase the CFL greater than a certain value and get convergence. For example, for the 2nd coarsest mesh (297 x 57 or 129) I cannot increase the CFL > 20. This is regardless of weather I use adaptive CFL or not. I cannot set the CFL higher than 20. . But this limit increases slightly for the finer meshes. For example, for the finest mesh I can push the CFL up to 30 (adaptive or otherwise). Basically cannot get high CFLs for the GG reconstruction. I should also mention that all these runs are without slope limiters to get the most accurate solutions.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-554101997
https://github.com/su2code/SU2/pull/790#issuecomment-558013706:30,Deployability,update,updated,30,"To prepare for v7, I have now updated most of the tutorials to take advantage of the new features in this PR. I have also completed a sweep through all regression tests using this branch and have verified that the tests are ok. So, from my point of view, this is ready to be merged, other than updating the final residuals for a few tests which are pending. I will keep looking into the LSQ issues, so for now, we should be cautious with that option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-558013706
https://github.com/su2code/SU2/pull/790#issuecomment-558013706:163,Testability,test,tests,163,"To prepare for v7, I have now updated most of the tutorials to take advantage of the new features in this PR. I have also completed a sweep through all regression tests using this branch and have verified that the tests are ok. So, from my point of view, this is ready to be merged, other than updating the final residuals for a few tests which are pending. I will keep looking into the LSQ issues, so for now, we should be cautious with that option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-558013706
https://github.com/su2code/SU2/pull/790#issuecomment-558013706:214,Testability,test,tests,214,"To prepare for v7, I have now updated most of the tutorials to take advantage of the new features in this PR. I have also completed a sweep through all regression tests using this branch and have verified that the tests are ok. So, from my point of view, this is ready to be merged, other than updating the final residuals for a few tests which are pending. I will keep looking into the LSQ issues, so for now, we should be cautious with that option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-558013706
https://github.com/su2code/SU2/pull/790#issuecomment-558013706:333,Testability,test,tests,333,"To prepare for v7, I have now updated most of the tutorials to take advantage of the new features in this PR. I have also completed a sweep through all regression tests using this branch and have verified that the tests are ok. So, from my point of view, this is ready to be merged, other than updating the final residuals for a few tests which are pending. I will keep looking into the LSQ issues, so for now, we should be cautious with that option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-558013706
https://github.com/su2code/SU2/pull/790#issuecomment-559370410:279,Deployability,release,release,279,"Ok, it's finally time to get this one merged! Thanks all for the comments and help. I'll merge this one in now as-is. I will leave the Tutorials branch in the regressions script set to the 'release_v7.0.0' branch, since we are collecting all changes to the website there for the release. @talbring @rsanfer : can you please revert that back to develop in the Release v7 PR when you are ready (after releasing the web updates)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-559370410
https://github.com/su2code/SU2/pull/790#issuecomment-559370410:359,Deployability,Release,Release,359,"Ok, it's finally time to get this one merged! Thanks all for the comments and help. I'll merge this one in now as-is. I will leave the Tutorials branch in the regressions script set to the 'release_v7.0.0' branch, since we are collecting all changes to the website there for the release. @talbring @rsanfer : can you please revert that back to develop in the Release v7 PR when you are ready (after releasing the web updates)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-559370410
https://github.com/su2code/SU2/pull/790#issuecomment-559370410:417,Deployability,update,updates,417,"Ok, it's finally time to get this one merged! Thanks all for the comments and help. I'll merge this one in now as-is. I will leave the Tutorials branch in the regressions script set to the 'release_v7.0.0' branch, since we are collecting all changes to the website there for the release. @talbring @rsanfer : can you please revert that back to develop in the Release v7 PR when you are ready (after releasing the web updates)?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/790#issuecomment-559370410
https://github.com/su2code/SU2/issues/791#issuecomment-533576279:194,Availability,robust,robust,194,"I've always interpolated my points externally, using Python. I'll take my data, take the inlet vertices, and write a python script to interpolate between the two. I would also like to have more robust interpolation within SU2 itself, but it's not a high enough priority for me to work on it personally.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533576279
https://github.com/su2code/SU2/issues/791#issuecomment-533740827:577,Availability,error,error,577,"If you are interested, @vdweide spent considerable time between 2003 and 2008 writing a multiblock-structured turbo machinery code called SUmb, as part of the DoE ASCI program. SUmb, although written in Fortran90/95, had all of the interpolation capabilities that you need for turbo machinery computations when radial inlet / outflow profiles (Tt, Pt, flow angles, static pressure, etc.) are given as inputs on a radial grid whose spacing does not match that of the actual computational grid. You may consider creating some interpolation functions (with all the safeguards and error codes) in C++ based on the SUmb code (which was structured in a C++-like way) or at least take inspiration from that approach to identify interpolation utilities / libraries in C++ that could be used for the same purpose. Both @vdweide and I can provide you with access to the appropriate routines / functions in SUmb. On Sep 20, 2019, at 3:30 PM, Aman uz zaman Baig <notifications@github.com<mailto:notifications@github.com>> wrote:. @clarkpede<https://github.com/clarkpede> Thanks for your response! My work in focused on Turbomachinery and very frequently we need to have inlet profiles. I hope my work will give a neater, cleaner way of making this possible, though I also used python scripts in the past. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/791?email_source=notifications&email_token=AA5FFRDZYQ56RTPMG7RHC6DQKVFJ5A5CNFSM4IYRTZJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7IBREI#issuecomment-533731473>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRCUZWNCGUIGYDSADO3QKVFJ5ANCNFSM4IYRTZJA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533740827
https://github.com/su2code/SU2/issues/791#issuecomment-533740827:872,Integrability,rout,routines,872,"If you are interested, @vdweide spent considerable time between 2003 and 2008 writing a multiblock-structured turbo machinery code called SUmb, as part of the DoE ASCI program. SUmb, although written in Fortran90/95, had all of the interpolation capabilities that you need for turbo machinery computations when radial inlet / outflow profiles (Tt, Pt, flow angles, static pressure, etc.) are given as inputs on a radial grid whose spacing does not match that of the actual computational grid. You may consider creating some interpolation functions (with all the safeguards and error codes) in C++ based on the SUmb code (which was structured in a C++-like way) or at least take inspiration from that approach to identify interpolation utilities / libraries in C++ that could be used for the same purpose. Both @vdweide and I can provide you with access to the appropriate routines / functions in SUmb. On Sep 20, 2019, at 3:30 PM, Aman uz zaman Baig <notifications@github.com<mailto:notifications@github.com>> wrote:. @clarkpede<https://github.com/clarkpede> Thanks for your response! My work in focused on Turbomachinery and very frequently we need to have inlet profiles. I hope my work will give a neater, cleaner way of making this possible, though I also used python scripts in the past. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/791?email_source=notifications&email_token=AA5FFRDZYQ56RTPMG7RHC6DQKVFJ5A5CNFSM4IYRTZJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7IBREI#issuecomment-533731473>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRCUZWNCGUIGYDSADO3QKVFJ5ANCNFSM4IYRTZJA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533740827
https://github.com/su2code/SU2/issues/791#issuecomment-533740827:562,Safety,safe,safeguards,562,"If you are interested, @vdweide spent considerable time between 2003 and 2008 writing a multiblock-structured turbo machinery code called SUmb, as part of the DoE ASCI program. SUmb, although written in Fortran90/95, had all of the interpolation capabilities that you need for turbo machinery computations when radial inlet / outflow profiles (Tt, Pt, flow angles, static pressure, etc.) are given as inputs on a radial grid whose spacing does not match that of the actual computational grid. You may consider creating some interpolation functions (with all the safeguards and error codes) in C++ based on the SUmb code (which was structured in a C++-like way) or at least take inspiration from that approach to identify interpolation utilities / libraries in C++ that could be used for the same purpose. Both @vdweide and I can provide you with access to the appropriate routines / functions in SUmb. On Sep 20, 2019, at 3:30 PM, Aman uz zaman Baig <notifications@github.com<mailto:notifications@github.com>> wrote:. @clarkpede<https://github.com/clarkpede> Thanks for your response! My work in focused on Turbomachinery and very frequently we need to have inlet profiles. I hope my work will give a neater, cleaner way of making this possible, though I also used python scripts in the past. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/791?email_source=notifications&email_token=AA5FFRDZYQ56RTPMG7RHC6DQKVFJ5A5CNFSM4IYRTZJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7IBREI#issuecomment-533731473>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRCUZWNCGUIGYDSADO3QKVFJ5ANCNFSM4IYRTZJA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533740827
https://github.com/su2code/SU2/issues/791#issuecomment-533740827:846,Security,access,access,846,"If you are interested, @vdweide spent considerable time between 2003 and 2008 writing a multiblock-structured turbo machinery code called SUmb, as part of the DoE ASCI program. SUmb, although written in Fortran90/95, had all of the interpolation capabilities that you need for turbo machinery computations when radial inlet / outflow profiles (Tt, Pt, flow angles, static pressure, etc.) are given as inputs on a radial grid whose spacing does not match that of the actual computational grid. You may consider creating some interpolation functions (with all the safeguards and error codes) in C++ based on the SUmb code (which was structured in a C++-like way) or at least take inspiration from that approach to identify interpolation utilities / libraries in C++ that could be used for the same purpose. Both @vdweide and I can provide you with access to the appropriate routines / functions in SUmb. On Sep 20, 2019, at 3:30 PM, Aman uz zaman Baig <notifications@github.com<mailto:notifications@github.com>> wrote:. @clarkpede<https://github.com/clarkpede> Thanks for your response! My work in focused on Turbomachinery and very frequently we need to have inlet profiles. I hope my work will give a neater, cleaner way of making this possible, though I also used python scripts in the past. —; You are receiving this because you were mentioned.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/791?email_source=notifications&email_token=AA5FFRDZYQ56RTPMG7RHC6DQKVFJ5A5CNFSM4IYRTZJKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD7IBREI#issuecomment-533731473>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AA5FFRCUZWNCGUIGYDSADO3QKVFJ5ANCNFSM4IYRTZJA>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533740827
https://github.com/su2code/SU2/issues/791#issuecomment-533796609:269,Integrability,rout,routines,269,@juanjosealonso Thanks for your response. I would definitely want to have a look at SUmb. If there is some documentation with the code and any published work that shows its capability will also help. > Both @vdweide and I can provide you with access to the appropriate routines / functions in SUmb. Please do provide me the access.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533796609
https://github.com/su2code/SU2/issues/791#issuecomment-533796609:243,Security,access,access,243,@juanjosealonso Thanks for your response. I would definitely want to have a look at SUmb. If there is some documentation with the code and any published work that shows its capability will also help. > Both @vdweide and I can provide you with access to the appropriate routines / functions in SUmb. Please do provide me the access.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533796609
https://github.com/su2code/SU2/issues/791#issuecomment-533796609:324,Security,access,access,324,@juanjosealonso Thanks for your response. I would definitely want to have a look at SUmb. If there is some documentation with the code and any published work that shows its capability will also help. > Both @vdweide and I can provide you with access to the appropriate routines / functions in SUmb. Please do provide me the access.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/791#issuecomment-533796609
https://github.com/su2code/SU2/issues/792#issuecomment-534110882:181,Integrability,rout,routine,181,"Hi @talbring ,. Also I noticed there is no breakdown file being written for incompressible problems. I suspect this is because the flow boolean in the SpecialOutput_ForcesBreakdown routine only checks for EULER, NS and RANS but not the INC versions of those. . Cheers,; Akshay",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/792#issuecomment-534110882
https://github.com/su2code/SU2/issues/793#issuecomment-535572291:249,Integrability,depend,depending,249,"Have you tried the CENTRAL_JACOBIAN_FIX_FACTOR option introduced in #691?; I recommend setting that to 3 or 4, the Lax coefficient to 0.1 (default is 0.15) the JST 4th order coeff to 0.01 and max CFL of 100 - 400 when using the ILU0 preconditioner, depending on how stretched the mesh is.; The justification for those settings is in the aforementioned PR.; Cheers,; Pedro",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/793#issuecomment-535572291
https://github.com/su2code/SU2/issues/794#issuecomment-546316470:650,Energy Efficiency,Power,Power,650,"Hi Daniel,. You can find the implementation of variable properties with cubic EoS in the master/develop version. If you need to compute the properties with more accurate thermo-physical models, e.g. multi-parameter, there are 2 main ways:. * By using the external library FluidProp (feature_fluidprop_final, yet outdated); * By means of look-up tables (feature_adjoint_lut). We are about to improve the look-up table method and will work on having this feature in the develop soon. Just let me know if you are interested and I will give you more details. Best,. Matteo. ——————————————————; Dr. ir. Matteo Pini, PhD; Assistant Professor; Propulsion & Power<http://www.pp.lr.tudelft.nl/>; Aerospace Engineering Faculty; Delft University of Technology. Kluyverweg 1; 2629 HS Delft; The Netherlands. Phone : +31 15 27 84794; Skype : matteo_pini1. From: banuti <notifications@github.com>; Reply-To: su2code/SU2 <reply@reply.github.com>; Date: Thursday, 24 October 2019 at 22:18; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] variable properties (transport and thermodynamic) for compressible flows with any eos (#794). Hi,. is that branch still active? It seems the last commit was more than two years ago. Best,; Daniel. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/794?email_source=notifications&email_token=ABTGC2MB627S4SOHCTMGOTTQQH7KFA5CNFSM4I2YNZ6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECGJUEI#issuecomment-546085393>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABTGC2JPU76ZE3WG5UUKBYDQQH7KFANCNFSM4I2YNZ6A>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/794#issuecomment-546316470
https://github.com/su2code/SU2/issues/794#issuecomment-546316470:47,Modifiability,variab,variable,47,"Hi Daniel,. You can find the implementation of variable properties with cubic EoS in the master/develop version. If you need to compute the properties with more accurate thermo-physical models, e.g. multi-parameter, there are 2 main ways:. * By using the external library FluidProp (feature_fluidprop_final, yet outdated); * By means of look-up tables (feature_adjoint_lut). We are about to improve the look-up table method and will work on having this feature in the develop soon. Just let me know if you are interested and I will give you more details. Best,. Matteo. ——————————————————; Dr. ir. Matteo Pini, PhD; Assistant Professor; Propulsion & Power<http://www.pp.lr.tudelft.nl/>; Aerospace Engineering Faculty; Delft University of Technology. Kluyverweg 1; 2629 HS Delft; The Netherlands. Phone : +31 15 27 84794; Skype : matteo_pini1. From: banuti <notifications@github.com>; Reply-To: su2code/SU2 <reply@reply.github.com>; Date: Thursday, 24 October 2019 at 22:18; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] variable properties (transport and thermodynamic) for compressible flows with any eos (#794). Hi,. is that branch still active? It seems the last commit was more than two years ago. Best,; Daniel. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/794?email_source=notifications&email_token=ABTGC2MB627S4SOHCTMGOTTQQH7KFA5CNFSM4I2YNZ6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECGJUEI#issuecomment-546085393>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABTGC2JPU76ZE3WG5UUKBYDQQH7KFANCNFSM4I2YNZ6A>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/794#issuecomment-546316470
https://github.com/su2code/SU2/issues/794#issuecomment-546316470:1091,Modifiability,variab,variable,1091,"Hi Daniel,. You can find the implementation of variable properties with cubic EoS in the master/develop version. If you need to compute the properties with more accurate thermo-physical models, e.g. multi-parameter, there are 2 main ways:. * By using the external library FluidProp (feature_fluidprop_final, yet outdated); * By means of look-up tables (feature_adjoint_lut). We are about to improve the look-up table method and will work on having this feature in the develop soon. Just let me know if you are interested and I will give you more details. Best,. Matteo. ——————————————————; Dr. ir. Matteo Pini, PhD; Assistant Professor; Propulsion & Power<http://www.pp.lr.tudelft.nl/>; Aerospace Engineering Faculty; Delft University of Technology. Kluyverweg 1; 2629 HS Delft; The Netherlands. Phone : +31 15 27 84794; Skype : matteo_pini1. From: banuti <notifications@github.com>; Reply-To: su2code/SU2 <reply@reply.github.com>; Date: Thursday, 24 October 2019 at 22:18; To: su2code/SU2 <SU2@noreply.github.com>; Cc: Subscribed <subscribed@noreply.github.com>; Subject: Re: [su2code/SU2] variable properties (transport and thermodynamic) for compressible flows with any eos (#794). Hi,. is that branch still active? It seems the last commit was more than two years ago. Best,; Daniel. —; You are receiving this because you are subscribed to this thread.; Reply to this email directly, view it on GitHub<https://github.com/su2code/SU2/issues/794?email_source=notifications&email_token=ABTGC2MB627S4SOHCTMGOTTQQH7KFA5CNFSM4I2YNZ6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECGJUEI#issuecomment-546085393>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/ABTGC2JPU76ZE3WG5UUKBYDQQH7KFANCNFSM4I2YNZ6A>.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/794#issuecomment-546316470
https://github.com/su2code/SU2/issues/796#issuecomment-537097526:27,Modifiability,enhance,enhancements,27,"As much as bug reports and enhancements are also appreciated, we are not following the strict *see something, say something* policy :) we need more application of the *see something, do something* policy :D",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/796#issuecomment-537097526
https://github.com/su2code/SU2/issues/796#issuecomment-569149919:19,Availability,error,error,19,"Addressed in #824, error message thrown (it is not easy to implement a good default due to shared code with other CONV_NUM_METHOD_??? options).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/796#issuecomment-569149919
https://github.com/su2code/SU2/issues/796#issuecomment-569149919:25,Integrability,message,message,25,"Addressed in #824, error message thrown (it is not easy to implement a good default due to shared code with other CONV_NUM_METHOD_??? options).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/796#issuecomment-569149919
https://github.com/su2code/SU2/issues/797#issuecomment-539577259:204,Energy Efficiency,energy,energy,204,"Thanks for reporting this, @emoralest6. My first suggestion is that we go through the mean flow solver and double-check our inclusion of the -2/3*rho*k term from the stress tensor (and TKE correction for energy) to make sure we do not have a bug there (see https://turbmodels.larc.nasa.gov/sst.html). This is one of the primary differences between the SA and SST implementations and would affect pressure. Could be a good place to start.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-539577259
https://github.com/su2code/SU2/issues/797#issuecomment-539882974:63,Deployability,update,updates,63,"Thanks for the quick answer @economon. I will wait for further updates. In the meanwhile, can you tell me which are the files in the source code where the SST and the mean flow are implemented in order to start looking at it?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-539882974
https://github.com/su2code/SU2/issues/797#issuecomment-540063840:351,Energy Efficiency,green,green,351,"Hello,. I ran an incompressible case with NACA 0012 (AoA=0, TMR case) and I see a similar difference between SA and SST on the grid level 3 (https://turbmodels.larc.nasa.gov/naca0012_grids.html, 257 points on the airfoil surface). I also tried the SST_SUST model and have attached the plots for mid section and wake here (white lines - SA, red - SST, green - SST_SUST). The SUST model gives the same difference at mid chord and LE but not in the wake. The SST_SUST under predicts the drag value though (also I had some convergence issues with SUST).; ![pressure_line_cmp_mid](https://user-images.githubusercontent.com/28007882/66496216-dd5a2580-eaba-11e9-869e-097cce8e52b4.png); ![pressure_line_cmp_wake](https://user-images.githubusercontent.com/28007882/66496217-dd5a2580-eaba-11e9-9c72-1980625dd550.png). @economon , the SetStressTensor routine includes the -2/3 * rho * TKE term, so I suppose the TKE is accounted for in the viscous residual of the mean flow equations. . @emoralest6 if you wanted to check the source code, the mean flow solver is in SU2_CFD/src/solver_direct_mean.cpp and the corresponding numerics in the SU2_CFD/src/numerics_direct_mean.cpp file. Cheers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-540063840
https://github.com/su2code/SU2/issues/797#issuecomment-540063840:840,Integrability,rout,routine,840,"Hello,. I ran an incompressible case with NACA 0012 (AoA=0, TMR case) and I see a similar difference between SA and SST on the grid level 3 (https://turbmodels.larc.nasa.gov/naca0012_grids.html, 257 points on the airfoil surface). I also tried the SST_SUST model and have attached the plots for mid section and wake here (white lines - SA, red - SST, green - SST_SUST). The SUST model gives the same difference at mid chord and LE but not in the wake. The SST_SUST under predicts the drag value though (also I had some convergence issues with SUST).; ![pressure_line_cmp_mid](https://user-images.githubusercontent.com/28007882/66496216-dd5a2580-eaba-11e9-869e-097cce8e52b4.png); ![pressure_line_cmp_wake](https://user-images.githubusercontent.com/28007882/66496217-dd5a2580-eaba-11e9-9c72-1980625dd550.png). @economon , the SetStressTensor routine includes the -2/3 * rho * TKE term, so I suppose the TKE is accounted for in the viscous residual of the mean flow equations. . @emoralest6 if you wanted to check the source code, the mean flow solver is in SU2_CFD/src/solver_direct_mean.cpp and the corresponding numerics in the SU2_CFD/src/numerics_direct_mean.cpp file. Cheers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-540063840
https://github.com/su2code/SU2/issues/797#issuecomment-540063840:471,Safety,predict,predicts,471,"Hello,. I ran an incompressible case with NACA 0012 (AoA=0, TMR case) and I see a similar difference between SA and SST on the grid level 3 (https://turbmodels.larc.nasa.gov/naca0012_grids.html, 257 points on the airfoil surface). I also tried the SST_SUST model and have attached the plots for mid section and wake here (white lines - SA, red - SST, green - SST_SUST). The SUST model gives the same difference at mid chord and LE but not in the wake. The SST_SUST under predicts the drag value though (also I had some convergence issues with SUST).; ![pressure_line_cmp_mid](https://user-images.githubusercontent.com/28007882/66496216-dd5a2580-eaba-11e9-869e-097cce8e52b4.png); ![pressure_line_cmp_wake](https://user-images.githubusercontent.com/28007882/66496217-dd5a2580-eaba-11e9-9c72-1980625dd550.png). @economon , the SetStressTensor routine includes the -2/3 * rho * TKE term, so I suppose the TKE is accounted for in the viscous residual of the mean flow equations. . @emoralest6 if you wanted to check the source code, the mean flow solver is in SU2_CFD/src/solver_direct_mean.cpp and the corresponding numerics in the SU2_CFD/src/numerics_direct_mean.cpp file. Cheers.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-540063840
https://github.com/su2code/SU2/issues/797#issuecomment-540140961:189,Modifiability,variab,variables,189,"Akshay, regarding the convergence problems with SST_SUST, what free-stream values did you use? This model is more sensitive to free-stream values than SST, because for latter the turbulent variables dissipate. For SST_SUST I typically use. % Ratio of the turbulent and laminar viscosity in the free-stream (10.0); FREESTREAM_TURB2LAMVISCRATIO= 0.882; %; % Free stream turbulence intensitity, sqrt(2 k_inf/3)/U_inf (0.0005); FREESTREAM_TURBULENCEINTENSITY= 0.0007. Especially FREESTREAM_TURB2LAMVISCRATIO is much lower than the default version.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-540140961
https://github.com/su2code/SU2/issues/797#issuecomment-546389216:44,Testability,test,test,44,"The verification you show is for a low-Mach test case. The omitted term in the stress tensor (the isotropic contribution from the turbulent stress) is mostly applicable for flows with strong velocity dilatation. Have you tried the new SST model for a flow with a shock wave? For example, how do the results change for the RAE2822 case?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-546389216
https://github.com/su2code/SU2/issues/797#issuecomment-546529544:416,Deployability,integrat,integrated,416,"Attaching some results for the RAE2822 of the pressure field zoomed in right near the shock on the upper surface. The results do change (lift and drag by a couple percent) mostly due to a change in shock position it seems. The pressure field also shows the same behavior referenced above when the term is included. Unfortunately, we do not have much data to compare with here, since this case is not on the TMR. The integrated quantities above for the bump problem do not appear to be too sensitive to it either way, but the pressure field does indeed show the same discrepancies. In general, I have not been able to find any strong arguments for or against including the term in literature/codes. Although it is prescribed by the theory, some folks mention it is sometimes dropped (TMR also says it is sometimes ignored unless supersonic), or it gets dropped without mention at all. It is certainly affecting the pressure distribution, so we should take that into consideration. It is possible that there is some other bug that gets exposed by its inclusion, but I did not come across anything yet. As we know the SA model does not exhibit this behavior, I lean toward removing it. I'm all ears if you have any other insight. <img width=""1313"" alt=""Screen Shot 2019-10-25 at 2 47 16 PM"" src=""https://user-images.githubusercontent.com/4896083/67607461-615a1180-f739-11e9-9d68-9c5d15fb0acc.png"">; <img width=""1312"" alt=""Screen Shot 2019-10-25 at 2 47 06 PM"" src=""https://user-images.githubusercontent.com/4896083/67607471-68811f80-f739-11e9-82bd-ac1c23b4caad.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-546529544
https://github.com/su2code/SU2/issues/797#issuecomment-546529544:416,Integrability,integrat,integrated,416,"Attaching some results for the RAE2822 of the pressure field zoomed in right near the shock on the upper surface. The results do change (lift and drag by a couple percent) mostly due to a change in shock position it seems. The pressure field also shows the same behavior referenced above when the term is included. Unfortunately, we do not have much data to compare with here, since this case is not on the TMR. The integrated quantities above for the bump problem do not appear to be too sensitive to it either way, but the pressure field does indeed show the same discrepancies. In general, I have not been able to find any strong arguments for or against including the term in literature/codes. Although it is prescribed by the theory, some folks mention it is sometimes dropped (TMR also says it is sometimes ignored unless supersonic), or it gets dropped without mention at all. It is certainly affecting the pressure distribution, so we should take that into consideration. It is possible that there is some other bug that gets exposed by its inclusion, but I did not come across anything yet. As we know the SA model does not exhibit this behavior, I lean toward removing it. I'm all ears if you have any other insight. <img width=""1313"" alt=""Screen Shot 2019-10-25 at 2 47 16 PM"" src=""https://user-images.githubusercontent.com/4896083/67607461-615a1180-f739-11e9-9d68-9c5d15fb0acc.png"">; <img width=""1312"" alt=""Screen Shot 2019-10-25 at 2 47 06 PM"" src=""https://user-images.githubusercontent.com/4896083/67607471-68811f80-f739-11e9-82bd-ac1c23b4caad.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-546529544
https://github.com/su2code/SU2/issues/797#issuecomment-546529544:1034,Security,expose,exposed,1034,"Attaching some results for the RAE2822 of the pressure field zoomed in right near the shock on the upper surface. The results do change (lift and drag by a couple percent) mostly due to a change in shock position it seems. The pressure field also shows the same behavior referenced above when the term is included. Unfortunately, we do not have much data to compare with here, since this case is not on the TMR. The integrated quantities above for the bump problem do not appear to be too sensitive to it either way, but the pressure field does indeed show the same discrepancies. In general, I have not been able to find any strong arguments for or against including the term in literature/codes. Although it is prescribed by the theory, some folks mention it is sometimes dropped (TMR also says it is sometimes ignored unless supersonic), or it gets dropped without mention at all. It is certainly affecting the pressure distribution, so we should take that into consideration. It is possible that there is some other bug that gets exposed by its inclusion, but I did not come across anything yet. As we know the SA model does not exhibit this behavior, I lean toward removing it. I'm all ears if you have any other insight. <img width=""1313"" alt=""Screen Shot 2019-10-25 at 2 47 16 PM"" src=""https://user-images.githubusercontent.com/4896083/67607461-615a1180-f739-11e9-9d68-9c5d15fb0acc.png"">; <img width=""1312"" alt=""Screen Shot 2019-10-25 at 2 47 06 PM"" src=""https://user-images.githubusercontent.com/4896083/67607471-68811f80-f739-11e9-82bd-ac1c23b4caad.png"">",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-546529544
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:123,Energy Efficiency,energy,energy,123,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:159,Energy Efficiency,energy,energy,159,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:641,Energy Efficiency,energy,energy,641,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:938,Energy Efficiency,energy,energy,938,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1019,Energy Efficiency,energy,energy,1019,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1347,Energy Efficiency,energy,energy,1347,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1411,Energy Efficiency,energy,energy,1411,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1713,Energy Efficiency,energy,energy,1713,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1780,Energy Efficiency,energy,energy,1780,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1833,Energy Efficiency,energy,energy,1833,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1970,Energy Efficiency,energy,energy,1970,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1990,Energy Efficiency,energy,energy,1990,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:955,Modifiability,config,configured,955,"This may be relevant, and it may not be. Is there a reason that the molecular and turbulent diffusion of turbulent kinetic energy is not included in the total energy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy cons",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:1442,Testability,test,tested,1442,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548886007:2122,Usability,simpl,simply,2122,"gy terms? I'm talking about terms like:. ![molecular and turbulent diffusion of tke](https://latex.codecogs.com/gif.latex?\left(&space;\mu&space;&plus;&space;\frac{\mu_t}{\sigma_k}\right)\frac{\partial&space;k}{\partial&space;x_j}). This term is listed both in Wilcox's ""Turbulence Modeling for CFD"" book and the [NASA TMR website](https://turbmodels.larc.nasa.gov/implementrans.html). NASA's page basically just copies what Wilcox states, and then says ""This expression in the energy equation is also sometimes neglected."". Rumsey clarified his position in a [2009 report](https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/20090015399.pdf), saying that ""when considering high Mach number compressible boundary layer flows using k-omega models, the conservation of total energy should be configured to include the contribution of the turbulent kinetic energy k... It is sometimes common practice to ignore these effects, which is certainly justified when k is signficantly smaller than the square of the mean velocity."" . But he also states: ""Note that in CFL3D, the turbulence models are decoupled from the mean flow equations, k is *not* included in the definition of the total energy, and the diffusion of k does not appear in the mean flow energy equation for its models tested here."" He also omitted the 2/3 \rho k term in both the production and the turbulent stress tensor, and found that it made little difference even for M=10 wall-bounded flows. SU2's version of SST is in a weird spot right now, where it's using the turbulent kinetic energy in some places but not others. It's using it here:. + Total energy definition; + Production of turbulent kinetic energy; + RANS evolution equations; + Eddy viscosity definition. But not here:. + Molecular and turbulent diffusion of turbulent kinetic energy in the total energy conservation equation; + Isotropic part of the turbulent stress tensor. Is there any rationale behind this split, aside from simply stating that ""this seems to work?""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548886007
https://github.com/su2code/SU2/issues/797#issuecomment-548890892:233,Energy Efficiency,energy,energy,233,"Thanks for digging around on this @clarkpede. I don't expect the original author will be able to chime in, but I would say we can investigate the differences w.r.t. how the tke is included. . I have tested removing it from the total energy definition for some low speed cases while I was debugging, and it had almost no impact. As stated above, we know that including in the mean flow stress tensor does noticeably impact the solution. I have not tried including it in the energy equation. I will reopen this issue, and we can continue the discussion here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548890892
https://github.com/su2code/SU2/issues/797#issuecomment-548890892:473,Energy Efficiency,energy,energy,473,"Thanks for digging around on this @clarkpede. I don't expect the original author will be able to chime in, but I would say we can investigate the differences w.r.t. how the tke is included. . I have tested removing it from the total energy definition for some low speed cases while I was debugging, and it had almost no impact. As stated above, we know that including in the mean flow stress tensor does noticeably impact the solution. I have not tried including it in the energy equation. I will reopen this issue, and we can continue the discussion here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548890892
https://github.com/su2code/SU2/issues/797#issuecomment-548890892:199,Testability,test,tested,199,"Thanks for digging around on this @clarkpede. I don't expect the original author will be able to chime in, but I would say we can investigate the differences w.r.t. how the tke is included. . I have tested removing it from the total energy definition for some low speed cases while I was debugging, and it had almost no impact. As stated above, we know that including in the mean flow stress tensor does noticeably impact the solution. I have not tried including it in the energy equation. I will reopen this issue, and we can continue the discussion here.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548890892
https://github.com/su2code/SU2/issues/797#issuecomment-548893764:6,Testability,test,test,6,"I can test out some aspects as well. This directly impacts my research, so it's a medium-level priority for me.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-548893764
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:77,Energy Efficiency,energy,energy,77,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:97,Energy Efficiency,energy,energy,97,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:273,Energy Efficiency,energy,energy,273,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:290,Energy Efficiency,energy,energy,290,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:512,Energy Efficiency,energy,energy,512,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:537,Energy Efficiency,energy,energy,537,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:563,Energy Efficiency,energy,energy,563,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:852,Energy Efficiency,energy,energy,852,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:881,Energy Efficiency,energy,energy,881,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-571730661:334,Testability,test,test,334,"So I tried adding the molecular and turbulent diffusion of turbulent kinetic energy in the total energy equation. It did not appear to fix this issue. At this point though, it's unclear exactly what the problem really is. I don't have ""correct"" pressure, turbulent kinetic energy, or total energy fields for the NACA 0012 or RAE 2822 test cases. By ""correct,"" I mean DNS or experimental data. The lack of ""correct"" data makes it hard to tell where the problems may actually be occurring. Is it coming from total energy? Resolved kinetic energy? Turbulent kinetic energy? All we're doing right now is comparing SST to SA, and one code's SST to another code's SST. That makes it hard to figure out what the correct answer really should be. Unless we have a problem that both 1) exhibits this problem, and 2) has high-quality pressure, temperature, total energy, or turbulent kinetic energy fields, then I agree that manufactured solutions is might be the best way to check ""correctness.""",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-571730661
https://github.com/su2code/SU2/issues/797#issuecomment-649816660:237,Availability,reliab,reliable,237,"Just an update: There is now WRLES data for the axisymmetric transonic bump case on the NASA Turbulence Modeling Resource. The data includes pressure, turbulent kinetic energy, and density. While the WRLES is not ""ground truth,"" it is a reliable data source for comparison. Sometime over the next few weeks, I'll compare the WRLES data with the SU2 results, including some of the possible changes. This will give us a better idea of how these model changes impact the predictive accuracy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-649816660
https://github.com/su2code/SU2/issues/797#issuecomment-649816660:8,Deployability,update,update,8,"Just an update: There is now WRLES data for the axisymmetric transonic bump case on the NASA Turbulence Modeling Resource. The data includes pressure, turbulent kinetic energy, and density. While the WRLES is not ""ground truth,"" it is a reliable data source for comparison. Sometime over the next few weeks, I'll compare the WRLES data with the SU2 results, including some of the possible changes. This will give us a better idea of how these model changes impact the predictive accuracy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-649816660
https://github.com/su2code/SU2/issues/797#issuecomment-649816660:169,Energy Efficiency,energy,energy,169,"Just an update: There is now WRLES data for the axisymmetric transonic bump case on the NASA Turbulence Modeling Resource. The data includes pressure, turbulent kinetic energy, and density. While the WRLES is not ""ground truth,"" it is a reliable data source for comparison. Sometime over the next few weeks, I'll compare the WRLES data with the SU2 results, including some of the possible changes. This will give us a better idea of how these model changes impact the predictive accuracy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-649816660
https://github.com/su2code/SU2/issues/797#issuecomment-649816660:468,Safety,predict,predictive,468,"Just an update: There is now WRLES data for the axisymmetric transonic bump case on the NASA Turbulence Modeling Resource. The data includes pressure, turbulent kinetic energy, and density. While the WRLES is not ""ground truth,"" it is a reliable data source for comparison. Sometime over the next few weeks, I'll compare the WRLES data with the SU2 results, including some of the possible changes. This will give us a better idea of how these model changes impact the predictive accuracy.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/797#issuecomment-649816660
https://github.com/su2code/SU2/pull/798#issuecomment-541239861:163,Availability,error,error-message,163,"@oleburghardt @talbring This PR fixes the multicore heat-flux-sensitivitiy issues. Tested with the tutorial made by ole. Good job. I added a commit that fixes the error-message if you want to have tecplot-binary output but compiled using the --disable-tecio flag. It caused a compile time error ... it is behind a preprocessor statement #ifndef HAVE_TECIO, so this thing is only seen when using the --disable-tecio flag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-541239861
https://github.com/su2code/SU2/pull/798#issuecomment-541239861:289,Availability,error,error,289,"@oleburghardt @talbring This PR fixes the multicore heat-flux-sensitivitiy issues. Tested with the tutorial made by ole. Good job. I added a commit that fixes the error-message if you want to have tecplot-binary output but compiled using the --disable-tecio flag. It caused a compile time error ... it is behind a preprocessor statement #ifndef HAVE_TECIO, so this thing is only seen when using the --disable-tecio flag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-541239861
https://github.com/su2code/SU2/pull/798#issuecomment-541239861:169,Integrability,message,message,169,"@oleburghardt @talbring This PR fixes the multicore heat-flux-sensitivitiy issues. Tested with the tutorial made by ole. Good job. I added a commit that fixes the error-message if you want to have tecplot-binary output but compiled using the --disable-tecio flag. It caused a compile time error ... it is behind a preprocessor statement #ifndef HAVE_TECIO, so this thing is only seen when using the --disable-tecio flag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-541239861
https://github.com/su2code/SU2/pull/798#issuecomment-541239861:83,Testability,Test,Tested,83,"@oleburghardt @talbring This PR fixes the multicore heat-flux-sensitivitiy issues. Tested with the tutorial made by ole. Good job. I added a commit that fixes the error-message if you want to have tecplot-binary output but compiled using the --disable-tecio flag. It caused a compile time error ... it is behind a preprocessor statement #ifndef HAVE_TECIO, so this thing is only seen when using the --disable-tecio flag.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-541239861
https://github.com/su2code/SU2/pull/798#issuecomment-543913612:402,Performance,perform,performance,402,"I noticed that the output phase values for WRT_PERFORMANCE= YES are currently off due to the number of output phases not being correctly tracked (we call the SetResultsFiles in the Iteration class most of the time, and the one in the driver with the timing only at the end of the run). @talbring, did you already have something in mind for this? Otherwise, I can think of a cleaner way to handle those performance benchmarks. I think it would be good to start printing that information by default too potentially. A good place might be within the MPI structure, since it is accessible everywhere and we can also hide the timer ifdefs for MPI.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-543913612
https://github.com/su2code/SU2/pull/798#issuecomment-543913612:574,Security,access,accessible,574,"I noticed that the output phase values for WRT_PERFORMANCE= YES are currently off due to the number of output phases not being correctly tracked (we call the SetResultsFiles in the Iteration class most of the time, and the one in the driver with the timing only at the end of the run). @talbring, did you already have something in mind for this? Otherwise, I can think of a cleaner way to handle those performance benchmarks. I think it would be good to start printing that information by default too potentially. A good place might be within the MPI structure, since it is accessible everywhere and we can also hide the timer ifdefs for MPI.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-543913612
https://github.com/su2code/SU2/pull/798#issuecomment-543913612:414,Testability,benchmark,benchmarks,414,"I noticed that the output phase values for WRT_PERFORMANCE= YES are currently off due to the number of output phases not being correctly tracked (we call the SetResultsFiles in the Iteration class most of the time, and the one in the driver with the timing only at the end of the run). @talbring, did you already have something in mind for this? Otherwise, I can think of a cleaner way to handle those performance benchmarks. I think it would be good to start printing that information by default too potentially. A good place might be within the MPI structure, since it is accessible everywhere and we can also hide the timer ifdefs for MPI.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-543913612
https://github.com/su2code/SU2/pull/798#issuecomment-544877793:60,Testability,test,tests,60,"I tried to solve the problem where sometimes the regression tests stall ... it seems to be a problem of openmpi. Changed it to mpich, but then mpi4py has problems. I reverted it for now. We have to live with that problem for a while unfortunately.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-544877793
https://github.com/su2code/SU2/pull/798#issuecomment-546376383:71,Integrability,rout,routines,71,"@pcarruscag ; I added a commit that improves the bad names for the new routines that we discussed #803. They should be more instructional now.; Moreover, at some places (default) function arguments are used instead of different functions, which hides the changes a bit and makes it more elegant.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/798#issuecomment-546376383
https://github.com/su2code/SU2/pull/799#issuecomment-541651742:383,Availability,redundant,redundant,383,"Hi @WallyMaier, good thought that you'd like the developers to not lose sight of proper documentation, especially for all the new stuff.; Though _appropriate_ can be very subjective and seems too vague to me. It could be code comments, a tutorial, contributions to the Docs page, a scientific article, ...; So in the end it might be too easy ticking this box... (making it an almost redundant addition in the worst case). Can we think of a more specific formulation?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541651742
https://github.com/su2code/SU2/pull/799#issuecomment-541651742:383,Safety,redund,redundant,383,"Hi @WallyMaier, good thought that you'd like the developers to not lose sight of proper documentation, especially for all the new stuff.; Though _appropriate_ can be very subjective and seems too vague to me. It could be code comments, a tutorial, contributions to the Docs page, a scientific article, ...; So in the end it might be too easy ticking this box... (making it an almost redundant addition in the worst case). Can we think of a more specific formulation?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541651742
https://github.com/su2code/SU2/pull/799#issuecomment-541779799:60,Deployability,update,update,60,"@oleburghardt, Absolutely. Originally, I had thought to say update Docs page/Tutorial/Config_template"". In my opinion, those things aren't covered with the current format. However, I am open to ideas!",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541779799
https://github.com/su2code/SU2/pull/799#issuecomment-541829846:110,Availability,error,errors,110,"As far as documenting the code itself, you could add the requirement that Doxygen generate no new warnings or errors.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541829846
https://github.com/su2code/SU2/pull/799#issuecomment-541832531:245,Security,access,accessible,245,"True. I was thinking more from the user point-of-view, to be sure people little little experience can use SU2 easier. Similar to something Tim has already started in the Docs page. The idea here is just to be sure new features are easily usable/accessible for people unfamiliar.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541832531
https://github.com/su2code/SU2/pull/799#issuecomment-541832531:238,Usability,usab,usable,238,"True. I was thinking more from the user point-of-view, to be sure people little little experience can use SU2 easier. Similar to something Tim has already started in the Docs page. The idea here is just to be sure new features are easily usable/accessible for people unfamiliar.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/799#issuecomment-541832531
https://github.com/su2code/SU2/issues/800#issuecomment-542657940:509,Availability,reliab,reliable,509,"Hi @chiefenne Thanks for bringing it up. I think it could additionally serve as a _quality measure_ for the solvers. ; (For instance, one concern sometimes was - don't know whether it still is - mass conservation in the incompressible solver. That would also be reflected in an energy balance if there really was a problem, or one could check in a very easy way if all boundaries that act as a heat sink/source do what they should. Altogether, one would have some global numbers to confirm that the result is reliable..); I think @economon could also be interested in such a feature. I'll have to do some maintenance for heat-related stuff soon, especially to push some fixes for instationary computations. I can then at least check how such a feature could be set up.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/800#issuecomment-542657940
https://github.com/su2code/SU2/issues/800#issuecomment-542657940:605,Availability,mainten,maintenance,605,"Hi @chiefenne Thanks for bringing it up. I think it could additionally serve as a _quality measure_ for the solvers. ; (For instance, one concern sometimes was - don't know whether it still is - mass conservation in the incompressible solver. That would also be reflected in an energy balance if there really was a problem, or one could check in a very easy way if all boundaries that act as a heat sink/source do what they should. Altogether, one would have some global numbers to confirm that the result is reliable..); I think @economon could also be interested in such a feature. I'll have to do some maintenance for heat-related stuff soon, especially to push some fixes for instationary computations. I can then at least check how such a feature could be set up.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/800#issuecomment-542657940
https://github.com/su2code/SU2/issues/800#issuecomment-542657940:278,Energy Efficiency,energy,energy,278,"Hi @chiefenne Thanks for bringing it up. I think it could additionally serve as a _quality measure_ for the solvers. ; (For instance, one concern sometimes was - don't know whether it still is - mass conservation in the incompressible solver. That would also be reflected in an energy balance if there really was a problem, or one could check in a very easy way if all boundaries that act as a heat sink/source do what they should. Altogether, one would have some global numbers to confirm that the result is reliable..); I think @economon could also be interested in such a feature. I'll have to do some maintenance for heat-related stuff soon, especially to push some fixes for instationary computations. I can then at least check how such a feature could be set up.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/800#issuecomment-542657940
https://github.com/su2code/SU2/issues/800#issuecomment-543819420:359,Energy Efficiency,energy,energy,359,"@chiefenne @oleburghardt : I like this idea a lot. This type of reporting is tremendously useful for assessing a simulation. You might want to take a look at the MARKER_ANALYZE capability, which will at least give you basic quantities averaged at any markers you specify (area- or mass-averaged). It likely needs some extension to better handle heat transfer/energy. However, it may be a good place to start when thinking about a more general framework.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/800#issuecomment-543819420
https://github.com/su2code/SU2/issues/801#issuecomment-541311289:11,Availability,fault,fault,11,"That is my fault.; The case was broken, I fixed it in #753 and updated the testcase repo thinking #753 would be merged shortly but merging with #774 is proving more difficult than I thought... If I can't find a solution soon I'll fix it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/801#issuecomment-541311289
https://github.com/su2code/SU2/issues/801#issuecomment-541311289:63,Deployability,update,updated,63,"That is my fault.; The case was broken, I fixed it in #753 and updated the testcase repo thinking #753 would be merged shortly but merging with #774 is proving more difficult than I thought... If I can't find a solution soon I'll fix it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/801#issuecomment-541311289
https://github.com/su2code/SU2/issues/801#issuecomment-541311289:75,Testability,test,testcase,75,"That is my fault.; The case was broken, I fixed it in #753 and updated the testcase repo thinking #753 would be merged shortly but merging with #774 is proving more difficult than I thought... If I can't find a solution soon I'll fix it.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/801#issuecomment-541311289
https://github.com/su2code/SU2/pull/803#issuecomment-542148416:38,Testability,test,testcase,38,"Thank you for bringing this back. The testcase was passing on #753 alone, so that should not be the problem, I'll have a look.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542148416
https://github.com/su2code/SU2/pull/803#issuecomment-542170904:52,Integrability,rout,routines,52,"@rsanfer You shouldn't get in touch with the new AD routines at all unless you're using `CDiscAdjMultizoneDriver`.; So in case `direct_solver->GetNodes()->GetAdjointSolution_intIndexBased(iPoint,Solution)` gets executed, that likely means that the if-statement above, `config->GetMultizone_Problem()`, evaluates to true.; Some weeks ago I added another boolean (`CConfig::GetMultiphysicsDiscrete_Adjoint()`) but I was asked to revert that to the line above.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542170904
https://github.com/su2code/SU2/pull/803#issuecomment-542170904:269,Modifiability,config,config,269,"@rsanfer You shouldn't get in touch with the new AD routines at all unless you're using `CDiscAdjMultizoneDriver`.; So in case `direct_solver->GetNodes()->GetAdjointSolution_intIndexBased(iPoint,Solution)` gets executed, that likely means that the if-statement above, `config->GetMultizone_Problem()`, evaluates to true.; Some weeks ago I added another boolean (`CConfig::GetMultiphysicsDiscrete_Adjoint()`) but I was asked to revert that to the line above.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542170904
https://github.com/su2code/SU2/pull/803#issuecomment-542173510:297,Integrability,rout,routines,297,"I'm getting to the same conclusion, the easier step might be to set; Multizone_Problem to false during recording steps... Ole Burghardt <notifications@github.com> escreveu no dia terça, 15/10/2019; à(s) 12:42:. > @rsanfer <https://github.com/rsanfer> You shouldn't get in touch with the; > new AD routines at all unless you're using CDiscAdjMultizoneDriver.; > So in case; > direct_solver->GetNodes()->GetAdjointSolution_intIndexBased(iPoint,Solution);; > gets executed, that likely means that the if-statement above,; > config->GetMultizone_Problem(), evaluates to true.; > Some weeks ago I added another boolean (Get_MultiphysicsDiscreteAdjoint or; > similar) but I was asked to revert that to the line above.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/803?email_source=notifications&email_token=AJCOXNYKA2UDXBUN6DTFXVDQOWUBNA5CNFSM4JAY4HS2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBIN6GA#issuecomment-542170904>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AJCOXN2V3264434E3UH75ITQOWUBNANCNFSM4JAY4HSQ>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542173510
https://github.com/su2code/SU2/pull/803#issuecomment-542173510:521,Modifiability,config,config,521,"I'm getting to the same conclusion, the easier step might be to set; Multizone_Problem to false during recording steps... Ole Burghardt <notifications@github.com> escreveu no dia terça, 15/10/2019; à(s) 12:42:. > @rsanfer <https://github.com/rsanfer> You shouldn't get in touch with the; > new AD routines at all unless you're using CDiscAdjMultizoneDriver.; > So in case; > direct_solver->GetNodes()->GetAdjointSolution_intIndexBased(iPoint,Solution);; > gets executed, that likely means that the if-statement above,; > config->GetMultizone_Problem(), evaluates to true.; > Some weeks ago I added another boolean (Get_MultiphysicsDiscreteAdjoint or; > similar) but I was asked to revert that to the line above.; >; > —; > You are receiving this because you were mentioned.; > Reply to this email directly, view it on GitHub; > <https://github.com/su2code/SU2/pull/803?email_source=notifications&email_token=AJCOXNYKA2UDXBUN6DTFXVDQOWUBNA5CNFSM4JAY4HS2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEBIN6GA#issuecomment-542170904>,; > or unsubscribe; > <https://github.com/notifications/unsubscribe-auth/AJCOXN2V3264434E3UH75ITQOWUBNANCNFSM4JAY4HSQ>; > .; >",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542173510
https://github.com/su2code/SU2/pull/803#issuecomment-542191835:283,Deployability,UPDATE,UPDATE,283,"It does not break the multizone adjoint but it does not fix the problem. So now when we register the coordinates we do it index-based because the multizone_problem boolean is set.; What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. UPDATE: This solves the segfault issue, but the derivatives are probably wrong.; The residuals for the flow adjoint are not moving, @rsanfer any chance that this due to some output adaptation (I'm guessing not).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542191835
https://github.com/su2code/SU2/pull/803#issuecomment-542191835:464,Energy Efficiency,adapt,adaptation,464,"It does not break the multizone adjoint but it does not fix the problem. So now when we register the coordinates we do it index-based because the multizone_problem boolean is set.; What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. UPDATE: This solves the segfault issue, but the derivatives are probably wrong.; The residuals for the flow adjoint are not moving, @rsanfer any chance that this due to some output adaptation (I'm guessing not).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542191835
https://github.com/su2code/SU2/pull/803#issuecomment-542191835:464,Modifiability,adapt,adaptation,464,"It does not break the multizone adjoint but it does not fix the problem. So now when we register the coordinates we do it index-based because the multizone_problem boolean is set.; What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. UPDATE: This solves the segfault issue, but the derivatives are probably wrong.; The residuals for the flow adjoint are not moving, @rsanfer any chance that this due to some output adaptation (I'm guessing not).",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542191835
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:1096,Deployability,integrat,integrated,1096,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:151,Integrability,rout,routines,151,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:497,Integrability,rout,routines,497,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:658,Integrability,rout,routines,658,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:706,Integrability,depend,dependencies,706,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:1096,Integrability,integrat,integrated,1096,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:271,Modifiability,variab,variable,271,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:293,Modifiability,variab,variable,293,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542202636:577,Modifiability,variab,variables,577,"Sure we do (e.g. `CDiscAdjSolver::RegisterSolution` will behave incorrectly). So actually both ways are based on saving indices somewhere. However the routines that I added (with the `_intIndexBased` extension) do save them internally together with ""their"" corresponding variable (in the same variable class) which is important for the multizone stuff. > So now when we register the coordinates we do it index-based because the multizone_problem boolean is set. We don't want the `_intIndexBased` routines for the FSI cases. They work by re-recording new tapes for each set of variables (fluid solution/coordinates/displacement solution) with added specific routines within the solvers/iterators for cross dependencies (which goes along with saving indices externally, but in a preassigned order). > What are the implications for when we extract the adjoints? Do we need an index-based GetDerivative?. Yes there are counterparts in `RegisterSolution`, `SetAdjoint_Output` and `ExtractAdjoint_Solution`. But nothing more. We can go for the internal indices in `CVariable` exclusively once we have integrated the FSI capabilities to the multiphysics driver.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542202636
https://github.com/su2code/SU2/pull/803#issuecomment-542204060:194,Modifiability,config,config,194,"@oleburghardt I figured why `direct_solver->GetNodes()->GetAdjointSolution_intIndexBased(iPoint,Solution)` was being executed, but as the FSI problem is multi-zone adjoint, it is required that `config->GetMultizone_Problem() = true` even when we are not using the driver `CDiscAdjMultizoneDriver`. . There is, of course, the possibility to set a specific boolean for these test cases in particular, but I think that would over-complicate the code. Else, it should be possible to extend the index based to the rest of the features required (geometry and structural solvers), which would be my preferred option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542204060
https://github.com/su2code/SU2/pull/803#issuecomment-542204060:479,Modifiability,extend,extend,479,"@oleburghardt I figured why `direct_solver->GetNodes()->GetAdjointSolution_intIndexBased(iPoint,Solution)` was being executed, but as the FSI problem is multi-zone adjoint, it is required that `config->GetMultizone_Problem() = true` even when we are not using the driver `CDiscAdjMultizoneDriver`. . There is, of course, the possibility to set a specific boolean for these test cases in particular, but I think that would over-complicate the code. Else, it should be possible to extend the index based to the rest of the features required (geometry and structural solvers), which would be my preferred option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542204060
https://github.com/su2code/SU2/pull/803#issuecomment-542204060:373,Testability,test,test,373,"@oleburghardt I figured why `direct_solver->GetNodes()->GetAdjointSolution_intIndexBased(iPoint,Solution)` was being executed, but as the FSI problem is multi-zone adjoint, it is required that `config->GetMultizone_Problem() = true` even when we are not using the driver `CDiscAdjMultizoneDriver`. . There is, of course, the possibility to set a specific boolean for these test cases in particular, but I think that would over-complicate the code. Else, it should be possible to extend the index based to the rest of the features required (geometry and structural solvers), which would be my preferred option.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542204060
https://github.com/su2code/SU2/pull/803#issuecomment-542206395:262,Energy Efficiency,adapt,adapt,262,"Ok. I don't think [these](https://github.com/su2code/SU2/pull/774/commits/e632133eded5edab7ff04f0979334c25c0f44ff8) changes are over-complicated. But I'm fine with changing the index saving procedure everywhere. There'd be just some work to do (we would have to adapt everything for the FEA elasticity solvers and all the variables they need as well)... so it's also a question of time, testing and so on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542206395
https://github.com/su2code/SU2/pull/803#issuecomment-542206395:262,Modifiability,adapt,adapt,262,"Ok. I don't think [these](https://github.com/su2code/SU2/pull/774/commits/e632133eded5edab7ff04f0979334c25c0f44ff8) changes are over-complicated. But I'm fine with changing the index saving procedure everywhere. There'd be just some work to do (we would have to adapt everything for the FEA elasticity solvers and all the variables they need as well)... so it's also a question of time, testing and so on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542206395
https://github.com/su2code/SU2/pull/803#issuecomment-542206395:322,Modifiability,variab,variables,322,"Ok. I don't think [these](https://github.com/su2code/SU2/pull/774/commits/e632133eded5edab7ff04f0979334c25c0f44ff8) changes are over-complicated. But I'm fine with changing the index saving procedure everywhere. There'd be just some work to do (we would have to adapt everything for the FEA elasticity solvers and all the variables they need as well)... so it's also a question of time, testing and so on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542206395
https://github.com/su2code/SU2/pull/803#issuecomment-542206395:387,Testability,test,testing,387,"Ok. I don't think [these](https://github.com/su2code/SU2/pull/774/commits/e632133eded5edab7ff04f0979334c25c0f44ff8) changes are over-complicated. But I'm fine with changing the index saving procedure everywhere. There'd be just some work to do (we would have to adapt everything for the FEA elasticity solvers and all the variables they need as well)... so it's also a question of time, testing and so on.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542206395
https://github.com/su2code/SU2/pull/803#issuecomment-542210441:372,Integrability,depend,depends,372,"I think one option would add yet one more config option and make it more difficult for the user, and the other would be to extend new features to all existing capabilities of the code. The idea behind the single and multi-zone drivers was precisely generalization. In my opinion it would be a no brainer to go for the second, but I'll leave it up to the community, but it depends also a lot on what timing we are moving in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542210441
https://github.com/su2code/SU2/pull/803#issuecomment-542210441:42,Modifiability,config,config,42,"I think one option would add yet one more config option and make it more difficult for the user, and the other would be to extend new features to all existing capabilities of the code. The idea behind the single and multi-zone drivers was precisely generalization. In my opinion it would be a no brainer to go for the second, but I'll leave it up to the community, but it depends also a lot on what timing we are moving in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542210441
https://github.com/su2code/SU2/pull/803#issuecomment-542210441:123,Modifiability,extend,extend,123,"I think one option would add yet one more config option and make it more difficult for the user, and the other would be to extend new features to all existing capabilities of the code. The idea behind the single and multi-zone drivers was precisely generalization. In my opinion it would be a no brainer to go for the second, but I'll leave it up to the community, but it depends also a lot on what timing we are moving in.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542210441
https://github.com/su2code/SU2/pull/803#issuecomment-542224837:672,Integrability,depend,depends,672,"> Is it possible for the fluid side to work index-based and the structural side as before?; > We are combining the cross terms manually and re-recording each step anyway... (Please rather say internal-based, or variable-based - both approaches are index-based, they differ in the way they are stored :-)). In principle, yes. One can have both at the same time. I'd have to think about it, sounds a bit messy to me right now to get it all consistent. One could also change `GetMultizone_Problem()` to `GetMultizone_Problem() && !GetFSI_Problem()` or similar at those places. Anyway, we know the reason for this problem, so I'll leave it up to you which way we go. > but it depends also a lot on what timing we are moving in. Yes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542224837
https://github.com/su2code/SU2/pull/803#issuecomment-542224837:211,Modifiability,variab,variable-based,211,"> Is it possible for the fluid side to work index-based and the structural side as before?; > We are combining the cross terms manually and re-recording each step anyway... (Please rather say internal-based, or variable-based - both approaches are index-based, they differ in the way they are stored :-)). In principle, yes. One can have both at the same time. I'd have to think about it, sounds a bit messy to me right now to get it all consistent. One could also change `GetMultizone_Problem()` to `GetMultizone_Problem() && !GetFSI_Problem()` or similar at those places. Anyway, we know the reason for this problem, so I'll leave it up to you which way we go. > but it depends also a lot on what timing we are moving in. Yes.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542224837
https://github.com/su2code/SU2/pull/803#issuecomment-542234952:63,Security,validat,validation,63,"@rsanfer , @oleburghardt , I think I fixed it, I'll do further validation tomorrow, but the reference derivative is very close to the regression value. The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542234952
https://github.com/su2code/SU2/pull/803#issuecomment-542360883:153,Integrability,rout,routine,153,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883
https://github.com/su2code/SU2/pull/803#issuecomment-542360883:533,Security,validat,validation,533,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883
https://github.com/su2code/SU2/pull/803#issuecomment-542360883:342,Usability,simpl,simple,342,"> The ""int"" in ""intIndexBased"" is for internal then? Because its type is also int, easy mistake to make xD. Yes.. The name was the first one I gave that routine. It somehow made it through.. Now that I had to type it several times I'd love to have it changed. But anyway.. I'm a bit puzzled that it seems to be so easy but maybe it's just as simple as you said - new approach inside `CDiscAdjSolver` and old in `CDiscAdjFEASolver` (if I got that correctly?). That would come in handy for all further developments. Let's wait for the validation. I'll also do one with this branch for the CHT adjoints tomorrow, just to be sure.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-542360883
https://github.com/su2code/SU2/pull/803#issuecomment-543067888:210,Deployability,update,updates,210,"Thanks a lot for your support, @pcarruscag. . I run the other test cases this morning and I noticed there is a very small difference in the sensitivities around the 10th significant figure (in the order of the updates you made on the discrete adjoint airfoil case). Given that the order of magnitude of this difference remains consistent even when extending the simulation, I updated the test values. I leave here the [reference to the previous state](https://github.com/su2code/SU2/commit/654ba3dfc207e25c31da9c09860224ad4044a610) for our records. . If there are no comments against it in the next day or so, I will be merging in this PR next, as it just puts back some functionality that was removed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543067888
https://github.com/su2code/SU2/pull/803#issuecomment-543067888:376,Deployability,update,updated,376,"Thanks a lot for your support, @pcarruscag. . I run the other test cases this morning and I noticed there is a very small difference in the sensitivities around the 10th significant figure (in the order of the updates you made on the discrete adjoint airfoil case). Given that the order of magnitude of this difference remains consistent even when extending the simulation, I updated the test values. I leave here the [reference to the previous state](https://github.com/su2code/SU2/commit/654ba3dfc207e25c31da9c09860224ad4044a610) for our records. . If there are no comments against it in the next day or so, I will be merging in this PR next, as it just puts back some functionality that was removed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543067888
https://github.com/su2code/SU2/pull/803#issuecomment-543067888:348,Modifiability,extend,extending,348,"Thanks a lot for your support, @pcarruscag. . I run the other test cases this morning and I noticed there is a very small difference in the sensitivities around the 10th significant figure (in the order of the updates you made on the discrete adjoint airfoil case). Given that the order of magnitude of this difference remains consistent even when extending the simulation, I updated the test values. I leave here the [reference to the previous state](https://github.com/su2code/SU2/commit/654ba3dfc207e25c31da9c09860224ad4044a610) for our records. . If there are no comments against it in the next day or so, I will be merging in this PR next, as it just puts back some functionality that was removed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543067888
https://github.com/su2code/SU2/pull/803#issuecomment-543067888:62,Testability,test,test,62,"Thanks a lot for your support, @pcarruscag. . I run the other test cases this morning and I noticed there is a very small difference in the sensitivities around the 10th significant figure (in the order of the updates you made on the discrete adjoint airfoil case). Given that the order of magnitude of this difference remains consistent even when extending the simulation, I updated the test values. I leave here the [reference to the previous state](https://github.com/su2code/SU2/commit/654ba3dfc207e25c31da9c09860224ad4044a610) for our records. . If there are no comments against it in the next day or so, I will be merging in this PR next, as it just puts back some functionality that was removed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543067888
https://github.com/su2code/SU2/pull/803#issuecomment-543067888:388,Testability,test,test,388,"Thanks a lot for your support, @pcarruscag. . I run the other test cases this morning and I noticed there is a very small difference in the sensitivities around the 10th significant figure (in the order of the updates you made on the discrete adjoint airfoil case). Given that the order of magnitude of this difference remains consistent even when extending the simulation, I updated the test values. I leave here the [reference to the previous state](https://github.com/su2code/SU2/commit/654ba3dfc207e25c31da9c09860224ad4044a610) for our records. . If there are no comments against it in the next day or so, I will be merging in this PR next, as it just puts back some functionality that was removed.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543067888
https://github.com/su2code/SU2/pull/803#issuecomment-543128540:40,Availability,failure,failures,40,"Does anyone know why we get this random failures from travis?. > No output has been received in the last 20m0s, this potentially indicates a stalled build or something wrong with the build itself. It does not seem to be related with a particular test case...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543128540
https://github.com/su2code/SU2/pull/803#issuecomment-543128540:246,Testability,test,test,246,"Does anyone know why we get this random failures from travis?. > No output has been received in the last 20m0s, this potentially indicates a stalled build or something wrong with the build itself. It does not seem to be related with a particular test case...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543128540
https://github.com/su2code/SU2/pull/803#issuecomment-543570100:42,Availability,failure,failures,42,"> Does anyone know why we get this random failures from travis?; > ; > > No output has been received in the last 20m0s, this potentially indicates a stalled build or something wrong with the build itself.; > ; > It does not seem to be related with a particular test case... Unfortunately that happens a lot lately. Haven't figured out what the reason is. I assume its something with MPI on the virtual machines in Travis. Hard to debug though, I can test a different MPI version maybe...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543570100
https://github.com/su2code/SU2/pull/803#issuecomment-543570100:261,Testability,test,test,261,"> Does anyone know why we get this random failures from travis?; > ; > > No output has been received in the last 20m0s, this potentially indicates a stalled build or something wrong with the build itself.; > ; > It does not seem to be related with a particular test case... Unfortunately that happens a lot lately. Haven't figured out what the reason is. I assume its something with MPI on the virtual machines in Travis. Hard to debug though, I can test a different MPI version maybe...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543570100
https://github.com/su2code/SU2/pull/803#issuecomment-543570100:450,Testability,test,test,450,"> Does anyone know why we get this random failures from travis?; > ; > > No output has been received in the last 20m0s, this potentially indicates a stalled build or something wrong with the build itself.; > ; > It does not seem to be related with a particular test case... Unfortunately that happens a lot lately. Haven't figured out what the reason is. I assume its something with MPI on the virtual machines in Travis. Hard to debug though, I can test a different MPI version maybe...",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/pull/803#issuecomment-543570100
https://github.com/su2code/SU2/issues/805#issuecomment-545454125:183,Modifiability,config,config,183,"If you are referring to surface heat flux it is one of the default surface outputs.; Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; I replaced the relevant time domain options but commented out all the output options. On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already. If you have issues with heatflux output with the develop version / v7 we can re-open this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545454125
https://github.com/su2code/SU2/issues/805#issuecomment-545454125:359,Usability,Guid,Guide-to-,359,"If you are referring to surface heat flux it is one of the default surface outputs.; Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; I replaced the relevant time domain options but commented out all the output options. On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already. If you have issues with heatflux output with the develop version / v7 we can re-open this issue.",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545454125
https://github.com/su2code/SU2/issues/805#issuecomment-545541390:209,Usability,Guid,Guide-to-,209,> 如果您指的是表面热通量，则它是默认的表面输出之一。; > v6.2中可能存在一个错误，但是在当前的开发中它似乎可以正常工作，您可以尝试使用以下配置：[v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > v6.2之后更改了一些选项的名称，您可以在此处阅读：[https：// /su2code.github.io/docs/Guide-to-v7/](https://su2code.github.io/docs/Guide-to-v7/); > 我替换了相关的时域选项，但注释了所有输出选项。; > ; > 另一方面，我认为您应该修改设置，例如对于不稳定的模拟，您将时间步长设置为0。如果您有设置方面的问题，请访问用户论坛[https://www.cfd-online.com/Forums/su2/，](https://www.cfd-online.com/Forums/su2/)并在没有相关主题的情况下启动主题。; > ; > 如果开发版本/ v7的heatflux输出存在问题，我们可以重新打开此问题。. Thank you. It helps a lot.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545541390
https://github.com/su2code/SU2/issues/805#issuecomment-545541390:254,Usability,Guid,Guide-to-,254,> 如果您指的是表面热通量，则它是默认的表面输出之一。; > v6.2中可能存在一个错误，但是在当前的开发中它似乎可以正常工作，您可以尝试使用以下配置：[v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > v6.2之后更改了一些选项的名称，您可以在此处阅读：[https：// /su2code.github.io/docs/Guide-to-v7/](https://su2code.github.io/docs/Guide-to-v7/); > 我替换了相关的时域选项，但注释了所有输出选项。; > ; > 另一方面，我认为您应该修改设置，例如对于不稳定的模拟，您将时间步长设置为0。如果您有设置方面的问题，请访问用户论坛[https://www.cfd-online.com/Forums/su2/，](https://www.cfd-online.com/Forums/su2/)并在没有相关主题的情况下启动主题。; > ; > 如果开发版本/ v7的heatflux输出存在问题，我们可以重新打开此问题。. Thank you. It helps a lot.,MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545541390
https://github.com/su2code/SU2/issues/805#issuecomment-545908540:187,Modifiability,config,config,187,"> If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?. > If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545908540
https://github.com/su2code/SU2/issues/805#issuecomment-545908540:1091,Modifiability,config,config,1091,"> If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?. > If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545908540
https://github.com/su2code/SU2/issues/805#issuecomment-545908540:365,Usability,Guid,Guide-to-,365,"> If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?. > If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545908540
https://github.com/su2code/SU2/issues/805#issuecomment-545908540:1269,Usability,Guid,Guide-to-,1269,"> If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?. > If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I tried but heatflux equals to 0.000. What is wrong?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-545908540
https://github.com/su2code/SU2/issues/805#issuecomment-546264432:44,Modifiability,config,configure,44,> Please describe what you tried. With this configure file and the same files above.; [BB_ISOTHERMAL_8.03_183500_AUSMPLUSUP_0.05.zip](https://github.com/su2code/SU2/files/3771219/BB_ISOTHERMAL_8.03_183500_AUSMPLUSUP_0.05.zip),MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-546264432
https://github.com/su2code/SU2/issues/805#issuecomment-546276782:187,Modifiability,config,config,187,"> If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I wonder that if I use TIME_STEPPING without dual time, is timestep a must?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-546276782
https://github.com/su2code/SU2/issues/805#issuecomment-546276782:365,Usability,Guid,Guide-to-,365,"> If you are referring to surface heat flux it is one of the default surface outputs.; > Maybe there is a bug in v6.2 but in current develop it seems to work fine, you can try using this config: [v7.cfg.zip](https://github.com/su2code/SU2/files/3762621/v7.cfg.zip); > Some options changed name since v6.2, you can read about it here: https://su2code.github.io/docs/Guide-to-v7/; > I replaced the relevant time domain options but commented out all the output options.; > ; > On another note I think you should revise your settings, you had a time step of 0 on an unsteady simulation for example. If you have setup questions have a look at the user forum https://www.cfd-online.com/Forums/su2/ and start a topic if there is no related one already.; > ; > If you have issues with heatflux output with the develop version / v7 we can re-open this issue. I wonder that if I use TIME_STEPPING without dual time, is timestep a must?",MatchSource.ISSUE_COMMENT,su2code,SU2,v8.1.0,https://su2code.github.io,https://github.com/su2code/SU2/issues/805#issuecomment-546276782
